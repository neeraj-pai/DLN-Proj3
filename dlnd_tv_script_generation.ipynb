{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TV Script Generation\n",
    "In this project, you'll generate your own [Simpsons](https://en.wikipedia.org/wiki/The_Simpsons) TV scripts using RNNs.  You'll be using part of the [Simpsons dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data) of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at [Moe's Tavern](https://simpsonswiki.com/wiki/Moe's_Tavern).\n",
    "## Get the Data\n",
    "The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like \"Moe's Cavern\", \"Flaming Moe's\", \"Uncle Moe's Family Feed-Bag\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "\n",
    "data_dir = './data/simpsons/moes_tavern_lines.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Ignore notice, since we don't use it for analysing the data\n",
    "text = text[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "Play around with `view_sentence_range` to view different parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 11492\n",
      "Number of scenes: 262\n",
      "Average number of sentences in each scene: 15.251908396946565\n",
      "Number of lines: 4258\n",
      "Average number of words in each line: 11.50164396430249\n",
      "\n",
      "The sentences 0 to 10:\n",
      "\n",
      "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
      "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
      "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
      "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
      "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
      "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
      "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n",
      "Barney_Gumble: Yeah, you should only drink to enhance your social skills.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocessing Functions\n",
    "The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following tuple `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    combined_words = set(text)\n",
    "    vocab_to_int = {word: ii for ii, word in enumerate(combined_words, 1)}       \n",
    "    int_to_vocab = dict(enumerate(combined_words,1))    \n",
    "    # TODO: Implement Function\n",
    "    return(vocab_to_int, int_to_vocab)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word \"bye\" and \"bye!\".\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( . )\n",
    "- Comma ( , )\n",
    "- Quotation Mark ( \" )\n",
    "- Semicolon ( ; )\n",
    "- Exclamation mark ( ! )\n",
    "- Question mark ( ? )\n",
    "- Left Parentheses ( ( )\n",
    "- Right Parentheses ( ) )\n",
    "- Dash ( -- )\n",
    "- Return ( \\n )\n",
    "\n",
    "This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    punc_dict = {'.': '||Period||', ',': '||Comma||', '\"': '||Quotation_Mark||',\\\n",
    "                 ';': '||SemiColon||', '!': '||Exclamation_Mark||', '?': '||Question_Mark||',\\\n",
    "                 '(': '||Left_Parenthesis||', ')': '||Right_Parenthesis||', '--': '||Dash||',\\\n",
    "                 '\\n': '||Return||'}\n",
    "    return punc_dict\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the data and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the Neural Network\n",
    "You'll build the components necessary to build a RNN by implementing the following functions below:\n",
    "- get_inputs\n",
    "- get_init_cell\n",
    "- get_embed\n",
    "- build_rnn\n",
    "- build_nn\n",
    "- get_batches\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neeraj_User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:14: UserWarning: No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "Implement the `get_inputs()` function to create TF Placeholders for the Neural Network.  It should create the following placeholders:\n",
    "- Input text placeholder named \"input\" using the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) `name` parameter.\n",
    "- Targets placeholder\n",
    "- Learning Rate placeholder\n",
    "\n",
    "Return the placeholders in the following the tuple `(Input, Targets, LearingRate)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    return inputs, targets, learning_rate\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_inputs(get_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN Cell and Initialize\n",
    "Stack one or more [`BasicLSTMCells`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) in a [`MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell).\n",
    "- The Rnn size should be set using `rnn_size`\n",
    "- Initalize Cell State using the MultiRNNCell's [`zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state) function\n",
    "    - Apply the name \"initial_state\" to the initial state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the cell and initial state in the following tuple `(Cell, InitialState)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "lstm_layers = 100\n",
    "def get_init_cell(batch_size, rnn_size):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function    \n",
    "    # Your basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    Cell = tf.contrib.rnn.MultiRNNCell([lstm] * lstm_layers)\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    InitialState = Cell.zero_state(batch_size, tf.float32)\n",
    "    InitialState = tf.identity(InitialState, name='initial_state')\n",
    "    \n",
    "    return Cell, InitialState\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_init_cell(get_init_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Embedding\n",
    "Apply embedding to `input_data` using TensorFlow.  Return the embedded sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    return embed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_embed(get_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN\n",
    "You created a RNN Cell in the `get_init_cell()` function.  Time to use the cell to create a RNN.\n",
    "- Build the RNN using the [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)\n",
    " - Apply the name \"final_state\" to the final state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the outputs and final_state state in the following tuple `(Outputs, FinalState)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    size = tf.shape(inputs)    \n",
    "    InitialState = cell.zero_state(size[0], tf.float32)\n",
    "    \n",
    "    Outputs, FinalState = tf.nn.dynamic_rnn(cell, inputs, initial_state=InitialState)\n",
    "    FinalState = tf.identity(FinalState, name='final_state')\n",
    "    return Outputs, FinalState\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_rnn(build_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Neural Network\n",
    "Apply the functions you implemented above to:\n",
    "- Apply embedding to `input_data` using your `get_embed(input_data, vocab_size, embed_dim)` function.\n",
    "- Build RNN using `cell` and your `build_rnn(cell, inputs)` function.\n",
    "- Apply a fully connected layer with a linear activation and `vocab_size` as the number of outputs.\n",
    "\n",
    "Return the logits and final state in the following tuple (Logits, FinalState) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    embed = get_embed(input_data, vocab_size, rnn_size)\n",
    "    Outputs, FinalState = build_rnn(cell,embed)\n",
    "    Logits = tf.contrib.layers.fully_connected(Outputs, vocab_size, activation_fn=None)\n",
    "    return Logits, FinalState\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_nn(build_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batches\n",
    "Implement `get_batches` to create batches of input and targets using `int_text`.  The batches should be a Numpy array with the shape `(number of batches, 2, batch size, sequence length)`. Each batch contains two elements:\n",
    "- The first element is a single batch of **input** with the shape `[batch size, sequence length]`\n",
    "- The second element is a single batch of **targets** with the shape `[batch size, sequence length]`\n",
    "\n",
    "If you can't fill the last batch with enough data, drop the last batch.\n",
    "\n",
    "For exmple, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)` would return a Numpy array of the following:\n",
    "```\n",
    "[\n",
    "  # First Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 1  2  3], [ 7  8  9]],\n",
    "    # Batch of targets\n",
    "    [[ 2  3  4], [ 8  9 10]]\n",
    "  ],\n",
    " \n",
    "  # Second Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 4  5  6], [10 11 12]],\n",
    "    # Batch of targets\n",
    "    [[ 5  6  7], [11 12 13]]\n",
    "  ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function       \n",
    "    num_batches = int(np.floor(len(int_text) / (batch_size*seq_length)))    \n",
    "    OutputArray = np.zeros((num_batches, 2, batch_size, seq_length), dtype=np.int)\n",
    "    for ii in range(0,num_batches-1):\n",
    "            for jj in range(0,batch_size-1):\n",
    "                    start_index = jj*num_batches*seq_length + 1 + ii * seq_length\n",
    "                    #print(start_index)\n",
    "                    end_index = start_index + seq_length                    \n",
    "                    OutputArray[ii,0,jj,:] = int_text[start_index:end_index]\n",
    "                    OutputArray[ii,1,jj,:] = int_text[start_index + 1:end_index + 1]            \n",
    "    return OutputArray\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_batches(get_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "\n",
    "- Set `num_epochs` to the number of epochs.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `rnn_size` to the size of the RNNs.\n",
    "- Set `seq_length` to the length of sequence.\n",
    "- Set `learning_rate` to the learning rate.\n",
    "- Set `show_every_n_batches` to the number of batches the neural network should print progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 1\n",
    "# Batch Size\n",
    "batch_size = 2\n",
    "# RNN Size\n",
    "rnn_size = 2\n",
    "# Sequence Length\n",
    "seq_length = 2\n",
    "# Learning Rate\n",
    "learning_rate = 0.1\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 1\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Graph\n",
    "Build the graph using the neural network you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train\n",
    "Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the [forms](https://discussions.udacity.com/) to see if anyone is having the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/17275   train_loss = 8.822\n",
      "Epoch   0 Batch    1/17275   train_loss = 8.722\n",
      "Epoch   0 Batch    2/17275   train_loss = 8.615\n",
      "Epoch   0 Batch    3/17275   train_loss = 8.500\n",
      "Epoch   0 Batch    4/17275   train_loss = 8.374\n",
      "Epoch   0 Batch    5/17275   train_loss = 8.233\n",
      "Epoch   0 Batch    6/17275   train_loss = 7.916\n",
      "Epoch   0 Batch    7/17275   train_loss = 7.894\n",
      "Epoch   0 Batch    8/17275   train_loss = 7.682\n",
      "Epoch   0 Batch    9/17275   train_loss = 7.369\n",
      "Epoch   0 Batch   10/17275   train_loss = 7.007\n",
      "Epoch   0 Batch   11/17275   train_loss = 6.882\n",
      "Epoch   0 Batch   12/17275   train_loss = 6.578\n",
      "Epoch   0 Batch   13/17275   train_loss = 6.276\n",
      "Epoch   0 Batch   14/17275   train_loss = 5.497\n",
      "Epoch   0 Batch   15/17275   train_loss = 4.138\n",
      "Epoch   0 Batch   16/17275   train_loss = 4.969\n",
      "Epoch   0 Batch   17/17275   train_loss = 3.615\n",
      "Epoch   0 Batch   18/17275   train_loss = 4.221\n",
      "Epoch   0 Batch   19/17275   train_loss = 4.015\n",
      "Epoch   0 Batch   20/17275   train_loss = 5.345\n",
      "Epoch   0 Batch   21/17275   train_loss = 2.927\n",
      "Epoch   0 Batch   22/17275   train_loss = 4.354\n",
      "Epoch   0 Batch   23/17275   train_loss = 3.055\n",
      "Epoch   0 Batch   24/17275   train_loss = 2.990\n",
      "Epoch   0 Batch   25/17275   train_loss = 3.745\n",
      "Epoch   0 Batch   26/17275   train_loss = 4.114\n",
      "Epoch   0 Batch   27/17275   train_loss = 4.333\n",
      "Epoch   0 Batch   28/17275   train_loss = 6.115\n",
      "Epoch   0 Batch   29/17275   train_loss = 3.348\n",
      "Epoch   0 Batch   30/17275   train_loss = 4.304\n",
      "Epoch   0 Batch   31/17275   train_loss = 2.988\n",
      "Epoch   0 Batch   32/17275   train_loss = 3.346\n",
      "Epoch   0 Batch   33/17275   train_loss = 2.538\n",
      "Epoch   0 Batch   34/17275   train_loss = 4.263\n",
      "Epoch   0 Batch   35/17275   train_loss = 6.339\n",
      "Epoch   0 Batch   36/17275   train_loss = 3.700\n",
      "Epoch   0 Batch   37/17275   train_loss = 6.390\n",
      "Epoch   0 Batch   38/17275   train_loss = 6.424\n",
      "Epoch   0 Batch   39/17275   train_loss = 6.453\n",
      "Epoch   0 Batch   40/17275   train_loss = 6.164\n",
      "Epoch   0 Batch   41/17275   train_loss = 4.244\n",
      "Epoch   0 Batch   42/17275   train_loss = 6.140\n",
      "Epoch   0 Batch   43/17275   train_loss = 6.476\n",
      "Epoch   0 Batch   44/17275   train_loss = 3.669\n",
      "Epoch   0 Batch   45/17275   train_loss = 6.460\n",
      "Epoch   0 Batch   46/17275   train_loss = 6.442\n",
      "Epoch   0 Batch   47/17275   train_loss = 6.422\n",
      "Epoch   0 Batch   48/17275   train_loss = 1.921\n",
      "Epoch   0 Batch   49/17275   train_loss = 4.798\n",
      "Epoch   0 Batch   50/17275   train_loss = 5.089\n",
      "Epoch   0 Batch   51/17275   train_loss = 4.256\n",
      "Epoch   0 Batch   52/17275   train_loss = 6.354\n",
      "Epoch   0 Batch   53/17275   train_loss = 5.995\n",
      "Epoch   0 Batch   54/17275   train_loss = 6.324\n",
      "Epoch   0 Batch   55/17275   train_loss = 1.902\n",
      "Epoch   0 Batch   56/17275   train_loss = 6.303\n",
      "Epoch   0 Batch   57/17275   train_loss = 5.710\n",
      "Epoch   0 Batch   58/17275   train_loss = 4.000\n",
      "Epoch   0 Batch   59/17275   train_loss = 3.951\n",
      "Epoch   0 Batch   60/17275   train_loss = 6.276\n",
      "Epoch   0 Batch   61/17275   train_loss = 5.445\n",
      "Epoch   0 Batch   62/17275   train_loss = 1.801\n",
      "Epoch   0 Batch   63/17275   train_loss = 3.855\n",
      "Epoch   0 Batch   64/17275   train_loss = 3.123\n",
      "Epoch   0 Batch   65/17275   train_loss = 3.132\n",
      "Epoch   0 Batch   66/17275   train_loss = 5.663\n",
      "Epoch   0 Batch   67/17275   train_loss = 3.123\n",
      "Epoch   0 Batch   68/17275   train_loss = 5.217\n",
      "Epoch   0 Batch   69/17275   train_loss = 3.354\n",
      "Epoch   0 Batch   70/17275   train_loss = 4.201\n",
      "Epoch   0 Batch   71/17275   train_loss = 2.490\n",
      "Epoch   0 Batch   72/17275   train_loss = 4.640\n",
      "Epoch   0 Batch   73/17275   train_loss = 4.546\n",
      "Epoch   0 Batch   74/17275   train_loss = 4.469\n",
      "Epoch   0 Batch   75/17275   train_loss = 5.080\n",
      "Epoch   0 Batch   76/17275   train_loss = 3.795\n",
      "Epoch   0 Batch   77/17275   train_loss = 1.889\n",
      "Epoch   0 Batch   78/17275   train_loss = 2.013\n",
      "Epoch   0 Batch   79/17275   train_loss = 3.823\n",
      "Epoch   0 Batch   80/17275   train_loss = 6.292\n",
      "Epoch   0 Batch   81/17275   train_loss = 3.849\n",
      "Epoch   0 Batch   82/17275   train_loss = 3.846\n",
      "Epoch   0 Batch   83/17275   train_loss = 3.274\n",
      "Epoch   0 Batch   84/17275   train_loss = 6.348\n",
      "Epoch   0 Batch   85/17275   train_loss = 6.351\n",
      "Epoch   0 Batch   86/17275   train_loss = 1.710\n",
      "Epoch   0 Batch   87/17275   train_loss = 5.732\n",
      "Epoch   0 Batch   88/17275   train_loss = 5.546\n",
      "Epoch   0 Batch   89/17275   train_loss = 3.858\n",
      "Epoch   0 Batch   90/17275   train_loss = 6.388\n",
      "Epoch   0 Batch   91/17275   train_loss = 6.383\n",
      "Epoch   0 Batch   92/17275   train_loss = 2.355\n",
      "Epoch   0 Batch   93/17275   train_loss = 4.508\n",
      "Epoch   0 Batch   94/17275   train_loss = 1.727\n",
      "Epoch   0 Batch   95/17275   train_loss = 3.073\n",
      "Epoch   0 Batch   96/17275   train_loss = 3.250\n",
      "Epoch   0 Batch   97/17275   train_loss = 4.304\n",
      "Epoch   0 Batch   98/17275   train_loss = 4.671\n",
      "Epoch   0 Batch   99/17275   train_loss = 6.416\n",
      "Epoch   0 Batch  100/17275   train_loss = 2.179\n",
      "Epoch   0 Batch  101/17275   train_loss = 5.449\n",
      "Epoch   0 Batch  102/17275   train_loss = 4.359\n",
      "Epoch   0 Batch  103/17275   train_loss = 6.435\n",
      "Epoch   0 Batch  104/17275   train_loss = 4.664\n",
      "Epoch   0 Batch  105/17275   train_loss = 3.983\n",
      "Epoch   0 Batch  106/17275   train_loss = 6.456\n",
      "Epoch   0 Batch  107/17275   train_loss = 5.659\n",
      "Epoch   0 Batch  108/17275   train_loss = 5.550\n",
      "Epoch   0 Batch  109/17275   train_loss = 6.032\n",
      "Epoch   0 Batch  110/17275   train_loss = 4.663\n",
      "Epoch   0 Batch  111/17275   train_loss = 3.920\n",
      "Epoch   0 Batch  112/17275   train_loss = 4.568\n",
      "Epoch   0 Batch  113/17275   train_loss = 2.074\n",
      "Epoch   0 Batch  114/17275   train_loss = 2.536\n",
      "Epoch   0 Batch  115/17275   train_loss = 5.008\n",
      "Epoch   0 Batch  116/17275   train_loss = 4.157\n",
      "Epoch   0 Batch  117/17275   train_loss = 6.417\n",
      "Epoch   0 Batch  118/17275   train_loss = 6.408\n",
      "Epoch   0 Batch  119/17275   train_loss = 6.392\n",
      "Epoch   0 Batch  120/17275   train_loss = 5.460\n",
      "Epoch   0 Batch  121/17275   train_loss = 2.332\n",
      "Epoch   0 Batch  122/17275   train_loss = 4.919\n",
      "Epoch   0 Batch  123/17275   train_loss = 4.635\n",
      "Epoch   0 Batch  124/17275   train_loss = 4.086\n",
      "Epoch   0 Batch  125/17275   train_loss = 2.921\n",
      "Epoch   0 Batch  126/17275   train_loss = 2.196\n",
      "Epoch   0 Batch  127/17275   train_loss = 4.440\n",
      "Epoch   0 Batch  128/17275   train_loss = 4.303\n",
      "Epoch   0 Batch  129/17275   train_loss = 4.783\n",
      "Epoch   0 Batch  130/17275   train_loss = 2.208\n",
      "Epoch   0 Batch  131/17275   train_loss = 2.306\n",
      "Epoch   0 Batch  132/17275   train_loss = 4.507\n",
      "Epoch   0 Batch  133/17275   train_loss = 5.998\n",
      "Epoch   0 Batch  134/17275   train_loss = 2.754\n",
      "Epoch   0 Batch  135/17275   train_loss = 3.835\n",
      "Epoch   0 Batch  136/17275   train_loss = 2.550\n",
      "Epoch   0 Batch  137/17275   train_loss = 5.037\n",
      "Epoch   0 Batch  138/17275   train_loss = 3.839\n",
      "Epoch   0 Batch  139/17275   train_loss = 4.478\n",
      "Epoch   0 Batch  140/17275   train_loss = 5.129\n",
      "Epoch   0 Batch  141/17275   train_loss = 4.700\n",
      "Epoch   0 Batch  142/17275   train_loss = 3.819\n",
      "Epoch   0 Batch  143/17275   train_loss = 2.367\n",
      "Epoch   0 Batch  144/17275   train_loss = 4.060\n",
      "Epoch   0 Batch  145/17275   train_loss = 6.014\n",
      "Epoch   0 Batch  146/17275   train_loss = 6.030\n",
      "Epoch   0 Batch  147/17275   train_loss = 4.689\n",
      "Epoch   0 Batch  148/17275   train_loss = 6.055\n",
      "Epoch   0 Batch  149/17275   train_loss = 4.226\n",
      "Epoch   0 Batch  150/17275   train_loss = 6.082\n",
      "Epoch   0 Batch  151/17275   train_loss = 2.796\n",
      "Epoch   0 Batch  152/17275   train_loss = 6.100\n",
      "Epoch   0 Batch  153/17275   train_loss = 6.111\n",
      "Epoch   0 Batch  154/17275   train_loss = 4.947\n",
      "Epoch   0 Batch  155/17275   train_loss = 3.917\n",
      "Epoch   0 Batch  156/17275   train_loss = 4.169\n",
      "Epoch   0 Batch  157/17275   train_loss = 4.426\n",
      "Epoch   0 Batch  158/17275   train_loss = 4.360\n",
      "Epoch   0 Batch  159/17275   train_loss = 4.194\n",
      "Epoch   0 Batch  160/17275   train_loss = 4.196\n",
      "Epoch   0 Batch  161/17275   train_loss = 4.846\n",
      "Epoch   0 Batch  162/17275   train_loss = 4.643\n",
      "Epoch   0 Batch  163/17275   train_loss = 2.804\n",
      "Epoch   0 Batch  164/17275   train_loss = 4.700\n",
      "Epoch   0 Batch  165/17275   train_loss = 4.668\n",
      "Epoch   0 Batch  166/17275   train_loss = 4.478\n",
      "Epoch   0 Batch  167/17275   train_loss = 3.969\n",
      "Epoch   0 Batch  168/17275   train_loss = 4.435\n",
      "Epoch   0 Batch  169/17275   train_loss = 6.349\n",
      "Epoch   0 Batch  170/17275   train_loss = 5.165\n",
      "Epoch   0 Batch  171/17275   train_loss = 4.866\n",
      "Epoch   0 Batch  172/17275   train_loss = 5.180\n",
      "Epoch   0 Batch  173/17275   train_loss = 2.791\n",
      "Epoch   0 Batch  174/17275   train_loss = 3.421\n",
      "Epoch   0 Batch  175/17275   train_loss = 5.114\n",
      "Epoch   0 Batch  176/17275   train_loss = 4.854\n",
      "Epoch   0 Batch  177/17275   train_loss = 4.024\n",
      "Epoch   0 Batch  178/17275   train_loss = 2.458\n",
      "Epoch   0 Batch  179/17275   train_loss = 4.083\n",
      "Epoch   0 Batch  180/17275   train_loss = 5.445\n",
      "Epoch   0 Batch  181/17275   train_loss = 2.145\n",
      "Epoch   0 Batch  182/17275   train_loss = 4.322\n",
      "Epoch   0 Batch  183/17275   train_loss = 3.969\n",
      "Epoch   0 Batch  184/17275   train_loss = 3.618\n",
      "Epoch   0 Batch  185/17275   train_loss = 4.668\n",
      "Epoch   0 Batch  186/17275   train_loss = 5.101\n",
      "Epoch   0 Batch  187/17275   train_loss = 3.925\n",
      "Epoch   0 Batch  188/17275   train_loss = 3.415\n",
      "Epoch   0 Batch  189/17275   train_loss = 2.887\n",
      "Epoch   0 Batch  190/17275   train_loss = 4.759\n",
      "Epoch   0 Batch  191/17275   train_loss = 4.692\n",
      "Epoch   0 Batch  192/17275   train_loss = 2.912\n",
      "Epoch   0 Batch  193/17275   train_loss = 4.050\n",
      "Epoch   0 Batch  194/17275   train_loss = 4.916\n",
      "Epoch   0 Batch  195/17275   train_loss = 3.916\n",
      "Epoch   0 Batch  196/17275   train_loss = 3.591\n",
      "Epoch   0 Batch  197/17275   train_loss = 3.064\n",
      "Epoch   0 Batch  198/17275   train_loss = 3.643\n",
      "Epoch   0 Batch  199/17275   train_loss = 2.469\n",
      "Epoch   0 Batch  200/17275   train_loss = 3.090\n",
      "Epoch   0 Batch  201/17275   train_loss = 5.586\n",
      "Epoch   0 Batch  202/17275   train_loss = 2.246\n",
      "Epoch   0 Batch  203/17275   train_loss = 3.956\n",
      "Epoch   0 Batch  204/17275   train_loss = 2.231\n",
      "Epoch   0 Batch  205/17275   train_loss = 3.266\n",
      "Epoch   0 Batch  206/17275   train_loss = 3.216\n",
      "Epoch   0 Batch  207/17275   train_loss = 2.829\n",
      "Epoch   0 Batch  208/17275   train_loss = 2.961\n",
      "Epoch   0 Batch  209/17275   train_loss = 6.302\n",
      "Epoch   0 Batch  210/17275   train_loss = 4.765\n",
      "Epoch   0 Batch  211/17275   train_loss = 6.091\n",
      "Epoch   0 Batch  212/17275   train_loss = 5.028\n",
      "Epoch   0 Batch  213/17275   train_loss = 5.840\n",
      "Epoch   0 Batch  214/17275   train_loss = 3.241\n",
      "Epoch   0 Batch  215/17275   train_loss = 3.274\n",
      "Epoch   0 Batch  216/17275   train_loss = 4.795\n",
      "Epoch   0 Batch  217/17275   train_loss = 3.499\n",
      "Epoch   0 Batch  218/17275   train_loss = 4.098\n",
      "Epoch   0 Batch  219/17275   train_loss = 4.359\n",
      "Epoch   0 Batch  220/17275   train_loss = 3.320\n",
      "Epoch   0 Batch  221/17275   train_loss = 3.386\n",
      "Epoch   0 Batch  222/17275   train_loss = 3.336\n",
      "Epoch   0 Batch  223/17275   train_loss = 5.760\n",
      "Epoch   0 Batch  224/17275   train_loss = 4.738\n",
      "Epoch   0 Batch  225/17275   train_loss = 4.285\n",
      "Epoch   0 Batch  226/17275   train_loss = 5.824\n",
      "Epoch   0 Batch  227/17275   train_loss = 3.133\n",
      "Epoch   0 Batch  228/17275   train_loss = 4.027\n",
      "Epoch   0 Batch  229/17275   train_loss = 3.919\n",
      "Epoch   0 Batch  230/17275   train_loss = 3.056\n",
      "Epoch   0 Batch  231/17275   train_loss = 4.374\n",
      "Epoch   0 Batch  232/17275   train_loss = 4.671\n",
      "Epoch   0 Batch  233/17275   train_loss = 3.229\n",
      "Epoch   0 Batch  234/17275   train_loss = 4.540\n",
      "Epoch   0 Batch  235/17275   train_loss = 4.490\n",
      "Epoch   0 Batch  236/17275   train_loss = 3.144\n",
      "Epoch   0 Batch  237/17275   train_loss = 4.381\n",
      "Epoch   0 Batch  238/17275   train_loss = 2.813\n",
      "Epoch   0 Batch  239/17275   train_loss = 3.043\n",
      "Epoch   0 Batch  240/17275   train_loss = 4.385\n",
      "Epoch   0 Batch  241/17275   train_loss = 2.922\n",
      "Epoch   0 Batch  242/17275   train_loss = 3.679\n",
      "Epoch   0 Batch  243/17275   train_loss = 4.134\n",
      "Epoch   0 Batch  244/17275   train_loss = 4.328\n",
      "Epoch   0 Batch  245/17275   train_loss = 5.392\n",
      "Epoch   0 Batch  246/17275   train_loss = 3.212\n",
      "Epoch   0 Batch  247/17275   train_loss = 3.307\n",
      "Epoch   0 Batch  248/17275   train_loss = 2.781\n",
      "Epoch   0 Batch  249/17275   train_loss = 4.165\n",
      "Epoch   0 Batch  250/17275   train_loss = 4.225\n",
      "Epoch   0 Batch  251/17275   train_loss = 4.618\n",
      "Epoch   0 Batch  252/17275   train_loss = 5.059\n",
      "Epoch   0 Batch  253/17275   train_loss = 2.472\n",
      "Epoch   0 Batch  254/17275   train_loss = 4.318\n",
      "Epoch   0 Batch  255/17275   train_loss = 4.444\n",
      "Epoch   0 Batch  256/17275   train_loss = 2.881\n",
      "Epoch   0 Batch  257/17275   train_loss = 4.307\n",
      "Epoch   0 Batch  258/17275   train_loss = 4.185\n",
      "Epoch   0 Batch  259/17275   train_loss = 2.800\n",
      "Epoch   0 Batch  260/17275   train_loss = 5.148\n",
      "Epoch   0 Batch  261/17275   train_loss = 4.491\n",
      "Epoch   0 Batch  262/17275   train_loss = 2.732\n",
      "Epoch   0 Batch  263/17275   train_loss = 2.872\n",
      "Epoch   0 Batch  264/17275   train_loss = 6.260\n",
      "Epoch   0 Batch  265/17275   train_loss = 4.266\n",
      "Epoch   0 Batch  266/17275   train_loss = 2.372\n",
      "Epoch   0 Batch  267/17275   train_loss = 2.648\n",
      "Epoch   0 Batch  268/17275   train_loss = 4.915\n",
      "Epoch   0 Batch  269/17275   train_loss = 2.593\n",
      "Epoch   0 Batch  270/17275   train_loss = 4.433\n",
      "Epoch   0 Batch  271/17275   train_loss = 4.291\n",
      "Epoch   0 Batch  272/17275   train_loss = 4.408\n",
      "Epoch   0 Batch  273/17275   train_loss = 2.985\n",
      "Epoch   0 Batch  274/17275   train_loss = 2.960\n",
      "Epoch   0 Batch  275/17275   train_loss = 4.278\n",
      "Epoch   0 Batch  276/17275   train_loss = 3.310\n",
      "Epoch   0 Batch  277/17275   train_loss = 2.210\n",
      "Epoch   0 Batch  278/17275   train_loss = 4.289\n",
      "Epoch   0 Batch  279/17275   train_loss = 4.606\n",
      "Epoch   0 Batch  280/17275   train_loss = 2.891\n",
      "Epoch   0 Batch  281/17275   train_loss = 4.674\n",
      "Epoch   0 Batch  282/17275   train_loss = 4.665\n",
      "Epoch   0 Batch  283/17275   train_loss = 4.338\n",
      "Epoch   0 Batch  284/17275   train_loss = 2.252\n",
      "Epoch   0 Batch  285/17275   train_loss = 6.236\n",
      "Epoch   0 Batch  286/17275   train_loss = 2.204\n",
      "Epoch   0 Batch  287/17275   train_loss = 4.315\n",
      "Epoch   0 Batch  288/17275   train_loss = 5.149\n",
      "Epoch   0 Batch  289/17275   train_loss = 4.267\n",
      "Epoch   0 Batch  290/17275   train_loss = 2.530\n",
      "Epoch   0 Batch  291/17275   train_loss = 3.045\n",
      "Epoch   0 Batch  292/17275   train_loss = 3.191\n",
      "Epoch   0 Batch  293/17275   train_loss = 3.485\n",
      "Epoch   0 Batch  294/17275   train_loss = 2.897\n",
      "Epoch   0 Batch  295/17275   train_loss = 2.773\n",
      "Epoch   0 Batch  296/17275   train_loss = 3.887\n",
      "Epoch   0 Batch  297/17275   train_loss = 1.807\n",
      "Epoch   0 Batch  298/17275   train_loss = 1.769\n",
      "Epoch   0 Batch  299/17275   train_loss = 4.575\n",
      "Epoch   0 Batch  300/17275   train_loss = 3.020\n",
      "Epoch   0 Batch  301/17275   train_loss = 4.139\n",
      "Epoch   0 Batch  302/17275   train_loss = 2.822\n",
      "Epoch   0 Batch  303/17275   train_loss = 6.573\n",
      "Epoch   0 Batch  304/17275   train_loss = 3.831\n",
      "Epoch   0 Batch  305/17275   train_loss = 6.585\n",
      "Epoch   0 Batch  306/17275   train_loss = 3.152\n",
      "Epoch   0 Batch  307/17275   train_loss = 6.591\n",
      "Epoch   0 Batch  308/17275   train_loss = 3.000\n",
      "Epoch   0 Batch  309/17275   train_loss = 4.827\n",
      "Epoch   0 Batch  310/17275   train_loss = 4.392\n",
      "Epoch   0 Batch  311/17275   train_loss = 3.055\n",
      "Epoch   0 Batch  312/17275   train_loss = 3.192\n",
      "Epoch   0 Batch  313/17275   train_loss = 4.855\n",
      "Epoch   0 Batch  314/17275   train_loss = 4.934\n",
      "Epoch   0 Batch  315/17275   train_loss = 1.894\n",
      "Epoch   0 Batch  316/17275   train_loss = 3.198\n",
      "Epoch   0 Batch  317/17275   train_loss = 4.448\n",
      "Epoch   0 Batch  318/17275   train_loss = 2.950\n",
      "Epoch   0 Batch  319/17275   train_loss = 4.555\n",
      "Epoch   0 Batch  320/17275   train_loss = 1.928\n",
      "Epoch   0 Batch  321/17275   train_loss = 3.425\n",
      "Epoch   0 Batch  322/17275   train_loss = 4.423\n",
      "Epoch   0 Batch  323/17275   train_loss = 4.174\n",
      "Epoch   0 Batch  324/17275   train_loss = 1.716\n",
      "Epoch   0 Batch  325/17275   train_loss = 2.150\n",
      "Epoch   0 Batch  326/17275   train_loss = 2.656\n",
      "Epoch   0 Batch  327/17275   train_loss = 4.415\n",
      "Epoch   0 Batch  328/17275   train_loss = 2.961\n",
      "Epoch   0 Batch  329/17275   train_loss = 4.643\n",
      "Epoch   0 Batch  330/17275   train_loss = 5.303\n",
      "Epoch   0 Batch  331/17275   train_loss = 5.307\n",
      "Epoch   0 Batch  332/17275   train_loss = 6.682\n",
      "Epoch   0 Batch  333/17275   train_loss = 4.832\n",
      "Epoch   0 Batch  334/17275   train_loss = 5.314\n",
      "Epoch   0 Batch  335/17275   train_loss = 1.845\n",
      "Epoch   0 Batch  336/17275   train_loss = 4.752\n",
      "Epoch   0 Batch  337/17275   train_loss = 3.934\n",
      "Epoch   0 Batch  338/17275   train_loss = 3.957\n",
      "Epoch   0 Batch  339/17275   train_loss = 4.754\n",
      "Epoch   0 Batch  340/17275   train_loss = 2.437\n",
      "Epoch   0 Batch  341/17275   train_loss = 2.628\n",
      "Epoch   0 Batch  342/17275   train_loss = 3.606\n",
      "Epoch   0 Batch  343/17275   train_loss = 4.984\n",
      "Epoch   0 Batch  344/17275   train_loss = 3.790\n",
      "Epoch   0 Batch  345/17275   train_loss = 4.006\n",
      "Epoch   0 Batch  346/17275   train_loss = 3.328\n",
      "Epoch   0 Batch  347/17275   train_loss = 2.260\n",
      "Epoch   0 Batch  348/17275   train_loss = 4.398\n",
      "Epoch   0 Batch  349/17275   train_loss = 2.569\n",
      "Epoch   0 Batch  350/17275   train_loss = 2.289\n",
      "Epoch   0 Batch  351/17275   train_loss = 4.857\n",
      "Epoch   0 Batch  352/17275   train_loss = 2.848\n",
      "Epoch   0 Batch  353/17275   train_loss = 4.816\n",
      "Epoch   0 Batch  354/17275   train_loss = 4.776\n",
      "Epoch   0 Batch  355/17275   train_loss = 2.661\n",
      "Epoch   0 Batch  356/17275   train_loss = 5.224\n",
      "Epoch   0 Batch  357/17275   train_loss = 5.180\n",
      "Epoch   0 Batch  358/17275   train_loss = 5.000\n",
      "Epoch   0 Batch  359/17275   train_loss = 4.362\n",
      "Epoch   0 Batch  360/17275   train_loss = 2.178\n",
      "Epoch   0 Batch  361/17275   train_loss = 3.995\n",
      "Epoch   0 Batch  362/17275   train_loss = 2.509\n",
      "Epoch   0 Batch  363/17275   train_loss = 2.184\n",
      "Epoch   0 Batch  364/17275   train_loss = 4.736\n",
      "Epoch   0 Batch  365/17275   train_loss = 6.761\n",
      "Epoch   0 Batch  366/17275   train_loss = 3.347\n",
      "Epoch   0 Batch  367/17275   train_loss = 4.384\n",
      "Epoch   0 Batch  368/17275   train_loss = 5.096\n",
      "Epoch   0 Batch  369/17275   train_loss = 4.777\n",
      "Epoch   0 Batch  370/17275   train_loss = 4.375\n",
      "Epoch   0 Batch  371/17275   train_loss = 4.331\n",
      "Epoch   0 Batch  372/17275   train_loss = 4.710\n",
      "Epoch   0 Batch  373/17275   train_loss = 3.180\n",
      "Epoch   0 Batch  374/17275   train_loss = 3.204\n",
      "Epoch   0 Batch  375/17275   train_loss = 4.387\n",
      "Epoch   0 Batch  376/17275   train_loss = 2.259\n",
      "Epoch   0 Batch  377/17275   train_loss = 2.516\n",
      "Epoch   0 Batch  378/17275   train_loss = 4.806\n",
      "Epoch   0 Batch  379/17275   train_loss = 6.801\n",
      "Epoch   0 Batch  380/17275   train_loss = 4.875\n",
      "Epoch   0 Batch  381/17275   train_loss = 4.032\n",
      "Epoch   0 Batch  382/17275   train_loss = 4.652\n",
      "Epoch   0 Batch  383/17275   train_loss = 2.625\n",
      "Epoch   0 Batch  384/17275   train_loss = 4.735\n",
      "Epoch   0 Batch  385/17275   train_loss = 3.419\n",
      "Epoch   0 Batch  386/17275   train_loss = 3.597\n",
      "Epoch   0 Batch  387/17275   train_loss = 2.092\n",
      "Epoch   0 Batch  388/17275   train_loss = 2.960\n",
      "Epoch   0 Batch  389/17275   train_loss = 3.366\n",
      "Epoch   0 Batch  390/17275   train_loss = 4.960\n",
      "Epoch   0 Batch  391/17275   train_loss = 4.417\n",
      "Epoch   0 Batch  392/17275   train_loss = 2.056\n",
      "Epoch   0 Batch  393/17275   train_loss = 4.466\n",
      "Epoch   0 Batch  394/17275   train_loss = 5.163\n",
      "Epoch   0 Batch  395/17275   train_loss = 4.697\n",
      "Epoch   0 Batch  396/17275   train_loss = 3.351\n",
      "Epoch   0 Batch  397/17275   train_loss = 1.938\n",
      "Epoch   0 Batch  398/17275   train_loss = 6.142\n",
      "Epoch   0 Batch  399/17275   train_loss = 5.081\n",
      "Epoch   0 Batch  400/17275   train_loss = 5.300\n",
      "Epoch   0 Batch  401/17275   train_loss = 1.989\n",
      "Epoch   0 Batch  402/17275   train_loss = 2.948\n",
      "Epoch   0 Batch  403/17275   train_loss = 1.938\n",
      "Epoch   0 Batch  404/17275   train_loss = 4.380\n",
      "Epoch   0 Batch  405/17275   train_loss = 1.863\n",
      "Epoch   0 Batch  406/17275   train_loss = 4.530\n",
      "Epoch   0 Batch  407/17275   train_loss = 4.467\n",
      "Epoch   0 Batch  408/17275   train_loss = 2.920\n",
      "Epoch   0 Batch  409/17275   train_loss = 4.808\n",
      "Epoch   0 Batch  410/17275   train_loss = 2.655\n",
      "Epoch   0 Batch  411/17275   train_loss = 3.567\n",
      "Epoch   0 Batch  412/17275   train_loss = 5.290\n",
      "Epoch   0 Batch  413/17275   train_loss = 3.123\n",
      "Epoch   0 Batch  414/17275   train_loss = 5.483\n",
      "Epoch   0 Batch  415/17275   train_loss = 4.241\n",
      "Epoch   0 Batch  416/17275   train_loss = 4.759\n",
      "Epoch   0 Batch  417/17275   train_loss = 6.923\n",
      "Epoch   0 Batch  418/17275   train_loss = 4.765\n",
      "Epoch   0 Batch  419/17275   train_loss = 3.352\n",
      "Epoch   0 Batch  420/17275   train_loss = 3.782\n",
      "Epoch   0 Batch  421/17275   train_loss = 2.478\n",
      "Epoch   0 Batch  422/17275   train_loss = 2.460\n",
      "Epoch   0 Batch  423/17275   train_loss = 2.464\n",
      "Epoch   0 Batch  424/17275   train_loss = 4.254\n",
      "Epoch   0 Batch  425/17275   train_loss = 4.731\n",
      "Epoch   0 Batch  426/17275   train_loss = 2.749\n",
      "Epoch   0 Batch  427/17275   train_loss = 4.247\n",
      "Epoch   0 Batch  428/17275   train_loss = 6.416\n",
      "Epoch   0 Batch  429/17275   train_loss = 2.340\n",
      "Epoch   0 Batch  430/17275   train_loss = 4.869\n",
      "Epoch   0 Batch  431/17275   train_loss = 4.261\n",
      "Epoch   0 Batch  432/17275   train_loss = 4.713\n",
      "Epoch   0 Batch  433/17275   train_loss = 4.035\n",
      "Epoch   0 Batch  434/17275   train_loss = 3.243\n",
      "Epoch   0 Batch  435/17275   train_loss = 6.923\n",
      "Epoch   0 Batch  436/17275   train_loss = 3.091\n",
      "Epoch   0 Batch  437/17275   train_loss = 6.923\n",
      "Epoch   0 Batch  438/17275   train_loss = 2.525\n",
      "Epoch   0 Batch  439/17275   train_loss = 3.567\n",
      "Epoch   0 Batch  440/17275   train_loss = 4.666\n",
      "Epoch   0 Batch  441/17275   train_loss = 3.581\n",
      "Epoch   0 Batch  442/17275   train_loss = 3.554\n",
      "Epoch   0 Batch  443/17275   train_loss = 3.562\n",
      "Epoch   0 Batch  444/17275   train_loss = 6.928\n",
      "Epoch   0 Batch  445/17275   train_loss = 2.008\n",
      "Epoch   0 Batch  446/17275   train_loss = 2.787\n",
      "Epoch   0 Batch  447/17275   train_loss = 2.887\n",
      "Epoch   0 Batch  448/17275   train_loss = 3.803\n",
      "Epoch   0 Batch  449/17275   train_loss = 5.025\n",
      "Epoch   0 Batch  450/17275   train_loss = 4.846\n",
      "Epoch   0 Batch  451/17275   train_loss = 2.453\n",
      "Epoch   0 Batch  452/17275   train_loss = 4.585\n",
      "Epoch   0 Batch  453/17275   train_loss = 2.976\n",
      "Epoch   0 Batch  454/17275   train_loss = 2.945\n",
      "Epoch   0 Batch  455/17275   train_loss = 4.028\n",
      "Epoch   0 Batch  456/17275   train_loss = 4.708\n",
      "Epoch   0 Batch  457/17275   train_loss = 5.153\n",
      "Epoch   0 Batch  458/17275   train_loss = 1.997\n",
      "Epoch   0 Batch  459/17275   train_loss = 4.787\n",
      "Epoch   0 Batch  460/17275   train_loss = 4.904\n",
      "Epoch   0 Batch  461/17275   train_loss = 4.838\n",
      "Epoch   0 Batch  462/17275   train_loss = 6.197\n",
      "Epoch   0 Batch  463/17275   train_loss = 5.059\n",
      "Epoch   0 Batch  464/17275   train_loss = 2.338\n",
      "Epoch   0 Batch  465/17275   train_loss = 6.509\n",
      "Epoch   0 Batch  466/17275   train_loss = 2.680\n",
      "Epoch   0 Batch  467/17275   train_loss = 6.721\n",
      "Epoch   0 Batch  468/17275   train_loss = 4.992\n",
      "Epoch   0 Batch  469/17275   train_loss = 4.963\n",
      "Epoch   0 Batch  470/17275   train_loss = 3.148\n",
      "Epoch   0 Batch  471/17275   train_loss = 4.457\n",
      "Epoch   0 Batch  472/17275   train_loss = 2.833\n",
      "Epoch   0 Batch  473/17275   train_loss = 5.172\n",
      "Epoch   0 Batch  474/17275   train_loss = 6.960\n",
      "Epoch   0 Batch  475/17275   train_loss = 2.346\n",
      "Epoch   0 Batch  476/17275   train_loss = 2.305\n",
      "Epoch   0 Batch  477/17275   train_loss = 4.632\n",
      "Epoch   0 Batch  478/17275   train_loss = 3.277\n",
      "Epoch   0 Batch  479/17275   train_loss = 2.019\n",
      "Epoch   0 Batch  480/17275   train_loss = 2.006\n",
      "Epoch   0 Batch  481/17275   train_loss = 2.620\n",
      "Epoch   0 Batch  482/17275   train_loss = 4.816\n",
      "Epoch   0 Batch  483/17275   train_loss = 4.647\n",
      "Epoch   0 Batch  484/17275   train_loss = 3.600\n",
      "Epoch   0 Batch  485/17275   train_loss = 1.960\n",
      "Epoch   0 Batch  486/17275   train_loss = 4.936\n",
      "Epoch   0 Batch  487/17275   train_loss = 2.782\n",
      "Epoch   0 Batch  488/17275   train_loss = 2.144\n",
      "Epoch   0 Batch  489/17275   train_loss = 4.632\n",
      "Epoch   0 Batch  490/17275   train_loss = 2.038\n",
      "Epoch   0 Batch  491/17275   train_loss = 3.283\n",
      "Epoch   0 Batch  492/17275   train_loss = 3.047\n",
      "Epoch   0 Batch  493/17275   train_loss = 3.142\n",
      "Epoch   0 Batch  494/17275   train_loss = 2.221\n",
      "Epoch   0 Batch  495/17275   train_loss = 3.092\n",
      "Epoch   0 Batch  496/17275   train_loss = 5.445\n",
      "Epoch   0 Batch  497/17275   train_loss = 4.536\n",
      "Epoch   0 Batch  498/17275   train_loss = 5.596\n",
      "Epoch   0 Batch  499/17275   train_loss = 5.598\n",
      "Epoch   0 Batch  500/17275   train_loss = 4.777\n",
      "Epoch   0 Batch  501/17275   train_loss = 4.528\n",
      "Epoch   0 Batch  502/17275   train_loss = 3.881\n",
      "Epoch   0 Batch  503/17275   train_loss = 2.969\n",
      "Epoch   0 Batch  504/17275   train_loss = 5.111\n",
      "Epoch   0 Batch  505/17275   train_loss = 3.299\n",
      "Epoch   0 Batch  506/17275   train_loss = 7.045\n",
      "Epoch   0 Batch  507/17275   train_loss = 3.945\n",
      "Epoch   0 Batch  508/17275   train_loss = 5.716\n",
      "Epoch   0 Batch  509/17275   train_loss = 3.757\n",
      "Epoch   0 Batch  510/17275   train_loss = 6.441\n",
      "Epoch   0 Batch  511/17275   train_loss = 4.870\n",
      "Epoch   0 Batch  512/17275   train_loss = 4.499\n",
      "Epoch   0 Batch  513/17275   train_loss = 2.147\n",
      "Epoch   0 Batch  514/17275   train_loss = 4.012\n",
      "Epoch   0 Batch  515/17275   train_loss = 4.682\n",
      "Epoch   0 Batch  516/17275   train_loss = 3.057\n",
      "Epoch   0 Batch  517/17275   train_loss = 5.245\n",
      "Epoch   0 Batch  518/17275   train_loss = 5.468\n",
      "Epoch   0 Batch  519/17275   train_loss = 4.494\n",
      "Epoch   0 Batch  520/17275   train_loss = 2.224\n",
      "Epoch   0 Batch  521/17275   train_loss = 5.388\n",
      "Epoch   0 Batch  522/17275   train_loss = 4.785\n",
      "Epoch   0 Batch  523/17275   train_loss = 7.026\n",
      "Epoch   0 Batch  524/17275   train_loss = 5.069\n",
      "Epoch   0 Batch  525/17275   train_loss = 3.034\n",
      "Epoch   0 Batch  526/17275   train_loss = 4.998\n",
      "Epoch   0 Batch  527/17275   train_loss = 7.020\n",
      "Epoch   0 Batch  528/17275   train_loss = 5.341\n",
      "Epoch   0 Batch  529/17275   train_loss = 1.985\n",
      "Epoch   0 Batch  530/17275   train_loss = 4.723\n",
      "Epoch   0 Batch  531/17275   train_loss = 4.883\n",
      "Epoch   0 Batch  532/17275   train_loss = 3.444\n",
      "Epoch   0 Batch  533/17275   train_loss = 2.338\n",
      "Epoch   0 Batch  534/17275   train_loss = 3.154\n",
      "Epoch   0 Batch  535/17275   train_loss = 2.782\n",
      "Epoch   0 Batch  536/17275   train_loss = 4.623\n",
      "Epoch   0 Batch  537/17275   train_loss = 1.985\n",
      "Epoch   0 Batch  538/17275   train_loss = 3.004\n",
      "Epoch   0 Batch  539/17275   train_loss = 3.551\n",
      "Epoch   0 Batch  540/17275   train_loss = 4.851\n",
      "Epoch   0 Batch  541/17275   train_loss = 5.749\n",
      "Epoch   0 Batch  542/17275   train_loss = 3.228\n",
      "Epoch   0 Batch  543/17275   train_loss = 1.977\n",
      "Epoch   0 Batch  544/17275   train_loss = 2.624\n",
      "Epoch   0 Batch  545/17275   train_loss = 2.326\n",
      "Epoch   0 Batch  546/17275   train_loss = 3.137\n",
      "Epoch   0 Batch  547/17275   train_loss = 3.053\n",
      "Epoch   0 Batch  548/17275   train_loss = 5.225\n",
      "Epoch   0 Batch  549/17275   train_loss = 3.334\n",
      "Epoch   0 Batch  550/17275   train_loss = 4.543\n",
      "Epoch   0 Batch  551/17275   train_loss = 4.880\n",
      "Epoch   0 Batch  552/17275   train_loss = 5.257\n",
      "Epoch   0 Batch  553/17275   train_loss = 4.894\n",
      "Epoch   0 Batch  554/17275   train_loss = 4.693\n",
      "Epoch   0 Batch  555/17275   train_loss = 3.684\n",
      "Epoch   0 Batch  556/17275   train_loss = 7.084\n",
      "Epoch   0 Batch  557/17275   train_loss = 2.882\n",
      "Epoch   0 Batch  558/17275   train_loss = 4.686\n",
      "Epoch   0 Batch  559/17275   train_loss = 5.597\n",
      "Epoch   0 Batch  560/17275   train_loss = 2.035\n",
      "Epoch   0 Batch  561/17275   train_loss = 2.979\n",
      "Epoch   0 Batch  562/17275   train_loss = 5.646\n",
      "Epoch   0 Batch  563/17275   train_loss = 2.573\n",
      "Epoch   0 Batch  564/17275   train_loss = 4.549\n",
      "Epoch   0 Batch  565/17275   train_loss = 5.129\n",
      "Epoch   0 Batch  566/17275   train_loss = 4.544\n",
      "Epoch   0 Batch  567/17275   train_loss = 5.941\n",
      "Epoch   0 Batch  568/17275   train_loss = 6.388\n",
      "Epoch   0 Batch  569/17275   train_loss = 5.936\n",
      "Epoch   0 Batch  570/17275   train_loss = 2.016\n",
      "Epoch   0 Batch  571/17275   train_loss = 4.648\n",
      "Epoch   0 Batch  572/17275   train_loss = 5.021\n",
      "Epoch   0 Batch  573/17275   train_loss = 2.491\n",
      "Epoch   0 Batch  574/17275   train_loss = 2.043\n",
      "Epoch   0 Batch  575/17275   train_loss = 5.557\n",
      "Epoch   0 Batch  576/17275   train_loss = 5.058\n",
      "Epoch   0 Batch  577/17275   train_loss = 7.095\n",
      "Epoch   0 Batch  578/17275   train_loss = 6.279\n",
      "Epoch   0 Batch  579/17275   train_loss = 2.710\n",
      "Epoch   0 Batch  580/17275   train_loss = 2.148\n",
      "Epoch   0 Batch  581/17275   train_loss = 4.954\n",
      "Epoch   0 Batch  582/17275   train_loss = 4.962\n",
      "Epoch   0 Batch  583/17275   train_loss = 2.262\n",
      "Epoch   0 Batch  584/17275   train_loss = 1.794\n",
      "Epoch   0 Batch  585/17275   train_loss = 4.974\n",
      "Epoch   0 Batch  586/17275   train_loss = 5.434\n",
      "Epoch   0 Batch  587/17275   train_loss = 4.960\n",
      "Epoch   0 Batch  588/17275   train_loss = 2.469\n",
      "Epoch   0 Batch  589/17275   train_loss = 4.919\n",
      "Epoch   0 Batch  590/17275   train_loss = 3.161\n",
      "Epoch   0 Batch  591/17275   train_loss = 2.242\n",
      "Epoch   0 Batch  592/17275   train_loss = 3.253\n",
      "Epoch   0 Batch  593/17275   train_loss = 4.014\n",
      "Epoch   0 Batch  594/17275   train_loss = 4.395\n",
      "Epoch   0 Batch  595/17275   train_loss = 4.874\n",
      "Epoch   0 Batch  596/17275   train_loss = 4.398\n",
      "Epoch   0 Batch  597/17275   train_loss = 4.695\n",
      "Epoch   0 Batch  598/17275   train_loss = 4.267\n",
      "Epoch   0 Batch  599/17275   train_loss = 1.668\n",
      "Epoch   0 Batch  600/17275   train_loss = 1.887\n",
      "Epoch   0 Batch  601/17275   train_loss = 3.283\n",
      "Epoch   0 Batch  602/17275   train_loss = 4.677\n",
      "Epoch   0 Batch  603/17275   train_loss = 1.860\n",
      "Epoch   0 Batch  604/17275   train_loss = 3.648\n",
      "Epoch   0 Batch  605/17275   train_loss = 4.685\n",
      "Epoch   0 Batch  606/17275   train_loss = 3.396\n",
      "Epoch   0 Batch  607/17275   train_loss = 5.109\n",
      "Epoch   0 Batch  608/17275   train_loss = 3.077\n",
      "Epoch   0 Batch  609/17275   train_loss = 2.503\n",
      "Epoch   0 Batch  610/17275   train_loss = 3.259\n",
      "Epoch   0 Batch  611/17275   train_loss = 4.852\n",
      "Epoch   0 Batch  612/17275   train_loss = 2.351\n",
      "Epoch   0 Batch  613/17275   train_loss = 2.719\n",
      "Epoch   0 Batch  614/17275   train_loss = 5.213\n",
      "Epoch   0 Batch  615/17275   train_loss = 3.047\n",
      "Epoch   0 Batch  616/17275   train_loss = 1.836\n",
      "Epoch   0 Batch  617/17275   train_loss = 3.267\n",
      "Epoch   0 Batch  618/17275   train_loss = 3.754\n",
      "Epoch   0 Batch  619/17275   train_loss = 3.386\n",
      "Epoch   0 Batch  620/17275   train_loss = 6.571\n",
      "Epoch   0 Batch  621/17275   train_loss = 3.667\n",
      "Epoch   0 Batch  622/17275   train_loss = 5.012\n",
      "Epoch   0 Batch  623/17275   train_loss = 4.616\n",
      "Epoch   0 Batch  624/17275   train_loss = 4.918\n",
      "Epoch   0 Batch  625/17275   train_loss = 2.272\n",
      "Epoch   0 Batch  626/17275   train_loss = 2.951\n",
      "Epoch   0 Batch  627/17275   train_loss = 2.882\n",
      "Epoch   0 Batch  628/17275   train_loss = 3.112\n",
      "Epoch   0 Batch  629/17275   train_loss = 7.174\n",
      "Epoch   0 Batch  630/17275   train_loss = 4.809\n",
      "Epoch   0 Batch  631/17275   train_loss = 2.137\n",
      "Epoch   0 Batch  632/17275   train_loss = 2.871\n",
      "Epoch   0 Batch  633/17275   train_loss = 4.429\n",
      "Epoch   0 Batch  634/17275   train_loss = 3.382\n",
      "Epoch   0 Batch  635/17275   train_loss = 5.062\n",
      "Epoch   0 Batch  636/17275   train_loss = 4.576\n",
      "Epoch   0 Batch  637/17275   train_loss = 2.115\n",
      "Epoch   0 Batch  638/17275   train_loss = 3.062\n",
      "Epoch   0 Batch  639/17275   train_loss = 4.095\n",
      "Epoch   0 Batch  640/17275   train_loss = 3.182\n",
      "Epoch   0 Batch  641/17275   train_loss = 7.190\n",
      "Epoch   0 Batch  642/17275   train_loss = 4.631\n",
      "Epoch   0 Batch  643/17275   train_loss = 4.619\n",
      "Epoch   0 Batch  644/17275   train_loss = 6.272\n",
      "Epoch   0 Batch  645/17275   train_loss = 2.063\n",
      "Epoch   0 Batch  646/17275   train_loss = 2.017\n",
      "Epoch   0 Batch  647/17275   train_loss = 2.860\n",
      "Epoch   0 Batch  648/17275   train_loss = 2.897\n",
      "Epoch   0 Batch  649/17275   train_loss = 4.003\n",
      "Epoch   0 Batch  650/17275   train_loss = 1.974\n",
      "Epoch   0 Batch  651/17275   train_loss = 4.672\n",
      "Epoch   0 Batch  652/17275   train_loss = 5.561\n",
      "Epoch   0 Batch  653/17275   train_loss = 7.200\n",
      "Epoch   0 Batch  654/17275   train_loss = 1.921\n",
      "Epoch   0 Batch  655/17275   train_loss = 4.919\n",
      "Epoch   0 Batch  656/17275   train_loss = 5.038\n",
      "Epoch   0 Batch  657/17275   train_loss = 5.249\n",
      "Epoch   0 Batch  658/17275   train_loss = 1.870\n",
      "Epoch   0 Batch  659/17275   train_loss = 2.489\n",
      "Epoch   0 Batch  660/17275   train_loss = 5.066\n",
      "Epoch   0 Batch  661/17275   train_loss = 3.785\n",
      "Epoch   0 Batch  662/17275   train_loss = 2.487\n",
      "Epoch   0 Batch  663/17275   train_loss = 4.829\n",
      "Epoch   0 Batch  664/17275   train_loss = 4.932\n",
      "Epoch   0 Batch  665/17275   train_loss = 5.496\n",
      "Epoch   0 Batch  666/17275   train_loss = 4.022\n",
      "Epoch   0 Batch  667/17275   train_loss = 5.038\n",
      "Epoch   0 Batch  668/17275   train_loss = 4.491\n",
      "Epoch   0 Batch  669/17275   train_loss = 4.557\n",
      "Epoch   0 Batch  670/17275   train_loss = 2.561\n",
      "Epoch   0 Batch  671/17275   train_loss = 3.935\n",
      "Epoch   0 Batch  672/17275   train_loss = 7.210\n",
      "Epoch   0 Batch  673/17275   train_loss = 2.311\n",
      "Epoch   0 Batch  674/17275   train_loss = 4.275\n",
      "Epoch   0 Batch  675/17275   train_loss = 5.727\n",
      "Epoch   0 Batch  676/17275   train_loss = 2.270\n",
      "Epoch   0 Batch  677/17275   train_loss = 4.986\n",
      "Epoch   0 Batch  678/17275   train_loss = 2.050\n",
      "Epoch   0 Batch  679/17275   train_loss = 2.454\n",
      "Epoch   0 Batch  680/17275   train_loss = 3.556\n",
      "Epoch   0 Batch  681/17275   train_loss = 3.460\n",
      "Epoch   0 Batch  682/17275   train_loss = 2.923\n",
      "Epoch   0 Batch  683/17275   train_loss = 4.476\n",
      "Epoch   0 Batch  684/17275   train_loss = 4.120\n",
      "Epoch   0 Batch  685/17275   train_loss = 2.346\n",
      "Epoch   0 Batch  686/17275   train_loss = 2.313\n",
      "Epoch   0 Batch  687/17275   train_loss = 3.772\n",
      "Epoch   0 Batch  688/17275   train_loss = 5.476\n",
      "Epoch   0 Batch  689/17275   train_loss = 2.926\n",
      "Epoch   0 Batch  690/17275   train_loss = 4.982\n",
      "Epoch   0 Batch  691/17275   train_loss = 7.223\n",
      "Epoch   0 Batch  692/17275   train_loss = 2.427\n",
      "Epoch   0 Batch  693/17275   train_loss = 3.001\n",
      "Epoch   0 Batch  694/17275   train_loss = 4.407\n",
      "Epoch   0 Batch  695/17275   train_loss = 2.423\n",
      "Epoch   0 Batch  696/17275   train_loss = 3.357\n",
      "Epoch   0 Batch  697/17275   train_loss = 3.669\n",
      "Epoch   0 Batch  698/17275   train_loss = 4.975\n",
      "Epoch   0 Batch  699/17275   train_loss = 4.195\n",
      "Epoch   0 Batch  700/17275   train_loss = 1.832\n",
      "Epoch   0 Batch  701/17275   train_loss = 1.926\n",
      "Epoch   0 Batch  702/17275   train_loss = 2.911\n",
      "Epoch   0 Batch  703/17275   train_loss = 3.953\n",
      "Epoch   0 Batch  704/17275   train_loss = 4.674\n",
      "Epoch   0 Batch  705/17275   train_loss = 3.961\n",
      "Epoch   0 Batch  706/17275   train_loss = 3.062\n",
      "Epoch   0 Batch  707/17275   train_loss = 3.343\n",
      "Epoch   0 Batch  708/17275   train_loss = 3.147\n",
      "Epoch   0 Batch  709/17275   train_loss = 2.608\n",
      "Epoch   0 Batch  710/17275   train_loss = 3.782\n",
      "Epoch   0 Batch  711/17275   train_loss = 2.158\n",
      "Epoch   0 Batch  712/17275   train_loss = 3.356\n",
      "Epoch   0 Batch  713/17275   train_loss = 2.996\n",
      "Epoch   0 Batch  714/17275   train_loss = 2.370\n",
      "Epoch   0 Batch  715/17275   train_loss = 4.375\n",
      "Epoch   0 Batch  716/17275   train_loss = 2.304\n",
      "Epoch   0 Batch  717/17275   train_loss = 3.977\n",
      "Epoch   0 Batch  718/17275   train_loss = 5.039\n",
      "Epoch   0 Batch  719/17275   train_loss = 3.190\n",
      "Epoch   0 Batch  720/17275   train_loss = 2.060\n",
      "Epoch   0 Batch  721/17275   train_loss = 2.878\n",
      "Epoch   0 Batch  722/17275   train_loss = 3.151\n",
      "Epoch   0 Batch  723/17275   train_loss = 5.101\n",
      "Epoch   0 Batch  724/17275   train_loss = 3.345\n",
      "Epoch   0 Batch  725/17275   train_loss = 2.936\n",
      "Epoch   0 Batch  726/17275   train_loss = 3.111\n",
      "Epoch   0 Batch  727/17275   train_loss = 2.782\n",
      "Epoch   0 Batch  728/17275   train_loss = 2.922\n",
      "Epoch   0 Batch  729/17275   train_loss = 2.104\n",
      "Epoch   0 Batch  730/17275   train_loss = 3.244\n",
      "Epoch   0 Batch  731/17275   train_loss = 2.981\n",
      "Epoch   0 Batch  732/17275   train_loss = 3.084\n",
      "Epoch   0 Batch  733/17275   train_loss = 2.497\n",
      "Epoch   0 Batch  734/17275   train_loss = 4.767\n",
      "Epoch   0 Batch  735/17275   train_loss = 4.637\n",
      "Epoch   0 Batch  736/17275   train_loss = 2.905\n",
      "Epoch   0 Batch  737/17275   train_loss = 3.523\n",
      "Epoch   0 Batch  738/17275   train_loss = 4.313\n",
      "Epoch   0 Batch  739/17275   train_loss = 4.637\n",
      "Epoch   0 Batch  740/17275   train_loss = 4.786\n",
      "Epoch   0 Batch  741/17275   train_loss = 5.161\n",
      "Epoch   0 Batch  742/17275   train_loss = 3.470\n",
      "Epoch   0 Batch  743/17275   train_loss = 3.745\n",
      "Epoch   0 Batch  744/17275   train_loss = 2.021\n",
      "Epoch   0 Batch  745/17275   train_loss = 2.479\n",
      "Epoch   0 Batch  746/17275   train_loss = 2.453\n",
      "Epoch   0 Batch  747/17275   train_loss = 5.852\n",
      "Epoch   0 Batch  748/17275   train_loss = 3.699\n",
      "Epoch   0 Batch  749/17275   train_loss = 5.183\n",
      "Epoch   0 Batch  750/17275   train_loss = 5.164\n",
      "Epoch   0 Batch  751/17275   train_loss = 7.331\n",
      "Epoch   0 Batch  752/17275   train_loss = 4.355\n",
      "Epoch   0 Batch  753/17275   train_loss = 3.257\n",
      "Epoch   0 Batch  754/17275   train_loss = 7.324\n",
      "Epoch   0 Batch  755/17275   train_loss = 4.609\n",
      "Epoch   0 Batch  756/17275   train_loss = 2.954\n",
      "Epoch   0 Batch  757/17275   train_loss = 4.113\n",
      "Epoch   0 Batch  758/17275   train_loss = 3.962\n",
      "Epoch   0 Batch  759/17275   train_loss = 5.342\n",
      "Epoch   0 Batch  760/17275   train_loss = 3.467\n",
      "Epoch   0 Batch  761/17275   train_loss = 2.536\n",
      "Epoch   0 Batch  762/17275   train_loss = 2.342\n",
      "Epoch   0 Batch  763/17275   train_loss = 4.322\n",
      "Epoch   0 Batch  764/17275   train_loss = 4.867\n",
      "Epoch   0 Batch  765/17275   train_loss = 5.279\n",
      "Epoch   0 Batch  766/17275   train_loss = 4.860\n",
      "Epoch   0 Batch  767/17275   train_loss = 4.497\n",
      "Epoch   0 Batch  768/17275   train_loss = 2.007\n",
      "Epoch   0 Batch  769/17275   train_loss = 5.066\n",
      "Epoch   0 Batch  770/17275   train_loss = 2.856\n",
      "Epoch   0 Batch  771/17275   train_loss = 3.576\n",
      "Epoch   0 Batch  772/17275   train_loss = 5.263\n",
      "Epoch   0 Batch  773/17275   train_loss = 7.304\n",
      "Epoch   0 Batch  774/17275   train_loss = 2.939\n",
      "Epoch   0 Batch  775/17275   train_loss = 3.469\n",
      "Epoch   0 Batch  776/17275   train_loss = 2.020\n",
      "Epoch   0 Batch  777/17275   train_loss = 6.112\n",
      "Epoch   0 Batch  778/17275   train_loss = 2.524\n",
      "Epoch   0 Batch  779/17275   train_loss = 5.045\n",
      "Epoch   0 Batch  780/17275   train_loss = 4.799\n",
      "Epoch   0 Batch  781/17275   train_loss = 3.302\n",
      "Epoch   0 Batch  782/17275   train_loss = 3.781\n",
      "Epoch   0 Batch  783/17275   train_loss = 2.489\n",
      "Epoch   0 Batch  784/17275   train_loss = 4.665\n",
      "Epoch   0 Batch  785/17275   train_loss = 4.775\n",
      "Epoch   0 Batch  786/17275   train_loss = 3.438\n",
      "Epoch   0 Batch  787/17275   train_loss = 7.306\n",
      "Epoch   0 Batch  788/17275   train_loss = 5.389\n",
      "Epoch   0 Batch  789/17275   train_loss = 2.017\n",
      "Epoch   0 Batch  790/17275   train_loss = 2.689\n",
      "Epoch   0 Batch  791/17275   train_loss = 3.408\n",
      "Epoch   0 Batch  792/17275   train_loss = 4.733\n",
      "Epoch   0 Batch  793/17275   train_loss = 4.910\n",
      "Epoch   0 Batch  794/17275   train_loss = 2.727\n",
      "Epoch   0 Batch  795/17275   train_loss = 3.523\n",
      "Epoch   0 Batch  796/17275   train_loss = 4.878\n",
      "Epoch   0 Batch  797/17275   train_loss = 2.261\n",
      "Epoch   0 Batch  798/17275   train_loss = 5.511\n",
      "Epoch   0 Batch  799/17275   train_loss = 4.714\n",
      "Epoch   0 Batch  800/17275   train_loss = 5.180\n",
      "Epoch   0 Batch  801/17275   train_loss = 4.685\n",
      "Epoch   0 Batch  802/17275   train_loss = 2.284\n",
      "Epoch   0 Batch  803/17275   train_loss = 3.978\n",
      "Epoch   0 Batch  804/17275   train_loss = 3.466\n",
      "Epoch   0 Batch  805/17275   train_loss = 3.784\n",
      "Epoch   0 Batch  806/17275   train_loss = 6.007\n",
      "Epoch   0 Batch  807/17275   train_loss = 5.732\n",
      "Epoch   0 Batch  808/17275   train_loss = 2.653\n",
      "Epoch   0 Batch  809/17275   train_loss = 5.074\n",
      "Epoch   0 Batch  810/17275   train_loss = 4.432\n",
      "Epoch   0 Batch  811/17275   train_loss = 3.392\n",
      "Epoch   0 Batch  812/17275   train_loss = 4.703\n",
      "Epoch   0 Batch  813/17275   train_loss = 5.227\n",
      "Epoch   0 Batch  814/17275   train_loss = 4.706\n",
      "Epoch   0 Batch  815/17275   train_loss = 2.048\n",
      "Epoch   0 Batch  816/17275   train_loss = 4.049\n",
      "Epoch   0 Batch  817/17275   train_loss = 6.097\n",
      "Epoch   0 Batch  818/17275   train_loss = 3.266\n",
      "Epoch   0 Batch  819/17275   train_loss = 3.828\n",
      "Epoch   0 Batch  820/17275   train_loss = 4.826\n",
      "Epoch   0 Batch  821/17275   train_loss = 2.208\n",
      "Epoch   0 Batch  822/17275   train_loss = 2.480\n",
      "Epoch   0 Batch  823/17275   train_loss = 3.828\n",
      "Epoch   0 Batch  824/17275   train_loss = 2.958\n",
      "Epoch   0 Batch  825/17275   train_loss = 5.179\n",
      "Epoch   0 Batch  826/17275   train_loss = 5.379\n",
      "Epoch   0 Batch  827/17275   train_loss = 6.224\n",
      "Epoch   0 Batch  828/17275   train_loss = 4.698\n",
      "Epoch   0 Batch  829/17275   train_loss = 2.058\n",
      "Epoch   0 Batch  830/17275   train_loss = 5.128\n",
      "Epoch   0 Batch  831/17275   train_loss = 2.026\n",
      "Epoch   0 Batch  832/17275   train_loss = 3.750\n",
      "Epoch   0 Batch  833/17275   train_loss = 5.033\n",
      "Epoch   0 Batch  834/17275   train_loss = 3.058\n",
      "Epoch   0 Batch  835/17275   train_loss = 4.766\n",
      "Epoch   0 Batch  836/17275   train_loss = 3.258\n",
      "Epoch   0 Batch  837/17275   train_loss = 4.785\n",
      "Epoch   0 Batch  838/17275   train_loss = 4.864\n",
      "Epoch   0 Batch  839/17275   train_loss = 2.267\n",
      "Epoch   0 Batch  840/17275   train_loss = 7.344\n",
      "Epoch   0 Batch  841/17275   train_loss = 5.039\n",
      "Epoch   0 Batch  842/17275   train_loss = 2.259\n",
      "Epoch   0 Batch  843/17275   train_loss = 4.989\n",
      "Epoch   0 Batch  844/17275   train_loss = 5.132\n",
      "Epoch   0 Batch  845/17275   train_loss = 3.688\n",
      "Epoch   0 Batch  846/17275   train_loss = 7.350\n",
      "Epoch   0 Batch  847/17275   train_loss = 1.966\n",
      "Epoch   0 Batch  848/17275   train_loss = 5.751\n",
      "Epoch   0 Batch  849/17275   train_loss = 4.852\n",
      "Epoch   0 Batch  850/17275   train_loss = 2.231\n",
      "Epoch   0 Batch  851/17275   train_loss = 5.400\n",
      "Epoch   0 Batch  852/17275   train_loss = 5.628\n",
      "Epoch   0 Batch  853/17275   train_loss = 5.234\n",
      "Epoch   0 Batch  854/17275   train_loss = 1.932\n",
      "Epoch   0 Batch  855/17275   train_loss = 3.221\n",
      "Epoch   0 Batch  856/17275   train_loss = 5.130\n",
      "Epoch   0 Batch  857/17275   train_loss = 4.262\n",
      "Epoch   0 Batch  858/17275   train_loss = 7.349\n",
      "Epoch   0 Batch  859/17275   train_loss = 4.600\n",
      "Epoch   0 Batch  860/17275   train_loss = 2.142\n",
      "Epoch   0 Batch  861/17275   train_loss = 3.104\n",
      "Epoch   0 Batch  862/17275   train_loss = 5.201\n",
      "Epoch   0 Batch  863/17275   train_loss = 4.907\n",
      "Epoch   0 Batch  864/17275   train_loss = 2.888\n",
      "Epoch   0 Batch  865/17275   train_loss = 4.601\n",
      "Epoch   0 Batch  866/17275   train_loss = 2.581\n",
      "Epoch   0 Batch  867/17275   train_loss = 4.934\n",
      "Epoch   0 Batch  868/17275   train_loss = 5.195\n",
      "Epoch   0 Batch  869/17275   train_loss = 1.850\n",
      "Epoch   0 Batch  870/17275   train_loss = 4.817\n",
      "Epoch   0 Batch  871/17275   train_loss = 4.691\n",
      "Epoch   0 Batch  872/17275   train_loss = 1.823\n",
      "Epoch   0 Batch  873/17275   train_loss = 4.263\n",
      "Epoch   0 Batch  874/17275   train_loss = 2.848\n",
      "Epoch   0 Batch  875/17275   train_loss = 5.004\n",
      "Epoch   0 Batch  876/17275   train_loss = 2.894\n",
      "Epoch   0 Batch  877/17275   train_loss = 2.820\n",
      "Epoch   0 Batch  878/17275   train_loss = 5.132\n",
      "Epoch   0 Batch  879/17275   train_loss = 4.192\n",
      "Epoch   0 Batch  880/17275   train_loss = 3.194\n",
      "Epoch   0 Batch  881/17275   train_loss = 2.898\n",
      "Epoch   0 Batch  882/17275   train_loss = 2.208\n",
      "Epoch   0 Batch  883/17275   train_loss = 3.363\n",
      "Epoch   0 Batch  884/17275   train_loss = 4.872\n",
      "Epoch   0 Batch  885/17275   train_loss = 3.582\n",
      "Epoch   0 Batch  886/17275   train_loss = 2.426\n",
      "Epoch   0 Batch  887/17275   train_loss = 5.744\n",
      "Epoch   0 Batch  888/17275   train_loss = 4.048\n",
      "Epoch   0 Batch  889/17275   train_loss = 3.297\n",
      "Epoch   0 Batch  890/17275   train_loss = 3.098\n",
      "Epoch   0 Batch  891/17275   train_loss = 3.490\n",
      "Epoch   0 Batch  892/17275   train_loss = 4.292\n",
      "Epoch   0 Batch  893/17275   train_loss = 2.413\n",
      "Epoch   0 Batch  894/17275   train_loss = 3.407\n",
      "Epoch   0 Batch  895/17275   train_loss = 6.506\n",
      "Epoch   0 Batch  896/17275   train_loss = 2.113\n",
      "Epoch   0 Batch  897/17275   train_loss = 4.146\n",
      "Epoch   0 Batch  898/17275   train_loss = 5.020\n",
      "Epoch   0 Batch  899/17275   train_loss = 5.729\n",
      "Epoch   0 Batch  900/17275   train_loss = 4.793\n",
      "Epoch   0 Batch  901/17275   train_loss = 5.166\n",
      "Epoch   0 Batch  902/17275   train_loss = 4.966\n",
      "Epoch   0 Batch  903/17275   train_loss = 1.908\n",
      "Epoch   0 Batch  904/17275   train_loss = 2.923\n",
      "Epoch   0 Batch  905/17275   train_loss = 3.220\n",
      "Epoch   0 Batch  906/17275   train_loss = 2.973\n",
      "Epoch   0 Batch  907/17275   train_loss = 4.055\n",
      "Epoch   0 Batch  908/17275   train_loss = 4.640\n",
      "Epoch   0 Batch  909/17275   train_loss = 3.702\n",
      "Epoch   0 Batch  910/17275   train_loss = 2.246\n",
      "Epoch   0 Batch  911/17275   train_loss = 4.381\n",
      "Epoch   0 Batch  912/17275   train_loss = 2.984\n",
      "Epoch   0 Batch  913/17275   train_loss = 3.459\n",
      "Epoch   0 Batch  914/17275   train_loss = 6.582\n",
      "Epoch   0 Batch  915/17275   train_loss = 3.154\n",
      "Epoch   0 Batch  916/17275   train_loss = 3.683\n",
      "Epoch   0 Batch  917/17275   train_loss = 5.232\n",
      "Epoch   0 Batch  918/17275   train_loss = 6.454\n",
      "Epoch   0 Batch  919/17275   train_loss = 4.634\n",
      "Epoch   0 Batch  920/17275   train_loss = 2.191\n",
      "Epoch   0 Batch  921/17275   train_loss = 3.131\n",
      "Epoch   0 Batch  922/17275   train_loss = 3.433\n",
      "Epoch   0 Batch  923/17275   train_loss = 5.403\n",
      "Epoch   0 Batch  924/17275   train_loss = 3.263\n",
      "Epoch   0 Batch  925/17275   train_loss = 4.212\n",
      "Epoch   0 Batch  926/17275   train_loss = 3.637\n",
      "Epoch   0 Batch  927/17275   train_loss = 7.387\n",
      "Epoch   0 Batch  928/17275   train_loss = 1.956\n",
      "Epoch   0 Batch  929/17275   train_loss = 3.215\n",
      "Epoch   0 Batch  930/17275   train_loss = 5.039\n",
      "Epoch   0 Batch  931/17275   train_loss = 4.188\n",
      "Epoch   0 Batch  932/17275   train_loss = 4.833\n",
      "Epoch   0 Batch  933/17275   train_loss = 3.471\n",
      "Epoch   0 Batch  934/17275   train_loss = 4.638\n",
      "Epoch   0 Batch  935/17275   train_loss = 3.556\n",
      "Epoch   0 Batch  936/17275   train_loss = 3.355\n",
      "Epoch   0 Batch  937/17275   train_loss = 5.304\n",
      "Epoch   0 Batch  938/17275   train_loss = 2.268\n",
      "Epoch   0 Batch  939/17275   train_loss = 2.240\n",
      "Epoch   0 Batch  940/17275   train_loss = 5.925\n",
      "Epoch   0 Batch  941/17275   train_loss = 1.975\n",
      "Epoch   0 Batch  942/17275   train_loss = 3.456\n",
      "Epoch   0 Batch  943/17275   train_loss = 5.209\n",
      "Epoch   0 Batch  944/17275   train_loss = 2.943\n",
      "Epoch   0 Batch  945/17275   train_loss = 2.804\n",
      "Epoch   0 Batch  946/17275   train_loss = 5.125\n",
      "Epoch   0 Batch  947/17275   train_loss = 5.178\n",
      "Epoch   0 Batch  948/17275   train_loss = 7.410\n",
      "Epoch   0 Batch  949/17275   train_loss = 2.612\n",
      "Epoch   0 Batch  950/17275   train_loss = 3.724\n",
      "Epoch   0 Batch  951/17275   train_loss = 5.179\n",
      "Epoch   0 Batch  952/17275   train_loss = 4.639\n",
      "Epoch   0 Batch  953/17275   train_loss = 2.240\n",
      "Epoch   0 Batch  954/17275   train_loss = 5.402\n",
      "Epoch   0 Batch  955/17275   train_loss = 2.359\n",
      "Epoch   0 Batch  956/17275   train_loss = 2.699\n",
      "Epoch   0 Batch  957/17275   train_loss = 2.601\n",
      "Epoch   0 Batch  958/17275   train_loss = 3.309\n",
      "Epoch   0 Batch  959/17275   train_loss = 5.023\n",
      "Epoch   0 Batch  960/17275   train_loss = 2.595\n",
      "Epoch   0 Batch  961/17275   train_loss = 3.253\n",
      "Epoch   0 Batch  962/17275   train_loss = 4.123\n",
      "Epoch   0 Batch  963/17275   train_loss = 3.080\n",
      "Epoch   0 Batch  964/17275   train_loss = 5.256\n",
      "Epoch   0 Batch  965/17275   train_loss = 5.396\n",
      "Epoch   0 Batch  966/17275   train_loss = 3.498\n",
      "Epoch   0 Batch  967/17275   train_loss = 3.204\n",
      "Epoch   0 Batch  968/17275   train_loss = 2.882\n",
      "Epoch   0 Batch  969/17275   train_loss = 2.981\n",
      "Epoch   0 Batch  970/17275   train_loss = 2.450\n",
      "Epoch   0 Batch  971/17275   train_loss = 2.249\n",
      "Epoch   0 Batch  972/17275   train_loss = 3.939\n",
      "Epoch   0 Batch  973/17275   train_loss = 5.827\n",
      "Epoch   0 Batch  974/17275   train_loss = 5.809\n",
      "Epoch   0 Batch  975/17275   train_loss = 5.193\n",
      "Epoch   0 Batch  976/17275   train_loss = 7.461\n",
      "Epoch   0 Batch  977/17275   train_loss = 3.264\n",
      "Epoch   0 Batch  978/17275   train_loss = 2.045\n",
      "Epoch   0 Batch  979/17275   train_loss = 2.701\n",
      "Epoch   0 Batch  980/17275   train_loss = 3.767\n",
      "Epoch   0 Batch  981/17275   train_loss = 3.202\n",
      "Epoch   0 Batch  982/17275   train_loss = 3.189\n",
      "Epoch   0 Batch  983/17275   train_loss = 3.170\n",
      "Epoch   0 Batch  984/17275   train_loss = 7.458\n",
      "Epoch   0 Batch  985/17275   train_loss = 5.652\n",
      "Epoch   0 Batch  986/17275   train_loss = 2.559\n",
      "Epoch   0 Batch  987/17275   train_loss = 4.812\n",
      "Epoch   0 Batch  988/17275   train_loss = 2.775\n",
      "Epoch   0 Batch  989/17275   train_loss = 2.636\n",
      "Epoch   0 Batch  990/17275   train_loss = 7.453\n",
      "Epoch   0 Batch  991/17275   train_loss = 4.210\n",
      "Epoch   0 Batch  992/17275   train_loss = 3.741\n",
      "Epoch   0 Batch  993/17275   train_loss = 4.904\n",
      "Epoch   0 Batch  994/17275   train_loss = 2.042\n",
      "Epoch   0 Batch  995/17275   train_loss = 2.557\n",
      "Epoch   0 Batch  996/17275   train_loss = 5.863\n",
      "Epoch   0 Batch  997/17275   train_loss = 3.733\n",
      "Epoch   0 Batch  998/17275   train_loss = 3.155\n",
      "Epoch   0 Batch  999/17275   train_loss = 5.543\n",
      "Epoch   0 Batch 1000/17275   train_loss = 5.271\n",
      "Epoch   0 Batch 1001/17275   train_loss = 2.894\n",
      "Epoch   0 Batch 1002/17275   train_loss = 4.686\n",
      "Epoch   0 Batch 1003/17275   train_loss = 2.709\n",
      "Epoch   0 Batch 1004/17275   train_loss = 4.948\n",
      "Epoch   0 Batch 1005/17275   train_loss = 4.956\n",
      "Epoch   0 Batch 1006/17275   train_loss = 2.442\n",
      "Epoch   0 Batch 1007/17275   train_loss = 4.684\n",
      "Epoch   0 Batch 1008/17275   train_loss = 5.229\n",
      "Epoch   0 Batch 1009/17275   train_loss = 5.096\n",
      "Epoch   0 Batch 1010/17275   train_loss = 2.476\n",
      "Epoch   0 Batch 1011/17275   train_loss = 3.287\n",
      "Epoch   0 Batch 1012/17275   train_loss = 3.797\n",
      "Epoch   0 Batch 1013/17275   train_loss = 5.052\n",
      "Epoch   0 Batch 1014/17275   train_loss = 5.173\n",
      "Epoch   0 Batch 1015/17275   train_loss = 7.473\n",
      "Epoch   0 Batch 1016/17275   train_loss = 4.702\n",
      "Epoch   0 Batch 1017/17275   train_loss = 3.573\n",
      "Epoch   0 Batch 1018/17275   train_loss = 4.647\n",
      "Epoch   0 Batch 1019/17275   train_loss = 5.982\n",
      "Epoch   0 Batch 1020/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 1021/17275   train_loss = 2.588\n",
      "Epoch   0 Batch 1022/17275   train_loss = 2.384\n",
      "Epoch   0 Batch 1023/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 1024/17275   train_loss = 4.152\n",
      "Epoch   0 Batch 1025/17275   train_loss = 5.026\n",
      "Epoch   0 Batch 1026/17275   train_loss = 5.007\n",
      "Epoch   0 Batch 1027/17275   train_loss = 4.693\n",
      "Epoch   0 Batch 1028/17275   train_loss = 2.264\n",
      "Epoch   0 Batch 1029/17275   train_loss = 2.908\n",
      "Epoch   0 Batch 1030/17275   train_loss = 2.848\n",
      "Epoch   0 Batch 1031/17275   train_loss = 2.660\n",
      "Epoch   0 Batch 1032/17275   train_loss = 7.483\n",
      "Epoch   0 Batch 1033/17275   train_loss = 3.894\n",
      "Epoch   0 Batch 1034/17275   train_loss = 3.792\n",
      "Epoch   0 Batch 1035/17275   train_loss = 3.236\n",
      "Epoch   0 Batch 1036/17275   train_loss = 5.132\n",
      "Epoch   0 Batch 1037/17275   train_loss = 4.014\n",
      "Epoch   0 Batch 1038/17275   train_loss = 2.481\n",
      "Epoch   0 Batch 1039/17275   train_loss = 5.008\n",
      "Epoch   0 Batch 1040/17275   train_loss = 2.983\n",
      "Epoch   0 Batch 1041/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 1042/17275   train_loss = 4.890\n",
      "Epoch   0 Batch 1043/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 1044/17275   train_loss = 2.247\n",
      "Epoch   0 Batch 1045/17275   train_loss = 5.066\n",
      "Epoch   0 Batch 1046/17275   train_loss = 3.263\n",
      "Epoch   0 Batch 1047/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 1048/17275   train_loss = 2.411\n",
      "Epoch   0 Batch 1049/17275   train_loss = 2.375\n",
      "Epoch   0 Batch 1050/17275   train_loss = 4.663\n",
      "Epoch   0 Batch 1051/17275   train_loss = 4.853\n",
      "Epoch   0 Batch 1052/17275   train_loss = 2.217\n",
      "Epoch   0 Batch 1053/17275   train_loss = 3.274\n",
      "Epoch   0 Batch 1054/17275   train_loss = 7.514\n",
      "Epoch   0 Batch 1055/17275   train_loss = 5.110\n",
      "Epoch   0 Batch 1056/17275   train_loss = 4.522\n",
      "Epoch   0 Batch 1057/17275   train_loss = 2.841\n",
      "Epoch   0 Batch 1058/17275   train_loss = 2.293\n",
      "Epoch   0 Batch 1059/17275   train_loss = 2.539\n",
      "Epoch   0 Batch 1060/17275   train_loss = 3.122\n",
      "Epoch   0 Batch 1061/17275   train_loss = 5.584\n",
      "Epoch   0 Batch 1062/17275   train_loss = 3.635\n",
      "Epoch   0 Batch 1063/17275   train_loss = 5.386\n",
      "Epoch   0 Batch 1064/17275   train_loss = 2.495\n",
      "Epoch   0 Batch 1065/17275   train_loss = 2.519\n",
      "Epoch   0 Batch 1066/17275   train_loss = 5.565\n",
      "Epoch   0 Batch 1067/17275   train_loss = 1.884\n",
      "Epoch   0 Batch 1068/17275   train_loss = 2.000\n",
      "Epoch   0 Batch 1069/17275   train_loss = 2.562\n",
      "Epoch   0 Batch 1070/17275   train_loss = 5.104\n",
      "Epoch   0 Batch 1071/17275   train_loss = 2.914\n",
      "Epoch   0 Batch 1072/17275   train_loss = 4.070\n",
      "Epoch   0 Batch 1073/17275   train_loss = 6.081\n",
      "Epoch   0 Batch 1074/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 1075/17275   train_loss = 5.066\n",
      "Epoch   0 Batch 1076/17275   train_loss = 4.565\n",
      "Epoch   0 Batch 1077/17275   train_loss = 4.706\n",
      "Epoch   0 Batch 1078/17275   train_loss = 2.085\n",
      "Epoch   0 Batch 1079/17275   train_loss = 2.501\n",
      "Epoch   0 Batch 1080/17275   train_loss = 2.610\n",
      "Epoch   0 Batch 1081/17275   train_loss = 7.552\n",
      "Epoch   0 Batch 1082/17275   train_loss = 2.244\n",
      "Epoch   0 Batch 1083/17275   train_loss = 2.555\n",
      "Epoch   0 Batch 1084/17275   train_loss = 3.861\n",
      "Epoch   0 Batch 1085/17275   train_loss = 2.777\n",
      "Epoch   0 Batch 1086/17275   train_loss = 5.515\n",
      "Epoch   0 Batch 1087/17275   train_loss = 4.663\n",
      "Epoch   0 Batch 1088/17275   train_loss = 5.201\n",
      "Epoch   0 Batch 1089/17275   train_loss = 4.748\n",
      "Epoch   0 Batch 1090/17275   train_loss = 7.555\n",
      "Epoch   0 Batch 1091/17275   train_loss = 4.744\n",
      "Epoch   0 Batch 1092/17275   train_loss = 2.144\n",
      "Epoch   0 Batch 1093/17275   train_loss = 3.450\n",
      "Epoch   0 Batch 1094/17275   train_loss = 4.902\n",
      "Epoch   0 Batch 1095/17275   train_loss = 3.212\n",
      "Epoch   0 Batch 1096/17275   train_loss = 5.092\n",
      "Epoch   0 Batch 1097/17275   train_loss = 6.066\n",
      "Epoch   0 Batch 1098/17275   train_loss = 6.848\n",
      "Epoch   0 Batch 1099/17275   train_loss = 5.076\n",
      "Epoch   0 Batch 1100/17275   train_loss = 3.964\n",
      "Epoch   0 Batch 1101/17275   train_loss = 4.870\n",
      "Epoch   0 Batch 1102/17275   train_loss = 4.872\n",
      "Epoch   0 Batch 1103/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 1104/17275   train_loss = 5.470\n",
      "Epoch   0 Batch 1105/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 1106/17275   train_loss = 5.474\n",
      "Epoch   0 Batch 1107/17275   train_loss = 5.419\n",
      "Epoch   0 Batch 1108/17275   train_loss = 4.053\n",
      "Epoch   0 Batch 1109/17275   train_loss = 5.023\n",
      "Epoch   0 Batch 1110/17275   train_loss = 5.280\n",
      "Epoch   0 Batch 1111/17275   train_loss = 5.004\n",
      "Epoch   0 Batch 1112/17275   train_loss = 7.535\n",
      "Epoch   0 Batch 1113/17275   train_loss = 6.329\n",
      "Epoch   0 Batch 1114/17275   train_loss = 2.007\n",
      "Epoch   0 Batch 1115/17275   train_loss = 2.950\n",
      "Epoch   0 Batch 1116/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 1117/17275   train_loss = 4.795\n",
      "Epoch   0 Batch 1118/17275   train_loss = 2.885\n",
      "Epoch   0 Batch 1119/17275   train_loss = 5.087\n",
      "Epoch   0 Batch 1120/17275   train_loss = 7.535\n",
      "Epoch   0 Batch 1121/17275   train_loss = 4.783\n",
      "Epoch   0 Batch 1122/17275   train_loss = 3.049\n",
      "Epoch   0 Batch 1123/17275   train_loss = 4.772\n",
      "Epoch   0 Batch 1124/17275   train_loss = 2.388\n",
      "Epoch   0 Batch 1125/17275   train_loss = 5.171\n",
      "Epoch   0 Batch 1126/17275   train_loss = 3.635\n",
      "Epoch   0 Batch 1127/17275   train_loss = 3.931\n",
      "Epoch   0 Batch 1128/17275   train_loss = 3.029\n",
      "Epoch   0 Batch 1129/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 1130/17275   train_loss = 3.323\n",
      "Epoch   0 Batch 1131/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 1132/17275   train_loss = 3.228\n",
      "Epoch   0 Batch 1133/17275   train_loss = 5.136\n",
      "Epoch   0 Batch 1134/17275   train_loss = 3.672\n",
      "Epoch   0 Batch 1135/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 1136/17275   train_loss = 3.080\n",
      "Epoch   0 Batch 1137/17275   train_loss = 3.497\n",
      "Epoch   0 Batch 1138/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 1139/17275   train_loss = 5.414\n",
      "Epoch   0 Batch 1140/17275   train_loss = 3.135\n",
      "Epoch   0 Batch 1141/17275   train_loss = 5.710\n",
      "Epoch   0 Batch 1142/17275   train_loss = 3.555\n",
      "Epoch   0 Batch 1143/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 1144/17275   train_loss = 4.909\n",
      "Epoch   0 Batch 1145/17275   train_loss = 4.467\n",
      "Epoch   0 Batch 1146/17275   train_loss = 4.465\n",
      "Epoch   0 Batch 1147/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 1148/17275   train_loss = 4.731\n",
      "Epoch   0 Batch 1149/17275   train_loss = 4.207\n",
      "Epoch   0 Batch 1150/17275   train_loss = 2.171\n",
      "Epoch   0 Batch 1151/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 1152/17275   train_loss = 2.288\n",
      "Epoch   0 Batch 1153/17275   train_loss = 7.546\n",
      "Epoch   0 Batch 1154/17275   train_loss = 5.190\n",
      "Epoch   0 Batch 1155/17275   train_loss = 2.835\n",
      "Epoch   0 Batch 1156/17275   train_loss = 2.820\n",
      "Epoch   0 Batch 1157/17275   train_loss = 2.481\n",
      "Epoch   0 Batch 1158/17275   train_loss = 6.871\n",
      "Epoch   0 Batch 1159/17275   train_loss = 4.789\n",
      "Epoch   0 Batch 1160/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 1161/17275   train_loss = 4.217\n",
      "Epoch   0 Batch 1162/17275   train_loss = 4.815\n",
      "Epoch   0 Batch 1163/17275   train_loss = 3.396\n",
      "Epoch   0 Batch 1164/17275   train_loss = 3.917\n",
      "Epoch   0 Batch 1165/17275   train_loss = 4.797\n",
      "Epoch   0 Batch 1166/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 1167/17275   train_loss = 3.700\n",
      "Epoch   0 Batch 1168/17275   train_loss = 4.776\n",
      "Epoch   0 Batch 1169/17275   train_loss = 4.251\n",
      "Epoch   0 Batch 1170/17275   train_loss = 3.301\n",
      "Epoch   0 Batch 1171/17275   train_loss = 3.682\n",
      "Epoch   0 Batch 1172/17275   train_loss = 5.517\n",
      "Epoch   0 Batch 1173/17275   train_loss = 3.726\n",
      "Epoch   0 Batch 1174/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 1175/17275   train_loss = 4.560\n",
      "Epoch   0 Batch 1176/17275   train_loss = 3.748\n",
      "Epoch   0 Batch 1177/17275   train_loss = 2.678\n",
      "Epoch   0 Batch 1178/17275   train_loss = 5.758\n",
      "Epoch   0 Batch 1179/17275   train_loss = 4.265\n",
      "Epoch   0 Batch 1180/17275   train_loss = 3.750\n",
      "Epoch   0 Batch 1181/17275   train_loss = 2.846\n",
      "Epoch   0 Batch 1182/17275   train_loss = 5.514\n",
      "Epoch   0 Batch 1183/17275   train_loss = 5.054\n",
      "Epoch   0 Batch 1184/17275   train_loss = 6.128\n",
      "Epoch   0 Batch 1185/17275   train_loss = 2.502\n",
      "Epoch   0 Batch 1186/17275   train_loss = 3.032\n",
      "Epoch   0 Batch 1187/17275   train_loss = 5.023\n",
      "Epoch   0 Batch 1188/17275   train_loss = 3.639\n",
      "Epoch   0 Batch 1189/17275   train_loss = 3.638\n",
      "Epoch   0 Batch 1190/17275   train_loss = 2.468\n",
      "Epoch   0 Batch 1191/17275   train_loss = 2.825\n",
      "Epoch   0 Batch 1192/17275   train_loss = 7.067\n",
      "Epoch   0 Batch 1193/17275   train_loss = 3.397\n",
      "Epoch   0 Batch 1194/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 1195/17275   train_loss = 3.904\n",
      "Epoch   0 Batch 1196/17275   train_loss = 3.458\n",
      "Epoch   0 Batch 1197/17275   train_loss = 3.853\n",
      "Epoch   0 Batch 1198/17275   train_loss = 3.266\n",
      "Epoch   0 Batch 1199/17275   train_loss = 4.248\n",
      "Epoch   0 Batch 1200/17275   train_loss = 7.592\n",
      "Epoch   0 Batch 1201/17275   train_loss = 5.471\n",
      "Epoch   0 Batch 1202/17275   train_loss = 2.087\n",
      "Epoch   0 Batch 1203/17275   train_loss = 3.823\n",
      "Epoch   0 Batch 1204/17275   train_loss = 6.598\n",
      "Epoch   0 Batch 1205/17275   train_loss = 2.412\n",
      "Epoch   0 Batch 1206/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 1207/17275   train_loss = 3.195\n",
      "Epoch   0 Batch 1208/17275   train_loss = 5.526\n",
      "Epoch   0 Batch 1209/17275   train_loss = 7.589\n",
      "Epoch   0 Batch 1210/17275   train_loss = 5.238\n",
      "Epoch   0 Batch 1211/17275   train_loss = 4.351\n",
      "Epoch   0 Batch 1212/17275   train_loss = 3.647\n",
      "Epoch   0 Batch 1213/17275   train_loss = 7.576\n",
      "Epoch   0 Batch 1214/17275   train_loss = 2.085\n",
      "Epoch   0 Batch 1215/17275   train_loss = 2.900\n",
      "Epoch   0 Batch 1216/17275   train_loss = 4.209\n",
      "Epoch   0 Batch 1217/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 1218/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 1219/17275   train_loss = 5.449\n",
      "Epoch   0 Batch 1220/17275   train_loss = 2.057\n",
      "Epoch   0 Batch 1221/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 1222/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 1223/17275   train_loss = 3.300\n",
      "Epoch   0 Batch 1224/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 1225/17275   train_loss = 4.290\n",
      "Epoch   0 Batch 1226/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 1227/17275   train_loss = 4.785\n",
      "Epoch   0 Batch 1228/17275   train_loss = 4.772\n",
      "Epoch   0 Batch 1229/17275   train_loss = 4.351\n",
      "Epoch   0 Batch 1230/17275   train_loss = 1.943\n",
      "Epoch   0 Batch 1231/17275   train_loss = 4.739\n",
      "Epoch   0 Batch 1232/17275   train_loss = 1.964\n",
      "Epoch   0 Batch 1233/17275   train_loss = 2.696\n",
      "Epoch   0 Batch 1234/17275   train_loss = 3.042\n",
      "Epoch   0 Batch 1235/17275   train_loss = 3.209\n",
      "Epoch   0 Batch 1236/17275   train_loss = 2.962\n",
      "Epoch   0 Batch 1237/17275   train_loss = 2.665\n",
      "Epoch   0 Batch 1238/17275   train_loss = 3.627\n",
      "Epoch   0 Batch 1239/17275   train_loss = 3.196\n",
      "Epoch   0 Batch 1240/17275   train_loss = 2.952\n",
      "Epoch   0 Batch 1241/17275   train_loss = 5.008\n",
      "Epoch   0 Batch 1242/17275   train_loss = 3.311\n",
      "Epoch   0 Batch 1243/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 1244/17275   train_loss = 6.560\n",
      "Epoch   0 Batch 1245/17275   train_loss = 4.048\n",
      "Epoch   0 Batch 1246/17275   train_loss = 3.947\n",
      "Epoch   0 Batch 1247/17275   train_loss = 4.937\n",
      "Epoch   0 Batch 1248/17275   train_loss = 3.857\n",
      "Epoch   0 Batch 1249/17275   train_loss = 3.028\n",
      "Epoch   0 Batch 1250/17275   train_loss = 3.478\n",
      "Epoch   0 Batch 1251/17275   train_loss = 4.624\n",
      "Epoch   0 Batch 1252/17275   train_loss = 2.553\n",
      "Epoch   0 Batch 1253/17275   train_loss = 3.391\n",
      "Epoch   0 Batch 1254/17275   train_loss = 3.698\n",
      "Epoch   0 Batch 1255/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 1256/17275   train_loss = 2.588\n",
      "Epoch   0 Batch 1257/17275   train_loss = 4.983\n",
      "Epoch   0 Batch 1258/17275   train_loss = 4.623\n",
      "Epoch   0 Batch 1259/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 1260/17275   train_loss = 2.487\n",
      "Epoch   0 Batch 1261/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 1262/17275   train_loss = 3.394\n",
      "Epoch   0 Batch 1263/17275   train_loss = 2.960\n",
      "Epoch   0 Batch 1264/17275   train_loss = 2.474\n",
      "Epoch   0 Batch 1265/17275   train_loss = 3.719\n",
      "Epoch   0 Batch 1266/17275   train_loss = 3.538\n",
      "Epoch   0 Batch 1267/17275   train_loss = 3.937\n",
      "Epoch   0 Batch 1268/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 1269/17275   train_loss = 3.038\n",
      "Epoch   0 Batch 1270/17275   train_loss = 2.730\n",
      "Epoch   0 Batch 1271/17275   train_loss = 4.693\n",
      "Epoch   0 Batch 1272/17275   train_loss = 5.586\n",
      "Epoch   0 Batch 1273/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 1274/17275   train_loss = 5.551\n",
      "Epoch   0 Batch 1275/17275   train_loss = 5.537\n",
      "Epoch   0 Batch 1276/17275   train_loss = 4.249\n",
      "Epoch   0 Batch 1277/17275   train_loss = 5.496\n",
      "Epoch   0 Batch 1278/17275   train_loss = 2.588\n",
      "Epoch   0 Batch 1279/17275   train_loss = 4.076\n",
      "Epoch   0 Batch 1280/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 1281/17275   train_loss = 3.441\n",
      "Epoch   0 Batch 1282/17275   train_loss = 3.629\n",
      "Epoch   0 Batch 1283/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 1284/17275   train_loss = 3.592\n",
      "Epoch   0 Batch 1285/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 1286/17275   train_loss = 3.110\n",
      "Epoch   0 Batch 1287/17275   train_loss = 5.484\n",
      "Epoch   0 Batch 1288/17275   train_loss = 2.132\n",
      "Epoch   0 Batch 1289/17275   train_loss = 3.349\n",
      "Epoch   0 Batch 1290/17275   train_loss = 3.268\n",
      "Epoch   0 Batch 1291/17275   train_loss = 5.935\n",
      "Epoch   0 Batch 1292/17275   train_loss = 5.200\n",
      "Epoch   0 Batch 1293/17275   train_loss = 3.992\n",
      "Epoch   0 Batch 1294/17275   train_loss = 3.373\n",
      "Epoch   0 Batch 1295/17275   train_loss = 5.586\n",
      "Epoch   0 Batch 1296/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 1297/17275   train_loss = 3.451\n",
      "Epoch   0 Batch 1298/17275   train_loss = 3.029\n",
      "Epoch   0 Batch 1299/17275   train_loss = 3.435\n",
      "Epoch   0 Batch 1300/17275   train_loss = 5.116\n",
      "Epoch   0 Batch 1301/17275   train_loss = 2.207\n",
      "Epoch   0 Batch 1302/17275   train_loss = 2.866\n",
      "Epoch   0 Batch 1303/17275   train_loss = 5.168\n",
      "Epoch   0 Batch 1304/17275   train_loss = 2.084\n",
      "Epoch   0 Batch 1305/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 1306/17275   train_loss = 6.023\n",
      "Epoch   0 Batch 1307/17275   train_loss = 3.899\n",
      "Epoch   0 Batch 1308/17275   train_loss = 4.833\n",
      "Epoch   0 Batch 1309/17275   train_loss = 2.166\n",
      "Epoch   0 Batch 1310/17275   train_loss = 5.209\n",
      "Epoch   0 Batch 1311/17275   train_loss = 5.214\n",
      "Epoch   0 Batch 1312/17275   train_loss = 3.252\n",
      "Epoch   0 Batch 1313/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 1314/17275   train_loss = 5.476\n",
      "Epoch   0 Batch 1315/17275   train_loss = 5.635\n",
      "Epoch   0 Batch 1316/17275   train_loss = 4.150\n",
      "Epoch   0 Batch 1317/17275   train_loss = 3.678\n",
      "Epoch   0 Batch 1318/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 1319/17275   train_loss = 2.913\n",
      "Epoch   0 Batch 1320/17275   train_loss = 3.619\n",
      "Epoch   0 Batch 1321/17275   train_loss = 3.243\n",
      "Epoch   0 Batch 1322/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 1323/17275   train_loss = 2.435\n",
      "Epoch   0 Batch 1324/17275   train_loss = 2.731\n",
      "Epoch   0 Batch 1325/17275   train_loss = 7.705\n",
      "Epoch   0 Batch 1326/17275   train_loss = 3.090\n",
      "Epoch   0 Batch 1327/17275   train_loss = 3.107\n",
      "Epoch   0 Batch 1328/17275   train_loss = 2.402\n",
      "Epoch   0 Batch 1329/17275   train_loss = 5.267\n",
      "Epoch   0 Batch 1330/17275   train_loss = 5.517\n",
      "Epoch   0 Batch 1331/17275   train_loss = 4.816\n",
      "Epoch   0 Batch 1332/17275   train_loss = 2.251\n",
      "Epoch   0 Batch 1333/17275   train_loss = 5.151\n",
      "Epoch   0 Batch 1334/17275   train_loss = 7.721\n",
      "Epoch   0 Batch 1335/17275   train_loss = 2.552\n",
      "Epoch   0 Batch 1336/17275   train_loss = 5.142\n",
      "Epoch   0 Batch 1337/17275   train_loss = 3.609\n",
      "Epoch   0 Batch 1338/17275   train_loss = 3.167\n",
      "Epoch   0 Batch 1339/17275   train_loss = 3.041\n",
      "Epoch   0 Batch 1340/17275   train_loss = 5.163\n",
      "Epoch   0 Batch 1341/17275   train_loss = 5.475\n",
      "Epoch   0 Batch 1342/17275   train_loss = 5.148\n",
      "Epoch   0 Batch 1343/17275   train_loss = 3.911\n",
      "Epoch   0 Batch 1344/17275   train_loss = 5.164\n",
      "Epoch   0 Batch 1345/17275   train_loss = 2.961\n",
      "Epoch   0 Batch 1346/17275   train_loss = 2.445\n",
      "Epoch   0 Batch 1347/17275   train_loss = 2.570\n",
      "Epoch   0 Batch 1348/17275   train_loss = 5.449\n",
      "Epoch   0 Batch 1349/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 1350/17275   train_loss = 2.599\n",
      "Epoch   0 Batch 1351/17275   train_loss = 2.264\n",
      "Epoch   0 Batch 1352/17275   train_loss = 2.135\n",
      "Epoch   0 Batch 1353/17275   train_loss = 5.054\n",
      "Epoch   0 Batch 1354/17275   train_loss = 2.360\n",
      "Epoch   0 Batch 1355/17275   train_loss = 4.977\n",
      "Epoch   0 Batch 1356/17275   train_loss = 4.981\n",
      "Epoch   0 Batch 1357/17275   train_loss = 7.753\n",
      "Epoch   0 Batch 1358/17275   train_loss = 7.752\n",
      "Epoch   0 Batch 1359/17275   train_loss = 3.835\n",
      "Epoch   0 Batch 1360/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 1361/17275   train_loss = 5.267\n",
      "Epoch   0 Batch 1362/17275   train_loss = 6.138\n",
      "Epoch   0 Batch 1363/17275   train_loss = 5.402\n",
      "Epoch   0 Batch 1364/17275   train_loss = 5.980\n",
      "Epoch   0 Batch 1365/17275   train_loss = 5.421\n",
      "Epoch   0 Batch 1366/17275   train_loss = 2.841\n",
      "Epoch   0 Batch 1367/17275   train_loss = 7.746\n",
      "Epoch   0 Batch 1368/17275   train_loss = 5.372\n",
      "Epoch   0 Batch 1369/17275   train_loss = 5.510\n",
      "Epoch   0 Batch 1370/17275   train_loss = 4.991\n",
      "Epoch   0 Batch 1371/17275   train_loss = 6.235\n",
      "Epoch   0 Batch 1372/17275   train_loss = 7.726\n",
      "Epoch   0 Batch 1373/17275   train_loss = 5.458\n",
      "Epoch   0 Batch 1374/17275   train_loss = 6.616\n",
      "Epoch   0 Batch 1375/17275   train_loss = 6.557\n",
      "Epoch   0 Batch 1376/17275   train_loss = 6.413\n",
      "Epoch   0 Batch 1377/17275   train_loss = 5.406\n",
      "Epoch   0 Batch 1378/17275   train_loss = 3.785\n",
      "Epoch   0 Batch 1379/17275   train_loss = 7.055\n",
      "Epoch   0 Batch 1380/17275   train_loss = 3.950\n",
      "Epoch   0 Batch 1381/17275   train_loss = 5.273\n",
      "Epoch   0 Batch 1382/17275   train_loss = 2.484\n",
      "Epoch   0 Batch 1383/17275   train_loss = 3.443\n",
      "Epoch   0 Batch 1384/17275   train_loss = 4.910\n",
      "Epoch   0 Batch 1385/17275   train_loss = 3.764\n",
      "Epoch   0 Batch 1386/17275   train_loss = 2.959\n",
      "Epoch   0 Batch 1387/17275   train_loss = 4.958\n",
      "Epoch   0 Batch 1388/17275   train_loss = 4.927\n",
      "Epoch   0 Batch 1389/17275   train_loss = 2.770\n",
      "Epoch   0 Batch 1390/17275   train_loss = 5.140\n",
      "Epoch   0 Batch 1391/17275   train_loss = 5.151\n",
      "Epoch   0 Batch 1392/17275   train_loss = 5.109\n",
      "Epoch   0 Batch 1393/17275   train_loss = 3.015\n",
      "Epoch   0 Batch 1394/17275   train_loss = 5.411\n",
      "Epoch   0 Batch 1395/17275   train_loss = 4.872\n",
      "Epoch   0 Batch 1396/17275   train_loss = 3.280\n",
      "Epoch   0 Batch 1397/17275   train_loss = 5.542\n",
      "Epoch   0 Batch 1398/17275   train_loss = 2.342\n",
      "Epoch   0 Batch 1399/17275   train_loss = 4.419\n",
      "Epoch   0 Batch 1400/17275   train_loss = 4.625\n",
      "Epoch   0 Batch 1401/17275   train_loss = 4.850\n",
      "Epoch   0 Batch 1402/17275   train_loss = 3.702\n",
      "Epoch   0 Batch 1403/17275   train_loss = 5.448\n",
      "Epoch   0 Batch 1404/17275   train_loss = 2.666\n",
      "Epoch   0 Batch 1405/17275   train_loss = 2.586\n",
      "Epoch   0 Batch 1406/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 1407/17275   train_loss = 3.660\n",
      "Epoch   0 Batch 1408/17275   train_loss = 6.204\n",
      "Epoch   0 Batch 1409/17275   train_loss = 5.778\n",
      "Epoch   0 Batch 1410/17275   train_loss = 2.998\n",
      "Epoch   0 Batch 1411/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 1412/17275   train_loss = 4.009\n",
      "Epoch   0 Batch 1413/17275   train_loss = 3.594\n",
      "Epoch   0 Batch 1414/17275   train_loss = 2.180\n",
      "Epoch   0 Batch 1415/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 1416/17275   train_loss = 3.441\n",
      "Epoch   0 Batch 1417/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 1418/17275   train_loss = 5.255\n",
      "Epoch   0 Batch 1419/17275   train_loss = 6.941\n",
      "Epoch   0 Batch 1420/17275   train_loss = 2.349\n",
      "Epoch   0 Batch 1421/17275   train_loss = 3.795\n",
      "Epoch   0 Batch 1422/17275   train_loss = 5.587\n",
      "Epoch   0 Batch 1423/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 1424/17275   train_loss = 3.162\n",
      "Epoch   0 Batch 1425/17275   train_loss = 7.696\n",
      "Epoch   0 Batch 1426/17275   train_loss = 2.538\n",
      "Epoch   0 Batch 1427/17275   train_loss = 5.732\n",
      "Epoch   0 Batch 1428/17275   train_loss = 4.052\n",
      "Epoch   0 Batch 1429/17275   train_loss = 4.876\n",
      "Epoch   0 Batch 1430/17275   train_loss = 7.693\n",
      "Epoch   0 Batch 1431/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 1432/17275   train_loss = 4.837\n",
      "Epoch   0 Batch 1433/17275   train_loss = 7.504\n",
      "Epoch   0 Batch 1434/17275   train_loss = 4.864\n",
      "Epoch   0 Batch 1435/17275   train_loss = 4.856\n",
      "Epoch   0 Batch 1436/17275   train_loss = 2.651\n",
      "Epoch   0 Batch 1437/17275   train_loss = 3.443\n",
      "Epoch   0 Batch 1438/17275   train_loss = 2.417\n",
      "Epoch   0 Batch 1439/17275   train_loss = 3.737\n",
      "Epoch   0 Batch 1440/17275   train_loss = 4.091\n",
      "Epoch   0 Batch 1441/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 1442/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 1443/17275   train_loss = 5.172\n",
      "Epoch   0 Batch 1444/17275   train_loss = 4.229\n",
      "Epoch   0 Batch 1445/17275   train_loss = 2.001\n",
      "Epoch   0 Batch 1446/17275   train_loss = 2.807\n",
      "Epoch   0 Batch 1447/17275   train_loss = 5.174\n",
      "Epoch   0 Batch 1448/17275   train_loss = 3.646\n",
      "Epoch   0 Batch 1449/17275   train_loss = 5.166\n",
      "Epoch   0 Batch 1450/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 1451/17275   train_loss = 3.600\n",
      "Epoch   0 Batch 1452/17275   train_loss = 7.692\n",
      "Epoch   0 Batch 1453/17275   train_loss = 3.436\n",
      "Epoch   0 Batch 1454/17275   train_loss = 4.077\n",
      "Epoch   0 Batch 1455/17275   train_loss = 7.691\n",
      "Epoch   0 Batch 1456/17275   train_loss = 2.464\n",
      "Epoch   0 Batch 1457/17275   train_loss = 3.202\n",
      "Epoch   0 Batch 1458/17275   train_loss = 4.353\n",
      "Epoch   0 Batch 1459/17275   train_loss = 1.968\n",
      "Epoch   0 Batch 1460/17275   train_loss = 3.449\n",
      "Epoch   0 Batch 1461/17275   train_loss = 3.622\n",
      "Epoch   0 Batch 1462/17275   train_loss = 4.754\n",
      "Epoch   0 Batch 1463/17275   train_loss = 3.527\n",
      "Epoch   0 Batch 1464/17275   train_loss = 4.624\n",
      "Epoch   0 Batch 1465/17275   train_loss = 2.715\n",
      "Epoch   0 Batch 1466/17275   train_loss = 2.927\n",
      "Epoch   0 Batch 1467/17275   train_loss = 4.646\n",
      "Epoch   0 Batch 1468/17275   train_loss = 5.875\n",
      "Epoch   0 Batch 1469/17275   train_loss = 2.833\n",
      "Epoch   0 Batch 1470/17275   train_loss = 3.542\n",
      "Epoch   0 Batch 1471/17275   train_loss = 5.875\n",
      "Epoch   0 Batch 1472/17275   train_loss = 5.222\n",
      "Epoch   0 Batch 1473/17275   train_loss = 3.051\n",
      "Epoch   0 Batch 1474/17275   train_loss = 2.919\n",
      "Epoch   0 Batch 1475/17275   train_loss = 5.218\n",
      "Epoch   0 Batch 1476/17275   train_loss = 3.422\n",
      "Epoch   0 Batch 1477/17275   train_loss = 3.100\n",
      "Epoch   0 Batch 1478/17275   train_loss = 1.997\n",
      "Epoch   0 Batch 1479/17275   train_loss = 2.849\n",
      "Epoch   0 Batch 1480/17275   train_loss = 3.223\n",
      "Epoch   0 Batch 1481/17275   train_loss = 4.354\n",
      "Epoch   0 Batch 1482/17275   train_loss = 2.713\n",
      "Epoch   0 Batch 1483/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 1484/17275   train_loss = 2.329\n",
      "Epoch   0 Batch 1485/17275   train_loss = 2.604\n",
      "Epoch   0 Batch 1486/17275   train_loss = 2.686\n",
      "Epoch   0 Batch 1487/17275   train_loss = 3.050\n",
      "Epoch   0 Batch 1488/17275   train_loss = 4.671\n",
      "Epoch   0 Batch 1489/17275   train_loss = 2.851\n",
      "Epoch   0 Batch 1490/17275   train_loss = 5.517\n",
      "Epoch   0 Batch 1491/17275   train_loss = 2.010\n",
      "Epoch   0 Batch 1492/17275   train_loss = 2.541\n",
      "Epoch   0 Batch 1493/17275   train_loss = 5.168\n",
      "Epoch   0 Batch 1494/17275   train_loss = 6.972\n",
      "Epoch   0 Batch 1495/17275   train_loss = 2.027\n",
      "Epoch   0 Batch 1496/17275   train_loss = 6.744\n",
      "Epoch   0 Batch 1497/17275   train_loss = 2.017\n",
      "Epoch   0 Batch 1498/17275   train_loss = 4.326\n",
      "Epoch   0 Batch 1499/17275   train_loss = 3.194\n",
      "Epoch   0 Batch 1500/17275   train_loss = 3.355\n",
      "Epoch   0 Batch 1501/17275   train_loss = 6.077\n",
      "Epoch   0 Batch 1502/17275   train_loss = 1.954\n",
      "Epoch   0 Batch 1503/17275   train_loss = 4.989\n",
      "Epoch   0 Batch 1504/17275   train_loss = 4.917\n",
      "Epoch   0 Batch 1505/17275   train_loss = 7.463\n",
      "Epoch   0 Batch 1506/17275   train_loss = 2.673\n",
      "Epoch   0 Batch 1507/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 1508/17275   train_loss = 3.939\n",
      "Epoch   0 Batch 1509/17275   train_loss = 1.802\n",
      "Epoch   0 Batch 1510/17275   train_loss = 1.958\n",
      "Epoch   0 Batch 1511/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 1512/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 1513/17275   train_loss = 4.966\n",
      "Epoch   0 Batch 1514/17275   train_loss = 3.899\n",
      "Epoch   0 Batch 1515/17275   train_loss = 5.769\n",
      "Epoch   0 Batch 1516/17275   train_loss = 5.602\n",
      "Epoch   0 Batch 1517/17275   train_loss = 5.449\n",
      "Epoch   0 Batch 1518/17275   train_loss = 2.518\n",
      "Epoch   0 Batch 1519/17275   train_loss = 3.688\n",
      "Epoch   0 Batch 1520/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 1521/17275   train_loss = 4.952\n",
      "Epoch   0 Batch 1522/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 1523/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 1524/17275   train_loss = 5.365\n",
      "Epoch   0 Batch 1525/17275   train_loss = 5.293\n",
      "Epoch   0 Batch 1526/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 1527/17275   train_loss = 2.173\n",
      "Epoch   0 Batch 1528/17275   train_loss = 5.022\n",
      "Epoch   0 Batch 1529/17275   train_loss = 3.362\n",
      "Epoch   0 Batch 1530/17275   train_loss = 6.470\n",
      "Epoch   0 Batch 1531/17275   train_loss = 4.290\n",
      "Epoch   0 Batch 1532/17275   train_loss = 1.700\n",
      "Epoch   0 Batch 1533/17275   train_loss = 2.682\n",
      "Epoch   0 Batch 1534/17275   train_loss = 5.668\n",
      "Epoch   0 Batch 1535/17275   train_loss = 3.852\n",
      "Epoch   0 Batch 1536/17275   train_loss = 5.558\n",
      "Epoch   0 Batch 1537/17275   train_loss = 2.359\n",
      "Epoch   0 Batch 1538/17275   train_loss = 2.660\n",
      "Epoch   0 Batch 1539/17275   train_loss = 3.589\n",
      "Epoch   0 Batch 1540/17275   train_loss = 3.230\n",
      "Epoch   0 Batch 1541/17275   train_loss = 2.640\n",
      "Epoch   0 Batch 1542/17275   train_loss = 6.614\n",
      "Epoch   0 Batch 1543/17275   train_loss = 2.268\n",
      "Epoch   0 Batch 1544/17275   train_loss = 2.260\n",
      "Epoch   0 Batch 1545/17275   train_loss = 2.083\n",
      "Epoch   0 Batch 1546/17275   train_loss = 3.678\n",
      "Epoch   0 Batch 1547/17275   train_loss = 5.538\n",
      "Epoch   0 Batch 1548/17275   train_loss = 4.735\n",
      "Epoch   0 Batch 1549/17275   train_loss = 3.745\n",
      "Epoch   0 Batch 1550/17275   train_loss = 3.426\n",
      "Epoch   0 Batch 1551/17275   train_loss = 1.813\n",
      "Epoch   0 Batch 1552/17275   train_loss = 2.727\n",
      "Epoch   0 Batch 1553/17275   train_loss = 4.399\n",
      "Epoch   0 Batch 1554/17275   train_loss = 7.837\n",
      "Epoch   0 Batch 1555/17275   train_loss = 7.695\n",
      "Epoch   0 Batch 1556/17275   train_loss = 7.668\n",
      "Epoch   0 Batch 1557/17275   train_loss = 7.293\n",
      "Epoch   0 Batch 1558/17275   train_loss = 7.306\n",
      "Epoch   0 Batch 1559/17275   train_loss = 4.897\n",
      "Epoch   0 Batch 1560/17275   train_loss = 3.325\n",
      "Epoch   0 Batch 1561/17275   train_loss = 5.151\n",
      "Epoch   0 Batch 1562/17275   train_loss = 5.801\n",
      "Epoch   0 Batch 1563/17275   train_loss = 6.045\n",
      "Epoch   0 Batch 1564/17275   train_loss = 5.847\n",
      "Epoch   0 Batch 1565/17275   train_loss = 6.003\n",
      "Epoch   0 Batch 1566/17275   train_loss = 5.398\n",
      "Epoch   0 Batch 1567/17275   train_loss = 5.592\n",
      "Epoch   0 Batch 1568/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 1569/17275   train_loss = 4.119\n",
      "Epoch   0 Batch 1570/17275   train_loss = 4.405\n",
      "Epoch   0 Batch 1571/17275   train_loss = 1.855\n",
      "Epoch   0 Batch 1572/17275   train_loss = 2.324\n",
      "Epoch   0 Batch 1573/17275   train_loss = 2.248\n",
      "Epoch   0 Batch 1574/17275   train_loss = 3.720\n",
      "Epoch   0 Batch 1575/17275   train_loss = 4.398\n",
      "Epoch   0 Batch 1576/17275   train_loss = 3.392\n",
      "Epoch   0 Batch 1577/17275   train_loss = 6.907\n",
      "Epoch   0 Batch 1578/17275   train_loss = 5.684\n",
      "Epoch   0 Batch 1579/17275   train_loss = 4.724\n",
      "Epoch   0 Batch 1580/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 1581/17275   train_loss = 5.197\n",
      "Epoch   0 Batch 1582/17275   train_loss = 3.528\n",
      "Epoch   0 Batch 1583/17275   train_loss = 3.597\n",
      "Epoch   0 Batch 1584/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 1585/17275   train_loss = 4.614\n",
      "Epoch   0 Batch 1586/17275   train_loss = 2.532\n",
      "Epoch   0 Batch 1587/17275   train_loss = 2.110\n",
      "Epoch   0 Batch 1588/17275   train_loss = 3.627\n",
      "Epoch   0 Batch 1589/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 1590/17275   train_loss = 3.728\n",
      "Epoch   0 Batch 1591/17275   train_loss = 7.782\n",
      "Epoch   0 Batch 1592/17275   train_loss = 5.458\n",
      "Epoch   0 Batch 1593/17275   train_loss = 4.838\n",
      "Epoch   0 Batch 1594/17275   train_loss = 2.402\n",
      "Epoch   0 Batch 1595/17275   train_loss = 3.037\n",
      "Epoch   0 Batch 1596/17275   train_loss = 4.767\n",
      "Epoch   0 Batch 1597/17275   train_loss = 4.421\n",
      "Epoch   0 Batch 1598/17275   train_loss = 5.806\n",
      "Epoch   0 Batch 1599/17275   train_loss = 5.887\n",
      "Epoch   0 Batch 1600/17275   train_loss = 1.913\n",
      "Epoch   0 Batch 1601/17275   train_loss = 2.741\n",
      "Epoch   0 Batch 1602/17275   train_loss = 5.158\n",
      "Epoch   0 Batch 1603/17275   train_loss = 3.427\n",
      "Epoch   0 Batch 1604/17275   train_loss = 3.632\n",
      "Epoch   0 Batch 1605/17275   train_loss = 5.361\n",
      "Epoch   0 Batch 1606/17275   train_loss = 3.696\n",
      "Epoch   0 Batch 1607/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 1608/17275   train_loss = 3.409\n",
      "Epoch   0 Batch 1609/17275   train_loss = 5.153\n",
      "Epoch   0 Batch 1610/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 1611/17275   train_loss = 7.764\n",
      "Epoch   0 Batch 1612/17275   train_loss = 3.170\n",
      "Epoch   0 Batch 1613/17275   train_loss = 5.260\n",
      "Epoch   0 Batch 1614/17275   train_loss = 2.947\n",
      "Epoch   0 Batch 1615/17275   train_loss = 5.801\n",
      "Epoch   0 Batch 1616/17275   train_loss = 5.258\n",
      "Epoch   0 Batch 1617/17275   train_loss = 4.883\n",
      "Epoch   0 Batch 1618/17275   train_loss = 3.109\n",
      "Epoch   0 Batch 1619/17275   train_loss = 5.849\n",
      "Epoch   0 Batch 1620/17275   train_loss = 2.712\n",
      "Epoch   0 Batch 1621/17275   train_loss = 2.272\n",
      "Epoch   0 Batch 1622/17275   train_loss = 3.827\n",
      "Epoch   0 Batch 1623/17275   train_loss = 5.485\n",
      "Epoch   0 Batch 1624/17275   train_loss = 3.704\n",
      "Epoch   0 Batch 1625/17275   train_loss = 4.897\n",
      "Epoch   0 Batch 1626/17275   train_loss = 2.437\n",
      "Epoch   0 Batch 1627/17275   train_loss = 5.227\n",
      "Epoch   0 Batch 1628/17275   train_loss = 5.606\n",
      "Epoch   0 Batch 1629/17275   train_loss = 4.190\n",
      "Epoch   0 Batch 1630/17275   train_loss = 2.431\n",
      "Epoch   0 Batch 1631/17275   train_loss = 3.149\n",
      "Epoch   0 Batch 1632/17275   train_loss = 3.144\n",
      "Epoch   0 Batch 1633/17275   train_loss = 6.272\n",
      "Epoch   0 Batch 1634/17275   train_loss = 4.445\n",
      "Epoch   0 Batch 1635/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 1636/17275   train_loss = 5.100\n",
      "Epoch   0 Batch 1637/17275   train_loss = 5.095\n",
      "Epoch   0 Batch 1638/17275   train_loss = 4.894\n",
      "Epoch   0 Batch 1639/17275   train_loss = 2.035\n",
      "Epoch   0 Batch 1640/17275   train_loss = 2.514\n",
      "Epoch   0 Batch 1641/17275   train_loss = 5.332\n",
      "Epoch   0 Batch 1642/17275   train_loss = 3.179\n",
      "Epoch   0 Batch 1643/17275   train_loss = 2.913\n",
      "Epoch   0 Batch 1644/17275   train_loss = 3.740\n",
      "Epoch   0 Batch 1645/17275   train_loss = 5.526\n",
      "Epoch   0 Batch 1646/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 1647/17275   train_loss = 4.941\n",
      "Epoch   0 Batch 1648/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 1649/17275   train_loss = 4.029\n",
      "Epoch   0 Batch 1650/17275   train_loss = 6.315\n",
      "Epoch   0 Batch 1651/17275   train_loss = 4.042\n",
      "Epoch   0 Batch 1652/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 1653/17275   train_loss = 6.308\n",
      "Epoch   0 Batch 1654/17275   train_loss = 4.939\n",
      "Epoch   0 Batch 1655/17275   train_loss = 6.316\n",
      "Epoch   0 Batch 1656/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 1657/17275   train_loss = 6.155\n",
      "Epoch   0 Batch 1658/17275   train_loss = 3.313\n",
      "Epoch   0 Batch 1659/17275   train_loss = 2.274\n",
      "Epoch   0 Batch 1660/17275   train_loss = 4.370\n",
      "Epoch   0 Batch 1661/17275   train_loss = 7.802\n",
      "Epoch   0 Batch 1662/17275   train_loss = 5.714\n",
      "Epoch   0 Batch 1663/17275   train_loss = 5.403\n",
      "Epoch   0 Batch 1664/17275   train_loss = 6.405\n",
      "Epoch   0 Batch 1665/17275   train_loss = 2.739\n",
      "Epoch   0 Batch 1666/17275   train_loss = 3.105\n",
      "Epoch   0 Batch 1667/17275   train_loss = 4.875\n",
      "Epoch   0 Batch 1668/17275   train_loss = 3.314\n",
      "Epoch   0 Batch 1669/17275   train_loss = 3.967\n",
      "Epoch   0 Batch 1670/17275   train_loss = 7.799\n",
      "Epoch   0 Batch 1671/17275   train_loss = 7.792\n",
      "Epoch   0 Batch 1672/17275   train_loss = 4.820\n",
      "Epoch   0 Batch 1673/17275   train_loss = 1.841\n",
      "Epoch   0 Batch 1674/17275   train_loss = 2.879\n",
      "Epoch   0 Batch 1675/17275   train_loss = 5.495\n",
      "Epoch   0 Batch 1676/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 1677/17275   train_loss = 5.331\n",
      "Epoch   0 Batch 1678/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 1679/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 1680/17275   train_loss = 5.174\n",
      "Epoch   0 Batch 1681/17275   train_loss = 3.675\n",
      "Epoch   0 Batch 1682/17275   train_loss = 3.312\n",
      "Epoch   0 Batch 1683/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 1684/17275   train_loss = 2.419\n",
      "Epoch   0 Batch 1685/17275   train_loss = 5.309\n",
      "Epoch   0 Batch 1686/17275   train_loss = 2.622\n",
      "Epoch   0 Batch 1687/17275   train_loss = 2.360\n",
      "Epoch   0 Batch 1688/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 1689/17275   train_loss = 5.390\n",
      "Epoch   0 Batch 1690/17275   train_loss = 5.342\n",
      "Epoch   0 Batch 1691/17275   train_loss = 1.912\n",
      "Epoch   0 Batch 1692/17275   train_loss = 2.754\n",
      "Epoch   0 Batch 1693/17275   train_loss = 6.890\n",
      "Epoch   0 Batch 1694/17275   train_loss = 3.273\n",
      "Epoch   0 Batch 1695/17275   train_loss = 4.958\n",
      "Epoch   0 Batch 1696/17275   train_loss = 6.164\n",
      "Epoch   0 Batch 1697/17275   train_loss = 1.901\n",
      "Epoch   0 Batch 1698/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 1699/17275   train_loss = 3.775\n",
      "Epoch   0 Batch 1700/17275   train_loss = 2.952\n",
      "Epoch   0 Batch 1701/17275   train_loss = 2.201\n",
      "Epoch   0 Batch 1702/17275   train_loss = 4.449\n",
      "Epoch   0 Batch 1703/17275   train_loss = 5.746\n",
      "Epoch   0 Batch 1704/17275   train_loss = 1.890\n",
      "Epoch   0 Batch 1705/17275   train_loss = 2.508\n",
      "Epoch   0 Batch 1706/17275   train_loss = 5.165\n",
      "Epoch   0 Batch 1707/17275   train_loss = 3.565\n",
      "Epoch   0 Batch 1708/17275   train_loss = 3.988\n",
      "Epoch   0 Batch 1709/17275   train_loss = 5.288\n",
      "Epoch   0 Batch 1710/17275   train_loss = 3.107\n",
      "Epoch   0 Batch 1711/17275   train_loss = 7.848\n",
      "Epoch   0 Batch 1712/17275   train_loss = 2.089\n",
      "Epoch   0 Batch 1713/17275   train_loss = 7.849\n",
      "Epoch   0 Batch 1714/17275   train_loss = 3.356\n",
      "Epoch   0 Batch 1715/17275   train_loss = 3.091\n",
      "Epoch   0 Batch 1716/17275   train_loss = 4.865\n",
      "Epoch   0 Batch 1717/17275   train_loss = 4.822\n",
      "Epoch   0 Batch 1718/17275   train_loss = 2.374\n",
      "Epoch   0 Batch 1719/17275   train_loss = 5.011\n",
      "Epoch   0 Batch 1720/17275   train_loss = 5.982\n",
      "Epoch   0 Batch 1721/17275   train_loss = 1.944\n",
      "Epoch   0 Batch 1722/17275   train_loss = 3.641\n",
      "Epoch   0 Batch 1723/17275   train_loss = 3.926\n",
      "Epoch   0 Batch 1724/17275   train_loss = 2.361\n",
      "Epoch   0 Batch 1725/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 1726/17275   train_loss = 3.536\n",
      "Epoch   0 Batch 1727/17275   train_loss = 1.820\n",
      "Epoch   0 Batch 1728/17275   train_loss = 4.650\n",
      "Epoch   0 Batch 1729/17275   train_loss = 4.822\n",
      "Epoch   0 Batch 1730/17275   train_loss = 1.754\n",
      "Epoch   0 Batch 1731/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 1732/17275   train_loss = 3.397\n",
      "Epoch   0 Batch 1733/17275   train_loss = 2.498\n",
      "Epoch   0 Batch 1734/17275   train_loss = 4.560\n",
      "Epoch   0 Batch 1735/17275   train_loss = 6.221\n",
      "Epoch   0 Batch 1736/17275   train_loss = 5.563\n",
      "Epoch   0 Batch 1737/17275   train_loss = 2.391\n",
      "Epoch   0 Batch 1738/17275   train_loss = 3.569\n",
      "Epoch   0 Batch 1739/17275   train_loss = 3.327\n",
      "Epoch   0 Batch 1740/17275   train_loss = 5.525\n",
      "Epoch   0 Batch 1741/17275   train_loss = 3.177\n",
      "Epoch   0 Batch 1742/17275   train_loss = 7.066\n",
      "Epoch   0 Batch 1743/17275   train_loss = 3.017\n",
      "Epoch   0 Batch 1744/17275   train_loss = 3.389\n",
      "Epoch   0 Batch 1745/17275   train_loss = 7.445\n",
      "Epoch   0 Batch 1746/17275   train_loss = 3.184\n",
      "Epoch   0 Batch 1747/17275   train_loss = 2.807\n",
      "Epoch   0 Batch 1748/17275   train_loss = 3.120\n",
      "Epoch   0 Batch 1749/17275   train_loss = 5.569\n",
      "Epoch   0 Batch 1750/17275   train_loss = 5.785\n",
      "Epoch   0 Batch 1751/17275   train_loss = 6.026\n",
      "Epoch   0 Batch 1752/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 1753/17275   train_loss = 1.746\n",
      "Epoch   0 Batch 1754/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 1755/17275   train_loss = 3.086\n",
      "Epoch   0 Batch 1756/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 1757/17275   train_loss = 5.277\n",
      "Epoch   0 Batch 1758/17275   train_loss = 2.375\n",
      "Epoch   0 Batch 1759/17275   train_loss = 3.281\n",
      "Epoch   0 Batch 1760/17275   train_loss = 3.005\n",
      "Epoch   0 Batch 1761/17275   train_loss = 4.419\n",
      "Epoch   0 Batch 1762/17275   train_loss = 4.414\n",
      "Epoch   0 Batch 1763/17275   train_loss = 6.826\n",
      "Epoch   0 Batch 1764/17275   train_loss = 4.800\n",
      "Epoch   0 Batch 1765/17275   train_loss = 2.564\n",
      "Epoch   0 Batch 1766/17275   train_loss = 3.541\n",
      "Epoch   0 Batch 1767/17275   train_loss = 4.806\n",
      "Epoch   0 Batch 1768/17275   train_loss = 5.567\n",
      "Epoch   0 Batch 1769/17275   train_loss = 2.323\n",
      "Epoch   0 Batch 1770/17275   train_loss = 3.176\n",
      "Epoch   0 Batch 1771/17275   train_loss = 3.171\n",
      "Epoch   0 Batch 1772/17275   train_loss = 7.117\n",
      "Epoch   0 Batch 1773/17275   train_loss = 4.074\n",
      "Epoch   0 Batch 1774/17275   train_loss = 7.894\n",
      "Epoch   0 Batch 1775/17275   train_loss = 2.782\n",
      "Epoch   0 Batch 1776/17275   train_loss = 5.603\n",
      "Epoch   0 Batch 1777/17275   train_loss = 4.824\n",
      "Epoch   0 Batch 1778/17275   train_loss = 2.242\n",
      "Epoch   0 Batch 1779/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 1780/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 1781/17275   train_loss = 3.733\n",
      "Epoch   0 Batch 1782/17275   train_loss = 4.437\n",
      "Epoch   0 Batch 1783/17275   train_loss = 3.939\n",
      "Epoch   0 Batch 1784/17275   train_loss = 3.732\n",
      "Epoch   0 Batch 1785/17275   train_loss = 2.863\n",
      "Epoch   0 Batch 1786/17275   train_loss = 2.679\n",
      "Epoch   0 Batch 1787/17275   train_loss = 4.983\n",
      "Epoch   0 Batch 1788/17275   train_loss = 5.144\n",
      "Epoch   0 Batch 1789/17275   train_loss = 2.951\n",
      "Epoch   0 Batch 1790/17275   train_loss = 2.406\n",
      "Epoch   0 Batch 1791/17275   train_loss = 3.429\n",
      "Epoch   0 Batch 1792/17275   train_loss = 3.435\n",
      "Epoch   0 Batch 1793/17275   train_loss = 6.861\n",
      "Epoch   0 Batch 1794/17275   train_loss = 5.869\n",
      "Epoch   0 Batch 1795/17275   train_loss = 1.831\n",
      "Epoch   0 Batch 1796/17275   train_loss = 1.949\n",
      "Epoch   0 Batch 1797/17275   train_loss = 2.505\n",
      "Epoch   0 Batch 1798/17275   train_loss = 4.797\n",
      "Epoch   0 Batch 1799/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 1800/17275   train_loss = 3.569\n",
      "Epoch   0 Batch 1801/17275   train_loss = 2.783\n",
      "Epoch   0 Batch 1802/17275   train_loss = 5.465\n",
      "Epoch   0 Batch 1803/17275   train_loss = 4.299\n",
      "Epoch   0 Batch 1804/17275   train_loss = 2.487\n",
      "Epoch   0 Batch 1805/17275   train_loss = 3.611\n",
      "Epoch   0 Batch 1806/17275   train_loss = 2.717\n",
      "Epoch   0 Batch 1807/17275   train_loss = 3.642\n",
      "Epoch   0 Batch 1808/17275   train_loss = 2.548\n",
      "Epoch   0 Batch 1809/17275   train_loss = 4.809\n",
      "Epoch   0 Batch 1810/17275   train_loss = 2.520\n",
      "Epoch   0 Batch 1811/17275   train_loss = 2.640\n",
      "Epoch   0 Batch 1812/17275   train_loss = 5.810\n",
      "Epoch   0 Batch 1813/17275   train_loss = 1.938\n",
      "Epoch   0 Batch 1814/17275   train_loss = 2.952\n",
      "Epoch   0 Batch 1815/17275   train_loss = 5.355\n",
      "Epoch   0 Batch 1816/17275   train_loss = 2.581\n",
      "Epoch   0 Batch 1817/17275   train_loss = 2.448\n",
      "Epoch   0 Batch 1818/17275   train_loss = 3.753\n",
      "Epoch   0 Batch 1819/17275   train_loss = 4.045\n",
      "Epoch   0 Batch 1820/17275   train_loss = 5.382\n",
      "Epoch   0 Batch 1821/17275   train_loss = 2.655\n",
      "Epoch   0 Batch 1822/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 1823/17275   train_loss = 4.626\n",
      "Epoch   0 Batch 1824/17275   train_loss = 4.453\n",
      "Epoch   0 Batch 1825/17275   train_loss = 5.579\n",
      "Epoch   0 Batch 1826/17275   train_loss = 5.495\n",
      "Epoch   0 Batch 1827/17275   train_loss = 2.756\n",
      "Epoch   0 Batch 1828/17275   train_loss = 4.945\n",
      "Epoch   0 Batch 1829/17275   train_loss = 4.784\n",
      "Epoch   0 Batch 1830/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 1831/17275   train_loss = 7.925\n",
      "Epoch   0 Batch 1832/17275   train_loss = 5.486\n",
      "Epoch   0 Batch 1833/17275   train_loss = 4.162\n",
      "Epoch   0 Batch 1834/17275   train_loss = 5.264\n",
      "Epoch   0 Batch 1835/17275   train_loss = 5.418\n",
      "Epoch   0 Batch 1836/17275   train_loss = 5.954\n",
      "Epoch   0 Batch 1837/17275   train_loss = 5.317\n",
      "Epoch   0 Batch 1838/17275   train_loss = 7.916\n",
      "Epoch   0 Batch 1839/17275   train_loss = 4.937\n",
      "Epoch   0 Batch 1840/17275   train_loss = 7.907\n",
      "Epoch   0 Batch 1841/17275   train_loss = 5.006\n",
      "Epoch   0 Batch 1842/17275   train_loss = 6.026\n",
      "Epoch   0 Batch 1843/17275   train_loss = 5.703\n",
      "Epoch   0 Batch 1844/17275   train_loss = 4.695\n",
      "Epoch   0 Batch 1845/17275   train_loss = 6.739\n",
      "Epoch   0 Batch 1846/17275   train_loss = 2.947\n",
      "Epoch   0 Batch 1847/17275   train_loss = 4.389\n",
      "Epoch   0 Batch 1848/17275   train_loss = 5.389\n",
      "Epoch   0 Batch 1849/17275   train_loss = 5.008\n",
      "Epoch   0 Batch 1850/17275   train_loss = 3.698\n",
      "Epoch   0 Batch 1851/17275   train_loss = 4.955\n",
      "Epoch   0 Batch 1852/17275   train_loss = 3.296\n",
      "Epoch   0 Batch 1853/17275   train_loss = 6.192\n",
      "Epoch   0 Batch 1854/17275   train_loss = 5.779\n",
      "Epoch   0 Batch 1855/17275   train_loss = 5.902\n",
      "Epoch   0 Batch 1856/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 1857/17275   train_loss = 3.473\n",
      "Epoch   0 Batch 1858/17275   train_loss = 7.627\n",
      "Epoch   0 Batch 1859/17275   train_loss = 2.290\n",
      "Epoch   0 Batch 1860/17275   train_loss = 7.880\n",
      "Epoch   0 Batch 1861/17275   train_loss = 5.660\n",
      "Epoch   0 Batch 1862/17275   train_loss = 5.173\n",
      "Epoch   0 Batch 1863/17275   train_loss = 3.006\n",
      "Epoch   0 Batch 1864/17275   train_loss = 7.627\n",
      "Epoch   0 Batch 1865/17275   train_loss = 2.736\n",
      "Epoch   0 Batch 1866/17275   train_loss = 5.150\n",
      "Epoch   0 Batch 1867/17275   train_loss = 6.397\n",
      "Epoch   0 Batch 1868/17275   train_loss = 2.498\n",
      "Epoch   0 Batch 1869/17275   train_loss = 4.797\n",
      "Epoch   0 Batch 1870/17275   train_loss = 3.702\n",
      "Epoch   0 Batch 1871/17275   train_loss = 3.879\n",
      "Epoch   0 Batch 1872/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 1873/17275   train_loss = 7.874\n",
      "Epoch   0 Batch 1874/17275   train_loss = 2.561\n",
      "Epoch   0 Batch 1875/17275   train_loss = 4.847\n",
      "Epoch   0 Batch 1876/17275   train_loss = 2.395\n",
      "Epoch   0 Batch 1877/17275   train_loss = 5.706\n",
      "Epoch   0 Batch 1878/17275   train_loss = 3.368\n",
      "Epoch   0 Batch 1879/17275   train_loss = 5.135\n",
      "Epoch   0 Batch 1880/17275   train_loss = 4.275\n",
      "Epoch   0 Batch 1881/17275   train_loss = 2.438\n",
      "Epoch   0 Batch 1882/17275   train_loss = 5.408\n",
      "Epoch   0 Batch 1883/17275   train_loss = 4.104\n",
      "Epoch   0 Batch 1884/17275   train_loss = 5.117\n",
      "Epoch   0 Batch 1885/17275   train_loss = 5.104\n",
      "Epoch   0 Batch 1886/17275   train_loss = 5.034\n",
      "Epoch   0 Batch 1887/17275   train_loss = 3.865\n",
      "Epoch   0 Batch 1888/17275   train_loss = 3.850\n",
      "Epoch   0 Batch 1889/17275   train_loss = 6.102\n",
      "Epoch   0 Batch 1890/17275   train_loss = 5.043\n",
      "Epoch   0 Batch 1891/17275   train_loss = 4.970\n",
      "Epoch   0 Batch 1892/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 1893/17275   train_loss = 5.440\n",
      "Epoch   0 Batch 1894/17275   train_loss = 5.694\n",
      "Epoch   0 Batch 1895/17275   train_loss = 4.996\n",
      "Epoch   0 Batch 1896/17275   train_loss = 2.204\n",
      "Epoch   0 Batch 1897/17275   train_loss = 6.995\n",
      "Epoch   0 Batch 1898/17275   train_loss = 5.683\n",
      "Epoch   0 Batch 1899/17275   train_loss = 2.833\n",
      "Epoch   0 Batch 1900/17275   train_loss = 3.103\n",
      "Epoch   0 Batch 1901/17275   train_loss = 4.629\n",
      "Epoch   0 Batch 1902/17275   train_loss = 3.338\n",
      "Epoch   0 Batch 1903/17275   train_loss = 6.181\n",
      "Epoch   0 Batch 1904/17275   train_loss = 5.007\n",
      "Epoch   0 Batch 1905/17275   train_loss = 4.424\n",
      "Epoch   0 Batch 1906/17275   train_loss = 5.178\n",
      "Epoch   0 Batch 1907/17275   train_loss = 7.891\n",
      "Epoch   0 Batch 1908/17275   train_loss = 4.986\n",
      "Epoch   0 Batch 1909/17275   train_loss = 2.658\n",
      "Epoch   0 Batch 1910/17275   train_loss = 5.768\n",
      "Epoch   0 Batch 1911/17275   train_loss = 4.965\n",
      "Epoch   0 Batch 1912/17275   train_loss = 7.886\n",
      "Epoch   0 Batch 1913/17275   train_loss = 3.238\n",
      "Epoch   0 Batch 1914/17275   train_loss = 3.935\n",
      "Epoch   0 Batch 1915/17275   train_loss = 2.604\n",
      "Epoch   0 Batch 1916/17275   train_loss = 6.256\n",
      "Epoch   0 Batch 1917/17275   train_loss = 5.711\n",
      "Epoch   0 Batch 1918/17275   train_loss = 3.758\n",
      "Epoch   0 Batch 1919/17275   train_loss = 4.595\n",
      "Epoch   0 Batch 1920/17275   train_loss = 2.524\n",
      "Epoch   0 Batch 1921/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 1922/17275   train_loss = 2.037\n",
      "Epoch   0 Batch 1923/17275   train_loss = 3.444\n",
      "Epoch   0 Batch 1924/17275   train_loss = 5.378\n",
      "Epoch   0 Batch 1925/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 1926/17275   train_loss = 4.910\n",
      "Epoch   0 Batch 1927/17275   train_loss = 3.490\n",
      "Epoch   0 Batch 1928/17275   train_loss = 3.690\n",
      "Epoch   0 Batch 1929/17275   train_loss = 5.179\n",
      "Epoch   0 Batch 1930/17275   train_loss = 3.207\n",
      "Epoch   0 Batch 1931/17275   train_loss = 3.290\n",
      "Epoch   0 Batch 1932/17275   train_loss = 7.876\n",
      "Epoch   0 Batch 1933/17275   train_loss = 6.206\n",
      "Epoch   0 Batch 1934/17275   train_loss = 1.933\n",
      "Epoch   0 Batch 1935/17275   train_loss = 4.891\n",
      "Epoch   0 Batch 1936/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 1937/17275   train_loss = 3.211\n",
      "Epoch   0 Batch 1938/17275   train_loss = 3.096\n",
      "Epoch   0 Batch 1939/17275   train_loss = 2.954\n",
      "Epoch   0 Batch 1940/17275   train_loss = 3.667\n",
      "Epoch   0 Batch 1941/17275   train_loss = 2.391\n",
      "Epoch   0 Batch 1942/17275   train_loss = 4.923\n",
      "Epoch   0 Batch 1943/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 1944/17275   train_loss = 5.586\n",
      "Epoch   0 Batch 1945/17275   train_loss = 7.933\n",
      "Epoch   0 Batch 1946/17275   train_loss = 4.889\n",
      "Epoch   0 Batch 1947/17275   train_loss = 4.845\n",
      "Epoch   0 Batch 1948/17275   train_loss = 6.382\n",
      "Epoch   0 Batch 1949/17275   train_loss = 3.517\n",
      "Epoch   0 Batch 1950/17275   train_loss = 3.300\n",
      "Epoch   0 Batch 1951/17275   train_loss = 2.660\n",
      "Epoch   0 Batch 1952/17275   train_loss = 6.291\n",
      "Epoch   0 Batch 1953/17275   train_loss = 3.951\n",
      "Epoch   0 Batch 1954/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 1955/17275   train_loss = 3.585\n",
      "Epoch   0 Batch 1956/17275   train_loss = 3.194\n",
      "Epoch   0 Batch 1957/17275   train_loss = 4.118\n",
      "Epoch   0 Batch 1958/17275   train_loss = 4.371\n",
      "Epoch   0 Batch 1959/17275   train_loss = 3.797\n",
      "Epoch   0 Batch 1960/17275   train_loss = 5.304\n",
      "Epoch   0 Batch 1961/17275   train_loss = 3.675\n",
      "Epoch   0 Batch 1962/17275   train_loss = 3.739\n",
      "Epoch   0 Batch 1963/17275   train_loss = 2.473\n",
      "Epoch   0 Batch 1964/17275   train_loss = 2.885\n",
      "Epoch   0 Batch 1965/17275   train_loss = 5.402\n",
      "Epoch   0 Batch 1966/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 1967/17275   train_loss = 2.696\n",
      "Epoch   0 Batch 1968/17275   train_loss = 2.116\n",
      "Epoch   0 Batch 1969/17275   train_loss = 3.717\n",
      "Epoch   0 Batch 1970/17275   train_loss = 2.563\n",
      "Epoch   0 Batch 1971/17275   train_loss = 3.233\n",
      "Epoch   0 Batch 1972/17275   train_loss = 2.976\n",
      "Epoch   0 Batch 1973/17275   train_loss = 6.891\n",
      "Epoch   0 Batch 1974/17275   train_loss = 6.144\n",
      "Epoch   0 Batch 1975/17275   train_loss = 1.942\n",
      "Epoch   0 Batch 1976/17275   train_loss = 2.751\n",
      "Epoch   0 Batch 1977/17275   train_loss = 4.111\n",
      "Epoch   0 Batch 1978/17275   train_loss = 3.582\n",
      "Epoch   0 Batch 1979/17275   train_loss = 2.377\n",
      "Epoch   0 Batch 1980/17275   train_loss = 5.281\n",
      "Epoch   0 Batch 1981/17275   train_loss = 5.236\n",
      "Epoch   0 Batch 1982/17275   train_loss = 2.280\n",
      "Epoch   0 Batch 1983/17275   train_loss = 3.725\n",
      "Epoch   0 Batch 1984/17275   train_loss = 2.966\n",
      "Epoch   0 Batch 1985/17275   train_loss = 3.910\n",
      "Epoch   0 Batch 1986/17275   train_loss = 2.923\n",
      "Epoch   0 Batch 1987/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 1988/17275   train_loss = 3.274\n",
      "Epoch   0 Batch 1989/17275   train_loss = 5.668\n",
      "Epoch   0 Batch 1990/17275   train_loss = 6.311\n",
      "Epoch   0 Batch 1991/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 1992/17275   train_loss = 5.128\n",
      "Epoch   0 Batch 1993/17275   train_loss = 3.297\n",
      "Epoch   0 Batch 1994/17275   train_loss = 6.057\n",
      "Epoch   0 Batch 1995/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 1996/17275   train_loss = 4.017\n",
      "Epoch   0 Batch 1997/17275   train_loss = 2.677\n",
      "Epoch   0 Batch 1998/17275   train_loss = 6.227\n",
      "Epoch   0 Batch 1999/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 2000/17275   train_loss = 6.353\n",
      "Epoch   0 Batch 2001/17275   train_loss = 5.881\n",
      "Epoch   0 Batch 2002/17275   train_loss = 5.639\n",
      "Epoch   0 Batch 2003/17275   train_loss = 6.444\n",
      "Epoch   0 Batch 2004/17275   train_loss = 2.887\n",
      "Epoch   0 Batch 2005/17275   train_loss = 7.957\n",
      "Epoch   0 Batch 2006/17275   train_loss = 6.122\n",
      "Epoch   0 Batch 2007/17275   train_loss = 4.953\n",
      "Epoch   0 Batch 2008/17275   train_loss = 5.244\n",
      "Epoch   0 Batch 2009/17275   train_loss = 2.006\n",
      "Epoch   0 Batch 2010/17275   train_loss = 3.718\n",
      "Epoch   0 Batch 2011/17275   train_loss = 3.431\n",
      "Epoch   0 Batch 2012/17275   train_loss = 3.332\n",
      "Epoch   0 Batch 2013/17275   train_loss = 1.937\n",
      "Epoch   0 Batch 2014/17275   train_loss = 2.006\n",
      "Epoch   0 Batch 2015/17275   train_loss = 4.144\n",
      "Epoch   0 Batch 2016/17275   train_loss = 3.953\n",
      "Epoch   0 Batch 2017/17275   train_loss = 5.471\n",
      "Epoch   0 Batch 2018/17275   train_loss = 2.963\n",
      "Epoch   0 Batch 2019/17275   train_loss = 2.673\n",
      "Epoch   0 Batch 2020/17275   train_loss = 3.312\n",
      "Epoch   0 Batch 2021/17275   train_loss = 4.888\n",
      "Epoch   0 Batch 2022/17275   train_loss = 3.082\n",
      "Epoch   0 Batch 2023/17275   train_loss = 6.438\n",
      "Epoch   0 Batch 2024/17275   train_loss = 4.638\n",
      "Epoch   0 Batch 2025/17275   train_loss = 4.860\n",
      "Epoch   0 Batch 2026/17275   train_loss = 2.354\n",
      "Epoch   0 Batch 2027/17275   train_loss = 3.516\n",
      "Epoch   0 Batch 2028/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 2029/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 2030/17275   train_loss = 3.836\n",
      "Epoch   0 Batch 2031/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 2032/17275   train_loss = 2.692\n",
      "Epoch   0 Batch 2033/17275   train_loss = 3.717\n",
      "Epoch   0 Batch 2034/17275   train_loss = 3.299\n",
      "Epoch   0 Batch 2035/17275   train_loss = 3.882\n",
      "Epoch   0 Batch 2036/17275   train_loss = 3.211\n",
      "Epoch   0 Batch 2037/17275   train_loss = 3.444\n",
      "Epoch   0 Batch 2038/17275   train_loss = 5.233\n",
      "Epoch   0 Batch 2039/17275   train_loss = 2.940\n",
      "Epoch   0 Batch 2040/17275   train_loss = 2.312\n",
      "Epoch   0 Batch 2041/17275   train_loss = 5.202\n",
      "Epoch   0 Batch 2042/17275   train_loss = 3.485\n",
      "Epoch   0 Batch 2043/17275   train_loss = 3.634\n",
      "Epoch   0 Batch 2044/17275   train_loss = 3.541\n",
      "Epoch   0 Batch 2045/17275   train_loss = 3.682\n",
      "Epoch   0 Batch 2046/17275   train_loss = 3.323\n",
      "Epoch   0 Batch 2047/17275   train_loss = 4.011\n",
      "Epoch   0 Batch 2048/17275   train_loss = 3.406\n",
      "Epoch   0 Batch 2049/17275   train_loss = 5.708\n",
      "Epoch   0 Batch 2050/17275   train_loss = 4.632\n",
      "Epoch   0 Batch 2051/17275   train_loss = 2.198\n",
      "Epoch   0 Batch 2052/17275   train_loss = 2.126\n",
      "Epoch   0 Batch 2053/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 2054/17275   train_loss = 3.054\n",
      "Epoch   0 Batch 2055/17275   train_loss = 3.790\n",
      "Epoch   0 Batch 2056/17275   train_loss = 5.448\n",
      "Epoch   0 Batch 2057/17275   train_loss = 3.315\n",
      "Epoch   0 Batch 2058/17275   train_loss = 2.675\n",
      "Epoch   0 Batch 2059/17275   train_loss = 6.061\n",
      "Epoch   0 Batch 2060/17275   train_loss = 2.533\n",
      "Epoch   0 Batch 2061/17275   train_loss = 5.628\n",
      "Epoch   0 Batch 2062/17275   train_loss = 3.429\n",
      "Epoch   0 Batch 2063/17275   train_loss = 3.089\n",
      "Epoch   0 Batch 2064/17275   train_loss = 2.919\n",
      "Epoch   0 Batch 2065/17275   train_loss = 3.754\n",
      "Epoch   0 Batch 2066/17275   train_loss = 4.416\n",
      "Epoch   0 Batch 2067/17275   train_loss = 2.471\n",
      "Epoch   0 Batch 2068/17275   train_loss = 8.023\n",
      "Epoch   0 Batch 2069/17275   train_loss = 5.483\n",
      "Epoch   0 Batch 2070/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 2071/17275   train_loss = 5.712\n",
      "Epoch   0 Batch 2072/17275   train_loss = 3.193\n",
      "Epoch   0 Batch 2073/17275   train_loss = 2.742\n",
      "Epoch   0 Batch 2074/17275   train_loss = 3.513\n",
      "Epoch   0 Batch 2075/17275   train_loss = 4.287\n",
      "Epoch   0 Batch 2076/17275   train_loss = 2.001\n",
      "Epoch   0 Batch 2077/17275   train_loss = 2.623\n",
      "Epoch   0 Batch 2078/17275   train_loss = 7.388\n",
      "Epoch   0 Batch 2079/17275   train_loss = 3.316\n",
      "Epoch   0 Batch 2080/17275   train_loss = 3.493\n",
      "Epoch   0 Batch 2081/17275   train_loss = 2.813\n",
      "Epoch   0 Batch 2082/17275   train_loss = 3.879\n",
      "Epoch   0 Batch 2083/17275   train_loss = 5.009\n",
      "Epoch   0 Batch 2084/17275   train_loss = 2.557\n",
      "Epoch   0 Batch 2085/17275   train_loss = 3.315\n",
      "Epoch   0 Batch 2086/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 2087/17275   train_loss = 6.514\n",
      "Epoch   0 Batch 2088/17275   train_loss = 4.979\n",
      "Epoch   0 Batch 2089/17275   train_loss = 5.304\n",
      "Epoch   0 Batch 2090/17275   train_loss = 5.306\n",
      "Epoch   0 Batch 2091/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 2092/17275   train_loss = 3.128\n",
      "Epoch   0 Batch 2093/17275   train_loss = 1.957\n",
      "Epoch   0 Batch 2094/17275   train_loss = 2.107\n",
      "Epoch   0 Batch 2095/17275   train_loss = 2.980\n",
      "Epoch   0 Batch 2096/17275   train_loss = 3.604\n",
      "Epoch   0 Batch 2097/17275   train_loss = 5.121\n",
      "Epoch   0 Batch 2098/17275   train_loss = 6.253\n",
      "Epoch   0 Batch 2099/17275   train_loss = 6.009\n",
      "Epoch   0 Batch 2100/17275   train_loss = 8.068\n",
      "Epoch   0 Batch 2101/17275   train_loss = 1.871\n",
      "Epoch   0 Batch 2102/17275   train_loss = 8.065\n",
      "Epoch   0 Batch 2103/17275   train_loss = 5.538\n",
      "Epoch   0 Batch 2104/17275   train_loss = 1.844\n",
      "Epoch   0 Batch 2105/17275   train_loss = 2.526\n",
      "Epoch   0 Batch 2106/17275   train_loss = 6.164\n",
      "Epoch   0 Batch 2107/17275   train_loss = 5.280\n",
      "Epoch   0 Batch 2108/17275   train_loss = 7.222\n",
      "Epoch   0 Batch 2109/17275   train_loss = 2.380\n",
      "Epoch   0 Batch 2110/17275   train_loss = 4.819\n",
      "Epoch   0 Batch 2111/17275   train_loss = 5.590\n",
      "Epoch   0 Batch 2112/17275   train_loss = 4.761\n",
      "Epoch   0 Batch 2113/17275   train_loss = 4.995\n",
      "Epoch   0 Batch 2114/17275   train_loss = 2.319\n",
      "Epoch   0 Batch 2115/17275   train_loss = 3.035\n",
      "Epoch   0 Batch 2116/17275   train_loss = 2.652\n",
      "Epoch   0 Batch 2117/17275   train_loss = 5.617\n",
      "Epoch   0 Batch 2118/17275   train_loss = 2.673\n",
      "Epoch   0 Batch 2119/17275   train_loss = 5.379\n",
      "Epoch   0 Batch 2120/17275   train_loss = 2.547\n",
      "Epoch   0 Batch 2121/17275   train_loss = 5.184\n",
      "Epoch   0 Batch 2122/17275   train_loss = 3.308\n",
      "Epoch   0 Batch 2123/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 2124/17275   train_loss = 5.807\n",
      "Epoch   0 Batch 2125/17275   train_loss = 2.449\n",
      "Epoch   0 Batch 2126/17275   train_loss = 4.000\n",
      "Epoch   0 Batch 2127/17275   train_loss = 4.353\n",
      "Epoch   0 Batch 2128/17275   train_loss = 1.931\n",
      "Epoch   0 Batch 2129/17275   train_loss = 2.250\n",
      "Epoch   0 Batch 2130/17275   train_loss = 3.834\n",
      "Epoch   0 Batch 2131/17275   train_loss = 3.640\n",
      "Epoch   0 Batch 2132/17275   train_loss = 5.826\n",
      "Epoch   0 Batch 2133/17275   train_loss = 2.155\n",
      "Epoch   0 Batch 2134/17275   train_loss = 1.870\n",
      "Epoch   0 Batch 2135/17275   train_loss = 2.202\n",
      "Epoch   0 Batch 2136/17275   train_loss = 5.142\n",
      "Epoch   0 Batch 2137/17275   train_loss = 3.795\n",
      "Epoch   0 Batch 2138/17275   train_loss = 3.530\n",
      "Epoch   0 Batch 2139/17275   train_loss = 3.673\n",
      "Epoch   0 Batch 2140/17275   train_loss = 4.847\n",
      "Epoch   0 Batch 2141/17275   train_loss = 3.672\n",
      "Epoch   0 Batch 2142/17275   train_loss = 2.400\n",
      "Epoch   0 Batch 2143/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 2144/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 2145/17275   train_loss = 5.127\n",
      "Epoch   0 Batch 2146/17275   train_loss = 5.372\n",
      "Epoch   0 Batch 2147/17275   train_loss = 5.145\n",
      "Epoch   0 Batch 2148/17275   train_loss = 3.167\n",
      "Epoch   0 Batch 2149/17275   train_loss = 5.521\n",
      "Epoch   0 Batch 2150/17275   train_loss = 5.144\n",
      "Epoch   0 Batch 2151/17275   train_loss = 2.012\n",
      "Epoch   0 Batch 2152/17275   train_loss = 3.573\n",
      "Epoch   0 Batch 2153/17275   train_loss = 2.669\n",
      "Epoch   0 Batch 2154/17275   train_loss = 5.262\n",
      "Epoch   0 Batch 2155/17275   train_loss = 6.051\n",
      "Epoch   0 Batch 2156/17275   train_loss = 3.275\n",
      "Epoch   0 Batch 2157/17275   train_loss = 3.133\n",
      "Epoch   0 Batch 2158/17275   train_loss = 3.895\n",
      "Epoch   0 Batch 2159/17275   train_loss = 2.855\n",
      "Epoch   0 Batch 2160/17275   train_loss = 2.329\n",
      "Epoch   0 Batch 2161/17275   train_loss = 5.233\n",
      "Epoch   0 Batch 2162/17275   train_loss = 4.268\n",
      "Epoch   0 Batch 2163/17275   train_loss = 2.622\n",
      "Epoch   0 Batch 2164/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 2165/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 2166/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 2167/17275   train_loss = 4.991\n",
      "Epoch   0 Batch 2168/17275   train_loss = 6.785\n",
      "Epoch   0 Batch 2169/17275   train_loss = 2.520\n",
      "Epoch   0 Batch 2170/17275   train_loss = 3.271\n",
      "Epoch   0 Batch 2171/17275   train_loss = 4.793\n",
      "Epoch   0 Batch 2172/17275   train_loss = 5.193\n",
      "Epoch   0 Batch 2173/17275   train_loss = 3.382\n",
      "Epoch   0 Batch 2174/17275   train_loss = 3.906\n",
      "Epoch   0 Batch 2175/17275   train_loss = 5.208\n",
      "Epoch   0 Batch 2176/17275   train_loss = 2.348\n",
      "Epoch   0 Batch 2177/17275   train_loss = 3.639\n",
      "Epoch   0 Batch 2178/17275   train_loss = 4.385\n",
      "Epoch   0 Batch 2179/17275   train_loss = 6.449\n",
      "Epoch   0 Batch 2180/17275   train_loss = 3.549\n",
      "Epoch   0 Batch 2181/17275   train_loss = 3.852\n",
      "Epoch   0 Batch 2182/17275   train_loss = 4.363\n",
      "Epoch   0 Batch 2183/17275   train_loss = 3.683\n",
      "Epoch   0 Batch 2184/17275   train_loss = 4.133\n",
      "Epoch   0 Batch 2185/17275   train_loss = 3.423\n",
      "Epoch   0 Batch 2186/17275   train_loss = 2.277\n",
      "Epoch   0 Batch 2187/17275   train_loss = 2.940\n",
      "Epoch   0 Batch 2188/17275   train_loss = 6.390\n",
      "Epoch   0 Batch 2189/17275   train_loss = 2.215\n",
      "Epoch   0 Batch 2190/17275   train_loss = 2.133\n",
      "Epoch   0 Batch 2191/17275   train_loss = 6.843\n",
      "Epoch   0 Batch 2192/17275   train_loss = 4.165\n",
      "Epoch   0 Batch 2193/17275   train_loss = 5.491\n",
      "Epoch   0 Batch 2194/17275   train_loss = 2.580\n",
      "Epoch   0 Batch 2195/17275   train_loss = 5.303\n",
      "Epoch   0 Batch 2196/17275   train_loss = 5.299\n",
      "Epoch   0 Batch 2197/17275   train_loss = 6.502\n",
      "Epoch   0 Batch 2198/17275   train_loss = 6.087\n",
      "Epoch   0 Batch 2199/17275   train_loss = 3.006\n",
      "Epoch   0 Batch 2200/17275   train_loss = 3.924\n",
      "Epoch   0 Batch 2201/17275   train_loss = 5.545\n",
      "Epoch   0 Batch 2202/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 2203/17275   train_loss = 3.622\n",
      "Epoch   0 Batch 2204/17275   train_loss = 8.124\n",
      "Epoch   0 Batch 2205/17275   train_loss = 2.006\n",
      "Epoch   0 Batch 2206/17275   train_loss = 2.550\n",
      "Epoch   0 Batch 2207/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 2208/17275   train_loss = 5.431\n",
      "Epoch   0 Batch 2209/17275   train_loss = 5.368\n",
      "Epoch   0 Batch 2210/17275   train_loss = 5.785\n",
      "Epoch   0 Batch 2211/17275   train_loss = 5.348\n",
      "Epoch   0 Batch 2212/17275   train_loss = 2.309\n",
      "Epoch   0 Batch 2213/17275   train_loss = 5.122\n",
      "Epoch   0 Batch 2214/17275   train_loss = 3.797\n",
      "Epoch   0 Batch 2215/17275   train_loss = 3.738\n",
      "Epoch   0 Batch 2216/17275   train_loss = 1.991\n",
      "Epoch   0 Batch 2217/17275   train_loss = 2.918\n",
      "Epoch   0 Batch 2218/17275   train_loss = 5.298\n",
      "Epoch   0 Batch 2219/17275   train_loss = 2.462\n",
      "Epoch   0 Batch 2220/17275   train_loss = 5.226\n",
      "Epoch   0 Batch 2221/17275   train_loss = 2.186\n",
      "Epoch   0 Batch 2222/17275   train_loss = 2.008\n",
      "Epoch   0 Batch 2223/17275   train_loss = 2.839\n",
      "Epoch   0 Batch 2224/17275   train_loss = 3.132\n",
      "Epoch   0 Batch 2225/17275   train_loss = 2.576\n",
      "Epoch   0 Batch 2226/17275   train_loss = 5.541\n",
      "Epoch   0 Batch 2227/17275   train_loss = 5.916\n",
      "Epoch   0 Batch 2228/17275   train_loss = 3.617\n",
      "Epoch   0 Batch 2229/17275   train_loss = 4.017\n",
      "Epoch   0 Batch 2230/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 2231/17275   train_loss = 2.016\n",
      "Epoch   0 Batch 2232/17275   train_loss = 1.930\n",
      "Epoch   0 Batch 2233/17275   train_loss = 5.558\n",
      "Epoch   0 Batch 2234/17275   train_loss = 1.959\n",
      "Epoch   0 Batch 2235/17275   train_loss = 4.889\n",
      "Epoch   0 Batch 2236/17275   train_loss = 1.878\n",
      "Epoch   0 Batch 2237/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 2238/17275   train_loss = 4.065\n",
      "Epoch   0 Batch 2239/17275   train_loss = 2.272\n",
      "Epoch   0 Batch 2240/17275   train_loss = 4.898\n",
      "Epoch   0 Batch 2241/17275   train_loss = 5.660\n",
      "Epoch   0 Batch 2242/17275   train_loss = 2.430\n",
      "Epoch   0 Batch 2243/17275   train_loss = 3.038\n",
      "Epoch   0 Batch 2244/17275   train_loss = 3.134\n",
      "Epoch   0 Batch 2245/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 2246/17275   train_loss = 6.132\n",
      "Epoch   0 Batch 2247/17275   train_loss = 2.408\n",
      "Epoch   0 Batch 2248/17275   train_loss = 5.387\n",
      "Epoch   0 Batch 2249/17275   train_loss = 2.928\n",
      "Epoch   0 Batch 2250/17275   train_loss = 4.327\n",
      "Epoch   0 Batch 2251/17275   train_loss = 5.696\n",
      "Epoch   0 Batch 2252/17275   train_loss = 3.243\n",
      "Epoch   0 Batch 2253/17275   train_loss = 4.978\n",
      "Epoch   0 Batch 2254/17275   train_loss = 4.446\n",
      "Epoch   0 Batch 2255/17275   train_loss = 7.052\n",
      "Epoch   0 Batch 2256/17275   train_loss = 4.874\n",
      "Epoch   0 Batch 2257/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 2258/17275   train_loss = 2.935\n",
      "Epoch   0 Batch 2259/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 2260/17275   train_loss = 3.379\n",
      "Epoch   0 Batch 2261/17275   train_loss = 7.105\n",
      "Epoch   0 Batch 2262/17275   train_loss = 4.916\n",
      "Epoch   0 Batch 2263/17275   train_loss = 2.320\n",
      "Epoch   0 Batch 2264/17275   train_loss = 5.422\n",
      "Epoch   0 Batch 2265/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 2266/17275   train_loss = 2.973\n",
      "Epoch   0 Batch 2267/17275   train_loss = 1.851\n",
      "Epoch   0 Batch 2268/17275   train_loss = 1.946\n",
      "Epoch   0 Batch 2269/17275   train_loss = 6.029\n",
      "Epoch   0 Batch 2270/17275   train_loss = 6.073\n",
      "Epoch   0 Batch 2271/17275   train_loss = 8.150\n",
      "Epoch   0 Batch 2272/17275   train_loss = 2.692\n",
      "Epoch   0 Batch 2273/17275   train_loss = 1.824\n",
      "Epoch   0 Batch 2274/17275   train_loss = 2.590\n",
      "Epoch   0 Batch 2275/17275   train_loss = 5.847\n",
      "Epoch   0 Batch 2276/17275   train_loss = 5.803\n",
      "Epoch   0 Batch 2277/17275   train_loss = 5.004\n",
      "Epoch   0 Batch 2278/17275   train_loss = 3.593\n",
      "Epoch   0 Batch 2279/17275   train_loss = 4.045\n",
      "Epoch   0 Batch 2280/17275   train_loss = 5.345\n",
      "Epoch   0 Batch 2281/17275   train_loss = 6.259\n",
      "Epoch   0 Batch 2282/17275   train_loss = 2.138\n",
      "Epoch   0 Batch 2283/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 2284/17275   train_loss = 4.734\n",
      "Epoch   0 Batch 2285/17275   train_loss = 5.425\n",
      "Epoch   0 Batch 2286/17275   train_loss = 5.679\n",
      "Epoch   0 Batch 2287/17275   train_loss = 1.848\n",
      "Epoch   0 Batch 2288/17275   train_loss = 4.735\n",
      "Epoch   0 Batch 2289/17275   train_loss = 4.103\n",
      "Epoch   0 Batch 2290/17275   train_loss = 3.871\n",
      "Epoch   0 Batch 2291/17275   train_loss = 2.243\n",
      "Epoch   0 Batch 2292/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 2293/17275   train_loss = 4.639\n",
      "Epoch   0 Batch 2294/17275   train_loss = 3.428\n",
      "Epoch   0 Batch 2295/17275   train_loss = 5.565\n",
      "Epoch   0 Batch 2296/17275   train_loss = 5.018\n",
      "Epoch   0 Batch 2297/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 2298/17275   train_loss = 4.670\n",
      "Epoch   0 Batch 2299/17275   train_loss = 7.680\n",
      "Epoch   0 Batch 2300/17275   train_loss = 3.233\n",
      "Epoch   0 Batch 2301/17275   train_loss = 5.211\n",
      "Epoch   0 Batch 2302/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 2303/17275   train_loss = 2.473\n",
      "Epoch   0 Batch 2304/17275   train_loss = 4.810\n",
      "Epoch   0 Batch 2305/17275   train_loss = 3.432\n",
      "Epoch   0 Batch 2306/17275   train_loss = 5.417\n",
      "Epoch   0 Batch 2307/17275   train_loss = 1.872\n",
      "Epoch   0 Batch 2308/17275   train_loss = 4.338\n",
      "Epoch   0 Batch 2309/17275   train_loss = 2.357\n",
      "Epoch   0 Batch 2310/17275   train_loss = 3.929\n",
      "Epoch   0 Batch 2311/17275   train_loss = 4.530\n",
      "Epoch   0 Batch 2312/17275   train_loss = 3.107\n",
      "Epoch   0 Batch 2313/17275   train_loss = 3.568\n",
      "Epoch   0 Batch 2314/17275   train_loss = 4.917\n",
      "Epoch   0 Batch 2315/17275   train_loss = 5.886\n",
      "Epoch   0 Batch 2316/17275   train_loss = 5.652\n",
      "Epoch   0 Batch 2317/17275   train_loss = 4.837\n",
      "Epoch   0 Batch 2318/17275   train_loss = 5.310\n",
      "Epoch   0 Batch 2319/17275   train_loss = 5.498\n",
      "Epoch   0 Batch 2320/17275   train_loss = 2.676\n",
      "Epoch   0 Batch 2321/17275   train_loss = 4.210\n",
      "Epoch   0 Batch 2322/17275   train_loss = 4.231\n",
      "Epoch   0 Batch 2323/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 2324/17275   train_loss = 2.803\n",
      "Epoch   0 Batch 2325/17275   train_loss = 2.935\n",
      "Epoch   0 Batch 2326/17275   train_loss = 5.293\n",
      "Epoch   0 Batch 2327/17275   train_loss = 4.868\n",
      "Epoch   0 Batch 2328/17275   train_loss = 2.472\n",
      "Epoch   0 Batch 2329/17275   train_loss = 4.294\n",
      "Epoch   0 Batch 2330/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 2331/17275   train_loss = 5.400\n",
      "Epoch   0 Batch 2332/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 2333/17275   train_loss = 3.944\n",
      "Epoch   0 Batch 2334/17275   train_loss = 2.004\n",
      "Epoch   0 Batch 2335/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 2336/17275   train_loss = 3.290\n",
      "Epoch   0 Batch 2337/17275   train_loss = 4.598\n",
      "Epoch   0 Batch 2338/17275   train_loss = 8.126\n",
      "Epoch   0 Batch 2339/17275   train_loss = 2.396\n",
      "Epoch   0 Batch 2340/17275   train_loss = 4.917\n",
      "Epoch   0 Batch 2341/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 2342/17275   train_loss = 2.000\n",
      "Epoch   0 Batch 2343/17275   train_loss = 2.801\n",
      "Epoch   0 Batch 2344/17275   train_loss = 5.994\n",
      "Epoch   0 Batch 2345/17275   train_loss = 2.730\n",
      "Epoch   0 Batch 2346/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 2347/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 2348/17275   train_loss = 5.332\n",
      "Epoch   0 Batch 2349/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 2350/17275   train_loss = 2.962\n",
      "Epoch   0 Batch 2351/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 2352/17275   train_loss = 4.090\n",
      "Epoch   0 Batch 2353/17275   train_loss = 2.313\n",
      "Epoch   0 Batch 2354/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 2355/17275   train_loss = 6.016\n",
      "Epoch   0 Batch 2356/17275   train_loss = 2.251\n",
      "Epoch   0 Batch 2357/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 2358/17275   train_loss = 6.600\n",
      "Epoch   0 Batch 2359/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 2360/17275   train_loss = 2.544\n",
      "Epoch   0 Batch 2361/17275   train_loss = 6.154\n",
      "Epoch   0 Batch 2362/17275   train_loss = 2.130\n",
      "Epoch   0 Batch 2363/17275   train_loss = 1.860\n",
      "Epoch   0 Batch 2364/17275   train_loss = 3.945\n",
      "Epoch   0 Batch 2365/17275   train_loss = 3.605\n",
      "Epoch   0 Batch 2366/17275   train_loss = 3.127\n",
      "Epoch   0 Batch 2367/17275   train_loss = 3.530\n",
      "Epoch   0 Batch 2368/17275   train_loss = 3.485\n",
      "Epoch   0 Batch 2369/17275   train_loss = 3.413\n",
      "Epoch   0 Batch 2370/17275   train_loss = 4.622\n",
      "Epoch   0 Batch 2371/17275   train_loss = 4.453\n",
      "Epoch   0 Batch 2372/17275   train_loss = 6.188\n",
      "Epoch   0 Batch 2373/17275   train_loss = 5.175\n",
      "Epoch   0 Batch 2374/17275   train_loss = 2.172\n",
      "Epoch   0 Batch 2375/17275   train_loss = 3.656\n",
      "Epoch   0 Batch 2376/17275   train_loss = 5.243\n",
      "Epoch   0 Batch 2377/17275   train_loss = 2.555\n",
      "Epoch   0 Batch 2378/17275   train_loss = 2.064\n",
      "Epoch   0 Batch 2379/17275   train_loss = 3.471\n",
      "Epoch   0 Batch 2380/17275   train_loss = 4.519\n",
      "Epoch   0 Batch 2381/17275   train_loss = 5.432\n",
      "Epoch   0 Batch 2382/17275   train_loss = 5.040\n",
      "Epoch   0 Batch 2383/17275   train_loss = 2.408\n",
      "Epoch   0 Batch 2384/17275   train_loss = 6.542\n",
      "Epoch   0 Batch 2385/17275   train_loss = 1.868\n",
      "Epoch   0 Batch 2386/17275   train_loss = 3.316\n",
      "Epoch   0 Batch 2387/17275   train_loss = 2.515\n",
      "Epoch   0 Batch 2388/17275   train_loss = 6.591\n",
      "Epoch   0 Batch 2389/17275   train_loss = 5.663\n",
      "Epoch   0 Batch 2390/17275   train_loss = 2.835\n",
      "Epoch   0 Batch 2391/17275   train_loss = 2.834\n",
      "Epoch   0 Batch 2392/17275   train_loss = 3.013\n",
      "Epoch   0 Batch 2393/17275   train_loss = 4.225\n",
      "Epoch   0 Batch 2394/17275   train_loss = 1.656\n",
      "Epoch   0 Batch 2395/17275   train_loss = 2.664\n",
      "Epoch   0 Batch 2396/17275   train_loss = 4.894\n",
      "Epoch   0 Batch 2397/17275   train_loss = 1.552\n",
      "Epoch   0 Batch 2398/17275   train_loss = 1.774\n",
      "Epoch   0 Batch 2399/17275   train_loss = 3.633\n",
      "Epoch   0 Batch 2400/17275   train_loss = 2.630\n",
      "Epoch   0 Batch 2401/17275   train_loss = 2.095\n",
      "Epoch   0 Batch 2402/17275   train_loss = 5.932\n",
      "Epoch   0 Batch 2403/17275   train_loss = 5.575\n",
      "Epoch   0 Batch 2404/17275   train_loss = 4.005\n",
      "Epoch   0 Batch 2405/17275   train_loss = 5.567\n",
      "Epoch   0 Batch 2406/17275   train_loss = 4.584\n",
      "Epoch   0 Batch 2407/17275   train_loss = 2.154\n",
      "Epoch   0 Batch 2408/17275   train_loss = 2.430\n",
      "Epoch   0 Batch 2409/17275   train_loss = 2.706\n",
      "Epoch   0 Batch 2410/17275   train_loss = 3.475\n",
      "Epoch   0 Batch 2411/17275   train_loss = 6.420\n",
      "Epoch   0 Batch 2412/17275   train_loss = 5.584\n",
      "Epoch   0 Batch 2413/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 2414/17275   train_loss = 4.828\n",
      "Epoch   0 Batch 2415/17275   train_loss = 1.414\n",
      "Epoch   0 Batch 2416/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 2417/17275   train_loss = 2.285\n",
      "Epoch   0 Batch 2418/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 2419/17275   train_loss = 2.428\n",
      "Epoch   0 Batch 2420/17275   train_loss = 3.231\n",
      "Epoch   0 Batch 2421/17275   train_loss = 2.502\n",
      "Epoch   0 Batch 2422/17275   train_loss = 4.048\n",
      "Epoch   0 Batch 2423/17275   train_loss = 5.428\n",
      "Epoch   0 Batch 2424/17275   train_loss = 3.772\n",
      "Epoch   0 Batch 2425/17275   train_loss = 2.192\n",
      "Epoch   0 Batch 2426/17275   train_loss = 2.154\n",
      "Epoch   0 Batch 2427/17275   train_loss = 5.545\n",
      "Epoch   0 Batch 2428/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 2429/17275   train_loss = 5.066\n",
      "Epoch   0 Batch 2430/17275   train_loss = 1.706\n",
      "Epoch   0 Batch 2431/17275   train_loss = 5.481\n",
      "Epoch   0 Batch 2432/17275   train_loss = 6.141\n",
      "Epoch   0 Batch 2433/17275   train_loss = 5.465\n",
      "Epoch   0 Batch 2434/17275   train_loss = 4.964\n",
      "Epoch   0 Batch 2435/17275   train_loss = 1.685\n",
      "Epoch   0 Batch 2436/17275   train_loss = 4.818\n",
      "Epoch   0 Batch 2437/17275   train_loss = 1.656\n",
      "Epoch   0 Batch 2438/17275   train_loss = 4.610\n",
      "Epoch   0 Batch 2439/17275   train_loss = 1.588\n",
      "Epoch   0 Batch 2440/17275   train_loss = 4.369\n",
      "Epoch   0 Batch 2441/17275   train_loss = 1.492\n",
      "Epoch   0 Batch 2442/17275   train_loss = 4.865\n",
      "Epoch   0 Batch 2443/17275   train_loss = 1.383\n",
      "Epoch   0 Batch 2444/17275   train_loss = 1.630\n",
      "Epoch   0 Batch 2445/17275   train_loss = 4.834\n",
      "Epoch   0 Batch 2446/17275   train_loss = 3.387\n",
      "Epoch   0 Batch 2447/17275   train_loss = 5.451\n",
      "Epoch   0 Batch 2448/17275   train_loss = 4.094\n",
      "Epoch   0 Batch 2449/17275   train_loss = 6.998\n",
      "Epoch   0 Batch 2450/17275   train_loss = 6.427\n",
      "Epoch   0 Batch 2451/17275   train_loss = 4.101\n",
      "Epoch   0 Batch 2452/17275   train_loss = 5.793\n",
      "Epoch   0 Batch 2453/17275   train_loss = 1.623\n",
      "Epoch   0 Batch 2454/17275   train_loss = 6.043\n",
      "Epoch   0 Batch 2455/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 2456/17275   train_loss = 3.362\n",
      "Epoch   0 Batch 2457/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 2458/17275   train_loss = 5.797\n",
      "Epoch   0 Batch 2459/17275   train_loss = 2.436\n",
      "Epoch   0 Batch 2460/17275   train_loss = 4.058\n",
      "Epoch   0 Batch 2461/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 2462/17275   train_loss = 5.802\n",
      "Epoch   0 Batch 2463/17275   train_loss = 8.289\n",
      "Epoch   0 Batch 2464/17275   train_loss = 4.176\n",
      "Epoch   0 Batch 2465/17275   train_loss = 5.657\n",
      "Epoch   0 Batch 2466/17275   train_loss = 4.572\n",
      "Epoch   0 Batch 2467/17275   train_loss = 5.910\n",
      "Epoch   0 Batch 2468/17275   train_loss = 4.891\n",
      "Epoch   0 Batch 2469/17275   train_loss = 5.739\n",
      "Epoch   0 Batch 2470/17275   train_loss = 3.468\n",
      "Epoch   0 Batch 2471/17275   train_loss = 7.370\n",
      "Epoch   0 Batch 2472/17275   train_loss = 4.938\n",
      "Epoch   0 Batch 2473/17275   train_loss = 3.441\n",
      "Epoch   0 Batch 2474/17275   train_loss = 3.561\n",
      "Epoch   0 Batch 2475/17275   train_loss = 8.211\n",
      "Epoch   0 Batch 2476/17275   train_loss = 4.621\n",
      "Epoch   0 Batch 2477/17275   train_loss = 5.943\n",
      "Epoch   0 Batch 2478/17275   train_loss = 3.747\n",
      "Epoch   0 Batch 2479/17275   train_loss = 3.456\n",
      "Epoch   0 Batch 2480/17275   train_loss = 5.984\n",
      "Epoch   0 Batch 2481/17275   train_loss = 3.843\n",
      "Epoch   0 Batch 2482/17275   train_loss = 5.700\n",
      "Epoch   0 Batch 2483/17275   train_loss = 2.808\n",
      "Epoch   0 Batch 2484/17275   train_loss = 3.148\n",
      "Epoch   0 Batch 2485/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 2486/17275   train_loss = 8.173\n",
      "Epoch   0 Batch 2487/17275   train_loss = 2.845\n",
      "Epoch   0 Batch 2488/17275   train_loss = 4.212\n",
      "Epoch   0 Batch 2489/17275   train_loss = 5.414\n",
      "Epoch   0 Batch 2490/17275   train_loss = 5.924\n",
      "Epoch   0 Batch 2491/17275   train_loss = 5.319\n",
      "Epoch   0 Batch 2492/17275   train_loss = 5.116\n",
      "Epoch   0 Batch 2493/17275   train_loss = 5.805\n",
      "Epoch   0 Batch 2494/17275   train_loss = 6.472\n",
      "Epoch   0 Batch 2495/17275   train_loss = 5.506\n",
      "Epoch   0 Batch 2496/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 2497/17275   train_loss = 5.477\n",
      "Epoch   0 Batch 2498/17275   train_loss = 6.016\n",
      "Epoch   0 Batch 2499/17275   train_loss = 5.191\n",
      "Epoch   0 Batch 2500/17275   train_loss = 2.520\n",
      "Epoch   0 Batch 2501/17275   train_loss = 4.771\n",
      "Epoch   0 Batch 2502/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 2503/17275   train_loss = 5.826\n",
      "Epoch   0 Batch 2504/17275   train_loss = 4.138\n",
      "Epoch   0 Batch 2505/17275   train_loss = 6.465\n",
      "Epoch   0 Batch 2506/17275   train_loss = 6.604\n",
      "Epoch   0 Batch 2507/17275   train_loss = 2.422\n",
      "Epoch   0 Batch 2508/17275   train_loss = 8.135\n",
      "Epoch   0 Batch 2509/17275   train_loss = 5.583\n",
      "Epoch   0 Batch 2510/17275   train_loss = 5.152\n",
      "Epoch   0 Batch 2511/17275   train_loss = 5.380\n",
      "Epoch   0 Batch 2512/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 2513/17275   train_loss = 5.495\n",
      "Epoch   0 Batch 2514/17275   train_loss = 8.138\n",
      "Epoch   0 Batch 2515/17275   train_loss = 5.657\n",
      "Epoch   0 Batch 2516/17275   train_loss = 8.129\n",
      "Epoch   0 Batch 2517/17275   train_loss = 2.155\n",
      "Epoch   0 Batch 2518/17275   train_loss = 6.037\n",
      "Epoch   0 Batch 2519/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 2520/17275   train_loss = 3.191\n",
      "Epoch   0 Batch 2521/17275   train_loss = 4.112\n",
      "Epoch   0 Batch 2522/17275   train_loss = 3.178\n",
      "Epoch   0 Batch 2523/17275   train_loss = 6.936\n",
      "Epoch   0 Batch 2524/17275   train_loss = 3.946\n",
      "Epoch   0 Batch 2525/17275   train_loss = 5.857\n",
      "Epoch   0 Batch 2526/17275   train_loss = 5.279\n",
      "Epoch   0 Batch 2527/17275   train_loss = 2.147\n",
      "Epoch   0 Batch 2528/17275   train_loss = 2.888\n",
      "Epoch   0 Batch 2529/17275   train_loss = 3.275\n",
      "Epoch   0 Batch 2530/17275   train_loss = 4.162\n",
      "Epoch   0 Batch 2531/17275   train_loss = 5.111\n",
      "Epoch   0 Batch 2532/17275   train_loss = 2.536\n",
      "Epoch   0 Batch 2533/17275   train_loss = 4.941\n",
      "Epoch   0 Batch 2534/17275   train_loss = 3.850\n",
      "Epoch   0 Batch 2535/17275   train_loss = 6.380\n",
      "Epoch   0 Batch 2536/17275   train_loss = 3.322\n",
      "Epoch   0 Batch 2537/17275   train_loss = 5.148\n",
      "Epoch   0 Batch 2538/17275   train_loss = 2.370\n",
      "Epoch   0 Batch 2539/17275   train_loss = 2.974\n",
      "Epoch   0 Batch 2540/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 2541/17275   train_loss = 3.820\n",
      "Epoch   0 Batch 2542/17275   train_loss = 4.198\n",
      "Epoch   0 Batch 2543/17275   train_loss = 6.498\n",
      "Epoch   0 Batch 2544/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 2545/17275   train_loss = 8.149\n",
      "Epoch   0 Batch 2546/17275   train_loss = 2.582\n",
      "Epoch   0 Batch 2547/17275   train_loss = 3.866\n",
      "Epoch   0 Batch 2548/17275   train_loss = 2.202\n",
      "Epoch   0 Batch 2549/17275   train_loss = 2.715\n",
      "Epoch   0 Batch 2550/17275   train_loss = 5.519\n",
      "Epoch   0 Batch 2551/17275   train_loss = 5.488\n",
      "Epoch   0 Batch 2552/17275   train_loss = 3.859\n",
      "Epoch   0 Batch 2553/17275   train_loss = 3.217\n",
      "Epoch   0 Batch 2554/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 2555/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 2556/17275   train_loss = 6.360\n",
      "Epoch   0 Batch 2557/17275   train_loss = 3.611\n",
      "Epoch   0 Batch 2558/17275   train_loss = 5.832\n",
      "Epoch   0 Batch 2559/17275   train_loss = 5.800\n",
      "Epoch   0 Batch 2560/17275   train_loss = 5.238\n",
      "Epoch   0 Batch 2561/17275   train_loss = 3.711\n",
      "Epoch   0 Batch 2562/17275   train_loss = 3.630\n",
      "Epoch   0 Batch 2563/17275   train_loss = 4.320\n",
      "Epoch   0 Batch 2564/17275   train_loss = 6.016\n",
      "Epoch   0 Batch 2565/17275   train_loss = 2.070\n",
      "Epoch   0 Batch 2566/17275   train_loss = 1.957\n",
      "Epoch   0 Batch 2567/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 2568/17275   train_loss = 5.823\n",
      "Epoch   0 Batch 2569/17275   train_loss = 4.156\n",
      "Epoch   0 Batch 2570/17275   train_loss = 4.033\n",
      "Epoch   0 Batch 2571/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 2572/17275   train_loss = 4.241\n",
      "Epoch   0 Batch 2573/17275   train_loss = 4.038\n",
      "Epoch   0 Batch 2574/17275   train_loss = 2.870\n",
      "Epoch   0 Batch 2575/17275   train_loss = 3.130\n",
      "Epoch   0 Batch 2576/17275   train_loss = 4.188\n",
      "Epoch   0 Batch 2577/17275   train_loss = 3.355\n",
      "Epoch   0 Batch 2578/17275   train_loss = 2.903\n",
      "Epoch   0 Batch 2579/17275   train_loss = 2.568\n",
      "Epoch   0 Batch 2580/17275   train_loss = 5.498\n",
      "Epoch   0 Batch 2581/17275   train_loss = 3.215\n",
      "Epoch   0 Batch 2582/17275   train_loss = 2.523\n",
      "Epoch   0 Batch 2583/17275   train_loss = 2.616\n",
      "Epoch   0 Batch 2584/17275   train_loss = 2.078\n",
      "Epoch   0 Batch 2585/17275   train_loss = 8.167\n",
      "Epoch   0 Batch 2586/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 2587/17275   train_loss = 3.005\n",
      "Epoch   0 Batch 2588/17275   train_loss = 4.790\n",
      "Epoch   0 Batch 2589/17275   train_loss = 3.918\n",
      "Epoch   0 Batch 2590/17275   train_loss = 3.342\n",
      "Epoch   0 Batch 2591/17275   train_loss = 3.438\n",
      "Epoch   0 Batch 2592/17275   train_loss = 1.920\n",
      "Epoch   0 Batch 2593/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 2594/17275   train_loss = 8.188\n",
      "Epoch   0 Batch 2595/17275   train_loss = 2.728\n",
      "Epoch   0 Batch 2596/17275   train_loss = 5.472\n",
      "Epoch   0 Batch 2597/17275   train_loss = 6.362\n",
      "Epoch   0 Batch 2598/17275   train_loss = 2.318\n",
      "Epoch   0 Batch 2599/17275   train_loss = 2.473\n",
      "Epoch   0 Batch 2600/17275   train_loss = 2.844\n",
      "Epoch   0 Batch 2601/17275   train_loss = 3.446\n",
      "Epoch   0 Batch 2602/17275   train_loss = 5.236\n",
      "Epoch   0 Batch 2603/17275   train_loss = 4.405\n",
      "Epoch   0 Batch 2604/17275   train_loss = 2.206\n",
      "Epoch   0 Batch 2605/17275   train_loss = 4.155\n",
      "Epoch   0 Batch 2606/17275   train_loss = 5.428\n",
      "Epoch   0 Batch 2607/17275   train_loss = 5.553\n",
      "Epoch   0 Batch 2608/17275   train_loss = 2.671\n",
      "Epoch   0 Batch 2609/17275   train_loss = 3.832\n",
      "Epoch   0 Batch 2610/17275   train_loss = 5.345\n",
      "Epoch   0 Batch 2611/17275   train_loss = 5.261\n",
      "Epoch   0 Batch 2612/17275   train_loss = 4.256\n",
      "Epoch   0 Batch 2613/17275   train_loss = 4.049\n",
      "Epoch   0 Batch 2614/17275   train_loss = 7.139\n",
      "Epoch   0 Batch 2615/17275   train_loss = 2.405\n",
      "Epoch   0 Batch 2616/17275   train_loss = 4.123\n",
      "Epoch   0 Batch 2617/17275   train_loss = 5.957\n",
      "Epoch   0 Batch 2618/17275   train_loss = 4.112\n",
      "Epoch   0 Batch 2619/17275   train_loss = 3.368\n",
      "Epoch   0 Batch 2620/17275   train_loss = 2.389\n",
      "Epoch   0 Batch 2621/17275   train_loss = 3.231\n",
      "Epoch   0 Batch 2622/17275   train_loss = 3.725\n",
      "Epoch   0 Batch 2623/17275   train_loss = 5.054\n",
      "Epoch   0 Batch 2624/17275   train_loss = 5.049\n",
      "Epoch   0 Batch 2625/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 2626/17275   train_loss = 3.441\n",
      "Epoch   0 Batch 2627/17275   train_loss = 3.871\n",
      "Epoch   0 Batch 2628/17275   train_loss = 3.672\n",
      "Epoch   0 Batch 2629/17275   train_loss = 3.339\n",
      "Epoch   0 Batch 2630/17275   train_loss = 6.186\n",
      "Epoch   0 Batch 2631/17275   train_loss = 5.514\n",
      "Epoch   0 Batch 2632/17275   train_loss = 3.869\n",
      "Epoch   0 Batch 2633/17275   train_loss = 5.842\n",
      "Epoch   0 Batch 2634/17275   train_loss = 6.397\n",
      "Epoch   0 Batch 2635/17275   train_loss = 5.896\n",
      "Epoch   0 Batch 2636/17275   train_loss = 3.993\n",
      "Epoch   0 Batch 2637/17275   train_loss = 2.310\n",
      "Epoch   0 Batch 2638/17275   train_loss = 5.388\n",
      "Epoch   0 Batch 2639/17275   train_loss = 3.349\n",
      "Epoch   0 Batch 2640/17275   train_loss = 6.338\n",
      "Epoch   0 Batch 2641/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 2642/17275   train_loss = 4.109\n",
      "Epoch   0 Batch 2643/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 2644/17275   train_loss = 5.924\n",
      "Epoch   0 Batch 2645/17275   train_loss = 5.902\n",
      "Epoch   0 Batch 2646/17275   train_loss = 7.366\n",
      "Epoch   0 Batch 2647/17275   train_loss = 5.101\n",
      "Epoch   0 Batch 2648/17275   train_loss = 2.336\n",
      "Epoch   0 Batch 2649/17275   train_loss = 3.091\n",
      "Epoch   0 Batch 2650/17275   train_loss = 3.199\n",
      "Epoch   0 Batch 2651/17275   train_loss = 5.707\n",
      "Epoch   0 Batch 2652/17275   train_loss = 5.111\n",
      "Epoch   0 Batch 2653/17275   train_loss = 2.286\n",
      "Epoch   0 Batch 2654/17275   train_loss = 2.892\n",
      "Epoch   0 Batch 2655/17275   train_loss = 6.213\n",
      "Epoch   0 Batch 2656/17275   train_loss = 3.752\n",
      "Epoch   0 Batch 2657/17275   train_loss = 5.538\n",
      "Epoch   0 Batch 2658/17275   train_loss = 5.097\n",
      "Epoch   0 Batch 2659/17275   train_loss = 2.594\n",
      "Epoch   0 Batch 2660/17275   train_loss = 5.439\n",
      "Epoch   0 Batch 2661/17275   train_loss = 4.656\n",
      "Epoch   0 Batch 2662/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 2663/17275   train_loss = 4.881\n",
      "Epoch   0 Batch 2664/17275   train_loss = 8.226\n",
      "Epoch   0 Batch 2665/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 2666/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 2667/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 2668/17275   train_loss = 5.389\n",
      "Epoch   0 Batch 2669/17275   train_loss = 3.886\n",
      "Epoch   0 Batch 2670/17275   train_loss = 5.573\n",
      "Epoch   0 Batch 2671/17275   train_loss = 3.239\n",
      "Epoch   0 Batch 2672/17275   train_loss = 5.110\n",
      "Epoch   0 Batch 2673/17275   train_loss = 5.337\n",
      "Epoch   0 Batch 2674/17275   train_loss = 2.705\n",
      "Epoch   0 Batch 2675/17275   train_loss = 6.675\n",
      "Epoch   0 Batch 2676/17275   train_loss = 2.300\n",
      "Epoch   0 Batch 2677/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 2678/17275   train_loss = 2.779\n",
      "Epoch   0 Batch 2679/17275   train_loss = 2.993\n",
      "Epoch   0 Batch 2680/17275   train_loss = 3.282\n",
      "Epoch   0 Batch 2681/17275   train_loss = 3.482\n",
      "Epoch   0 Batch 2682/17275   train_loss = 2.061\n",
      "Epoch   0 Batch 2683/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 2684/17275   train_loss = 5.144\n",
      "Epoch   0 Batch 2685/17275   train_loss = 5.852\n",
      "Epoch   0 Batch 2686/17275   train_loss = 5.100\n",
      "Epoch   0 Batch 2687/17275   train_loss = 2.180\n",
      "Epoch   0 Batch 2688/17275   train_loss = 6.767\n",
      "Epoch   0 Batch 2689/17275   train_loss = 2.859\n",
      "Epoch   0 Batch 2690/17275   train_loss = 3.404\n",
      "Epoch   0 Batch 2691/17275   train_loss = 3.799\n",
      "Epoch   0 Batch 2692/17275   train_loss = 1.918\n",
      "Epoch   0 Batch 2693/17275   train_loss = 5.369\n",
      "Epoch   0 Batch 2694/17275   train_loss = 5.122\n",
      "Epoch   0 Batch 2695/17275   train_loss = 3.146\n",
      "Epoch   0 Batch 2696/17275   train_loss = 4.286\n",
      "Epoch   0 Batch 2697/17275   train_loss = 7.796\n",
      "Epoch   0 Batch 2698/17275   train_loss = 4.739\n",
      "Epoch   0 Batch 2699/17275   train_loss = 4.691\n",
      "Epoch   0 Batch 2700/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 2701/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 2702/17275   train_loss = 6.007\n",
      "Epoch   0 Batch 2703/17275   train_loss = 5.727\n",
      "Epoch   0 Batch 2704/17275   train_loss = 4.152\n",
      "Epoch   0 Batch 2705/17275   train_loss = 4.124\n",
      "Epoch   0 Batch 2706/17275   train_loss = 5.085\n",
      "Epoch   0 Batch 2707/17275   train_loss = 5.191\n",
      "Epoch   0 Batch 2708/17275   train_loss = 5.108\n",
      "Epoch   0 Batch 2709/17275   train_loss = 4.795\n",
      "Epoch   0 Batch 2710/17275   train_loss = 1.923\n",
      "Epoch   0 Batch 2711/17275   train_loss = 2.204\n",
      "Epoch   0 Batch 2712/17275   train_loss = 3.630\n",
      "Epoch   0 Batch 2713/17275   train_loss = 3.071\n",
      "Epoch   0 Batch 2714/17275   train_loss = 3.206\n",
      "Epoch   0 Batch 2715/17275   train_loss = 4.964\n",
      "Epoch   0 Batch 2716/17275   train_loss = 2.998\n",
      "Epoch   0 Batch 2717/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 2718/17275   train_loss = 3.196\n",
      "Epoch   0 Batch 2719/17275   train_loss = 2.373\n",
      "Epoch   0 Batch 2720/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 2721/17275   train_loss = 2.889\n",
      "Epoch   0 Batch 2722/17275   train_loss = 3.696\n",
      "Epoch   0 Batch 2723/17275   train_loss = 4.365\n",
      "Epoch   0 Batch 2724/17275   train_loss = 2.833\n",
      "Epoch   0 Batch 2725/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 2726/17275   train_loss = 8.312\n",
      "Epoch   0 Batch 2727/17275   train_loss = 4.972\n",
      "Epoch   0 Batch 2728/17275   train_loss = 5.079\n",
      "Epoch   0 Batch 2729/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 2730/17275   train_loss = 2.904\n",
      "Epoch   0 Batch 2731/17275   train_loss = 5.733\n",
      "Epoch   0 Batch 2732/17275   train_loss = 4.024\n",
      "Epoch   0 Batch 2733/17275   train_loss = 1.761\n",
      "Epoch   0 Batch 2734/17275   train_loss = 2.880\n",
      "Epoch   0 Batch 2735/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 2736/17275   train_loss = 6.196\n",
      "Epoch   0 Batch 2737/17275   train_loss = 4.048\n",
      "Epoch   0 Batch 2738/17275   train_loss = 3.144\n",
      "Epoch   0 Batch 2739/17275   train_loss = 4.641\n",
      "Epoch   0 Batch 2740/17275   train_loss = 2.739\n",
      "Epoch   0 Batch 2741/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 2742/17275   train_loss = 5.438\n",
      "Epoch   0 Batch 2743/17275   train_loss = 5.002\n",
      "Epoch   0 Batch 2744/17275   train_loss = 2.357\n",
      "Epoch   0 Batch 2745/17275   train_loss = 5.611\n",
      "Epoch   0 Batch 2746/17275   train_loss = 3.476\n",
      "Epoch   0 Batch 2747/17275   train_loss = 5.126\n",
      "Epoch   0 Batch 2748/17275   train_loss = 1.833\n",
      "Epoch   0 Batch 2749/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 2750/17275   train_loss = 6.295\n",
      "Epoch   0 Batch 2751/17275   train_loss = 3.940\n",
      "Epoch   0 Batch 2752/17275   train_loss = 3.053\n",
      "Epoch   0 Batch 2753/17275   train_loss = 4.293\n",
      "Epoch   0 Batch 2754/17275   train_loss = 5.654\n",
      "Epoch   0 Batch 2755/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 2756/17275   train_loss = 5.232\n",
      "Epoch   0 Batch 2757/17275   train_loss = 3.835\n",
      "Epoch   0 Batch 2758/17275   train_loss = 2.594\n",
      "Epoch   0 Batch 2759/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 2760/17275   train_loss = 4.414\n",
      "Epoch   0 Batch 2761/17275   train_loss = 5.918\n",
      "Epoch   0 Batch 2762/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 2763/17275   train_loss = 2.718\n",
      "Epoch   0 Batch 2764/17275   train_loss = 2.354\n",
      "Epoch   0 Batch 2765/17275   train_loss = 3.082\n",
      "Epoch   0 Batch 2766/17275   train_loss = 6.219\n",
      "Epoch   0 Batch 2767/17275   train_loss = 2.589\n",
      "Epoch   0 Batch 2768/17275   train_loss = 3.660\n",
      "Epoch   0 Batch 2769/17275   train_loss = 3.192\n",
      "Epoch   0 Batch 2770/17275   train_loss = 6.291\n",
      "Epoch   0 Batch 2771/17275   train_loss = 2.879\n",
      "Epoch   0 Batch 2772/17275   train_loss = 3.350\n",
      "Epoch   0 Batch 2773/17275   train_loss = 2.386\n",
      "Epoch   0 Batch 2774/17275   train_loss = 4.103\n",
      "Epoch   0 Batch 2775/17275   train_loss = 2.691\n",
      "Epoch   0 Batch 2776/17275   train_loss = 5.713\n",
      "Epoch   0 Batch 2777/17275   train_loss = 3.229\n",
      "Epoch   0 Batch 2778/17275   train_loss = 3.572\n",
      "Epoch   0 Batch 2779/17275   train_loss = 2.340\n",
      "Epoch   0 Batch 2780/17275   train_loss = 2.870\n",
      "Epoch   0 Batch 2781/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 2782/17275   train_loss = 8.284\n",
      "Epoch   0 Batch 2783/17275   train_loss = 5.689\n",
      "Epoch   0 Batch 2784/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 2785/17275   train_loss = 4.267\n",
      "Epoch   0 Batch 2786/17275   train_loss = 2.320\n",
      "Epoch   0 Batch 2787/17275   train_loss = 3.670\n",
      "Epoch   0 Batch 2788/17275   train_loss = 4.633\n",
      "Epoch   0 Batch 2789/17275   train_loss = 4.309\n",
      "Epoch   0 Batch 2790/17275   train_loss = 5.497\n",
      "Epoch   0 Batch 2791/17275   train_loss = 2.567\n",
      "Epoch   0 Batch 2792/17275   train_loss = 5.820\n",
      "Epoch   0 Batch 2793/17275   train_loss = 4.635\n",
      "Epoch   0 Batch 2794/17275   train_loss = 2.091\n",
      "Epoch   0 Batch 2795/17275   train_loss = 5.496\n",
      "Epoch   0 Batch 2796/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 2797/17275   train_loss = 3.723\n",
      "Epoch   0 Batch 2798/17275   train_loss = 8.312\n",
      "Epoch   0 Batch 2799/17275   train_loss = 5.414\n",
      "Epoch   0 Batch 2800/17275   train_loss = 2.186\n",
      "Epoch   0 Batch 2801/17275   train_loss = 3.207\n",
      "Epoch   0 Batch 2802/17275   train_loss = 3.577\n",
      "Epoch   0 Batch 2803/17275   train_loss = 3.503\n",
      "Epoch   0 Batch 2804/17275   train_loss = 5.680\n",
      "Epoch   0 Batch 2805/17275   train_loss = 2.086\n",
      "Epoch   0 Batch 2806/17275   train_loss = 3.180\n",
      "Epoch   0 Batch 2807/17275   train_loss = 6.282\n",
      "Epoch   0 Batch 2808/17275   train_loss = 3.830\n",
      "Epoch   0 Batch 2809/17275   train_loss = 8.320\n",
      "Epoch   0 Batch 2810/17275   train_loss = 5.118\n",
      "Epoch   0 Batch 2811/17275   train_loss = 5.038\n",
      "Epoch   0 Batch 2812/17275   train_loss = 5.234\n",
      "Epoch   0 Batch 2813/17275   train_loss = 3.751\n",
      "Epoch   0 Batch 2814/17275   train_loss = 2.878\n",
      "Epoch   0 Batch 2815/17275   train_loss = 3.757\n",
      "Epoch   0 Batch 2816/17275   train_loss = 5.194\n",
      "Epoch   0 Batch 2817/17275   train_loss = 1.790\n",
      "Epoch   0 Batch 2818/17275   train_loss = 1.991\n",
      "Epoch   0 Batch 2819/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 2820/17275   train_loss = 3.100\n",
      "Epoch   0 Batch 2821/17275   train_loss = 3.121\n",
      "Epoch   0 Batch 2822/17275   train_loss = 4.520\n",
      "Epoch   0 Batch 2823/17275   train_loss = 3.958\n",
      "Epoch   0 Batch 2824/17275   train_loss = 2.760\n",
      "Epoch   0 Batch 2825/17275   train_loss = 7.080\n",
      "Epoch   0 Batch 2826/17275   train_loss = 1.962\n",
      "Epoch   0 Batch 2827/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 2828/17275   train_loss = 3.271\n",
      "Epoch   0 Batch 2829/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 2830/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 2831/17275   train_loss = 4.246\n",
      "Epoch   0 Batch 2832/17275   train_loss = 4.433\n",
      "Epoch   0 Batch 2833/17275   train_loss = 2.021\n",
      "Epoch   0 Batch 2834/17275   train_loss = 4.460\n",
      "Epoch   0 Batch 2835/17275   train_loss = 5.457\n",
      "Epoch   0 Batch 2836/17275   train_loss = 5.461\n",
      "Epoch   0 Batch 2837/17275   train_loss = 2.700\n",
      "Epoch   0 Batch 2838/17275   train_loss = 6.230\n",
      "Epoch   0 Batch 2839/17275   train_loss = 5.510\n",
      "Epoch   0 Batch 2840/17275   train_loss = 2.152\n",
      "Epoch   0 Batch 2841/17275   train_loss = 1.744\n",
      "Epoch   0 Batch 2842/17275   train_loss = 4.425\n",
      "Epoch   0 Batch 2843/17275   train_loss = 3.930\n",
      "Epoch   0 Batch 2844/17275   train_loss = 2.832\n",
      "Epoch   0 Batch 2845/17275   train_loss = 8.353\n",
      "Epoch   0 Batch 2846/17275   train_loss = 2.864\n",
      "Epoch   0 Batch 2847/17275   train_loss = 3.501\n",
      "Epoch   0 Batch 2848/17275   train_loss = 5.956\n",
      "Epoch   0 Batch 2849/17275   train_loss = 3.268\n",
      "Epoch   0 Batch 2850/17275   train_loss = 2.650\n",
      "Epoch   0 Batch 2851/17275   train_loss = 4.397\n",
      "Epoch   0 Batch 2852/17275   train_loss = 2.675\n",
      "Epoch   0 Batch 2853/17275   train_loss = 3.700\n",
      "Epoch   0 Batch 2854/17275   train_loss = 3.835\n",
      "Epoch   0 Batch 2855/17275   train_loss = 4.384\n",
      "Epoch   0 Batch 2856/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 2857/17275   train_loss = 4.034\n",
      "Epoch   0 Batch 2858/17275   train_loss = 2.024\n",
      "Epoch   0 Batch 2859/17275   train_loss = 4.375\n",
      "Epoch   0 Batch 2860/17275   train_loss = 3.671\n",
      "Epoch   0 Batch 2861/17275   train_loss = 3.030\n",
      "Epoch   0 Batch 2862/17275   train_loss = 4.729\n",
      "Epoch   0 Batch 2863/17275   train_loss = 3.071\n",
      "Epoch   0 Batch 2864/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 2865/17275   train_loss = 2.961\n",
      "Epoch   0 Batch 2866/17275   train_loss = 4.096\n",
      "Epoch   0 Batch 2867/17275   train_loss = 2.219\n",
      "Epoch   0 Batch 2868/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 2869/17275   train_loss = 4.052\n",
      "Epoch   0 Batch 2870/17275   train_loss = 3.668\n",
      "Epoch   0 Batch 2871/17275   train_loss = 6.025\n",
      "Epoch   0 Batch 2872/17275   train_loss = 5.661\n",
      "Epoch   0 Batch 2873/17275   train_loss = 4.349\n",
      "Epoch   0 Batch 2874/17275   train_loss = 4.401\n",
      "Epoch   0 Batch 2875/17275   train_loss = 3.252\n",
      "Epoch   0 Batch 2876/17275   train_loss = 2.531\n",
      "Epoch   0 Batch 2877/17275   train_loss = 3.802\n",
      "Epoch   0 Batch 2878/17275   train_loss = 3.999\n",
      "Epoch   0 Batch 2879/17275   train_loss = 2.871\n",
      "Epoch   0 Batch 2880/17275   train_loss = 2.455\n",
      "Epoch   0 Batch 2881/17275   train_loss = 6.622\n",
      "Epoch   0 Batch 2882/17275   train_loss = 1.993\n",
      "Epoch   0 Batch 2883/17275   train_loss = 3.142\n",
      "Epoch   0 Batch 2884/17275   train_loss = 3.689\n",
      "Epoch   0 Batch 2885/17275   train_loss = 4.243\n",
      "Epoch   0 Batch 2886/17275   train_loss = 3.605\n",
      "Epoch   0 Batch 2887/17275   train_loss = 2.329\n",
      "Epoch   0 Batch 2888/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 2889/17275   train_loss = 3.028\n",
      "Epoch   0 Batch 2890/17275   train_loss = 1.836\n",
      "Epoch   0 Batch 2891/17275   train_loss = 2.237\n",
      "Epoch   0 Batch 2892/17275   train_loss = 3.884\n",
      "Epoch   0 Batch 2893/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 2894/17275   train_loss = 3.126\n",
      "Epoch   0 Batch 2895/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 2896/17275   train_loss = 4.288\n",
      "Epoch   0 Batch 2897/17275   train_loss = 5.248\n",
      "Epoch   0 Batch 2898/17275   train_loss = 2.285\n",
      "Epoch   0 Batch 2899/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 2900/17275   train_loss = 5.612\n",
      "Epoch   0 Batch 2901/17275   train_loss = 6.189\n",
      "Epoch   0 Batch 2902/17275   train_loss = 5.463\n",
      "Epoch   0 Batch 2903/17275   train_loss = 4.099\n",
      "Epoch   0 Batch 2904/17275   train_loss = 2.039\n",
      "Epoch   0 Batch 2905/17275   train_loss = 3.411\n",
      "Epoch   0 Batch 2906/17275   train_loss = 5.531\n",
      "Epoch   0 Batch 2907/17275   train_loss = 2.825\n",
      "Epoch   0 Batch 2908/17275   train_loss = 1.680\n",
      "Epoch   0 Batch 2909/17275   train_loss = 1.991\n",
      "Epoch   0 Batch 2910/17275   train_loss = 5.431\n",
      "Epoch   0 Batch 2911/17275   train_loss = 3.167\n",
      "Epoch   0 Batch 2912/17275   train_loss = 3.184\n",
      "Epoch   0 Batch 2913/17275   train_loss = 4.907\n",
      "Epoch   0 Batch 2914/17275   train_loss = 3.162\n",
      "Epoch   0 Batch 2915/17275   train_loss = 3.193\n",
      "Epoch   0 Batch 2916/17275   train_loss = 2.328\n",
      "Epoch   0 Batch 2917/17275   train_loss = 3.515\n",
      "Epoch   0 Batch 2918/17275   train_loss = 5.009\n",
      "Epoch   0 Batch 2919/17275   train_loss = 5.531\n",
      "Epoch   0 Batch 2920/17275   train_loss = 3.045\n",
      "Epoch   0 Batch 2921/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 2922/17275   train_loss = 4.722\n",
      "Epoch   0 Batch 2923/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 2924/17275   train_loss = 5.564\n",
      "Epoch   0 Batch 2925/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 2926/17275   train_loss = 2.791\n",
      "Epoch   0 Batch 2927/17275   train_loss = 4.229\n",
      "Epoch   0 Batch 2928/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 2929/17275   train_loss = 2.062\n",
      "Epoch   0 Batch 2930/17275   train_loss = 5.424\n",
      "Epoch   0 Batch 2931/17275   train_loss = 2.941\n",
      "Epoch   0 Batch 2932/17275   train_loss = 3.605\n",
      "Epoch   0 Batch 2933/17275   train_loss = 6.103\n",
      "Epoch   0 Batch 2934/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 2935/17275   train_loss = 2.331\n",
      "Epoch   0 Batch 2936/17275   train_loss = 3.085\n",
      "Epoch   0 Batch 2937/17275   train_loss = 6.358\n",
      "Epoch   0 Batch 2938/17275   train_loss = 3.580\n",
      "Epoch   0 Batch 2939/17275   train_loss = 2.717\n",
      "Epoch   0 Batch 2940/17275   train_loss = 3.111\n",
      "Epoch   0 Batch 2941/17275   train_loss = 3.263\n",
      "Epoch   0 Batch 2942/17275   train_loss = 4.433\n",
      "Epoch   0 Batch 2943/17275   train_loss = 5.217\n",
      "Epoch   0 Batch 2944/17275   train_loss = 2.401\n",
      "Epoch   0 Batch 2945/17275   train_loss = 3.433\n",
      "Epoch   0 Batch 2946/17275   train_loss = 5.207\n",
      "Epoch   0 Batch 2947/17275   train_loss = 3.909\n",
      "Epoch   0 Batch 2948/17275   train_loss = 2.847\n",
      "Epoch   0 Batch 2949/17275   train_loss = 8.422\n",
      "Epoch   0 Batch 2950/17275   train_loss = 2.736\n",
      "Epoch   0 Batch 2951/17275   train_loss = 1.935\n",
      "Epoch   0 Batch 2952/17275   train_loss = 2.148\n",
      "Epoch   0 Batch 2953/17275   train_loss = 6.273\n",
      "Epoch   0 Batch 2954/17275   train_loss = 5.386\n",
      "Epoch   0 Batch 2955/17275   train_loss = 1.920\n",
      "Epoch   0 Batch 2956/17275   train_loss = 5.584\n",
      "Epoch   0 Batch 2957/17275   train_loss = 1.892\n",
      "Epoch   0 Batch 2958/17275   train_loss = 4.880\n",
      "Epoch   0 Batch 2959/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 2960/17275   train_loss = 5.877\n",
      "Epoch   0 Batch 2961/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 2962/17275   train_loss = 2.380\n",
      "Epoch   0 Batch 2963/17275   train_loss = 3.253\n",
      "Epoch   0 Batch 2964/17275   train_loss = 6.358\n",
      "Epoch   0 Batch 2965/17275   train_loss = 4.390\n",
      "Epoch   0 Batch 2966/17275   train_loss = 1.818\n",
      "Epoch   0 Batch 2967/17275   train_loss = 3.489\n",
      "Epoch   0 Batch 2968/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 2969/17275   train_loss = 2.114\n",
      "Epoch   0 Batch 2970/17275   train_loss = 6.684\n",
      "Epoch   0 Batch 2971/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 2972/17275   train_loss = 4.207\n",
      "Epoch   0 Batch 2973/17275   train_loss = 2.288\n",
      "Epoch   0 Batch 2974/17275   train_loss = 1.634\n",
      "Epoch   0 Batch 2975/17275   train_loss = 3.170\n",
      "Epoch   0 Batch 2976/17275   train_loss = 1.594\n",
      "Epoch   0 Batch 2977/17275   train_loss = 2.449\n",
      "Epoch   0 Batch 2978/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 2979/17275   train_loss = 2.351\n",
      "Epoch   0 Batch 2980/17275   train_loss = 4.297\n",
      "Epoch   0 Batch 2981/17275   train_loss = 3.865\n",
      "Epoch   0 Batch 2982/17275   train_loss = 2.152\n",
      "Epoch   0 Batch 2983/17275   train_loss = 3.239\n",
      "Epoch   0 Batch 2984/17275   train_loss = 6.408\n",
      "Epoch   0 Batch 2985/17275   train_loss = 3.730\n",
      "Epoch   0 Batch 2986/17275   train_loss = 8.495\n",
      "Epoch   0 Batch 2987/17275   train_loss = 1.770\n",
      "Epoch   0 Batch 2988/17275   train_loss = 2.089\n",
      "Epoch   0 Batch 2989/17275   train_loss = 5.437\n",
      "Epoch   0 Batch 2990/17275   train_loss = 6.244\n",
      "Epoch   0 Batch 2991/17275   train_loss = 6.230\n",
      "Epoch   0 Batch 2992/17275   train_loss = 6.468\n",
      "Epoch   0 Batch 2993/17275   train_loss = 6.878\n",
      "Epoch   0 Batch 2994/17275   train_loss = 1.747\n",
      "Epoch   0 Batch 2995/17275   train_loss = 2.630\n",
      "Epoch   0 Batch 2996/17275   train_loss = 4.571\n",
      "Epoch   0 Batch 2997/17275   train_loss = 3.831\n",
      "Epoch   0 Batch 2998/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 2999/17275   train_loss = 4.698\n",
      "Epoch   0 Batch 3000/17275   train_loss = 6.146\n",
      "Epoch   0 Batch 3001/17275   train_loss = 4.931\n",
      "Epoch   0 Batch 3002/17275   train_loss = 3.048\n",
      "Epoch   0 Batch 3003/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 3004/17275   train_loss = 5.830\n",
      "Epoch   0 Batch 3005/17275   train_loss = 5.917\n",
      "Epoch   0 Batch 3006/17275   train_loss = 5.046\n",
      "Epoch   0 Batch 3007/17275   train_loss = 2.297\n",
      "Epoch   0 Batch 3008/17275   train_loss = 3.879\n",
      "Epoch   0 Batch 3009/17275   train_loss = 8.460\n",
      "Epoch   0 Batch 3010/17275   train_loss = 2.854\n",
      "Epoch   0 Batch 3011/17275   train_loss = 6.261\n",
      "Epoch   0 Batch 3012/17275   train_loss = 5.383\n",
      "Epoch   0 Batch 3013/17275   train_loss = 3.261\n",
      "Epoch   0 Batch 3014/17275   train_loss = 2.954\n",
      "Epoch   0 Batch 3015/17275   train_loss = 6.869\n",
      "Epoch   0 Batch 3016/17275   train_loss = 8.450\n",
      "Epoch   0 Batch 3017/17275   train_loss = 3.073\n",
      "Epoch   0 Batch 3018/17275   train_loss = 3.679\n",
      "Epoch   0 Batch 3019/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 3020/17275   train_loss = 6.226\n",
      "Epoch   0 Batch 3021/17275   train_loss = 4.574\n",
      "Epoch   0 Batch 3022/17275   train_loss = 5.705\n",
      "Epoch   0 Batch 3023/17275   train_loss = 4.387\n",
      "Epoch   0 Batch 3024/17275   train_loss = 5.194\n",
      "Epoch   0 Batch 3025/17275   train_loss = 5.531\n",
      "Epoch   0 Batch 3026/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 3027/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 3028/17275   train_loss = 3.044\n",
      "Epoch   0 Batch 3029/17275   train_loss = 4.191\n",
      "Epoch   0 Batch 3030/17275   train_loss = 3.260\n",
      "Epoch   0 Batch 3031/17275   train_loss = 5.153\n",
      "Epoch   0 Batch 3032/17275   train_loss = 2.856\n",
      "Epoch   0 Batch 3033/17275   train_loss = 5.971\n",
      "Epoch   0 Batch 3034/17275   train_loss = 2.237\n",
      "Epoch   0 Batch 3035/17275   train_loss = 5.473\n",
      "Epoch   0 Batch 3036/17275   train_loss = 2.768\n",
      "Epoch   0 Batch 3037/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 3038/17275   train_loss = 4.126\n",
      "Epoch   0 Batch 3039/17275   train_loss = 2.990\n",
      "Epoch   0 Batch 3040/17275   train_loss = 2.378\n",
      "Epoch   0 Batch 3041/17275   train_loss = 3.497\n",
      "Epoch   0 Batch 3042/17275   train_loss = 1.930\n",
      "Epoch   0 Batch 3043/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 3044/17275   train_loss = 3.918\n",
      "Epoch   0 Batch 3045/17275   train_loss = 4.309\n",
      "Epoch   0 Batch 3046/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 3047/17275   train_loss = 4.104\n",
      "Epoch   0 Batch 3048/17275   train_loss = 5.113\n",
      "Epoch   0 Batch 3049/17275   train_loss = 4.162\n",
      "Epoch   0 Batch 3050/17275   train_loss = 6.346\n",
      "Epoch   0 Batch 3051/17275   train_loss = 5.093\n",
      "Epoch   0 Batch 3052/17275   train_loss = 1.764\n",
      "Epoch   0 Batch 3053/17275   train_loss = 2.486\n",
      "Epoch   0 Batch 3054/17275   train_loss = 1.695\n",
      "Epoch   0 Batch 3055/17275   train_loss = 2.800\n",
      "Epoch   0 Batch 3056/17275   train_loss = 3.502\n",
      "Epoch   0 Batch 3057/17275   train_loss = 2.832\n",
      "Epoch   0 Batch 3058/17275   train_loss = 2.717\n",
      "Epoch   0 Batch 3059/17275   train_loss = 2.684\n",
      "Epoch   0 Batch 3060/17275   train_loss = 2.725\n",
      "Epoch   0 Batch 3061/17275   train_loss = 3.467\n",
      "Epoch   0 Batch 3062/17275   train_loss = 3.645\n",
      "Epoch   0 Batch 3063/17275   train_loss = 2.347\n",
      "Epoch   0 Batch 3064/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 3065/17275   train_loss = 3.043\n",
      "Epoch   0 Batch 3066/17275   train_loss = 6.427\n",
      "Epoch   0 Batch 3067/17275   train_loss = 3.271\n",
      "Epoch   0 Batch 3068/17275   train_loss = 2.657\n",
      "Epoch   0 Batch 3069/17275   train_loss = 5.584\n",
      "Epoch   0 Batch 3070/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 3071/17275   train_loss = 6.062\n",
      "Epoch   0 Batch 3072/17275   train_loss = 4.202\n",
      "Epoch   0 Batch 3073/17275   train_loss = 1.889\n",
      "Epoch   0 Batch 3074/17275   train_loss = 3.425\n",
      "Epoch   0 Batch 3075/17275   train_loss = 3.330\n",
      "Epoch   0 Batch 3076/17275   train_loss = 3.052\n",
      "Epoch   0 Batch 3077/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 3078/17275   train_loss = 2.870\n",
      "Epoch   0 Batch 3079/17275   train_loss = 3.042\n",
      "Epoch   0 Batch 3080/17275   train_loss = 5.079\n",
      "Epoch   0 Batch 3081/17275   train_loss = 1.684\n",
      "Epoch   0 Batch 3082/17275   train_loss = 3.160\n",
      "Epoch   0 Batch 3083/17275   train_loss = 5.555\n",
      "Epoch   0 Batch 3084/17275   train_loss = 5.300\n",
      "Epoch   0 Batch 3085/17275   train_loss = 4.633\n",
      "Epoch   0 Batch 3086/17275   train_loss = 7.397\n",
      "Epoch   0 Batch 3087/17275   train_loss = 4.118\n",
      "Epoch   0 Batch 3088/17275   train_loss = 5.325\n",
      "Epoch   0 Batch 3089/17275   train_loss = 3.377\n",
      "Epoch   0 Batch 3090/17275   train_loss = 4.686\n",
      "Epoch   0 Batch 3091/17275   train_loss = 3.545\n",
      "Epoch   0 Batch 3092/17275   train_loss = 2.314\n",
      "Epoch   0 Batch 3093/17275   train_loss = 5.828\n",
      "Epoch   0 Batch 3094/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 3095/17275   train_loss = 2.427\n",
      "Epoch   0 Batch 3096/17275   train_loss = 6.185\n",
      "Epoch   0 Batch 3097/17275   train_loss = 5.627\n",
      "Epoch   0 Batch 3098/17275   train_loss = 5.734\n",
      "Epoch   0 Batch 3099/17275   train_loss = 3.982\n",
      "Epoch   0 Batch 3100/17275   train_loss = 4.236\n",
      "Epoch   0 Batch 3101/17275   train_loss = 1.934\n",
      "Epoch   0 Batch 3102/17275   train_loss = 2.786\n",
      "Epoch   0 Batch 3103/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 3104/17275   train_loss = 3.634\n",
      "Epoch   0 Batch 3105/17275   train_loss = 6.053\n",
      "Epoch   0 Batch 3106/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 3107/17275   train_loss = 1.957\n",
      "Epoch   0 Batch 3108/17275   train_loss = 5.157\n",
      "Epoch   0 Batch 3109/17275   train_loss = 6.007\n",
      "Epoch   0 Batch 3110/17275   train_loss = 3.310\n",
      "Epoch   0 Batch 3111/17275   train_loss = 5.262\n",
      "Epoch   0 Batch 3112/17275   train_loss = 2.444\n",
      "Epoch   0 Batch 3113/17275   train_loss = 3.737\n",
      "Epoch   0 Batch 3114/17275   train_loss = 3.141\n",
      "Epoch   0 Batch 3115/17275   train_loss = 3.629\n",
      "Epoch   0 Batch 3116/17275   train_loss = 2.780\n",
      "Epoch   0 Batch 3117/17275   train_loss = 4.089\n",
      "Epoch   0 Batch 3118/17275   train_loss = 3.065\n",
      "Epoch   0 Batch 3119/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 3120/17275   train_loss = 1.917\n",
      "Epoch   0 Batch 3121/17275   train_loss = 4.552\n",
      "Epoch   0 Batch 3122/17275   train_loss = 5.554\n",
      "Epoch   0 Batch 3123/17275   train_loss = 2.786\n",
      "Epoch   0 Batch 3124/17275   train_loss = 3.244\n",
      "Epoch   0 Batch 3125/17275   train_loss = 6.004\n",
      "Epoch   0 Batch 3126/17275   train_loss = 5.887\n",
      "Epoch   0 Batch 3127/17275   train_loss = 1.861\n",
      "Epoch   0 Batch 3128/17275   train_loss = 4.972\n",
      "Epoch   0 Batch 3129/17275   train_loss = 4.495\n",
      "Epoch   0 Batch 3130/17275   train_loss = 5.095\n",
      "Epoch   0 Batch 3131/17275   train_loss = 3.992\n",
      "Epoch   0 Batch 3132/17275   train_loss = 2.640\n",
      "Epoch   0 Batch 3133/17275   train_loss = 3.722\n",
      "Epoch   0 Batch 3134/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 3135/17275   train_loss = 3.839\n",
      "Epoch   0 Batch 3136/17275   train_loss = 5.083\n",
      "Epoch   0 Batch 3137/17275   train_loss = 2.807\n",
      "Epoch   0 Batch 3138/17275   train_loss = 6.353\n",
      "Epoch   0 Batch 3139/17275   train_loss = 2.829\n",
      "Epoch   0 Batch 3140/17275   train_loss = 1.807\n",
      "Epoch   0 Batch 3141/17275   train_loss = 4.719\n",
      "Epoch   0 Batch 3142/17275   train_loss = 8.484\n",
      "Epoch   0 Batch 3143/17275   train_loss = 3.098\n",
      "Epoch   0 Batch 3144/17275   train_loss = 8.489\n",
      "Epoch   0 Batch 3145/17275   train_loss = 1.798\n",
      "Epoch   0 Batch 3146/17275   train_loss = 3.910\n",
      "Epoch   0 Batch 3147/17275   train_loss = 5.556\n",
      "Epoch   0 Batch 3148/17275   train_loss = 3.258\n",
      "Epoch   0 Batch 3149/17275   train_loss = 3.353\n",
      "Epoch   0 Batch 3150/17275   train_loss = 5.582\n",
      "Epoch   0 Batch 3151/17275   train_loss = 5.097\n",
      "Epoch   0 Batch 3152/17275   train_loss = 2.143\n",
      "Epoch   0 Batch 3153/17275   train_loss = 1.711\n",
      "Epoch   0 Batch 3154/17275   train_loss = 2.753\n",
      "Epoch   0 Batch 3155/17275   train_loss = 1.661\n",
      "Epoch   0 Batch 3156/17275   train_loss = 4.495\n",
      "Epoch   0 Batch 3157/17275   train_loss = 3.924\n",
      "Epoch   0 Batch 3158/17275   train_loss = 2.323\n",
      "Epoch   0 Batch 3159/17275   train_loss = 3.398\n",
      "Epoch   0 Batch 3160/17275   train_loss = 2.015\n",
      "Epoch   0 Batch 3161/17275   train_loss = 5.658\n",
      "Epoch   0 Batch 3162/17275   train_loss = 3.134\n",
      "Epoch   0 Batch 3163/17275   train_loss = 4.241\n",
      "Epoch   0 Batch 3164/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 3165/17275   train_loss = 2.984\n",
      "Epoch   0 Batch 3166/17275   train_loss = 1.914\n",
      "Epoch   0 Batch 3167/17275   train_loss = 6.682\n",
      "Epoch   0 Batch 3168/17275   train_loss = 2.848\n",
      "Epoch   0 Batch 3169/17275   train_loss = 3.988\n",
      "Epoch   0 Batch 3170/17275   train_loss = 4.690\n",
      "Epoch   0 Batch 3171/17275   train_loss = 5.533\n",
      "Epoch   0 Batch 3172/17275   train_loss = 4.007\n",
      "Epoch   0 Batch 3173/17275   train_loss = 3.052\n",
      "Epoch   0 Batch 3174/17275   train_loss = 5.371\n",
      "Epoch   0 Batch 3175/17275   train_loss = 3.406\n",
      "Epoch   0 Batch 3176/17275   train_loss = 5.352\n",
      "Epoch   0 Batch 3177/17275   train_loss = 2.445\n",
      "Epoch   0 Batch 3178/17275   train_loss = 8.561\n",
      "Epoch   0 Batch 3179/17275   train_loss = 2.584\n",
      "Epoch   0 Batch 3180/17275   train_loss = 2.160\n",
      "Epoch   0 Batch 3181/17275   train_loss = 5.484\n",
      "Epoch   0 Batch 3182/17275   train_loss = 3.333\n",
      "Epoch   0 Batch 3183/17275   train_loss = 3.216\n",
      "Epoch   0 Batch 3184/17275   train_loss = 1.561\n",
      "Epoch   0 Batch 3185/17275   train_loss = 2.685\n",
      "Epoch   0 Batch 3186/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 3187/17275   train_loss = 3.400\n",
      "Epoch   0 Batch 3188/17275   train_loss = 1.583\n",
      "Epoch   0 Batch 3189/17275   train_loss = 1.764\n",
      "Epoch   0 Batch 3190/17275   train_loss = 2.935\n",
      "Epoch   0 Batch 3191/17275   train_loss = 2.875\n",
      "Epoch   0 Batch 3192/17275   train_loss = 2.677\n",
      "Epoch   0 Batch 3193/17275   train_loss = 1.547\n",
      "Epoch   0 Batch 3194/17275   train_loss = 5.230\n",
      "Epoch   0 Batch 3195/17275   train_loss = 2.611\n",
      "Epoch   0 Batch 3196/17275   train_loss = 2.712\n",
      "Epoch   0 Batch 3197/17275   train_loss = 1.499\n",
      "Epoch   0 Batch 3198/17275   train_loss = 1.678\n",
      "Epoch   0 Batch 3199/17275   train_loss = 5.349\n",
      "Epoch   0 Batch 3200/17275   train_loss = 2.326\n",
      "Epoch   0 Batch 3201/17275   train_loss = 2.735\n",
      "Epoch   0 Batch 3202/17275   train_loss = 8.643\n",
      "Epoch   0 Batch 3203/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 3204/17275   train_loss = 5.604\n",
      "Epoch   0 Batch 3205/17275   train_loss = 6.475\n",
      "Epoch   0 Batch 3206/17275   train_loss = 2.389\n",
      "Epoch   0 Batch 3207/17275   train_loss = 8.276\n",
      "Epoch   0 Batch 3208/17275   train_loss = 5.654\n",
      "Epoch   0 Batch 3209/17275   train_loss = 6.295\n",
      "Epoch   0 Batch 3210/17275   train_loss = 6.503\n",
      "Epoch   0 Batch 3211/17275   train_loss = 4.557\n",
      "Epoch   0 Batch 3212/17275   train_loss = 6.988\n",
      "Epoch   0 Batch 3213/17275   train_loss = 1.668\n",
      "Epoch   0 Batch 3214/17275   train_loss = 5.185\n",
      "Epoch   0 Batch 3215/17275   train_loss = 1.834\n",
      "Epoch   0 Batch 3216/17275   train_loss = 4.115\n",
      "Epoch   0 Batch 3217/17275   train_loss = 6.406\n",
      "Epoch   0 Batch 3218/17275   train_loss = 3.495\n",
      "Epoch   0 Batch 3219/17275   train_loss = 5.558\n",
      "Epoch   0 Batch 3220/17275   train_loss = 5.491\n",
      "Epoch   0 Batch 3221/17275   train_loss = 5.456\n",
      "Epoch   0 Batch 3222/17275   train_loss = 6.092\n",
      "Epoch   0 Batch 3223/17275   train_loss = 3.665\n",
      "Epoch   0 Batch 3224/17275   train_loss = 5.139\n",
      "Epoch   0 Batch 3225/17275   train_loss = 4.290\n",
      "Epoch   0 Batch 3226/17275   train_loss = 1.568\n",
      "Epoch   0 Batch 3227/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 3228/17275   train_loss = 5.613\n",
      "Epoch   0 Batch 3229/17275   train_loss = 6.684\n",
      "Epoch   0 Batch 3230/17275   train_loss = 1.778\n",
      "Epoch   0 Batch 3231/17275   train_loss = 5.131\n",
      "Epoch   0 Batch 3232/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 3233/17275   train_loss = 2.462\n",
      "Epoch   0 Batch 3234/17275   train_loss = 5.430\n",
      "Epoch   0 Batch 3235/17275   train_loss = 3.058\n",
      "Epoch   0 Batch 3236/17275   train_loss = 3.305\n",
      "Epoch   0 Batch 3237/17275   train_loss = 1.548\n",
      "Epoch   0 Batch 3238/17275   train_loss = 2.596\n",
      "Epoch   0 Batch 3239/17275   train_loss = 5.104\n",
      "Epoch   0 Batch 3240/17275   train_loss = 5.430\n",
      "Epoch   0 Batch 3241/17275   train_loss = 1.526\n",
      "Epoch   0 Batch 3242/17275   train_loss = 1.744\n",
      "Epoch   0 Batch 3243/17275   train_loss = 4.612\n",
      "Epoch   0 Batch 3244/17275   train_loss = 4.732\n",
      "Epoch   0 Batch 3245/17275   train_loss = 8.538\n",
      "Epoch   0 Batch 3246/17275   train_loss = 4.746\n",
      "Epoch   0 Batch 3247/17275   train_loss = 1.477\n",
      "Epoch   0 Batch 3248/17275   train_loss = 1.711\n",
      "Epoch   0 Batch 3249/17275   train_loss = 5.529\n",
      "Epoch   0 Batch 3250/17275   train_loss = 6.023\n",
      "Epoch   0 Batch 3251/17275   train_loss = 5.743\n",
      "Epoch   0 Batch 3252/17275   train_loss = 3.586\n",
      "Epoch   0 Batch 3253/17275   train_loss = 8.198\n",
      "Epoch   0 Batch 3254/17275   train_loss = 3.128\n",
      "Epoch   0 Batch 3255/17275   train_loss = 5.486\n",
      "Epoch   0 Batch 3256/17275   train_loss = 8.548\n",
      "Epoch   0 Batch 3257/17275   train_loss = 2.498\n",
      "Epoch   0 Batch 3258/17275   train_loss = 6.204\n",
      "Epoch   0 Batch 3259/17275   train_loss = 2.998\n",
      "Epoch   0 Batch 3260/17275   train_loss = 5.833\n",
      "Epoch   0 Batch 3261/17275   train_loss = 4.531\n",
      "Epoch   0 Batch 3262/17275   train_loss = 2.726\n",
      "Epoch   0 Batch 3263/17275   train_loss = 3.571\n",
      "Epoch   0 Batch 3264/17275   train_loss = 6.102\n",
      "Epoch   0 Batch 3265/17275   train_loss = 5.086\n",
      "Epoch   0 Batch 3266/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 3267/17275   train_loss = 3.899\n",
      "Epoch   0 Batch 3268/17275   train_loss = 4.729\n",
      "Epoch   0 Batch 3269/17275   train_loss = 3.415\n",
      "Epoch   0 Batch 3270/17275   train_loss = 4.572\n",
      "Epoch   0 Batch 3271/17275   train_loss = 4.278\n",
      "Epoch   0 Batch 3272/17275   train_loss = 1.768\n",
      "Epoch   0 Batch 3273/17275   train_loss = 2.505\n",
      "Epoch   0 Batch 3274/17275   train_loss = 2.569\n",
      "Epoch   0 Batch 3275/17275   train_loss = 5.457\n",
      "Epoch   0 Batch 3276/17275   train_loss = 5.270\n",
      "Epoch   0 Batch 3277/17275   train_loss = 5.927\n",
      "Epoch   0 Batch 3278/17275   train_loss = 5.123\n",
      "Epoch   0 Batch 3279/17275   train_loss = 3.550\n",
      "Epoch   0 Batch 3280/17275   train_loss = 5.432\n",
      "Epoch   0 Batch 3281/17275   train_loss = 6.217\n",
      "Epoch   0 Batch 3282/17275   train_loss = 3.059\n",
      "Epoch   0 Batch 3283/17275   train_loss = 4.130\n",
      "Epoch   0 Batch 3284/17275   train_loss = 5.674\n",
      "Epoch   0 Batch 3285/17275   train_loss = 2.987\n",
      "Epoch   0 Batch 3286/17275   train_loss = 2.298\n",
      "Epoch   0 Batch 3287/17275   train_loss = 5.379\n",
      "Epoch   0 Batch 3288/17275   train_loss = 3.035\n",
      "Epoch   0 Batch 3289/17275   train_loss = 4.817\n",
      "Epoch   0 Batch 3290/17275   train_loss = 3.180\n",
      "Epoch   0 Batch 3291/17275   train_loss = 1.835\n",
      "Epoch   0 Batch 3292/17275   train_loss = 4.512\n",
      "Epoch   0 Batch 3293/17275   train_loss = 7.395\n",
      "Epoch   0 Batch 3294/17275   train_loss = 4.527\n",
      "Epoch   0 Batch 3295/17275   train_loss = 7.661\n",
      "Epoch   0 Batch 3296/17275   train_loss = 1.846\n",
      "Epoch   0 Batch 3297/17275   train_loss = 6.286\n",
      "Epoch   0 Batch 3298/17275   train_loss = 5.108\n",
      "Epoch   0 Batch 3299/17275   train_loss = 3.648\n",
      "Epoch   0 Batch 3300/17275   train_loss = 7.556\n",
      "Epoch   0 Batch 3301/17275   train_loss = 3.470\n",
      "Epoch   0 Batch 3302/17275   train_loss = 5.489\n",
      "Epoch   0 Batch 3303/17275   train_loss = 5.100\n",
      "Epoch   0 Batch 3304/17275   train_loss = 3.994\n",
      "Epoch   0 Batch 3305/17275   train_loss = 3.104\n",
      "Epoch   0 Batch 3306/17275   train_loss = 4.065\n",
      "Epoch   0 Batch 3307/17275   train_loss = 4.758\n",
      "Epoch   0 Batch 3308/17275   train_loss = 8.461\n",
      "Epoch   0 Batch 3309/17275   train_loss = 1.823\n",
      "Epoch   0 Batch 3310/17275   train_loss = 3.870\n",
      "Epoch   0 Batch 3311/17275   train_loss = 3.048\n",
      "Epoch   0 Batch 3312/17275   train_loss = 6.518\n",
      "Epoch   0 Batch 3313/17275   train_loss = 2.727\n",
      "Epoch   0 Batch 3314/17275   train_loss = 5.666\n",
      "Epoch   0 Batch 3315/17275   train_loss = 4.693\n",
      "Epoch   0 Batch 3316/17275   train_loss = 3.090\n",
      "Epoch   0 Batch 3317/17275   train_loss = 3.139\n",
      "Epoch   0 Batch 3318/17275   train_loss = 2.317\n",
      "Epoch   0 Batch 3319/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 3320/17275   train_loss = 4.537\n",
      "Epoch   0 Batch 3321/17275   train_loss = 6.400\n",
      "Epoch   0 Batch 3322/17275   train_loss = 3.217\n",
      "Epoch   0 Batch 3323/17275   train_loss = 3.908\n",
      "Epoch   0 Batch 3324/17275   train_loss = 1.799\n",
      "Epoch   0 Batch 3325/17275   train_loss = 1.880\n",
      "Epoch   0 Batch 3326/17275   train_loss = 5.442\n",
      "Epoch   0 Batch 3327/17275   train_loss = 2.963\n",
      "Epoch   0 Batch 3328/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 3329/17275   train_loss = 5.865\n",
      "Epoch   0 Batch 3330/17275   train_loss = 5.989\n",
      "Epoch   0 Batch 3331/17275   train_loss = 6.658\n",
      "Epoch   0 Batch 3332/17275   train_loss = 1.719\n",
      "Epoch   0 Batch 3333/17275   train_loss = 1.854\n",
      "Epoch   0 Batch 3334/17275   train_loss = 4.672\n",
      "Epoch   0 Batch 3335/17275   train_loss = 3.962\n",
      "Epoch   0 Batch 3336/17275   train_loss = 2.433\n",
      "Epoch   0 Batch 3337/17275   train_loss = 4.939\n",
      "Epoch   0 Batch 3338/17275   train_loss = 3.020\n",
      "Epoch   0 Batch 3339/17275   train_loss = 2.553\n",
      "Epoch   0 Batch 3340/17275   train_loss = 4.860\n",
      "Epoch   0 Batch 3341/17275   train_loss = 2.801\n",
      "Epoch   0 Batch 3342/17275   train_loss = 5.894\n",
      "Epoch   0 Batch 3343/17275   train_loss = 6.008\n",
      "Epoch   0 Batch 3344/17275   train_loss = 3.966\n",
      "Epoch   0 Batch 3345/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 3346/17275   train_loss = 5.811\n",
      "Epoch   0 Batch 3347/17275   train_loss = 5.772\n",
      "Epoch   0 Batch 3348/17275   train_loss = 2.526\n",
      "Epoch   0 Batch 3349/17275   train_loss = 3.548\n",
      "Epoch   0 Batch 3350/17275   train_loss = 1.754\n",
      "Epoch   0 Batch 3351/17275   train_loss = 1.859\n",
      "Epoch   0 Batch 3352/17275   train_loss = 3.738\n",
      "Epoch   0 Batch 3353/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 3354/17275   train_loss = 5.407\n",
      "Epoch   0 Batch 3355/17275   train_loss = 5.413\n",
      "Epoch   0 Batch 3356/17275   train_loss = 6.337\n",
      "Epoch   0 Batch 3357/17275   train_loss = 3.191\n",
      "Epoch   0 Batch 3358/17275   train_loss = 4.035\n",
      "Epoch   0 Batch 3359/17275   train_loss = 5.982\n",
      "Epoch   0 Batch 3360/17275   train_loss = 3.055\n",
      "Epoch   0 Batch 3361/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 3362/17275   train_loss = 1.800\n",
      "Epoch   0 Batch 3363/17275   train_loss = 1.882\n",
      "Epoch   0 Batch 3364/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 3365/17275   train_loss = 3.757\n",
      "Epoch   0 Batch 3366/17275   train_loss = 8.486\n",
      "Epoch   0 Batch 3367/17275   train_loss = 1.871\n",
      "Epoch   0 Batch 3368/17275   train_loss = 3.471\n",
      "Epoch   0 Batch 3369/17275   train_loss = 3.598\n",
      "Epoch   0 Batch 3370/17275   train_loss = 6.386\n",
      "Epoch   0 Batch 3371/17275   train_loss = 1.857\n",
      "Epoch   0 Batch 3372/17275   train_loss = 2.723\n",
      "Epoch   0 Batch 3373/17275   train_loss = 3.360\n",
      "Epoch   0 Batch 3374/17275   train_loss = 7.924\n",
      "Epoch   0 Batch 3375/17275   train_loss = 1.842\n",
      "Epoch   0 Batch 3376/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 3377/17275   train_loss = 3.087\n",
      "Epoch   0 Batch 3378/17275   train_loss = 4.894\n",
      "Epoch   0 Batch 3379/17275   train_loss = 1.735\n",
      "Epoch   0 Batch 3380/17275   train_loss = 1.721\n",
      "Epoch   0 Batch 3381/17275   train_loss = 4.477\n",
      "Epoch   0 Batch 3382/17275   train_loss = 4.499\n",
      "Epoch   0 Batch 3383/17275   train_loss = 2.336\n",
      "Epoch   0 Batch 3384/17275   train_loss = 4.437\n",
      "Epoch   0 Batch 3385/17275   train_loss = 3.361\n",
      "Epoch   0 Batch 3386/17275   train_loss = 2.532\n",
      "Epoch   0 Batch 3387/17275   train_loss = 4.295\n",
      "Epoch   0 Batch 3388/17275   train_loss = 3.172\n",
      "Epoch   0 Batch 3389/17275   train_loss = 2.039\n",
      "Epoch   0 Batch 3390/17275   train_loss = 1.638\n",
      "Epoch   0 Batch 3391/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 3392/17275   train_loss = 3.131\n",
      "Epoch   0 Batch 3393/17275   train_loss = 5.322\n",
      "Epoch   0 Batch 3394/17275   train_loss = 6.025\n",
      "Epoch   0 Batch 3395/17275   train_loss = 5.805\n",
      "Epoch   0 Batch 3396/17275   train_loss = 4.743\n",
      "Epoch   0 Batch 3397/17275   train_loss = 3.490\n",
      "Epoch   0 Batch 3398/17275   train_loss = 3.299\n",
      "Epoch   0 Batch 3399/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 3400/17275   train_loss = 3.884\n",
      "Epoch   0 Batch 3401/17275   train_loss = 6.569\n",
      "Epoch   0 Batch 3402/17275   train_loss = 4.090\n",
      "Epoch   0 Batch 3403/17275   train_loss = 4.635\n",
      "Epoch   0 Batch 3404/17275   train_loss = 2.667\n",
      "Epoch   0 Batch 3405/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 3406/17275   train_loss = 3.414\n",
      "Epoch   0 Batch 3407/17275   train_loss = 5.882\n",
      "Epoch   0 Batch 3408/17275   train_loss = 2.330\n",
      "Epoch   0 Batch 3409/17275   train_loss = 2.120\n",
      "Epoch   0 Batch 3410/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 3411/17275   train_loss = 8.543\n",
      "Epoch   0 Batch 3412/17275   train_loss = 3.198\n",
      "Epoch   0 Batch 3413/17275   train_loss = 3.685\n",
      "Epoch   0 Batch 3414/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 3415/17275   train_loss = 6.304\n",
      "Epoch   0 Batch 3416/17275   train_loss = 2.748\n",
      "Epoch   0 Batch 3417/17275   train_loss = 3.946\n",
      "Epoch   0 Batch 3418/17275   train_loss = 4.929\n",
      "Epoch   0 Batch 3419/17275   train_loss = 1.857\n",
      "Epoch   0 Batch 3420/17275   train_loss = 4.057\n",
      "Epoch   0 Batch 3421/17275   train_loss = 6.134\n",
      "Epoch   0 Batch 3422/17275   train_loss = 8.529\n",
      "Epoch   0 Batch 3423/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 3424/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 3425/17275   train_loss = 4.974\n",
      "Epoch   0 Batch 3426/17275   train_loss = 2.377\n",
      "Epoch   0 Batch 3427/17275   train_loss = 3.903\n",
      "Epoch   0 Batch 3428/17275   train_loss = 6.556\n",
      "Epoch   0 Batch 3429/17275   train_loss = 4.098\n",
      "Epoch   0 Batch 3430/17275   train_loss = 6.708\n",
      "Epoch   0 Batch 3431/17275   train_loss = 2.287\n",
      "Epoch   0 Batch 3432/17275   train_loss = 3.103\n",
      "Epoch   0 Batch 3433/17275   train_loss = 3.643\n",
      "Epoch   0 Batch 3434/17275   train_loss = 1.890\n",
      "Epoch   0 Batch 3435/17275   train_loss = 2.990\n",
      "Epoch   0 Batch 3436/17275   train_loss = 3.674\n",
      "Epoch   0 Batch 3437/17275   train_loss = 3.992\n",
      "Epoch   0 Batch 3438/17275   train_loss = 5.886\n",
      "Epoch   0 Batch 3439/17275   train_loss = 3.459\n",
      "Epoch   0 Batch 3440/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 3441/17275   train_loss = 6.801\n",
      "Epoch   0 Batch 3442/17275   train_loss = 7.206\n",
      "Epoch   0 Batch 3443/17275   train_loss = 3.792\n",
      "Epoch   0 Batch 3444/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 3445/17275   train_loss = 1.934\n",
      "Epoch   0 Batch 3446/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 3447/17275   train_loss = 3.521\n",
      "Epoch   0 Batch 3448/17275   train_loss = 6.233\n",
      "Epoch   0 Batch 3449/17275   train_loss = 2.209\n",
      "Epoch   0 Batch 3450/17275   train_loss = 3.816\n",
      "Epoch   0 Batch 3451/17275   train_loss = 1.945\n",
      "Epoch   0 Batch 3452/17275   train_loss = 3.273\n",
      "Epoch   0 Batch 3453/17275   train_loss = 5.793\n",
      "Epoch   0 Batch 3454/17275   train_loss = 1.933\n",
      "Epoch   0 Batch 3455/17275   train_loss = 2.772\n",
      "Epoch   0 Batch 3456/17275   train_loss = 5.441\n",
      "Epoch   0 Batch 3457/17275   train_loss = 1.913\n",
      "Epoch   0 Batch 3458/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 3459/17275   train_loss = 5.033\n",
      "Epoch   0 Batch 3460/17275   train_loss = 1.888\n",
      "Epoch   0 Batch 3461/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 3462/17275   train_loss = 4.598\n",
      "Epoch   0 Batch 3463/17275   train_loss = 2.324\n",
      "Epoch   0 Batch 3464/17275   train_loss = 6.827\n",
      "Epoch   0 Batch 3465/17275   train_loss = 2.254\n",
      "Epoch   0 Batch 3466/17275   train_loss = 3.170\n",
      "Epoch   0 Batch 3467/17275   train_loss = 6.428\n",
      "Epoch   0 Batch 3468/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 3469/17275   train_loss = 3.418\n",
      "Epoch   0 Batch 3470/17275   train_loss = 5.721\n",
      "Epoch   0 Batch 3471/17275   train_loss = 4.136\n",
      "Epoch   0 Batch 3472/17275   train_loss = 5.221\n",
      "Epoch   0 Batch 3473/17275   train_loss = 3.230\n",
      "Epoch   0 Batch 3474/17275   train_loss = 4.848\n",
      "Epoch   0 Batch 3475/17275   train_loss = 3.970\n",
      "Epoch   0 Batch 3476/17275   train_loss = 4.254\n",
      "Epoch   0 Batch 3477/17275   train_loss = 8.541\n",
      "Epoch   0 Batch 3478/17275   train_loss = 1.870\n",
      "Epoch   0 Batch 3479/17275   train_loss = 2.824\n",
      "Epoch   0 Batch 3480/17275   train_loss = 3.873\n",
      "Epoch   0 Batch 3481/17275   train_loss = 2.994\n",
      "Epoch   0 Batch 3482/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 3483/17275   train_loss = 5.727\n",
      "Epoch   0 Batch 3484/17275   train_loss = 2.533\n",
      "Epoch   0 Batch 3485/17275   train_loss = 2.371\n",
      "Epoch   0 Batch 3486/17275   train_loss = 4.029\n",
      "Epoch   0 Batch 3487/17275   train_loss = 3.458\n",
      "Epoch   0 Batch 3488/17275   train_loss = 2.881\n",
      "Epoch   0 Batch 3489/17275   train_loss = 5.231\n",
      "Epoch   0 Batch 3490/17275   train_loss = 3.723\n",
      "Epoch   0 Batch 3491/17275   train_loss = 5.615\n",
      "Epoch   0 Batch 3492/17275   train_loss = 7.587\n",
      "Epoch   0 Batch 3493/17275   train_loss = 6.045\n",
      "Epoch   0 Batch 3494/17275   train_loss = 5.378\n",
      "Epoch   0 Batch 3495/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 3496/17275   train_loss = 8.536\n",
      "Epoch   0 Batch 3497/17275   train_loss = 1.952\n",
      "Epoch   0 Batch 3498/17275   train_loss = 3.548\n",
      "Epoch   0 Batch 3499/17275   train_loss = 3.759\n",
      "Epoch   0 Batch 3500/17275   train_loss = 1.950\n",
      "Epoch   0 Batch 3501/17275   train_loss = 1.933\n",
      "Epoch   0 Batch 3502/17275   train_loss = 3.815\n",
      "Epoch   0 Batch 3503/17275   train_loss = 3.928\n",
      "Epoch   0 Batch 3504/17275   train_loss = 3.081\n",
      "Epoch   0 Batch 3505/17275   train_loss = 4.317\n",
      "Epoch   0 Batch 3506/17275   train_loss = 2.816\n",
      "Epoch   0 Batch 3507/17275   train_loss = 5.674\n",
      "Epoch   0 Batch 3508/17275   train_loss = 4.771\n",
      "Epoch   0 Batch 3509/17275   train_loss = 4.632\n",
      "Epoch   0 Batch 3510/17275   train_loss = 2.890\n",
      "Epoch   0 Batch 3511/17275   train_loss = 5.237\n",
      "Epoch   0 Batch 3512/17275   train_loss = 2.325\n",
      "Epoch   0 Batch 3513/17275   train_loss = 3.909\n",
      "Epoch   0 Batch 3514/17275   train_loss = 3.291\n",
      "Epoch   0 Batch 3515/17275   train_loss = 3.150\n",
      "Epoch   0 Batch 3516/17275   train_loss = 4.482\n",
      "Epoch   0 Batch 3517/17275   train_loss = 4.374\n",
      "Epoch   0 Batch 3518/17275   train_loss = 2.292\n",
      "Epoch   0 Batch 3519/17275   train_loss = 2.259\n",
      "Epoch   0 Batch 3520/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 3521/17275   train_loss = 3.481\n",
      "Epoch   0 Batch 3522/17275   train_loss = 6.243\n",
      "Epoch   0 Batch 3523/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 3524/17275   train_loss = 3.193\n",
      "Epoch   0 Batch 3525/17275   train_loss = 2.185\n",
      "Epoch   0 Batch 3526/17275   train_loss = 2.739\n",
      "Epoch   0 Batch 3527/17275   train_loss = 3.882\n",
      "Epoch   0 Batch 3528/17275   train_loss = 3.733\n",
      "Epoch   0 Batch 3529/17275   train_loss = 5.423\n",
      "Epoch   0 Batch 3530/17275   train_loss = 5.563\n",
      "Epoch   0 Batch 3531/17275   train_loss = 2.291\n",
      "Epoch   0 Batch 3532/17275   train_loss = 1.874\n",
      "Epoch   0 Batch 3533/17275   train_loss = 5.907\n",
      "Epoch   0 Batch 3534/17275   train_loss = 5.777\n",
      "Epoch   0 Batch 3535/17275   train_loss = 4.095\n",
      "Epoch   0 Batch 3536/17275   train_loss = 6.525\n",
      "Epoch   0 Batch 3537/17275   train_loss = 3.747\n",
      "Epoch   0 Batch 3538/17275   train_loss = 1.928\n",
      "Epoch   0 Batch 3539/17275   train_loss = 2.796\n",
      "Epoch   0 Batch 3540/17275   train_loss = 4.647\n",
      "Epoch   0 Batch 3541/17275   train_loss = 3.703\n",
      "Epoch   0 Batch 3542/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 3543/17275   train_loss = 2.382\n",
      "Epoch   0 Batch 3544/17275   train_loss = 2.924\n",
      "Epoch   0 Batch 3545/17275   train_loss = 3.037\n",
      "Epoch   0 Batch 3546/17275   train_loss = 5.326\n",
      "Epoch   0 Batch 3547/17275   train_loss = 3.716\n",
      "Epoch   0 Batch 3548/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 3549/17275   train_loss = 1.935\n",
      "Epoch   0 Batch 3550/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 3551/17275   train_loss = 2.808\n",
      "Epoch   0 Batch 3552/17275   train_loss = 6.051\n",
      "Epoch   0 Batch 3553/17275   train_loss = 3.954\n",
      "Epoch   0 Batch 3554/17275   train_loss = 3.150\n",
      "Epoch   0 Batch 3555/17275   train_loss = 4.463\n",
      "Epoch   0 Batch 3556/17275   train_loss = 4.803\n",
      "Epoch   0 Batch 3557/17275   train_loss = 6.970\n",
      "Epoch   0 Batch 3558/17275   train_loss = 1.914\n",
      "Epoch   0 Batch 3559/17275   train_loss = 1.833\n",
      "Epoch   0 Batch 3560/17275   train_loss = 2.889\n",
      "Epoch   0 Batch 3561/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 3562/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 3563/17275   train_loss = 5.255\n",
      "Epoch   0 Batch 3564/17275   train_loss = 2.121\n",
      "Epoch   0 Batch 3565/17275   train_loss = 3.026\n",
      "Epoch   0 Batch 3566/17275   train_loss = 2.124\n",
      "Epoch   0 Batch 3567/17275   train_loss = 3.422\n",
      "Epoch   0 Batch 3568/17275   train_loss = 3.544\n",
      "Epoch   0 Batch 3569/17275   train_loss = 4.041\n",
      "Epoch   0 Batch 3570/17275   train_loss = 5.233\n",
      "Epoch   0 Batch 3571/17275   train_loss = 1.869\n",
      "Epoch   0 Batch 3572/17275   train_loss = 5.607\n",
      "Epoch   0 Batch 3573/17275   train_loss = 5.605\n",
      "Epoch   0 Batch 3574/17275   train_loss = 5.778\n",
      "Epoch   0 Batch 3575/17275   train_loss = 3.637\n",
      "Epoch   0 Batch 3576/17275   train_loss = 1.757\n",
      "Epoch   0 Batch 3577/17275   train_loss = 5.271\n",
      "Epoch   0 Batch 3578/17275   train_loss = 5.588\n",
      "Epoch   0 Batch 3579/17275   train_loss = 1.744\n",
      "Epoch   0 Batch 3580/17275   train_loss = 3.168\n",
      "Epoch   0 Batch 3581/17275   train_loss = 5.625\n",
      "Epoch   0 Batch 3582/17275   train_loss = 3.024\n",
      "Epoch   0 Batch 3583/17275   train_loss = 5.170\n",
      "Epoch   0 Batch 3584/17275   train_loss = 1.725\n",
      "Epoch   0 Batch 3585/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 3586/17275   train_loss = 4.811\n",
      "Epoch   0 Batch 3587/17275   train_loss = 3.362\n",
      "Epoch   0 Batch 3588/17275   train_loss = 2.988\n",
      "Epoch   0 Batch 3589/17275   train_loss = 5.961\n",
      "Epoch   0 Batch 3590/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 3591/17275   train_loss = 2.200\n",
      "Epoch   0 Batch 3592/17275   train_loss = 3.368\n",
      "Epoch   0 Batch 3593/17275   train_loss = 3.189\n",
      "Epoch   0 Batch 3594/17275   train_loss = 3.363\n",
      "Epoch   0 Batch 3595/17275   train_loss = 3.823\n",
      "Epoch   0 Batch 3596/17275   train_loss = 2.845\n",
      "Epoch   0 Batch 3597/17275   train_loss = 5.791\n",
      "Epoch   0 Batch 3598/17275   train_loss = 6.463\n",
      "Epoch   0 Batch 3599/17275   train_loss = 2.604\n",
      "Epoch   0 Batch 3600/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 3601/17275   train_loss = 3.433\n",
      "Epoch   0 Batch 3602/17275   train_loss = 3.575\n",
      "Epoch   0 Batch 3603/17275   train_loss = 2.525\n",
      "Epoch   0 Batch 3604/17275   train_loss = 5.490\n",
      "Epoch   0 Batch 3605/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 3606/17275   train_loss = 5.869\n",
      "Epoch   0 Batch 3607/17275   train_loss = 6.173\n",
      "Epoch   0 Batch 3608/17275   train_loss = 3.576\n",
      "Epoch   0 Batch 3609/17275   train_loss = 8.595\n",
      "Epoch   0 Batch 3610/17275   train_loss = 5.191\n",
      "Epoch   0 Batch 3611/17275   train_loss = 2.541\n",
      "Epoch   0 Batch 3612/17275   train_loss = 4.785\n",
      "Epoch   0 Batch 3613/17275   train_loss = 3.955\n",
      "Epoch   0 Batch 3614/17275   train_loss = 5.879\n",
      "Epoch   0 Batch 3615/17275   train_loss = 4.727\n",
      "Epoch   0 Batch 3616/17275   train_loss = 6.016\n",
      "Epoch   0 Batch 3617/17275   train_loss = 2.778\n",
      "Epoch   0 Batch 3618/17275   train_loss = 2.346\n",
      "Epoch   0 Batch 3619/17275   train_loss = 2.719\n",
      "Epoch   0 Batch 3620/17275   train_loss = 3.533\n",
      "Epoch   0 Batch 3621/17275   train_loss = 6.094\n",
      "Epoch   0 Batch 3622/17275   train_loss = 2.815\n",
      "Epoch   0 Batch 3623/17275   train_loss = 3.961\n",
      "Epoch   0 Batch 3624/17275   train_loss = 3.982\n",
      "Epoch   0 Batch 3625/17275   train_loss = 3.840\n",
      "Epoch   0 Batch 3626/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 3627/17275   train_loss = 3.022\n",
      "Epoch   0 Batch 3628/17275   train_loss = 3.786\n",
      "Epoch   0 Batch 3629/17275   train_loss = 3.523\n",
      "Epoch   0 Batch 3630/17275   train_loss = 5.313\n",
      "Epoch   0 Batch 3631/17275   train_loss = 5.210\n",
      "Epoch   0 Batch 3632/17275   train_loss = 2.111\n",
      "Epoch   0 Batch 3633/17275   train_loss = 2.316\n",
      "Epoch   0 Batch 3634/17275   train_loss = 3.039\n",
      "Epoch   0 Batch 3635/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 3636/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 3637/17275   train_loss = 8.565\n",
      "Epoch   0 Batch 3638/17275   train_loss = 2.989\n",
      "Epoch   0 Batch 3639/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 3640/17275   train_loss = 8.568\n",
      "Epoch   0 Batch 3641/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 3642/17275   train_loss = 3.343\n",
      "Epoch   0 Batch 3643/17275   train_loss = 5.228\n",
      "Epoch   0 Batch 3644/17275   train_loss = 4.263\n",
      "Epoch   0 Batch 3645/17275   train_loss = 3.893\n",
      "Epoch   0 Batch 3646/17275   train_loss = 5.721\n",
      "Epoch   0 Batch 3647/17275   train_loss = 2.559\n",
      "Epoch   0 Batch 3648/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 3649/17275   train_loss = 2.838\n",
      "Epoch   0 Batch 3650/17275   train_loss = 5.457\n",
      "Epoch   0 Batch 3651/17275   train_loss = 2.786\n",
      "Epoch   0 Batch 3652/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 3653/17275   train_loss = 3.353\n",
      "Epoch   0 Batch 3654/17275   train_loss = 2.348\n",
      "Epoch   0 Batch 3655/17275   train_loss = 4.715\n",
      "Epoch   0 Batch 3656/17275   train_loss = 1.889\n",
      "Epoch   0 Batch 3657/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 3658/17275   train_loss = 5.213\n",
      "Epoch   0 Batch 3659/17275   train_loss = 2.107\n",
      "Epoch   0 Batch 3660/17275   train_loss = 2.198\n",
      "Epoch   0 Batch 3661/17275   train_loss = 3.848\n",
      "Epoch   0 Batch 3662/17275   train_loss = 7.002\n",
      "Epoch   0 Batch 3663/17275   train_loss = 3.346\n",
      "Epoch   0 Batch 3664/17275   train_loss = 2.440\n",
      "Epoch   0 Batch 3665/17275   train_loss = 3.221\n",
      "Epoch   0 Batch 3666/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 3667/17275   train_loss = 7.308\n",
      "Epoch   0 Batch 3668/17275   train_loss = 3.678\n",
      "Epoch   0 Batch 3669/17275   train_loss = 2.499\n",
      "Epoch   0 Batch 3670/17275   train_loss = 6.465\n",
      "Epoch   0 Batch 3671/17275   train_loss = 6.913\n",
      "Epoch   0 Batch 3672/17275   train_loss = 3.496\n",
      "Epoch   0 Batch 3673/17275   train_loss = 4.232\n",
      "Epoch   0 Batch 3674/17275   train_loss = 8.628\n",
      "Epoch   0 Batch 3675/17275   train_loss = 2.538\n",
      "Epoch   0 Batch 3676/17275   train_loss = 1.888\n",
      "Epoch   0 Batch 3677/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 3678/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 3679/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 3680/17275   train_loss = 4.541\n",
      "Epoch   0 Batch 3681/17275   train_loss = 3.385\n",
      "Epoch   0 Batch 3682/17275   train_loss = 5.717\n",
      "Epoch   0 Batch 3683/17275   train_loss = 3.913\n",
      "Epoch   0 Batch 3684/17275   train_loss = 7.481\n",
      "Epoch   0 Batch 3685/17275   train_loss = 2.266\n",
      "Epoch   0 Batch 3686/17275   train_loss = 2.793\n",
      "Epoch   0 Batch 3687/17275   train_loss = 4.495\n",
      "Epoch   0 Batch 3688/17275   train_loss = 2.678\n",
      "Epoch   0 Batch 3689/17275   train_loss = 4.358\n",
      "Epoch   0 Batch 3690/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 3691/17275   train_loss = 5.739\n",
      "Epoch   0 Batch 3692/17275   train_loss = 2.430\n",
      "Epoch   0 Batch 3693/17275   train_loss = 2.673\n",
      "Epoch   0 Batch 3694/17275   train_loss = 1.723\n",
      "Epoch   0 Batch 3695/17275   train_loss = 2.744\n",
      "Epoch   0 Batch 3696/17275   train_loss = 5.301\n",
      "Epoch   0 Batch 3697/17275   train_loss = 3.688\n",
      "Epoch   0 Batch 3698/17275   train_loss = 3.944\n",
      "Epoch   0 Batch 3699/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 3700/17275   train_loss = 3.030\n",
      "Epoch   0 Batch 3701/17275   train_loss = 7.005\n",
      "Epoch   0 Batch 3702/17275   train_loss = 4.189\n",
      "Epoch   0 Batch 3703/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 3704/17275   train_loss = 4.026\n",
      "Epoch   0 Batch 3705/17275   train_loss = 2.296\n",
      "Epoch   0 Batch 3706/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 3707/17275   train_loss = 6.196\n",
      "Epoch   0 Batch 3708/17275   train_loss = 3.464\n",
      "Epoch   0 Batch 3709/17275   train_loss = 1.843\n",
      "Epoch   0 Batch 3710/17275   train_loss = 5.721\n",
      "Epoch   0 Batch 3711/17275   train_loss = 4.139\n",
      "Epoch   0 Batch 3712/17275   train_loss = 5.149\n",
      "Epoch   0 Batch 3713/17275   train_loss = 3.622\n",
      "Epoch   0 Batch 3714/17275   train_loss = 4.272\n",
      "Epoch   0 Batch 3715/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 3716/17275   train_loss = 4.392\n",
      "Epoch   0 Batch 3717/17275   train_loss = 2.653\n",
      "Epoch   0 Batch 3718/17275   train_loss = 6.029\n",
      "Epoch   0 Batch 3719/17275   train_loss = 4.303\n",
      "Epoch   0 Batch 3720/17275   train_loss = 5.952\n",
      "Epoch   0 Batch 3721/17275   train_loss = 1.906\n",
      "Epoch   0 Batch 3722/17275   train_loss = 2.830\n",
      "Epoch   0 Batch 3723/17275   train_loss = 3.813\n",
      "Epoch   0 Batch 3724/17275   train_loss = 5.105\n",
      "Epoch   0 Batch 3725/17275   train_loss = 5.825\n",
      "Epoch   0 Batch 3726/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 3727/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 3728/17275   train_loss = 2.776\n",
      "Epoch   0 Batch 3729/17275   train_loss = 3.843\n",
      "Epoch   0 Batch 3730/17275   train_loss = 4.817\n",
      "Epoch   0 Batch 3731/17275   train_loss = 2.216\n",
      "Epoch   0 Batch 3732/17275   train_loss = 3.196\n",
      "Epoch   0 Batch 3733/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 3734/17275   train_loss = 3.084\n",
      "Epoch   0 Batch 3735/17275   train_loss = 4.321\n",
      "Epoch   0 Batch 3736/17275   train_loss = 5.579\n",
      "Epoch   0 Batch 3737/17275   train_loss = 2.404\n",
      "Epoch   0 Batch 3738/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 3739/17275   train_loss = 5.266\n",
      "Epoch   0 Batch 3740/17275   train_loss = 2.966\n",
      "Epoch   0 Batch 3741/17275   train_loss = 5.954\n",
      "Epoch   0 Batch 3742/17275   train_loss = 2.063\n",
      "Epoch   0 Batch 3743/17275   train_loss = 4.435\n",
      "Epoch   0 Batch 3744/17275   train_loss = 5.724\n",
      "Epoch   0 Batch 3745/17275   train_loss = 3.646\n",
      "Epoch   0 Batch 3746/17275   train_loss = 4.527\n",
      "Epoch   0 Batch 3747/17275   train_loss = 4.320\n",
      "Epoch   0 Batch 3748/17275   train_loss = 5.267\n",
      "Epoch   0 Batch 3749/17275   train_loss = 3.924\n",
      "Epoch   0 Batch 3750/17275   train_loss = 3.146\n",
      "Epoch   0 Batch 3751/17275   train_loss = 4.087\n",
      "Epoch   0 Batch 3752/17275   train_loss = 2.917\n",
      "Epoch   0 Batch 3753/17275   train_loss = 5.267\n",
      "Epoch   0 Batch 3754/17275   train_loss = 5.017\n",
      "Epoch   0 Batch 3755/17275   train_loss = 3.011\n",
      "Epoch   0 Batch 3756/17275   train_loss = 5.260\n",
      "Epoch   0 Batch 3757/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 3758/17275   train_loss = 3.899\n",
      "Epoch   0 Batch 3759/17275   train_loss = 3.054\n",
      "Epoch   0 Batch 3760/17275   train_loss = 2.016\n",
      "Epoch   0 Batch 3761/17275   train_loss = 2.184\n",
      "Epoch   0 Batch 3762/17275   train_loss = 3.281\n",
      "Epoch   0 Batch 3763/17275   train_loss = 3.799\n",
      "Epoch   0 Batch 3764/17275   train_loss = 2.463\n",
      "Epoch   0 Batch 3765/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 3766/17275   train_loss = 5.765\n",
      "Epoch   0 Batch 3767/17275   train_loss = 8.657\n",
      "Epoch   0 Batch 3768/17275   train_loss = 3.177\n",
      "Epoch   0 Batch 3769/17275   train_loss = 4.571\n",
      "Epoch   0 Batch 3770/17275   train_loss = 1.865\n",
      "Epoch   0 Batch 3771/17275   train_loss = 3.032\n",
      "Epoch   0 Batch 3772/17275   train_loss = 3.369\n",
      "Epoch   0 Batch 3773/17275   train_loss = 3.078\n",
      "Epoch   0 Batch 3774/17275   train_loss = 2.308\n",
      "Epoch   0 Batch 3775/17275   train_loss = 3.838\n",
      "Epoch   0 Batch 3776/17275   train_loss = 3.820\n",
      "Epoch   0 Batch 3777/17275   train_loss = 3.661\n",
      "Epoch   0 Batch 3778/17275   train_loss = 4.281\n",
      "Epoch   0 Batch 3779/17275   train_loss = 5.811\n",
      "Epoch   0 Batch 3780/17275   train_loss = 6.758\n",
      "Epoch   0 Batch 3781/17275   train_loss = 1.864\n",
      "Epoch   0 Batch 3782/17275   train_loss = 6.825\n",
      "Epoch   0 Batch 3783/17275   train_loss = 4.388\n",
      "Epoch   0 Batch 3784/17275   train_loss = 2.832\n",
      "Epoch   0 Batch 3785/17275   train_loss = 3.748\n",
      "Epoch   0 Batch 3786/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 3787/17275   train_loss = 6.502\n",
      "Epoch   0 Batch 3788/17275   train_loss = 5.555\n",
      "Epoch   0 Batch 3789/17275   train_loss = 7.134\n",
      "Epoch   0 Batch 3790/17275   train_loss = 1.889\n",
      "Epoch   0 Batch 3791/17275   train_loss = 1.897\n",
      "Epoch   0 Batch 3792/17275   train_loss = 2.733\n",
      "Epoch   0 Batch 3793/17275   train_loss = 3.280\n",
      "Epoch   0 Batch 3794/17275   train_loss = 6.797\n",
      "Epoch   0 Batch 3795/17275   train_loss = 5.700\n",
      "Epoch   0 Batch 3796/17275   train_loss = 6.073\n",
      "Epoch   0 Batch 3797/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 3798/17275   train_loss = 2.253\n",
      "Epoch   0 Batch 3799/17275   train_loss = 3.848\n",
      "Epoch   0 Batch 3800/17275   train_loss = 1.856\n",
      "Epoch   0 Batch 3801/17275   train_loss = 1.795\n",
      "Epoch   0 Batch 3802/17275   train_loss = 5.531\n",
      "Epoch   0 Batch 3803/17275   train_loss = 6.228\n",
      "Epoch   0 Batch 3804/17275   train_loss = 3.443\n",
      "Epoch   0 Batch 3805/17275   train_loss = 6.094\n",
      "Epoch   0 Batch 3806/17275   train_loss = 2.989\n",
      "Epoch   0 Batch 3807/17275   train_loss = 3.311\n",
      "Epoch   0 Batch 3808/17275   train_loss = 5.626\n",
      "Epoch   0 Batch 3809/17275   train_loss = 5.104\n",
      "Epoch   0 Batch 3810/17275   train_loss = 6.775\n",
      "Epoch   0 Batch 3811/17275   train_loss = 1.792\n",
      "Epoch   0 Batch 3812/17275   train_loss = 5.794\n",
      "Epoch   0 Batch 3813/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 3814/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 3815/17275   train_loss = 4.269\n",
      "Epoch   0 Batch 3816/17275   train_loss = 4.225\n",
      "Epoch   0 Batch 3817/17275   train_loss = 6.364\n",
      "Epoch   0 Batch 3818/17275   train_loss = 5.575\n",
      "Epoch   0 Batch 3819/17275   train_loss = 5.265\n",
      "Epoch   0 Batch 3820/17275   train_loss = 4.368\n",
      "Epoch   0 Batch 3821/17275   train_loss = 5.634\n",
      "Epoch   0 Batch 3822/17275   train_loss = 5.788\n",
      "Epoch   0 Batch 3823/17275   train_loss = 3.697\n",
      "Epoch   0 Batch 3824/17275   train_loss = 5.558\n",
      "Epoch   0 Batch 3825/17275   train_loss = 6.054\n",
      "Epoch   0 Batch 3826/17275   train_loss = 3.365\n",
      "Epoch   0 Batch 3827/17275   train_loss = 2.806\n",
      "Epoch   0 Batch 3828/17275   train_loss = 3.927\n",
      "Epoch   0 Batch 3829/17275   train_loss = 5.808\n",
      "Epoch   0 Batch 3830/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 3831/17275   train_loss = 7.440\n",
      "Epoch   0 Batch 3832/17275   train_loss = 3.428\n",
      "Epoch   0 Batch 3833/17275   train_loss = 2.953\n",
      "Epoch   0 Batch 3834/17275   train_loss = 5.782\n",
      "Epoch   0 Batch 3835/17275   train_loss = 5.904\n",
      "Epoch   0 Batch 3836/17275   train_loss = 2.800\n",
      "Epoch   0 Batch 3837/17275   train_loss = 4.896\n",
      "Epoch   0 Batch 3838/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 3839/17275   train_loss = 5.685\n",
      "Epoch   0 Batch 3840/17275   train_loss = 5.470\n",
      "Epoch   0 Batch 3841/17275   train_loss = 6.107\n",
      "Epoch   0 Batch 3842/17275   train_loss = 4.126\n",
      "Epoch   0 Batch 3843/17275   train_loss = 2.969\n",
      "Epoch   0 Batch 3844/17275   train_loss = 3.575\n",
      "Epoch   0 Batch 3845/17275   train_loss = 4.246\n",
      "Epoch   0 Batch 3846/17275   train_loss = 4.579\n",
      "Epoch   0 Batch 3847/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 3848/17275   train_loss = 3.448\n",
      "Epoch   0 Batch 3849/17275   train_loss = 3.640\n",
      "Epoch   0 Batch 3850/17275   train_loss = 3.189\n",
      "Epoch   0 Batch 3851/17275   train_loss = 4.938\n",
      "Epoch   0 Batch 3852/17275   train_loss = 2.780\n",
      "Epoch   0 Batch 3853/17275   train_loss = 3.091\n",
      "Epoch   0 Batch 3854/17275   train_loss = 3.802\n",
      "Epoch   0 Batch 3855/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 3856/17275   train_loss = 3.093\n",
      "Epoch   0 Batch 3857/17275   train_loss = 4.732\n",
      "Epoch   0 Batch 3858/17275   train_loss = 2.809\n",
      "Epoch   0 Batch 3859/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 3860/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 3861/17275   train_loss = 2.620\n",
      "Epoch   0 Batch 3862/17275   train_loss = 4.343\n",
      "Epoch   0 Batch 3863/17275   train_loss = 4.913\n",
      "Epoch   0 Batch 3864/17275   train_loss = 7.099\n",
      "Epoch   0 Batch 3865/17275   train_loss = 5.818\n",
      "Epoch   0 Batch 3866/17275   train_loss = 2.308\n",
      "Epoch   0 Batch 3867/17275   train_loss = 5.854\n",
      "Epoch   0 Batch 3868/17275   train_loss = 2.199\n",
      "Epoch   0 Batch 3869/17275   train_loss = 2.279\n",
      "Epoch   0 Batch 3870/17275   train_loss = 4.360\n",
      "Epoch   0 Batch 3871/17275   train_loss = 3.692\n",
      "Epoch   0 Batch 3872/17275   train_loss = 2.089\n",
      "Epoch   0 Batch 3873/17275   train_loss = 2.357\n",
      "Epoch   0 Batch 3874/17275   train_loss = 3.576\n",
      "Epoch   0 Batch 3875/17275   train_loss = 8.691\n",
      "Epoch   0 Batch 3876/17275   train_loss = 2.299\n",
      "Epoch   0 Batch 3877/17275   train_loss = 3.328\n",
      "Epoch   0 Batch 3878/17275   train_loss = 8.702\n",
      "Epoch   0 Batch 3879/17275   train_loss = 2.204\n",
      "Epoch   0 Batch 3880/17275   train_loss = 6.494\n",
      "Epoch   0 Batch 3881/17275   train_loss = 2.933\n",
      "Epoch   0 Batch 3882/17275   train_loss = 2.418\n",
      "Epoch   0 Batch 3883/17275   train_loss = 5.874\n",
      "Epoch   0 Batch 3884/17275   train_loss = 2.916\n",
      "Epoch   0 Batch 3885/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 3886/17275   train_loss = 5.197\n",
      "Epoch   0 Batch 3887/17275   train_loss = 2.330\n",
      "Epoch   0 Batch 3888/17275   train_loss = 3.471\n",
      "Epoch   0 Batch 3889/17275   train_loss = 4.198\n",
      "Epoch   0 Batch 3890/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 3891/17275   train_loss = 4.021\n",
      "Epoch   0 Batch 3892/17275   train_loss = 2.758\n",
      "Epoch   0 Batch 3893/17275   train_loss = 6.513\n",
      "Epoch   0 Batch 3894/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 3895/17275   train_loss = 3.837\n",
      "Epoch   0 Batch 3896/17275   train_loss = 3.976\n",
      "Epoch   0 Batch 3897/17275   train_loss = 6.704\n",
      "Epoch   0 Batch 3898/17275   train_loss = 2.026\n",
      "Epoch   0 Batch 3899/17275   train_loss = 3.541\n",
      "Epoch   0 Batch 3900/17275   train_loss = 2.968\n",
      "Epoch   0 Batch 3901/17275   train_loss = 2.003\n",
      "Epoch   0 Batch 3902/17275   train_loss = 4.753\n",
      "Epoch   0 Batch 3903/17275   train_loss = 3.988\n",
      "Epoch   0 Batch 3904/17275   train_loss = 4.709\n",
      "Epoch   0 Batch 3905/17275   train_loss = 2.593\n",
      "Epoch   0 Batch 3906/17275   train_loss = 4.011\n",
      "Epoch   0 Batch 3907/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 3908/17275   train_loss = 2.907\n",
      "Epoch   0 Batch 3909/17275   train_loss = 6.234\n",
      "Epoch   0 Batch 3910/17275   train_loss = 6.808\n",
      "Epoch   0 Batch 3911/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 3912/17275   train_loss = 5.276\n",
      "Epoch   0 Batch 3913/17275   train_loss = 3.248\n",
      "Epoch   0 Batch 3914/17275   train_loss = 4.517\n",
      "Epoch   0 Batch 3915/17275   train_loss = 1.938\n",
      "Epoch   0 Batch 3916/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 3917/17275   train_loss = 3.464\n",
      "Epoch   0 Batch 3918/17275   train_loss = 6.103\n",
      "Epoch   0 Batch 3919/17275   train_loss = 8.695\n",
      "Epoch   0 Batch 3920/17275   train_loss = 4.972\n",
      "Epoch   0 Batch 3921/17275   train_loss = 6.294\n",
      "Epoch   0 Batch 3922/17275   train_loss = 8.682\n",
      "Epoch   0 Batch 3923/17275   train_loss = 1.951\n",
      "Epoch   0 Batch 3924/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 3925/17275   train_loss = 4.085\n",
      "Epoch   0 Batch 3926/17275   train_loss = 3.696\n",
      "Epoch   0 Batch 3927/17275   train_loss = 4.141\n",
      "Epoch   0 Batch 3928/17275   train_loss = 5.701\n",
      "Epoch   0 Batch 3929/17275   train_loss = 6.311\n",
      "Epoch   0 Batch 3930/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 3931/17275   train_loss = 3.349\n",
      "Epoch   0 Batch 3932/17275   train_loss = 1.827\n",
      "Epoch   0 Batch 3933/17275   train_loss = 3.817\n",
      "Epoch   0 Batch 3934/17275   train_loss = 5.702\n",
      "Epoch   0 Batch 3935/17275   train_loss = 2.660\n",
      "Epoch   0 Batch 3936/17275   train_loss = 4.038\n",
      "Epoch   0 Batch 3937/17275   train_loss = 3.085\n",
      "Epoch   0 Batch 3938/17275   train_loss = 2.646\n",
      "Epoch   0 Batch 3939/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 3940/17275   train_loss = 6.729\n",
      "Epoch   0 Batch 3941/17275   train_loss = 1.951\n",
      "Epoch   0 Batch 3942/17275   train_loss = 8.653\n",
      "Epoch   0 Batch 3943/17275   train_loss = 5.904\n",
      "Epoch   0 Batch 3944/17275   train_loss = 2.178\n",
      "Epoch   0 Batch 3945/17275   train_loss = 4.227\n",
      "Epoch   0 Batch 3946/17275   train_loss = 3.186\n",
      "Epoch   0 Batch 3947/17275   train_loss = 4.055\n",
      "Epoch   0 Batch 3948/17275   train_loss = 4.424\n",
      "Epoch   0 Batch 3949/17275   train_loss = 1.818\n",
      "Epoch   0 Batch 3950/17275   train_loss = 2.110\n",
      "Epoch   0 Batch 3951/17275   train_loss = 4.233\n",
      "Epoch   0 Batch 3952/17275   train_loss = 6.209\n",
      "Epoch   0 Batch 3953/17275   train_loss = 2.080\n",
      "Epoch   0 Batch 3954/17275   train_loss = 1.739\n",
      "Epoch   0 Batch 3955/17275   train_loss = 2.645\n",
      "Epoch   0 Batch 3956/17275   train_loss = 2.212\n",
      "Epoch   0 Batch 3957/17275   train_loss = 5.497\n",
      "Epoch   0 Batch 3958/17275   train_loss = 2.676\n",
      "Epoch   0 Batch 3959/17275   train_loss = 2.844\n",
      "Epoch   0 Batch 3960/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 3961/17275   train_loss = 2.482\n",
      "Epoch   0 Batch 3962/17275   train_loss = 2.999\n",
      "Epoch   0 Batch 3963/17275   train_loss = 1.572\n",
      "Epoch   0 Batch 3964/17275   train_loss = 5.140\n",
      "Epoch   0 Batch 3965/17275   train_loss = 2.879\n",
      "Epoch   0 Batch 3966/17275   train_loss = 5.998\n",
      "Epoch   0 Batch 3967/17275   train_loss = 1.833\n",
      "Epoch   0 Batch 3968/17275   train_loss = 5.303\n",
      "Epoch   0 Batch 3969/17275   train_loss = 6.465\n",
      "Epoch   0 Batch 3970/17275   train_loss = 6.165\n",
      "Epoch   0 Batch 3971/17275   train_loss = 2.974\n",
      "Epoch   0 Batch 3972/17275   train_loss = 5.092\n",
      "Epoch   0 Batch 3973/17275   train_loss = 4.056\n",
      "Epoch   0 Batch 3974/17275   train_loss = 6.591\n",
      "Epoch   0 Batch 3975/17275   train_loss = 6.331\n",
      "Epoch   0 Batch 3976/17275   train_loss = 5.169\n",
      "Epoch   0 Batch 3977/17275   train_loss = 3.306\n",
      "Epoch   0 Batch 3978/17275   train_loss = 3.441\n",
      "Epoch   0 Batch 3979/17275   train_loss = 3.628\n",
      "Epoch   0 Batch 3980/17275   train_loss = 6.426\n",
      "Epoch   0 Batch 3981/17275   train_loss = 3.077\n",
      "Epoch   0 Batch 3982/17275   train_loss = 5.103\n",
      "Epoch   0 Batch 3983/17275   train_loss = 2.989\n",
      "Epoch   0 Batch 3984/17275   train_loss = 4.071\n",
      "Epoch   0 Batch 3985/17275   train_loss = 4.009\n",
      "Epoch   0 Batch 3986/17275   train_loss = 2.509\n",
      "Epoch   0 Batch 3987/17275   train_loss = 2.101\n",
      "Epoch   0 Batch 3988/17275   train_loss = 1.513\n",
      "Epoch   0 Batch 3989/17275   train_loss = 2.415\n",
      "Epoch   0 Batch 3990/17275   train_loss = 3.777\n",
      "Epoch   0 Batch 3991/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 3992/17275   train_loss = 1.505\n",
      "Epoch   0 Batch 3993/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 3994/17275   train_loss = 1.481\n",
      "Epoch   0 Batch 3995/17275   train_loss = 2.013\n",
      "Epoch   0 Batch 3996/17275   train_loss = 3.562\n",
      "Epoch   0 Batch 3997/17275   train_loss = 3.245\n",
      "Epoch   0 Batch 3998/17275   train_loss = 4.507\n",
      "Epoch   0 Batch 3999/17275   train_loss = 4.101\n",
      "Epoch   0 Batch 4000/17275   train_loss = 1.379\n",
      "Epoch   0 Batch 4001/17275   train_loss = 5.084\n",
      "Epoch   0 Batch 4002/17275   train_loss = 1.860\n",
      "Epoch   0 Batch 4003/17275   train_loss = 5.083\n",
      "Epoch   0 Batch 4004/17275   train_loss = 5.505\n",
      "Epoch   0 Batch 4005/17275   train_loss = 1.839\n",
      "Epoch   0 Batch 4006/17275   train_loss = 4.829\n",
      "Epoch   0 Batch 4007/17275   train_loss = 1.819\n",
      "Epoch   0 Batch 4008/17275   train_loss = 6.500\n",
      "Epoch   0 Batch 4009/17275   train_loss = 1.794\n",
      "Epoch   0 Batch 4010/17275   train_loss = 5.755\n",
      "Epoch   0 Batch 4011/17275   train_loss = 1.764\n",
      "Epoch   0 Batch 4012/17275   train_loss = 5.457\n",
      "Epoch   0 Batch 4013/17275   train_loss = 3.754\n",
      "Epoch   0 Batch 4014/17275   train_loss = 2.965\n",
      "Epoch   0 Batch 4015/17275   train_loss = 7.757\n",
      "Epoch   0 Batch 4016/17275   train_loss = 2.784\n",
      "Epoch   0 Batch 4017/17275   train_loss = 3.343\n",
      "Epoch   0 Batch 4018/17275   train_loss = 1.695\n",
      "Epoch   0 Batch 4019/17275   train_loss = 4.439\n",
      "Epoch   0 Batch 4020/17275   train_loss = 6.352\n",
      "Epoch   0 Batch 4021/17275   train_loss = 3.845\n",
      "Epoch   0 Batch 4022/17275   train_loss = 2.020\n",
      "Epoch   0 Batch 4023/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 4024/17275   train_loss = 2.929\n",
      "Epoch   0 Batch 4025/17275   train_loss = 2.927\n",
      "Epoch   0 Batch 4026/17275   train_loss = 1.876\n",
      "Epoch   0 Batch 4027/17275   train_loss = 2.102\n",
      "Epoch   0 Batch 4028/17275   train_loss = 2.655\n",
      "Epoch   0 Batch 4029/17275   train_loss = 3.867\n",
      "Epoch   0 Batch 4030/17275   train_loss = 6.550\n",
      "Epoch   0 Batch 4031/17275   train_loss = 2.098\n",
      "Epoch   0 Batch 4032/17275   train_loss = 1.733\n",
      "Epoch   0 Batch 4033/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 4034/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 4035/17275   train_loss = 3.667\n",
      "Epoch   0 Batch 4036/17275   train_loss = 3.888\n",
      "Epoch   0 Batch 4037/17275   train_loss = 1.687\n",
      "Epoch   0 Batch 4038/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 4039/17275   train_loss = 3.425\n",
      "Epoch   0 Batch 4040/17275   train_loss = 2.252\n",
      "Epoch   0 Batch 4041/17275   train_loss = 3.827\n",
      "Epoch   0 Batch 4042/17275   train_loss = 5.303\n",
      "Epoch   0 Batch 4043/17275   train_loss = 5.892\n",
      "Epoch   0 Batch 4044/17275   train_loss = 4.061\n",
      "Epoch   0 Batch 4045/17275   train_loss = 2.983\n",
      "Epoch   0 Batch 4046/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 4047/17275   train_loss = 4.153\n",
      "Epoch   0 Batch 4048/17275   train_loss = 3.949\n",
      "Epoch   0 Batch 4049/17275   train_loss = 5.279\n",
      "Epoch   0 Batch 4050/17275   train_loss = 2.007\n",
      "Epoch   0 Batch 4051/17275   train_loss = 3.694\n",
      "Epoch   0 Batch 4052/17275   train_loss = 2.897\n",
      "Epoch   0 Batch 4053/17275   train_loss = 3.405\n",
      "Epoch   0 Batch 4054/17275   train_loss = 4.108\n",
      "Epoch   0 Batch 4055/17275   train_loss = 1.749\n",
      "Epoch   0 Batch 4056/17275   train_loss = 2.351\n",
      "Epoch   0 Batch 4057/17275   train_loss = 4.608\n",
      "Epoch   0 Batch 4058/17275   train_loss = 2.403\n",
      "Epoch   0 Batch 4059/17275   train_loss = 3.519\n",
      "Epoch   0 Batch 4060/17275   train_loss = 4.664\n",
      "Epoch   0 Batch 4061/17275   train_loss = 3.355\n",
      "Epoch   0 Batch 4062/17275   train_loss = 3.358\n",
      "Epoch   0 Batch 4063/17275   train_loss = 3.628\n",
      "Epoch   0 Batch 4064/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 4065/17275   train_loss = 3.735\n",
      "Epoch   0 Batch 4066/17275   train_loss = 1.790\n",
      "Epoch   0 Batch 4067/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 4068/17275   train_loss = 2.675\n",
      "Epoch   0 Batch 4069/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 4070/17275   train_loss = 5.584\n",
      "Epoch   0 Batch 4071/17275   train_loss = 2.640\n",
      "Epoch   0 Batch 4072/17275   train_loss = 2.995\n",
      "Epoch   0 Batch 4073/17275   train_loss = 1.635\n",
      "Epoch   0 Batch 4074/17275   train_loss = 1.779\n",
      "Epoch   0 Batch 4075/17275   train_loss = 5.226\n",
      "Epoch   0 Batch 4076/17275   train_loss = 4.194\n",
      "Epoch   0 Batch 4077/17275   train_loss = 2.818\n",
      "Epoch   0 Batch 4078/17275   train_loss = 2.132\n",
      "Epoch   0 Batch 4079/17275   train_loss = 4.449\n",
      "Epoch   0 Batch 4080/17275   train_loss = 3.558\n",
      "Epoch   0 Batch 4081/17275   train_loss = 3.138\n",
      "Epoch   0 Batch 4082/17275   train_loss = 6.218\n",
      "Epoch   0 Batch 4083/17275   train_loss = 2.402\n",
      "Epoch   0 Batch 4084/17275   train_loss = 1.865\n",
      "Epoch   0 Batch 4085/17275   train_loss = 5.896\n",
      "Epoch   0 Batch 4086/17275   train_loss = 8.834\n",
      "Epoch   0 Batch 4087/17275   train_loss = 3.398\n",
      "Epoch   0 Batch 4088/17275   train_loss = 3.190\n",
      "Epoch   0 Batch 4089/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 4090/17275   train_loss = 6.396\n",
      "Epoch   0 Batch 4091/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 4092/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 4093/17275   train_loss = 2.698\n",
      "Epoch   0 Batch 4094/17275   train_loss = 3.341\n",
      "Epoch   0 Batch 4095/17275   train_loss = 4.624\n",
      "Epoch   0 Batch 4096/17275   train_loss = 5.516\n",
      "Epoch   0 Batch 4097/17275   train_loss = 1.769\n",
      "Epoch   0 Batch 4098/17275   train_loss = 4.869\n",
      "Epoch   0 Batch 4099/17275   train_loss = 4.316\n",
      "Epoch   0 Batch 4100/17275   train_loss = 4.028\n",
      "Epoch   0 Batch 4101/17275   train_loss = 4.087\n",
      "Epoch   0 Batch 4102/17275   train_loss = 2.538\n",
      "Epoch   0 Batch 4103/17275   train_loss = 6.299\n",
      "Epoch   0 Batch 4104/17275   train_loss = 5.831\n",
      "Epoch   0 Batch 4105/17275   train_loss = 5.354\n",
      "Epoch   0 Batch 4106/17275   train_loss = 4.123\n",
      "Epoch   0 Batch 4107/17275   train_loss = 3.611\n",
      "Epoch   0 Batch 4108/17275   train_loss = 5.446\n",
      "Epoch   0 Batch 4109/17275   train_loss = 4.111\n",
      "Epoch   0 Batch 4110/17275   train_loss = 3.086\n",
      "Epoch   0 Batch 4111/17275   train_loss = 2.543\n",
      "Epoch   0 Batch 4112/17275   train_loss = 4.019\n",
      "Epoch   0 Batch 4113/17275   train_loss = 4.246\n",
      "Epoch   0 Batch 4114/17275   train_loss = 3.397\n",
      "Epoch   0 Batch 4115/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 4116/17275   train_loss = 3.490\n",
      "Epoch   0 Batch 4117/17275   train_loss = 2.224\n",
      "Epoch   0 Batch 4118/17275   train_loss = 5.266\n",
      "Epoch   0 Batch 4119/17275   train_loss = 6.106\n",
      "Epoch   0 Batch 4120/17275   train_loss = 2.431\n",
      "Epoch   0 Batch 4121/17275   train_loss = 2.845\n",
      "Epoch   0 Batch 4122/17275   train_loss = 8.792\n",
      "Epoch   0 Batch 4123/17275   train_loss = 3.351\n",
      "Epoch   0 Batch 4124/17275   train_loss = 2.856\n",
      "Epoch   0 Batch 4125/17275   train_loss = 2.036\n",
      "Epoch   0 Batch 4126/17275   train_loss = 2.733\n",
      "Epoch   0 Batch 4127/17275   train_loss = 2.999\n",
      "Epoch   0 Batch 4128/17275   train_loss = 6.548\n",
      "Epoch   0 Batch 4129/17275   train_loss = 5.650\n",
      "Epoch   0 Batch 4130/17275   train_loss = 5.857\n",
      "Epoch   0 Batch 4131/17275   train_loss = 2.508\n",
      "Epoch   0 Batch 4132/17275   train_loss = 2.851\n",
      "Epoch   0 Batch 4133/17275   train_loss = 2.956\n",
      "Epoch   0 Batch 4134/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 4135/17275   train_loss = 5.682\n",
      "Epoch   0 Batch 4136/17275   train_loss = 3.476\n",
      "Epoch   0 Batch 4137/17275   train_loss = 6.624\n",
      "Epoch   0 Batch 4138/17275   train_loss = 5.420\n",
      "Epoch   0 Batch 4139/17275   train_loss = 2.834\n",
      "Epoch   0 Batch 4140/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 4141/17275   train_loss = 5.141\n",
      "Epoch   0 Batch 4142/17275   train_loss = 4.527\n",
      "Epoch   0 Batch 4143/17275   train_loss = 3.299\n",
      "Epoch   0 Batch 4144/17275   train_loss = 2.087\n",
      "Epoch   0 Batch 4145/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 4146/17275   train_loss = 5.544\n",
      "Epoch   0 Batch 4147/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 4148/17275   train_loss = 4.239\n",
      "Epoch   0 Batch 4149/17275   train_loss = 6.346\n",
      "Epoch   0 Batch 4150/17275   train_loss = 4.113\n",
      "Epoch   0 Batch 4151/17275   train_loss = 2.836\n",
      "Epoch   0 Batch 4152/17275   train_loss = 2.682\n",
      "Epoch   0 Batch 4153/17275   train_loss = 6.078\n",
      "Epoch   0 Batch 4154/17275   train_loss = 5.856\n",
      "Epoch   0 Batch 4155/17275   train_loss = 2.103\n",
      "Epoch   0 Batch 4156/17275   train_loss = 2.879\n",
      "Epoch   0 Batch 4157/17275   train_loss = 6.045\n",
      "Epoch   0 Batch 4158/17275   train_loss = 3.023\n",
      "Epoch   0 Batch 4159/17275   train_loss = 3.657\n",
      "Epoch   0 Batch 4160/17275   train_loss = 3.363\n",
      "Epoch   0 Batch 4161/17275   train_loss = 2.623\n",
      "Epoch   0 Batch 4162/17275   train_loss = 2.350\n",
      "Epoch   0 Batch 4163/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 4164/17275   train_loss = 2.846\n",
      "Epoch   0 Batch 4165/17275   train_loss = 5.715\n",
      "Epoch   0 Batch 4166/17275   train_loss = 2.296\n",
      "Epoch   0 Batch 4167/17275   train_loss = 2.470\n",
      "Epoch   0 Batch 4168/17275   train_loss = 6.190\n",
      "Epoch   0 Batch 4169/17275   train_loss = 3.969\n",
      "Epoch   0 Batch 4170/17275   train_loss = 3.719\n",
      "Epoch   0 Batch 4171/17275   train_loss = 2.896\n",
      "Epoch   0 Batch 4172/17275   train_loss = 4.595\n",
      "Epoch   0 Batch 4173/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 4174/17275   train_loss = 3.755\n",
      "Epoch   0 Batch 4175/17275   train_loss = 2.535\n",
      "Epoch   0 Batch 4176/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 4177/17275   train_loss = 2.985\n",
      "Epoch   0 Batch 4178/17275   train_loss = 6.500\n",
      "Epoch   0 Batch 4179/17275   train_loss = 6.626\n",
      "Epoch   0 Batch 4180/17275   train_loss = 3.456\n",
      "Epoch   0 Batch 4181/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 4182/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 4183/17275   train_loss = 4.226\n",
      "Epoch   0 Batch 4184/17275   train_loss = 4.497\n",
      "Epoch   0 Batch 4185/17275   train_loss = 2.143\n",
      "Epoch   0 Batch 4186/17275   train_loss = 5.306\n",
      "Epoch   0 Batch 4187/17275   train_loss = 3.986\n",
      "Epoch   0 Batch 4188/17275   train_loss = 5.785\n",
      "Epoch   0 Batch 4189/17275   train_loss = 3.789\n",
      "Epoch   0 Batch 4190/17275   train_loss = 4.145\n",
      "Epoch   0 Batch 4191/17275   train_loss = 3.580\n",
      "Epoch   0 Batch 4192/17275   train_loss = 2.113\n",
      "Epoch   0 Batch 4193/17275   train_loss = 2.870\n",
      "Epoch   0 Batch 4194/17275   train_loss = 2.611\n",
      "Epoch   0 Batch 4195/17275   train_loss = 5.681\n",
      "Epoch   0 Batch 4196/17275   train_loss = 3.634\n",
      "Epoch   0 Batch 4197/17275   train_loss = 3.314\n",
      "Epoch   0 Batch 4198/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 4199/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 4200/17275   train_loss = 3.344\n",
      "Epoch   0 Batch 4201/17275   train_loss = 3.658\n",
      "Epoch   0 Batch 4202/17275   train_loss = 4.039\n",
      "Epoch   0 Batch 4203/17275   train_loss = 2.955\n",
      "Epoch   0 Batch 4204/17275   train_loss = 1.953\n",
      "Epoch   0 Batch 4205/17275   train_loss = 3.283\n",
      "Epoch   0 Batch 4206/17275   train_loss = 2.352\n",
      "Epoch   0 Batch 4207/17275   train_loss = 2.373\n",
      "Epoch   0 Batch 4208/17275   train_loss = 4.476\n",
      "Epoch   0 Batch 4209/17275   train_loss = 4.385\n",
      "Epoch   0 Batch 4210/17275   train_loss = 3.662\n",
      "Epoch   0 Batch 4211/17275   train_loss = 5.746\n",
      "Epoch   0 Batch 4212/17275   train_loss = 2.915\n",
      "Epoch   0 Batch 4213/17275   train_loss = 6.808\n",
      "Epoch   0 Batch 4214/17275   train_loss = 2.661\n",
      "Epoch   0 Batch 4215/17275   train_loss = 3.684\n",
      "Epoch   0 Batch 4216/17275   train_loss = 6.768\n",
      "Epoch   0 Batch 4217/17275   train_loss = 6.120\n",
      "Epoch   0 Batch 4218/17275   train_loss = 5.374\n",
      "Epoch   0 Batch 4219/17275   train_loss = 1.994\n",
      "Epoch   0 Batch 4220/17275   train_loss = 2.742\n",
      "Epoch   0 Batch 4221/17275   train_loss = 5.949\n",
      "Epoch   0 Batch 4222/17275   train_loss = 6.088\n",
      "Epoch   0 Batch 4223/17275   train_loss = 4.155\n",
      "Epoch   0 Batch 4224/17275   train_loss = 2.978\n",
      "Epoch   0 Batch 4225/17275   train_loss = 8.798\n",
      "Epoch   0 Batch 4226/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 4227/17275   train_loss = 2.911\n",
      "Epoch   0 Batch 4228/17275   train_loss = 3.592\n",
      "Epoch   0 Batch 4229/17275   train_loss = 3.825\n",
      "Epoch   0 Batch 4230/17275   train_loss = 8.791\n",
      "Epoch   0 Batch 4231/17275   train_loss = 3.362\n",
      "Epoch   0 Batch 4232/17275   train_loss = 2.205\n",
      "Epoch   0 Batch 4233/17275   train_loss = 2.674\n",
      "Epoch   0 Batch 4234/17275   train_loss = 3.484\n",
      "Epoch   0 Batch 4235/17275   train_loss = 3.789\n",
      "Epoch   0 Batch 4236/17275   train_loss = 3.821\n",
      "Epoch   0 Batch 4237/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 4238/17275   train_loss = 5.342\n",
      "Epoch   0 Batch 4239/17275   train_loss = 3.835\n",
      "Epoch   0 Batch 4240/17275   train_loss = 5.558\n",
      "Epoch   0 Batch 4241/17275   train_loss = 8.795\n",
      "Epoch   0 Batch 4242/17275   train_loss = 5.715\n",
      "Epoch   0 Batch 4243/17275   train_loss = 1.870\n",
      "Epoch   0 Batch 4244/17275   train_loss = 1.942\n",
      "Epoch   0 Batch 4245/17275   train_loss = 2.735\n",
      "Epoch   0 Batch 4246/17275   train_loss = 4.183\n",
      "Epoch   0 Batch 4247/17275   train_loss = 6.125\n",
      "Epoch   0 Batch 4248/17275   train_loss = 3.734\n",
      "Epoch   0 Batch 4249/17275   train_loss = 4.145\n",
      "Epoch   0 Batch 4250/17275   train_loss = 5.279\n",
      "Epoch   0 Batch 4251/17275   train_loss = 5.414\n",
      "Epoch   0 Batch 4252/17275   train_loss = 3.123\n",
      "Epoch   0 Batch 4253/17275   train_loss = 5.623\n",
      "Epoch   0 Batch 4254/17275   train_loss = 5.560\n",
      "Epoch   0 Batch 4255/17275   train_loss = 4.192\n",
      "Epoch   0 Batch 4256/17275   train_loss = 5.250\n",
      "Epoch   0 Batch 4257/17275   train_loss = 3.737\n",
      "Epoch   0 Batch 4258/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 4259/17275   train_loss = 3.915\n",
      "Epoch   0 Batch 4260/17275   train_loss = 2.452\n",
      "Epoch   0 Batch 4261/17275   train_loss = 2.986\n",
      "Epoch   0 Batch 4262/17275   train_loss = 3.245\n",
      "Epoch   0 Batch 4263/17275   train_loss = 4.412\n",
      "Epoch   0 Batch 4264/17275   train_loss = 2.686\n",
      "Epoch   0 Batch 4265/17275   train_loss = 1.866\n",
      "Epoch   0 Batch 4266/17275   train_loss = 4.921\n",
      "Epoch   0 Batch 4267/17275   train_loss = 6.233\n",
      "Epoch   0 Batch 4268/17275   train_loss = 2.721\n",
      "Epoch   0 Batch 4269/17275   train_loss = 2.856\n",
      "Epoch   0 Batch 4270/17275   train_loss = 3.634\n",
      "Epoch   0 Batch 4271/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 4272/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 4273/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 4274/17275   train_loss = 6.732\n",
      "Epoch   0 Batch 4275/17275   train_loss = 1.925\n",
      "Epoch   0 Batch 4276/17275   train_loss = 2.547\n",
      "Epoch   0 Batch 4277/17275   train_loss = 3.399\n",
      "Epoch   0 Batch 4278/17275   train_loss = 5.937\n",
      "Epoch   0 Batch 4279/17275   train_loss = 3.165\n",
      "Epoch   0 Batch 4280/17275   train_loss = 3.658\n",
      "Epoch   0 Batch 4281/17275   train_loss = 3.428\n",
      "Epoch   0 Batch 4282/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 4283/17275   train_loss = 8.821\n",
      "Epoch   0 Batch 4284/17275   train_loss = 2.078\n",
      "Epoch   0 Batch 4285/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 4286/17275   train_loss = 8.833\n",
      "Epoch   0 Batch 4287/17275   train_loss = 2.907\n",
      "Epoch   0 Batch 4288/17275   train_loss = 5.281\n",
      "Epoch   0 Batch 4289/17275   train_loss = 5.918\n",
      "Epoch   0 Batch 4290/17275   train_loss = 5.880\n",
      "Epoch   0 Batch 4291/17275   train_loss = 2.425\n",
      "Epoch   0 Batch 4292/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 4293/17275   train_loss = 4.283\n",
      "Epoch   0 Batch 4294/17275   train_loss = 4.359\n",
      "Epoch   0 Batch 4295/17275   train_loss = 2.481\n",
      "Epoch   0 Batch 4296/17275   train_loss = 5.512\n",
      "Epoch   0 Batch 4297/17275   train_loss = 2.370\n",
      "Epoch   0 Batch 4298/17275   train_loss = 4.033\n",
      "Epoch   0 Batch 4299/17275   train_loss = 3.745\n",
      "Epoch   0 Batch 4300/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 4301/17275   train_loss = 4.315\n",
      "Epoch   0 Batch 4302/17275   train_loss = 4.147\n",
      "Epoch   0 Batch 4303/17275   train_loss = 3.466\n",
      "Epoch   0 Batch 4304/17275   train_loss = 2.422\n",
      "Epoch   0 Batch 4305/17275   train_loss = 3.495\n",
      "Epoch   0 Batch 4306/17275   train_loss = 3.451\n",
      "Epoch   0 Batch 4307/17275   train_loss = 5.540\n",
      "Epoch   0 Batch 4308/17275   train_loss = 2.132\n",
      "Epoch   0 Batch 4309/17275   train_loss = 3.427\n",
      "Epoch   0 Batch 4310/17275   train_loss = 2.971\n",
      "Epoch   0 Batch 4311/17275   train_loss = 5.466\n",
      "Epoch   0 Batch 4312/17275   train_loss = 2.229\n",
      "Epoch   0 Batch 4313/17275   train_loss = 5.564\n",
      "Epoch   0 Batch 4314/17275   train_loss = 3.052\n",
      "Epoch   0 Batch 4315/17275   train_loss = 2.443\n",
      "Epoch   0 Batch 4316/17275   train_loss = 8.510\n",
      "Epoch   0 Batch 4317/17275   train_loss = 2.099\n",
      "Epoch   0 Batch 4318/17275   train_loss = 2.098\n",
      "Epoch   0 Batch 4319/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 4320/17275   train_loss = 2.514\n",
      "Epoch   0 Batch 4321/17275   train_loss = 2.641\n",
      "Epoch   0 Batch 4322/17275   train_loss = 6.464\n",
      "Epoch   0 Batch 4323/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 4324/17275   train_loss = 3.838\n",
      "Epoch   0 Batch 4325/17275   train_loss = 3.464\n",
      "Epoch   0 Batch 4326/17275   train_loss = 5.461\n",
      "Epoch   0 Batch 4327/17275   train_loss = 3.531\n",
      "Epoch   0 Batch 4328/17275   train_loss = 5.916\n",
      "Epoch   0 Batch 4329/17275   train_loss = 5.606\n",
      "Epoch   0 Batch 4330/17275   train_loss = 4.000\n",
      "Epoch   0 Batch 4331/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 4332/17275   train_loss = 5.411\n",
      "Epoch   0 Batch 4333/17275   train_loss = 3.094\n",
      "Epoch   0 Batch 4334/17275   train_loss = 3.062\n",
      "Epoch   0 Batch 4335/17275   train_loss = 6.141\n",
      "Epoch   0 Batch 4336/17275   train_loss = 5.791\n",
      "Epoch   0 Batch 4337/17275   train_loss = 5.458\n",
      "Epoch   0 Batch 4338/17275   train_loss = 2.194\n",
      "Epoch   0 Batch 4339/17275   train_loss = 3.568\n",
      "Epoch   0 Batch 4340/17275   train_loss = 4.181\n",
      "Epoch   0 Batch 4341/17275   train_loss = 5.275\n",
      "Epoch   0 Batch 4342/17275   train_loss = 5.421\n",
      "Epoch   0 Batch 4343/17275   train_loss = 2.908\n",
      "Epoch   0 Batch 4344/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 4345/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 4346/17275   train_loss = 3.675\n",
      "Epoch   0 Batch 4347/17275   train_loss = 3.833\n",
      "Epoch   0 Batch 4348/17275   train_loss = 3.265\n",
      "Epoch   0 Batch 4349/17275   train_loss = 5.831\n",
      "Epoch   0 Batch 4350/17275   train_loss = 3.788\n",
      "Epoch   0 Batch 4351/17275   train_loss = 2.557\n",
      "Epoch   0 Batch 4352/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 4353/17275   train_loss = 2.852\n",
      "Epoch   0 Batch 4354/17275   train_loss = 3.441\n",
      "Epoch   0 Batch 4355/17275   train_loss = 2.748\n",
      "Epoch   0 Batch 4356/17275   train_loss = 8.063\n",
      "Epoch   0 Batch 4357/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 4358/17275   train_loss = 5.581\n",
      "Epoch   0 Batch 4359/17275   train_loss = 6.391\n",
      "Epoch   0 Batch 4360/17275   train_loss = 4.245\n",
      "Epoch   0 Batch 4361/17275   train_loss = 3.073\n",
      "Epoch   0 Batch 4362/17275   train_loss = 6.266\n",
      "Epoch   0 Batch 4363/17275   train_loss = 4.878\n",
      "Epoch   0 Batch 4364/17275   train_loss = 5.636\n",
      "Epoch   0 Batch 4365/17275   train_loss = 4.435\n",
      "Epoch   0 Batch 4366/17275   train_loss = 3.477\n",
      "Epoch   0 Batch 4367/17275   train_loss = 3.318\n",
      "Epoch   0 Batch 4368/17275   train_loss = 2.194\n",
      "Epoch   0 Batch 4369/17275   train_loss = 2.888\n",
      "Epoch   0 Batch 4370/17275   train_loss = 3.476\n",
      "Epoch   0 Batch 4371/17275   train_loss = 5.653\n",
      "Epoch   0 Batch 4372/17275   train_loss = 6.052\n",
      "Epoch   0 Batch 4373/17275   train_loss = 3.758\n",
      "Epoch   0 Batch 4374/17275   train_loss = 5.720\n",
      "Epoch   0 Batch 4375/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 4376/17275   train_loss = 2.965\n",
      "Epoch   0 Batch 4377/17275   train_loss = 6.227\n",
      "Epoch   0 Batch 4378/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 4379/17275   train_loss = 4.123\n",
      "Epoch   0 Batch 4380/17275   train_loss = 5.555\n",
      "Epoch   0 Batch 4381/17275   train_loss = 2.849\n",
      "Epoch   0 Batch 4382/17275   train_loss = 5.491\n",
      "Epoch   0 Batch 4383/17275   train_loss = 5.540\n",
      "Epoch   0 Batch 4384/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 4385/17275   train_loss = 4.720\n",
      "Epoch   0 Batch 4386/17275   train_loss = 6.198\n",
      "Epoch   0 Batch 4387/17275   train_loss = 2.183\n",
      "Epoch   0 Batch 4388/17275   train_loss = 6.348\n",
      "Epoch   0 Batch 4389/17275   train_loss = 5.543\n",
      "Epoch   0 Batch 4390/17275   train_loss = 7.337\n",
      "Epoch   0 Batch 4391/17275   train_loss = 5.543\n",
      "Epoch   0 Batch 4392/17275   train_loss = 3.472\n",
      "Epoch   0 Batch 4393/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 4394/17275   train_loss = 6.221\n",
      "Epoch   0 Batch 4395/17275   train_loss = 5.357\n",
      "Epoch   0 Batch 4396/17275   train_loss = 2.148\n",
      "Epoch   0 Batch 4397/17275   train_loss = 2.968\n",
      "Epoch   0 Batch 4398/17275   train_loss = 4.300\n",
      "Epoch   0 Batch 4399/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 4400/17275   train_loss = 3.950\n",
      "Epoch   0 Batch 4401/17275   train_loss = 3.606\n",
      "Epoch   0 Batch 4402/17275   train_loss = 4.865\n",
      "Epoch   0 Batch 4403/17275   train_loss = 3.733\n",
      "Epoch   0 Batch 4404/17275   train_loss = 3.688\n",
      "Epoch   0 Batch 4405/17275   train_loss = 4.083\n",
      "Epoch   0 Batch 4406/17275   train_loss = 6.602\n",
      "Epoch   0 Batch 4407/17275   train_loss = 3.732\n",
      "Epoch   0 Batch 4408/17275   train_loss = 4.302\n",
      "Epoch   0 Batch 4409/17275   train_loss = 4.174\n",
      "Epoch   0 Batch 4410/17275   train_loss = 2.532\n",
      "Epoch   0 Batch 4411/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 4412/17275   train_loss = 3.609\n",
      "Epoch   0 Batch 4413/17275   train_loss = 2.456\n",
      "Epoch   0 Batch 4414/17275   train_loss = 3.432\n",
      "Epoch   0 Batch 4415/17275   train_loss = 3.791\n",
      "Epoch   0 Batch 4416/17275   train_loss = 2.973\n",
      "Epoch   0 Batch 4417/17275   train_loss = 6.596\n",
      "Epoch   0 Batch 4418/17275   train_loss = 2.018\n",
      "Epoch   0 Batch 4419/17275   train_loss = 4.556\n",
      "Epoch   0 Batch 4420/17275   train_loss = 3.905\n",
      "Epoch   0 Batch 4421/17275   train_loss = 2.799\n",
      "Epoch   0 Batch 4422/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 4423/17275   train_loss = 7.067\n",
      "Epoch   0 Batch 4424/17275   train_loss = 5.397\n",
      "Epoch   0 Batch 4425/17275   train_loss = 2.203\n",
      "Epoch   0 Batch 4426/17275   train_loss = 2.980\n",
      "Epoch   0 Batch 4427/17275   train_loss = 3.564\n",
      "Epoch   0 Batch 4428/17275   train_loss = 2.877\n",
      "Epoch   0 Batch 4429/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 4430/17275   train_loss = 4.683\n",
      "Epoch   0 Batch 4431/17275   train_loss = 5.848\n",
      "Epoch   0 Batch 4432/17275   train_loss = 2.944\n",
      "Epoch   0 Batch 4433/17275   train_loss = 4.051\n",
      "Epoch   0 Batch 4434/17275   train_loss = 1.983\n",
      "Epoch   0 Batch 4435/17275   train_loss = 5.402\n",
      "Epoch   0 Batch 4436/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 4437/17275   train_loss = 5.892\n",
      "Epoch   0 Batch 4438/17275   train_loss = 6.019\n",
      "Epoch   0 Batch 4439/17275   train_loss = 6.604\n",
      "Epoch   0 Batch 4440/17275   train_loss = 5.042\n",
      "Epoch   0 Batch 4441/17275   train_loss = 2.031\n",
      "Epoch   0 Batch 4442/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 4443/17275   train_loss = 8.856\n",
      "Epoch   0 Batch 4444/17275   train_loss = 7.604\n",
      "Epoch   0 Batch 4445/17275   train_loss = 6.266\n",
      "Epoch   0 Batch 4446/17275   train_loss = 3.637\n",
      "Epoch   0 Batch 4447/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 4448/17275   train_loss = 3.487\n",
      "Epoch   0 Batch 4449/17275   train_loss = 6.250\n",
      "Epoch   0 Batch 4450/17275   train_loss = 5.680\n",
      "Epoch   0 Batch 4451/17275   train_loss = 6.743\n",
      "Epoch   0 Batch 4452/17275   train_loss = 1.874\n",
      "Epoch   0 Batch 4453/17275   train_loss = 5.679\n",
      "Epoch   0 Batch 4454/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 4455/17275   train_loss = 6.038\n",
      "Epoch   0 Batch 4456/17275   train_loss = 3.510\n",
      "Epoch   0 Batch 4457/17275   train_loss = 5.341\n",
      "Epoch   0 Batch 4458/17275   train_loss = 2.547\n",
      "Epoch   0 Batch 4459/17275   train_loss = 5.811\n",
      "Epoch   0 Batch 4460/17275   train_loss = 3.209\n",
      "Epoch   0 Batch 4461/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 4462/17275   train_loss = 5.559\n",
      "Epoch   0 Batch 4463/17275   train_loss = 3.470\n",
      "Epoch   0 Batch 4464/17275   train_loss = 2.453\n",
      "Epoch   0 Batch 4465/17275   train_loss = 3.929\n",
      "Epoch   0 Batch 4466/17275   train_loss = 6.028\n",
      "Epoch   0 Batch 4467/17275   train_loss = 5.000\n",
      "Epoch   0 Batch 4468/17275   train_loss = 6.936\n",
      "Epoch   0 Batch 4469/17275   train_loss = 3.666\n",
      "Epoch   0 Batch 4470/17275   train_loss = 4.728\n",
      "Epoch   0 Batch 4471/17275   train_loss = 2.983\n",
      "Epoch   0 Batch 4472/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 4473/17275   train_loss = 5.823\n",
      "Epoch   0 Batch 4474/17275   train_loss = 4.516\n",
      "Epoch   0 Batch 4475/17275   train_loss = 3.724\n",
      "Epoch   0 Batch 4476/17275   train_loss = 6.364\n",
      "Epoch   0 Batch 4477/17275   train_loss = 1.961\n",
      "Epoch   0 Batch 4478/17275   train_loss = 3.542\n",
      "Epoch   0 Batch 4479/17275   train_loss = 5.366\n",
      "Epoch   0 Batch 4480/17275   train_loss = 2.644\n",
      "Epoch   0 Batch 4481/17275   train_loss = 5.375\n",
      "Epoch   0 Batch 4482/17275   train_loss = 3.747\n",
      "Epoch   0 Batch 4483/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 4484/17275   train_loss = 2.775\n",
      "Epoch   0 Batch 4485/17275   train_loss = 2.452\n",
      "Epoch   0 Batch 4486/17275   train_loss = 4.267\n",
      "Epoch   0 Batch 4487/17275   train_loss = 5.180\n",
      "Epoch   0 Batch 4488/17275   train_loss = 6.387\n",
      "Epoch   0 Batch 4489/17275   train_loss = 5.958\n",
      "Epoch   0 Batch 4490/17275   train_loss = 6.348\n",
      "Epoch   0 Batch 4491/17275   train_loss = 4.063\n",
      "Epoch   0 Batch 4492/17275   train_loss = 5.860\n",
      "Epoch   0 Batch 4493/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 4494/17275   train_loss = 3.483\n",
      "Epoch   0 Batch 4495/17275   train_loss = 6.828\n",
      "Epoch   0 Batch 4496/17275   train_loss = 4.703\n",
      "Epoch   0 Batch 4497/17275   train_loss = 2.347\n",
      "Epoch   0 Batch 4498/17275   train_loss = 6.538\n",
      "Epoch   0 Batch 4499/17275   train_loss = 5.864\n",
      "Epoch   0 Batch 4500/17275   train_loss = 5.375\n",
      "Epoch   0 Batch 4501/17275   train_loss = 3.408\n",
      "Epoch   0 Batch 4502/17275   train_loss = 3.858\n",
      "Epoch   0 Batch 4503/17275   train_loss = 5.779\n",
      "Epoch   0 Batch 4504/17275   train_loss = 4.800\n",
      "Epoch   0 Batch 4505/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 4506/17275   train_loss = 5.983\n",
      "Epoch   0 Batch 4507/17275   train_loss = 4.293\n",
      "Epoch   0 Batch 4508/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 4509/17275   train_loss = 2.984\n",
      "Epoch   0 Batch 4510/17275   train_loss = 4.327\n",
      "Epoch   0 Batch 4511/17275   train_loss = 5.627\n",
      "Epoch   0 Batch 4512/17275   train_loss = 2.117\n",
      "Epoch   0 Batch 4513/17275   train_loss = 4.511\n",
      "Epoch   0 Batch 4514/17275   train_loss = 5.841\n",
      "Epoch   0 Batch 4515/17275   train_loss = 3.864\n",
      "Epoch   0 Batch 4516/17275   train_loss = 6.326\n",
      "Epoch   0 Batch 4517/17275   train_loss = 1.985\n",
      "Epoch   0 Batch 4518/17275   train_loss = 2.116\n",
      "Epoch   0 Batch 4519/17275   train_loss = 4.248\n",
      "Epoch   0 Batch 4520/17275   train_loss = 4.721\n",
      "Epoch   0 Batch 4521/17275   train_loss = 6.739\n",
      "Epoch   0 Batch 4522/17275   train_loss = 2.345\n",
      "Epoch   0 Batch 4523/17275   train_loss = 1.878\n",
      "Epoch   0 Batch 4524/17275   train_loss = 4.914\n",
      "Epoch   0 Batch 4525/17275   train_loss = 1.811\n",
      "Epoch   0 Batch 4526/17275   train_loss = 3.231\n",
      "Epoch   0 Batch 4527/17275   train_loss = 1.720\n",
      "Epoch   0 Batch 4528/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 4529/17275   train_loss = 1.939\n",
      "Epoch   0 Batch 4530/17275   train_loss = 4.452\n",
      "Epoch   0 Batch 4531/17275   train_loss = 3.496\n",
      "Epoch   0 Batch 4532/17275   train_loss = 4.820\n",
      "Epoch   0 Batch 4533/17275   train_loss = 7.622\n",
      "Epoch   0 Batch 4534/17275   train_loss = 2.453\n",
      "Epoch   0 Batch 4535/17275   train_loss = 4.435\n",
      "Epoch   0 Batch 4536/17275   train_loss = 6.591\n",
      "Epoch   0 Batch 4537/17275   train_loss = 6.071\n",
      "Epoch   0 Batch 4538/17275   train_loss = 5.588\n",
      "Epoch   0 Batch 4539/17275   train_loss = 3.489\n",
      "Epoch   0 Batch 4540/17275   train_loss = 2.699\n",
      "Epoch   0 Batch 4541/17275   train_loss = 2.951\n",
      "Epoch   0 Batch 4542/17275   train_loss = 2.914\n",
      "Epoch   0 Batch 4543/17275   train_loss = 6.290\n",
      "Epoch   0 Batch 4544/17275   train_loss = 3.080\n",
      "Epoch   0 Batch 4545/17275   train_loss = 2.728\n",
      "Epoch   0 Batch 4546/17275   train_loss = 2.186\n",
      "Epoch   0 Batch 4547/17275   train_loss = 2.560\n",
      "Epoch   0 Batch 4548/17275   train_loss = 2.824\n",
      "Epoch   0 Batch 4549/17275   train_loss = 2.985\n",
      "Epoch   0 Batch 4550/17275   train_loss = 4.347\n",
      "Epoch   0 Batch 4551/17275   train_loss = 7.432\n",
      "Epoch   0 Batch 4552/17275   train_loss = 4.323\n",
      "Epoch   0 Batch 4553/17275   train_loss = 5.621\n",
      "Epoch   0 Batch 4554/17275   train_loss = 3.538\n",
      "Epoch   0 Batch 4555/17275   train_loss = 2.773\n",
      "Epoch   0 Batch 4556/17275   train_loss = 6.907\n",
      "Epoch   0 Batch 4557/17275   train_loss = 1.829\n",
      "Epoch   0 Batch 4558/17275   train_loss = 3.805\n",
      "Epoch   0 Batch 4559/17275   train_loss = 6.846\n",
      "Epoch   0 Batch 4560/17275   train_loss = 4.849\n",
      "Epoch   0 Batch 4561/17275   train_loss = 4.594\n",
      "Epoch   0 Batch 4562/17275   train_loss = 2.911\n",
      "Epoch   0 Batch 4563/17275   train_loss = 2.598\n",
      "Epoch   0 Batch 4564/17275   train_loss = 6.285\n",
      "Epoch   0 Batch 4565/17275   train_loss = 6.010\n",
      "Epoch   0 Batch 4566/17275   train_loss = 2.930\n",
      "Epoch   0 Batch 4567/17275   train_loss = 4.370\n",
      "Epoch   0 Batch 4568/17275   train_loss = 8.832\n",
      "Epoch   0 Batch 4569/17275   train_loss = 6.246\n",
      "Epoch   0 Batch 4570/17275   train_loss = 2.554\n",
      "Epoch   0 Batch 4571/17275   train_loss = 5.829\n",
      "Epoch   0 Batch 4572/17275   train_loss = 4.207\n",
      "Epoch   0 Batch 4573/17275   train_loss = 4.834\n",
      "Epoch   0 Batch 4574/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 4575/17275   train_loss = 5.119\n",
      "Epoch   0 Batch 4576/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 4577/17275   train_loss = 3.135\n",
      "Epoch   0 Batch 4578/17275   train_loss = 5.392\n",
      "Epoch   0 Batch 4579/17275   train_loss = 5.674\n",
      "Epoch   0 Batch 4580/17275   train_loss = 4.658\n",
      "Epoch   0 Batch 4581/17275   train_loss = 8.812\n",
      "Epoch   0 Batch 4582/17275   train_loss = 2.828\n",
      "Epoch   0 Batch 4583/17275   train_loss = 5.451\n",
      "Epoch   0 Batch 4584/17275   train_loss = 4.798\n",
      "Epoch   0 Batch 4585/17275   train_loss = 3.753\n",
      "Epoch   0 Batch 4586/17275   train_loss = 3.268\n",
      "Epoch   0 Batch 4587/17275   train_loss = 3.081\n",
      "Epoch   0 Batch 4588/17275   train_loss = 3.984\n",
      "Epoch   0 Batch 4589/17275   train_loss = 4.221\n",
      "Epoch   0 Batch 4590/17275   train_loss = 6.111\n",
      "Epoch   0 Batch 4591/17275   train_loss = 5.511\n",
      "Epoch   0 Batch 4592/17275   train_loss = 3.343\n",
      "Epoch   0 Batch 4593/17275   train_loss = 4.531\n",
      "Epoch   0 Batch 4594/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 4595/17275   train_loss = 3.795\n",
      "Epoch   0 Batch 4596/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 4597/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 4598/17275   train_loss = 5.806\n",
      "Epoch   0 Batch 4599/17275   train_loss = 5.803\n",
      "Epoch   0 Batch 4600/17275   train_loss = 5.274\n",
      "Epoch   0 Batch 4601/17275   train_loss = 3.919\n",
      "Epoch   0 Batch 4602/17275   train_loss = 3.105\n",
      "Epoch   0 Batch 4603/17275   train_loss = 2.619\n",
      "Epoch   0 Batch 4604/17275   train_loss = 3.692\n",
      "Epoch   0 Batch 4605/17275   train_loss = 2.020\n",
      "Epoch   0 Batch 4606/17275   train_loss = 5.952\n",
      "Epoch   0 Batch 4607/17275   train_loss = 3.043\n",
      "Epoch   0 Batch 4608/17275   train_loss = 3.277\n",
      "Epoch   0 Batch 4609/17275   train_loss = 7.220\n",
      "Epoch   0 Batch 4610/17275   train_loss = 5.265\n",
      "Epoch   0 Batch 4611/17275   train_loss = 1.956\n",
      "Epoch   0 Batch 4612/17275   train_loss = 2.001\n",
      "Epoch   0 Batch 4613/17275   train_loss = 3.858\n",
      "Epoch   0 Batch 4614/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 4615/17275   train_loss = 3.571\n",
      "Epoch   0 Batch 4616/17275   train_loss = 5.043\n",
      "Epoch   0 Batch 4617/17275   train_loss = 2.894\n",
      "Epoch   0 Batch 4618/17275   train_loss = 5.007\n",
      "Epoch   0 Batch 4619/17275   train_loss = 5.969\n",
      "Epoch   0 Batch 4620/17275   train_loss = 2.339\n",
      "Epoch   0 Batch 4621/17275   train_loss = 2.829\n",
      "Epoch   0 Batch 4622/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 4623/17275   train_loss = 5.864\n",
      "Epoch   0 Batch 4624/17275   train_loss = 4.437\n",
      "Epoch   0 Batch 4625/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 4626/17275   train_loss = 3.714\n",
      "Epoch   0 Batch 4627/17275   train_loss = 2.359\n",
      "Epoch   0 Batch 4628/17275   train_loss = 4.493\n",
      "Epoch   0 Batch 4629/17275   train_loss = 2.517\n",
      "Epoch   0 Batch 4630/17275   train_loss = 3.324\n",
      "Epoch   0 Batch 4631/17275   train_loss = 2.259\n",
      "Epoch   0 Batch 4632/17275   train_loss = 3.132\n",
      "Epoch   0 Batch 4633/17275   train_loss = 2.645\n",
      "Epoch   0 Batch 4634/17275   train_loss = 3.367\n",
      "Epoch   0 Batch 4635/17275   train_loss = 5.368\n",
      "Epoch   0 Batch 4636/17275   train_loss = 5.460\n",
      "Epoch   0 Batch 4637/17275   train_loss = 2.699\n",
      "Epoch   0 Batch 4638/17275   train_loss = 6.533\n",
      "Epoch   0 Batch 4639/17275   train_loss = 4.689\n",
      "Epoch   0 Batch 4640/17275   train_loss = 6.429\n",
      "Epoch   0 Batch 4641/17275   train_loss = 4.598\n",
      "Epoch   0 Batch 4642/17275   train_loss = 4.606\n",
      "Epoch   0 Batch 4643/17275   train_loss = 5.845\n",
      "Epoch   0 Batch 4644/17275   train_loss = 5.428\n",
      "Epoch   0 Batch 4645/17275   train_loss = 5.738\n",
      "Epoch   0 Batch 4646/17275   train_loss = 4.991\n",
      "Epoch   0 Batch 4647/17275   train_loss = 3.850\n",
      "Epoch   0 Batch 4648/17275   train_loss = 4.836\n",
      "Epoch   0 Batch 4649/17275   train_loss = 2.548\n",
      "Epoch   0 Batch 4650/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 4651/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 4652/17275   train_loss = 6.030\n",
      "Epoch   0 Batch 4653/17275   train_loss = 6.018\n",
      "Epoch   0 Batch 4654/17275   train_loss = 3.334\n",
      "Epoch   0 Batch 4655/17275   train_loss = 6.426\n",
      "Epoch   0 Batch 4656/17275   train_loss = 3.036\n",
      "Epoch   0 Batch 4657/17275   train_loss = 3.917\n",
      "Epoch   0 Batch 4658/17275   train_loss = 5.442\n",
      "Epoch   0 Batch 4659/17275   train_loss = 4.752\n",
      "Epoch   0 Batch 4660/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 4661/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 4662/17275   train_loss = 3.144\n",
      "Epoch   0 Batch 4663/17275   train_loss = 4.093\n",
      "Epoch   0 Batch 4664/17275   train_loss = 6.353\n",
      "Epoch   0 Batch 4665/17275   train_loss = 5.399\n",
      "Epoch   0 Batch 4666/17275   train_loss = 6.291\n",
      "Epoch   0 Batch 4667/17275   train_loss = 6.050\n",
      "Epoch   0 Batch 4668/17275   train_loss = 5.220\n",
      "Epoch   0 Batch 4669/17275   train_loss = 5.914\n",
      "Epoch   0 Batch 4670/17275   train_loss = 4.627\n",
      "Epoch   0 Batch 4671/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 4672/17275   train_loss = 2.775\n",
      "Epoch   0 Batch 4673/17275   train_loss = 2.618\n",
      "Epoch   0 Batch 4674/17275   train_loss = 3.003\n",
      "Epoch   0 Batch 4675/17275   train_loss = 4.517\n",
      "Epoch   0 Batch 4676/17275   train_loss = 3.830\n",
      "Epoch   0 Batch 4677/17275   train_loss = 5.528\n",
      "Epoch   0 Batch 4678/17275   train_loss = 4.623\n",
      "Epoch   0 Batch 4679/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 4680/17275   train_loss = 8.839\n",
      "Epoch   0 Batch 4681/17275   train_loss = 2.511\n",
      "Epoch   0 Batch 4682/17275   train_loss = 3.374\n",
      "Epoch   0 Batch 4683/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 4684/17275   train_loss = 2.035\n",
      "Epoch   0 Batch 4685/17275   train_loss = 3.203\n",
      "Epoch   0 Batch 4686/17275   train_loss = 2.586\n",
      "Epoch   0 Batch 4687/17275   train_loss = 3.535\n",
      "Epoch   0 Batch 4688/17275   train_loss = 3.078\n",
      "Epoch   0 Batch 4689/17275   train_loss = 7.839\n",
      "Epoch   0 Batch 4690/17275   train_loss = 2.601\n",
      "Epoch   0 Batch 4691/17275   train_loss = 2.463\n",
      "Epoch   0 Batch 4692/17275   train_loss = 5.962\n",
      "Epoch   0 Batch 4693/17275   train_loss = 5.842\n",
      "Epoch   0 Batch 4694/17275   train_loss = 2.031\n",
      "Epoch   0 Batch 4695/17275   train_loss = 1.962\n",
      "Epoch   0 Batch 4696/17275   train_loss = 3.434\n",
      "Epoch   0 Batch 4697/17275   train_loss = 6.215\n",
      "Epoch   0 Batch 4698/17275   train_loss = 1.903\n",
      "Epoch   0 Batch 4699/17275   train_loss = 2.892\n",
      "Epoch   0 Batch 4700/17275   train_loss = 1.833\n",
      "Epoch   0 Batch 4701/17275   train_loss = 2.979\n",
      "Epoch   0 Batch 4702/17275   train_loss = 3.253\n",
      "Epoch   0 Batch 4703/17275   train_loss = 2.227\n",
      "Epoch   0 Batch 4704/17275   train_loss = 5.152\n",
      "Epoch   0 Batch 4705/17275   train_loss = 4.916\n",
      "Epoch   0 Batch 4706/17275   train_loss = 5.591\n",
      "Epoch   0 Batch 4707/17275   train_loss = 4.055\n",
      "Epoch   0 Batch 4708/17275   train_loss = 5.590\n",
      "Epoch   0 Batch 4709/17275   train_loss = 2.892\n",
      "Epoch   0 Batch 4710/17275   train_loss = 3.456\n",
      "Epoch   0 Batch 4711/17275   train_loss = 7.196\n",
      "Epoch   0 Batch 4712/17275   train_loss = 3.629\n",
      "Epoch   0 Batch 4713/17275   train_loss = 5.580\n",
      "Epoch   0 Batch 4714/17275   train_loss = 2.448\n",
      "Epoch   0 Batch 4715/17275   train_loss = 2.630\n",
      "Epoch   0 Batch 4716/17275   train_loss = 5.656\n",
      "Epoch   0 Batch 4717/17275   train_loss = 5.892\n",
      "Epoch   0 Batch 4718/17275   train_loss = 6.121\n",
      "Epoch   0 Batch 4719/17275   train_loss = 6.629\n",
      "Epoch   0 Batch 4720/17275   train_loss = 4.262\n",
      "Epoch   0 Batch 4721/17275   train_loss = 1.902\n",
      "Epoch   0 Batch 4722/17275   train_loss = 4.078\n",
      "Epoch   0 Batch 4723/17275   train_loss = 8.944\n",
      "Epoch   0 Batch 4724/17275   train_loss = 6.097\n",
      "Epoch   0 Batch 4725/17275   train_loss = 2.674\n",
      "Epoch   0 Batch 4726/17275   train_loss = 3.802\n",
      "Epoch   0 Batch 4727/17275   train_loss = 3.693\n",
      "Epoch   0 Batch 4728/17275   train_loss = 3.611\n",
      "Epoch   0 Batch 4729/17275   train_loss = 5.402\n",
      "Epoch   0 Batch 4730/17275   train_loss = 1.908\n",
      "Epoch   0 Batch 4731/17275   train_loss = 5.092\n",
      "Epoch   0 Batch 4732/17275   train_loss = 8.913\n",
      "Epoch   0 Batch 4733/17275   train_loss = 4.174\n",
      "Epoch   0 Batch 4734/17275   train_loss = 3.909\n",
      "Epoch   0 Batch 4735/17275   train_loss = 5.556\n",
      "Epoch   0 Batch 4736/17275   train_loss = 6.556\n",
      "Epoch   0 Batch 4737/17275   train_loss = 6.382\n",
      "Epoch   0 Batch 4738/17275   train_loss = 6.266\n",
      "Epoch   0 Batch 4739/17275   train_loss = 6.872\n",
      "Epoch   0 Batch 4740/17275   train_loss = 3.531\n",
      "Epoch   0 Batch 4741/17275   train_loss = 1.944\n",
      "Epoch   0 Batch 4742/17275   train_loss = 2.028\n",
      "Epoch   0 Batch 4743/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 4744/17275   train_loss = 5.949\n",
      "Epoch   0 Batch 4745/17275   train_loss = 5.594\n",
      "Epoch   0 Batch 4746/17275   train_loss = 7.168\n",
      "Epoch   0 Batch 4747/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 4748/17275   train_loss = 3.798\n",
      "Epoch   0 Batch 4749/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 4750/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 4751/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 4752/17275   train_loss = 2.036\n",
      "Epoch   0 Batch 4753/17275   train_loss = 3.258\n",
      "Epoch   0 Batch 4754/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 4755/17275   train_loss = 4.207\n",
      "Epoch   0 Batch 4756/17275   train_loss = 2.833\n",
      "Epoch   0 Batch 4757/17275   train_loss = 2.915\n",
      "Epoch   0 Batch 4758/17275   train_loss = 3.237\n",
      "Epoch   0 Batch 4759/17275   train_loss = 3.867\n",
      "Epoch   0 Batch 4760/17275   train_loss = 3.357\n",
      "Epoch   0 Batch 4761/17275   train_loss = 3.612\n",
      "Epoch   0 Batch 4762/17275   train_loss = 3.842\n",
      "Epoch   0 Batch 4763/17275   train_loss = 2.392\n",
      "Epoch   0 Batch 4764/17275   train_loss = 3.891\n",
      "Epoch   0 Batch 4765/17275   train_loss = 2.683\n",
      "Epoch   0 Batch 4766/17275   train_loss = 2.592\n",
      "Epoch   0 Batch 4767/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 4768/17275   train_loss = 3.138\n",
      "Epoch   0 Batch 4769/17275   train_loss = 2.941\n",
      "Epoch   0 Batch 4770/17275   train_loss = 3.381\n",
      "Epoch   0 Batch 4771/17275   train_loss = 3.953\n",
      "Epoch   0 Batch 4772/17275   train_loss = 6.449\n",
      "Epoch   0 Batch 4773/17275   train_loss = 3.683\n",
      "Epoch   0 Batch 4774/17275   train_loss = 4.914\n",
      "Epoch   0 Batch 4775/17275   train_loss = 5.424\n",
      "Epoch   0 Batch 4776/17275   train_loss = 5.479\n",
      "Epoch   0 Batch 4777/17275   train_loss = 5.514\n",
      "Epoch   0 Batch 4778/17275   train_loss = 3.930\n",
      "Epoch   0 Batch 4779/17275   train_loss = 4.454\n",
      "Epoch   0 Batch 4780/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 4781/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 4782/17275   train_loss = 2.931\n",
      "Epoch   0 Batch 4783/17275   train_loss = 5.465\n",
      "Epoch   0 Batch 4784/17275   train_loss = 3.287\n",
      "Epoch   0 Batch 4785/17275   train_loss = 4.481\n",
      "Epoch   0 Batch 4786/17275   train_loss = 3.750\n",
      "Epoch   0 Batch 4787/17275   train_loss = 5.786\n",
      "Epoch   0 Batch 4788/17275   train_loss = 8.904\n",
      "Epoch   0 Batch 4789/17275   train_loss = 1.972\n",
      "Epoch   0 Batch 4790/17275   train_loss = 3.451\n",
      "Epoch   0 Batch 4791/17275   train_loss = 5.905\n",
      "Epoch   0 Batch 4792/17275   train_loss = 3.156\n",
      "Epoch   0 Batch 4793/17275   train_loss = 6.522\n",
      "Epoch   0 Batch 4794/17275   train_loss = 3.879\n",
      "Epoch   0 Batch 4795/17275   train_loss = 5.132\n",
      "Epoch   0 Batch 4796/17275   train_loss = 5.829\n",
      "Epoch   0 Batch 4797/17275   train_loss = 6.404\n",
      "Epoch   0 Batch 4798/17275   train_loss = 3.185\n",
      "Epoch   0 Batch 4799/17275   train_loss = 7.009\n",
      "Epoch   0 Batch 4800/17275   train_loss = 3.935\n",
      "Epoch   0 Batch 4801/17275   train_loss = 1.970\n",
      "Epoch   0 Batch 4802/17275   train_loss = 6.265\n",
      "Epoch   0 Batch 4803/17275   train_loss = 6.806\n",
      "Epoch   0 Batch 4804/17275   train_loss = 3.987\n",
      "Epoch   0 Batch 4805/17275   train_loss = 6.161\n",
      "Epoch   0 Batch 4806/17275   train_loss = 5.311\n",
      "Epoch   0 Batch 4807/17275   train_loss = 3.019\n",
      "Epoch   0 Batch 4808/17275   train_loss = 2.725\n",
      "Epoch   0 Batch 4809/17275   train_loss = 3.351\n",
      "Epoch   0 Batch 4810/17275   train_loss = 2.404\n",
      "Epoch   0 Batch 4811/17275   train_loss = 2.876\n",
      "Epoch   0 Batch 4812/17275   train_loss = 3.897\n",
      "Epoch   0 Batch 4813/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 4814/17275   train_loss = 4.922\n",
      "Epoch   0 Batch 4815/17275   train_loss = 3.523\n",
      "Epoch   0 Batch 4816/17275   train_loss = 3.496\n",
      "Epoch   0 Batch 4817/17275   train_loss = 2.258\n",
      "Epoch   0 Batch 4818/17275   train_loss = 4.403\n",
      "Epoch   0 Batch 4819/17275   train_loss = 4.593\n",
      "Epoch   0 Batch 4820/17275   train_loss = 2.467\n",
      "Epoch   0 Batch 4821/17275   train_loss = 2.731\n",
      "Epoch   0 Batch 4822/17275   train_loss = 4.136\n",
      "Epoch   0 Batch 4823/17275   train_loss = 3.300\n",
      "Epoch   0 Batch 4824/17275   train_loss = 2.714\n",
      "Epoch   0 Batch 4825/17275   train_loss = 5.194\n",
      "Epoch   0 Batch 4826/17275   train_loss = 2.875\n",
      "Epoch   0 Batch 4827/17275   train_loss = 3.492\n",
      "Epoch   0 Batch 4828/17275   train_loss = 4.629\n",
      "Epoch   0 Batch 4829/17275   train_loss = 2.656\n",
      "Epoch   0 Batch 4830/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 4831/17275   train_loss = 4.451\n",
      "Epoch   0 Batch 4832/17275   train_loss = 4.994\n",
      "Epoch   0 Batch 4833/17275   train_loss = 3.291\n",
      "Epoch   0 Batch 4834/17275   train_loss = 3.651\n",
      "Epoch   0 Batch 4835/17275   train_loss = 6.281\n",
      "Epoch   0 Batch 4836/17275   train_loss = 5.809\n",
      "Epoch   0 Batch 4837/17275   train_loss = 6.404\n",
      "Epoch   0 Batch 4838/17275   train_loss = 2.380\n",
      "Epoch   0 Batch 4839/17275   train_loss = 4.002\n",
      "Epoch   0 Batch 4840/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 4841/17275   train_loss = 3.885\n",
      "Epoch   0 Batch 4842/17275   train_loss = 5.057\n",
      "Epoch   0 Batch 4843/17275   train_loss = 2.358\n",
      "Epoch   0 Batch 4844/17275   train_loss = 2.956\n",
      "Epoch   0 Batch 4845/17275   train_loss = 3.942\n",
      "Epoch   0 Batch 4846/17275   train_loss = 5.837\n",
      "Epoch   0 Batch 4847/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 4848/17275   train_loss = 2.311\n",
      "Epoch   0 Batch 4849/17275   train_loss = 4.412\n",
      "Epoch   0 Batch 4850/17275   train_loss = 2.836\n",
      "Epoch   0 Batch 4851/17275   train_loss = 3.478\n",
      "Epoch   0 Batch 4852/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 4853/17275   train_loss = 4.266\n",
      "Epoch   0 Batch 4854/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 4855/17275   train_loss = 8.926\n",
      "Epoch   0 Batch 4856/17275   train_loss = 2.003\n",
      "Epoch   0 Batch 4857/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 4858/17275   train_loss = 6.633\n",
      "Epoch   0 Batch 4859/17275   train_loss = 6.884\n",
      "Epoch   0 Batch 4860/17275   train_loss = 5.901\n",
      "Epoch   0 Batch 4861/17275   train_loss = 5.488\n",
      "Epoch   0 Batch 4862/17275   train_loss = 3.103\n",
      "Epoch   0 Batch 4863/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 4864/17275   train_loss = 2.188\n",
      "Epoch   0 Batch 4865/17275   train_loss = 5.419\n",
      "Epoch   0 Batch 4866/17275   train_loss = 3.325\n",
      "Epoch   0 Batch 4867/17275   train_loss = 3.533\n",
      "Epoch   0 Batch 4868/17275   train_loss = 3.991\n",
      "Epoch   0 Batch 4869/17275   train_loss = 3.862\n",
      "Epoch   0 Batch 4870/17275   train_loss = 3.667\n",
      "Epoch   0 Batch 4871/17275   train_loss = 5.575\n",
      "Epoch   0 Batch 4872/17275   train_loss = 3.006\n",
      "Epoch   0 Batch 4873/17275   train_loss = 2.493\n",
      "Epoch   0 Batch 4874/17275   train_loss = 3.341\n",
      "Epoch   0 Batch 4875/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 4876/17275   train_loss = 6.368\n",
      "Epoch   0 Batch 4877/17275   train_loss = 8.924\n",
      "Epoch   0 Batch 4878/17275   train_loss = 2.347\n",
      "Epoch   0 Batch 4879/17275   train_loss = 4.864\n",
      "Epoch   0 Batch 4880/17275   train_loss = 3.014\n",
      "Epoch   0 Batch 4881/17275   train_loss = 2.286\n",
      "Epoch   0 Batch 4882/17275   train_loss = 2.712\n",
      "Epoch   0 Batch 4883/17275   train_loss = 7.734\n",
      "Epoch   0 Batch 4884/17275   train_loss = 5.618\n",
      "Epoch   0 Batch 4885/17275   train_loss = 3.232\n",
      "Epoch   0 Batch 4886/17275   train_loss = 2.933\n",
      "Epoch   0 Batch 4887/17275   train_loss = 4.546\n",
      "Epoch   0 Batch 4888/17275   train_loss = 3.145\n",
      "Epoch   0 Batch 4889/17275   train_loss = 5.884\n",
      "Epoch   0 Batch 4890/17275   train_loss = 4.313\n",
      "Epoch   0 Batch 4891/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 4892/17275   train_loss = 2.316\n",
      "Epoch   0 Batch 4893/17275   train_loss = 2.169\n",
      "Epoch   0 Batch 4894/17275   train_loss = 4.073\n",
      "Epoch   0 Batch 4895/17275   train_loss = 2.533\n",
      "Epoch   0 Batch 4896/17275   train_loss = 8.965\n",
      "Epoch   0 Batch 4897/17275   train_loss = 3.069\n",
      "Epoch   0 Batch 4898/17275   train_loss = 2.134\n",
      "Epoch   0 Batch 4899/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 4900/17275   train_loss = 3.791\n",
      "Epoch   0 Batch 4901/17275   train_loss = 3.648\n",
      "Epoch   0 Batch 4902/17275   train_loss = 5.535\n",
      "Epoch   0 Batch 4903/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 4904/17275   train_loss = 5.839\n",
      "Epoch   0 Batch 4905/17275   train_loss = 4.262\n",
      "Epoch   0 Batch 4906/17275   train_loss = 5.388\n",
      "Epoch   0 Batch 4907/17275   train_loss = 1.980\n",
      "Epoch   0 Batch 4908/17275   train_loss = 4.102\n",
      "Epoch   0 Batch 4909/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 4910/17275   train_loss = 5.955\n",
      "Epoch   0 Batch 4911/17275   train_loss = 3.272\n",
      "Epoch   0 Batch 4912/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 4913/17275   train_loss = 3.155\n",
      "Epoch   0 Batch 4914/17275   train_loss = 1.959\n",
      "Epoch   0 Batch 4915/17275   train_loss = 5.632\n",
      "Epoch   0 Batch 4916/17275   train_loss = 3.582\n",
      "Epoch   0 Batch 4917/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 4918/17275   train_loss = 2.864\n",
      "Epoch   0 Batch 4919/17275   train_loss = 2.984\n",
      "Epoch   0 Batch 4920/17275   train_loss = 3.588\n",
      "Epoch   0 Batch 4921/17275   train_loss = 2.734\n",
      "Epoch   0 Batch 4922/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 4923/17275   train_loss = 3.570\n",
      "Epoch   0 Batch 4924/17275   train_loss = 2.944\n",
      "Epoch   0 Batch 4925/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 4926/17275   train_loss = 4.938\n",
      "Epoch   0 Batch 4927/17275   train_loss = 4.214\n",
      "Epoch   0 Batch 4928/17275   train_loss = 4.274\n",
      "Epoch   0 Batch 4929/17275   train_loss = 5.444\n",
      "Epoch   0 Batch 4930/17275   train_loss = 2.180\n",
      "Epoch   0 Batch 4931/17275   train_loss = 4.620\n",
      "Epoch   0 Batch 4932/17275   train_loss = 4.349\n",
      "Epoch   0 Batch 4933/17275   train_loss = 7.176\n",
      "Epoch   0 Batch 4934/17275   train_loss = 1.932\n",
      "Epoch   0 Batch 4935/17275   train_loss = 3.750\n",
      "Epoch   0 Batch 4936/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 4937/17275   train_loss = 3.408\n",
      "Epoch   0 Batch 4938/17275   train_loss = 8.983\n",
      "Epoch   0 Batch 4939/17275   train_loss = 2.665\n",
      "Epoch   0 Batch 4940/17275   train_loss = 2.248\n",
      "Epoch   0 Batch 4941/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 4942/17275   train_loss = 3.173\n",
      "Epoch   0 Batch 4943/17275   train_loss = 2.178\n",
      "Epoch   0 Batch 4944/17275   train_loss = 5.933\n",
      "Epoch   0 Batch 4945/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 4946/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 4947/17275   train_loss = 2.837\n",
      "Epoch   0 Batch 4948/17275   train_loss = 2.992\n",
      "Epoch   0 Batch 4949/17275   train_loss = 2.660\n",
      "Epoch   0 Batch 4950/17275   train_loss = 4.606\n",
      "Epoch   0 Batch 4951/17275   train_loss = 4.511\n",
      "Epoch   0 Batch 4952/17275   train_loss = 3.477\n",
      "Epoch   0 Batch 4953/17275   train_loss = 3.079\n",
      "Epoch   0 Batch 4954/17275   train_loss = 2.515\n",
      "Epoch   0 Batch 4955/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 4956/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 4957/17275   train_loss = 3.621\n",
      "Epoch   0 Batch 4958/17275   train_loss = 2.858\n",
      "Epoch   0 Batch 4959/17275   train_loss = 4.391\n",
      "Epoch   0 Batch 4960/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 4961/17275   train_loss = 4.505\n",
      "Epoch   0 Batch 4962/17275   train_loss = 7.315\n",
      "Epoch   0 Batch 4963/17275   train_loss = 4.005\n",
      "Epoch   0 Batch 4964/17275   train_loss = 4.369\n",
      "Epoch   0 Batch 4965/17275   train_loss = 5.400\n",
      "Epoch   0 Batch 4966/17275   train_loss = 3.885\n",
      "Epoch   0 Batch 4967/17275   train_loss = 3.109\n",
      "Epoch   0 Batch 4968/17275   train_loss = 2.633\n",
      "Epoch   0 Batch 4969/17275   train_loss = 3.701\n",
      "Epoch   0 Batch 4970/17275   train_loss = 2.657\n",
      "Epoch   0 Batch 4971/17275   train_loss = 2.799\n",
      "Epoch   0 Batch 4972/17275   train_loss = 5.986\n",
      "Epoch   0 Batch 4973/17275   train_loss = 1.863\n",
      "Epoch   0 Batch 4974/17275   train_loss = 2.396\n",
      "Epoch   0 Batch 4975/17275   train_loss = 2.454\n",
      "Epoch   0 Batch 4976/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 4977/17275   train_loss = 3.041\n",
      "Epoch   0 Batch 4978/17275   train_loss = 2.513\n",
      "Epoch   0 Batch 4979/17275   train_loss = 2.990\n",
      "Epoch   0 Batch 4980/17275   train_loss = 3.357\n",
      "Epoch   0 Batch 4981/17275   train_loss = 5.459\n",
      "Epoch   0 Batch 4982/17275   train_loss = 2.717\n",
      "Epoch   0 Batch 4983/17275   train_loss = 3.497\n",
      "Epoch   0 Batch 4984/17275   train_loss = 5.653\n",
      "Epoch   0 Batch 4985/17275   train_loss = 5.642\n",
      "Epoch   0 Batch 4986/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 4987/17275   train_loss = 3.976\n",
      "Epoch   0 Batch 4988/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 4989/17275   train_loss = 7.448\n",
      "Epoch   0 Batch 4990/17275   train_loss = 3.527\n",
      "Epoch   0 Batch 4991/17275   train_loss = 1.958\n",
      "Epoch   0 Batch 4992/17275   train_loss = 2.083\n",
      "Epoch   0 Batch 4993/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 4994/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 4995/17275   train_loss = 3.728\n",
      "Epoch   0 Batch 4996/17275   train_loss = 4.578\n",
      "Epoch   0 Batch 4997/17275   train_loss = 3.639\n",
      "Epoch   0 Batch 4998/17275   train_loss = 3.768\n",
      "Epoch   0 Batch 4999/17275   train_loss = 5.708\n",
      "Epoch   0 Batch 5000/17275   train_loss = 3.711\n",
      "Epoch   0 Batch 5001/17275   train_loss = 3.124\n",
      "Epoch   0 Batch 5002/17275   train_loss = 5.516\n",
      "Epoch   0 Batch 5003/17275   train_loss = 1.922\n",
      "Epoch   0 Batch 5004/17275   train_loss = 1.957\n",
      "Epoch   0 Batch 5005/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 5006/17275   train_loss = 2.808\n",
      "Epoch   0 Batch 5007/17275   train_loss = 2.513\n",
      "Epoch   0 Batch 5008/17275   train_loss = 4.105\n",
      "Epoch   0 Batch 5009/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 5010/17275   train_loss = 5.469\n",
      "Epoch   0 Batch 5011/17275   train_loss = 1.822\n",
      "Epoch   0 Batch 5012/17275   train_loss = 2.061\n",
      "Epoch   0 Batch 5013/17275   train_loss = 2.311\n",
      "Epoch   0 Batch 5014/17275   train_loss = 5.995\n",
      "Epoch   0 Batch 5015/17275   train_loss = 3.836\n",
      "Epoch   0 Batch 5016/17275   train_loss = 6.876\n",
      "Epoch   0 Batch 5017/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 5018/17275   train_loss = 3.363\n",
      "Epoch   0 Batch 5019/17275   train_loss = 4.466\n",
      "Epoch   0 Batch 5020/17275   train_loss = 6.541\n",
      "Epoch   0 Batch 5021/17275   train_loss = 2.063\n",
      "Epoch   0 Batch 5022/17275   train_loss = 5.819\n",
      "Epoch   0 Batch 5023/17275   train_loss = 1.606\n",
      "Epoch   0 Batch 5024/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 5025/17275   train_loss = 4.377\n",
      "Epoch   0 Batch 5026/17275   train_loss = 5.071\n",
      "Epoch   0 Batch 5027/17275   train_loss = 3.420\n",
      "Epoch   0 Batch 5028/17275   train_loss = 6.330\n",
      "Epoch   0 Batch 5029/17275   train_loss = 3.825\n",
      "Epoch   0 Batch 5030/17275   train_loss = 9.095\n",
      "Epoch   0 Batch 5031/17275   train_loss = 6.131\n",
      "Epoch   0 Batch 5032/17275   train_loss = 1.760\n",
      "Epoch   0 Batch 5033/17275   train_loss = 2.878\n",
      "Epoch   0 Batch 5034/17275   train_loss = 5.597\n",
      "Epoch   0 Batch 5035/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 5036/17275   train_loss = 3.645\n",
      "Epoch   0 Batch 5037/17275   train_loss = 3.381\n",
      "Epoch   0 Batch 5038/17275   train_loss = 4.893\n",
      "Epoch   0 Batch 5039/17275   train_loss = 4.803\n",
      "Epoch   0 Batch 5040/17275   train_loss = 5.809\n",
      "Epoch   0 Batch 5041/17275   train_loss = 1.793\n",
      "Epoch   0 Batch 5042/17275   train_loss = 6.397\n",
      "Epoch   0 Batch 5043/17275   train_loss = 4.549\n",
      "Epoch   0 Batch 5044/17275   train_loss = 3.703\n",
      "Epoch   0 Batch 5045/17275   train_loss = 4.861\n",
      "Epoch   0 Batch 5046/17275   train_loss = 1.816\n",
      "Epoch   0 Batch 5047/17275   train_loss = 6.430\n",
      "Epoch   0 Batch 5048/17275   train_loss = 2.641\n",
      "Epoch   0 Batch 5049/17275   train_loss = 3.869\n",
      "Epoch   0 Batch 5050/17275   train_loss = 3.747\n",
      "Epoch   0 Batch 5051/17275   train_loss = 3.373\n",
      "Epoch   0 Batch 5052/17275   train_loss = 2.064\n",
      "Epoch   0 Batch 5053/17275   train_loss = 1.757\n",
      "Epoch   0 Batch 5054/17275   train_loss = 5.486\n",
      "Epoch   0 Batch 5055/17275   train_loss = 5.892\n",
      "Epoch   0 Batch 5056/17275   train_loss = 4.249\n",
      "Epoch   0 Batch 5057/17275   train_loss = 1.835\n",
      "Epoch   0 Batch 5058/17275   train_loss = 2.691\n",
      "Epoch   0 Batch 5059/17275   train_loss = 4.027\n",
      "Epoch   0 Batch 5060/17275   train_loss = 2.664\n",
      "Epoch   0 Batch 5061/17275   train_loss = 4.892\n",
      "Epoch   0 Batch 5062/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 5063/17275   train_loss = 5.377\n",
      "Epoch   0 Batch 5064/17275   train_loss = 2.756\n",
      "Epoch   0 Batch 5065/17275   train_loss = 4.564\n",
      "Epoch   0 Batch 5066/17275   train_loss = 7.454\n",
      "Epoch   0 Batch 5067/17275   train_loss = 3.787\n",
      "Epoch   0 Batch 5068/17275   train_loss = 5.467\n",
      "Epoch   0 Batch 5069/17275   train_loss = 2.082\n",
      "Epoch   0 Batch 5070/17275   train_loss = 4.099\n",
      "Epoch   0 Batch 5071/17275   train_loss = 5.211\n",
      "Epoch   0 Batch 5072/17275   train_loss = 4.315\n",
      "Epoch   0 Batch 5073/17275   train_loss = 4.472\n",
      "Epoch   0 Batch 5074/17275   train_loss = 3.747\n",
      "Epoch   0 Batch 5075/17275   train_loss = 2.962\n",
      "Epoch   0 Batch 5076/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 5077/17275   train_loss = 2.420\n",
      "Epoch   0 Batch 5078/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 5079/17275   train_loss = 2.106\n",
      "Epoch   0 Batch 5080/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 5081/17275   train_loss = 5.680\n",
      "Epoch   0 Batch 5082/17275   train_loss = 5.678\n",
      "Epoch   0 Batch 5083/17275   train_loss = 7.086\n",
      "Epoch   0 Batch 5084/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 5085/17275   train_loss = 5.469\n",
      "Epoch   0 Batch 5086/17275   train_loss = 4.272\n",
      "Epoch   0 Batch 5087/17275   train_loss = 4.344\n",
      "Epoch   0 Batch 5088/17275   train_loss = 4.334\n",
      "Epoch   0 Batch 5089/17275   train_loss = 3.130\n",
      "Epoch   0 Batch 5090/17275   train_loss = 6.895\n",
      "Epoch   0 Batch 5091/17275   train_loss = 1.882\n",
      "Epoch   0 Batch 5092/17275   train_loss = 3.633\n",
      "Epoch   0 Batch 5093/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 5094/17275   train_loss = 6.422\n",
      "Epoch   0 Batch 5095/17275   train_loss = 5.097\n",
      "Epoch   0 Batch 5096/17275   train_loss = 3.881\n",
      "Epoch   0 Batch 5097/17275   train_loss = 5.414\n",
      "Epoch   0 Batch 5098/17275   train_loss = 1.813\n",
      "Epoch   0 Batch 5099/17275   train_loss = 2.606\n",
      "Epoch   0 Batch 5100/17275   train_loss = 3.694\n",
      "Epoch   0 Batch 5101/17275   train_loss = 4.213\n",
      "Epoch   0 Batch 5102/17275   train_loss = 3.048\n",
      "Epoch   0 Batch 5103/17275   train_loss = 5.540\n",
      "Epoch   0 Batch 5104/17275   train_loss = 3.984\n",
      "Epoch   0 Batch 5105/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 5106/17275   train_loss = 5.515\n",
      "Epoch   0 Batch 5107/17275   train_loss = 5.407\n",
      "Epoch   0 Batch 5108/17275   train_loss = 3.382\n",
      "Epoch   0 Batch 5109/17275   train_loss = 5.685\n",
      "Epoch   0 Batch 5110/17275   train_loss = 4.319\n",
      "Epoch   0 Batch 5111/17275   train_loss = 4.411\n",
      "Epoch   0 Batch 5112/17275   train_loss = 6.579\n",
      "Epoch   0 Batch 5113/17275   train_loss = 5.464\n",
      "Epoch   0 Batch 5114/17275   train_loss = 6.799\n",
      "Epoch   0 Batch 5115/17275   train_loss = 6.413\n",
      "Epoch   0 Batch 5116/17275   train_loss = 4.384\n",
      "Epoch   0 Batch 5117/17275   train_loss = 2.475\n",
      "Epoch   0 Batch 5118/17275   train_loss = 4.172\n",
      "Epoch   0 Batch 5119/17275   train_loss = 9.019\n",
      "Epoch   0 Batch 5120/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 5121/17275   train_loss = 3.151\n",
      "Epoch   0 Batch 5122/17275   train_loss = 5.698\n",
      "Epoch   0 Batch 5123/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 5124/17275   train_loss = 3.039\n",
      "Epoch   0 Batch 5125/17275   train_loss = 5.468\n",
      "Epoch   0 Batch 5126/17275   train_loss = 6.113\n",
      "Epoch   0 Batch 5127/17275   train_loss = 6.816\n",
      "Epoch   0 Batch 5128/17275   train_loss = 5.887\n",
      "Epoch   0 Batch 5129/17275   train_loss = 3.732\n",
      "Epoch   0 Batch 5130/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 5131/17275   train_loss = 6.342\n",
      "Epoch   0 Batch 5132/17275   train_loss = 6.230\n",
      "Epoch   0 Batch 5133/17275   train_loss = 2.349\n",
      "Epoch   0 Batch 5134/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 5135/17275   train_loss = 4.077\n",
      "Epoch   0 Batch 5136/17275   train_loss = 4.385\n",
      "Epoch   0 Batch 5137/17275   train_loss = 3.481\n",
      "Epoch   0 Batch 5138/17275   train_loss = 2.926\n",
      "Epoch   0 Batch 5139/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 5140/17275   train_loss = 4.399\n",
      "Epoch   0 Batch 5141/17275   train_loss = 5.497\n",
      "Epoch   0 Batch 5142/17275   train_loss = 2.916\n",
      "Epoch   0 Batch 5143/17275   train_loss = 3.570\n",
      "Epoch   0 Batch 5144/17275   train_loss = 5.843\n",
      "Epoch   0 Batch 5145/17275   train_loss = 2.501\n",
      "Epoch   0 Batch 5146/17275   train_loss = 2.994\n",
      "Epoch   0 Batch 5147/17275   train_loss = 6.727\n",
      "Epoch   0 Batch 5148/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 5149/17275   train_loss = 7.400\n",
      "Epoch   0 Batch 5150/17275   train_loss = 5.693\n",
      "Epoch   0 Batch 5151/17275   train_loss = 1.995\n",
      "Epoch   0 Batch 5152/17275   train_loss = 3.295\n",
      "Epoch   0 Batch 5153/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 5154/17275   train_loss = 8.988\n",
      "Epoch   0 Batch 5155/17275   train_loss = 3.005\n",
      "Epoch   0 Batch 5156/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 5157/17275   train_loss = 3.848\n",
      "Epoch   0 Batch 5158/17275   train_loss = 3.621\n",
      "Epoch   0 Batch 5159/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 5160/17275   train_loss = 4.680\n",
      "Epoch   0 Batch 5161/17275   train_loss = 5.435\n",
      "Epoch   0 Batch 5162/17275   train_loss = 2.261\n",
      "Epoch   0 Batch 5163/17275   train_loss = 2.448\n",
      "Epoch   0 Batch 5164/17275   train_loss = 4.410\n",
      "Epoch   0 Batch 5165/17275   train_loss = 2.031\n",
      "Epoch   0 Batch 5166/17275   train_loss = 3.468\n",
      "Epoch   0 Batch 5167/17275   train_loss = 4.324\n",
      "Epoch   0 Batch 5168/17275   train_loss = 3.941\n",
      "Epoch   0 Batch 5169/17275   train_loss = 3.875\n",
      "Epoch   0 Batch 5170/17275   train_loss = 3.568\n",
      "Epoch   0 Batch 5171/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 5172/17275   train_loss = 2.875\n",
      "Epoch   0 Batch 5173/17275   train_loss = 5.386\n",
      "Epoch   0 Batch 5174/17275   train_loss = 2.298\n",
      "Epoch   0 Batch 5175/17275   train_loss = 2.972\n",
      "Epoch   0 Batch 5176/17275   train_loss = 3.918\n",
      "Epoch   0 Batch 5177/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 5178/17275   train_loss = 3.444\n",
      "Epoch   0 Batch 5179/17275   train_loss = 3.055\n",
      "Epoch   0 Batch 5180/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 5181/17275   train_loss = 3.130\n",
      "Epoch   0 Batch 5182/17275   train_loss = 2.647\n",
      "Epoch   0 Batch 5183/17275   train_loss = 5.086\n",
      "Epoch   0 Batch 5184/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 5185/17275   train_loss = 2.750\n",
      "Epoch   0 Batch 5186/17275   train_loss = 7.804\n",
      "Epoch   0 Batch 5187/17275   train_loss = 4.206\n",
      "Epoch   0 Batch 5188/17275   train_loss = 3.055\n",
      "Epoch   0 Batch 5189/17275   train_loss = 2.363\n",
      "Epoch   0 Batch 5190/17275   train_loss = 1.771\n",
      "Epoch   0 Batch 5191/17275   train_loss = 3.385\n",
      "Epoch   0 Batch 5192/17275   train_loss = 4.528\n",
      "Epoch   0 Batch 5193/17275   train_loss = 2.307\n",
      "Epoch   0 Batch 5194/17275   train_loss = 3.260\n",
      "Epoch   0 Batch 5195/17275   train_loss = 3.693\n",
      "Epoch   0 Batch 5196/17275   train_loss = 3.617\n",
      "Epoch   0 Batch 5197/17275   train_loss = 5.390\n",
      "Epoch   0 Batch 5198/17275   train_loss = 5.108\n",
      "Epoch   0 Batch 5199/17275   train_loss = 3.305\n",
      "Epoch   0 Batch 5200/17275   train_loss = 6.299\n",
      "Epoch   0 Batch 5201/17275   train_loss = 2.974\n",
      "Epoch   0 Batch 5202/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 5203/17275   train_loss = 4.305\n",
      "Epoch   0 Batch 5204/17275   train_loss = 6.341\n",
      "Epoch   0 Batch 5205/17275   train_loss = 3.108\n",
      "Epoch   0 Batch 5206/17275   train_loss = 3.254\n",
      "Epoch   0 Batch 5207/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 5208/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 5209/17275   train_loss = 3.638\n",
      "Epoch   0 Batch 5210/17275   train_loss = 5.857\n",
      "Epoch   0 Batch 5211/17275   train_loss = 4.118\n",
      "Epoch   0 Batch 5212/17275   train_loss = 6.289\n",
      "Epoch   0 Batch 5213/17275   train_loss = 2.137\n",
      "Epoch   0 Batch 5214/17275   train_loss = 4.606\n",
      "Epoch   0 Batch 5215/17275   train_loss = 2.956\n",
      "Epoch   0 Batch 5216/17275   train_loss = 2.064\n",
      "Epoch   0 Batch 5217/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 5218/17275   train_loss = 3.844\n",
      "Epoch   0 Batch 5219/17275   train_loss = 4.230\n",
      "Epoch   0 Batch 5220/17275   train_loss = 4.546\n",
      "Epoch   0 Batch 5221/17275   train_loss = 5.989\n",
      "Epoch   0 Batch 5222/17275   train_loss = 2.456\n",
      "Epoch   0 Batch 5223/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 5224/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 5225/17275   train_loss = 2.540\n",
      "Epoch   0 Batch 5226/17275   train_loss = 4.655\n",
      "Epoch   0 Batch 5227/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 5228/17275   train_loss = 3.552\n",
      "Epoch   0 Batch 5229/17275   train_loss = 5.926\n",
      "Epoch   0 Batch 5230/17275   train_loss = 6.802\n",
      "Epoch   0 Batch 5231/17275   train_loss = 2.238\n",
      "Epoch   0 Batch 5232/17275   train_loss = 4.248\n",
      "Epoch   0 Batch 5233/17275   train_loss = 5.640\n",
      "Epoch   0 Batch 5234/17275   train_loss = 6.364\n",
      "Epoch   0 Batch 5235/17275   train_loss = 6.552\n",
      "Epoch   0 Batch 5236/17275   train_loss = 3.487\n",
      "Epoch   0 Batch 5237/17275   train_loss = 5.546\n",
      "Epoch   0 Batch 5238/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 5239/17275   train_loss = 4.531\n",
      "Epoch   0 Batch 5240/17275   train_loss = 4.041\n",
      "Epoch   0 Batch 5241/17275   train_loss = 6.552\n",
      "Epoch   0 Batch 5242/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 5243/17275   train_loss = 2.930\n",
      "Epoch   0 Batch 5244/17275   train_loss = 3.426\n",
      "Epoch   0 Batch 5245/17275   train_loss = 5.610\n",
      "Epoch   0 Batch 5246/17275   train_loss = 6.346\n",
      "Epoch   0 Batch 5247/17275   train_loss = 2.904\n",
      "Epoch   0 Batch 5248/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 5249/17275   train_loss = 2.739\n",
      "Epoch   0 Batch 5250/17275   train_loss = 2.907\n",
      "Epoch   0 Batch 5251/17275   train_loss = 3.669\n",
      "Epoch   0 Batch 5252/17275   train_loss = 2.778\n",
      "Epoch   0 Batch 5253/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 5254/17275   train_loss = 6.640\n",
      "Epoch   0 Batch 5255/17275   train_loss = 4.454\n",
      "Epoch   0 Batch 5256/17275   train_loss = 3.110\n",
      "Epoch   0 Batch 5257/17275   train_loss = 3.958\n",
      "Epoch   0 Batch 5258/17275   train_loss = 2.859\n",
      "Epoch   0 Batch 5259/17275   train_loss = 4.184\n",
      "Epoch   0 Batch 5260/17275   train_loss = 6.951\n",
      "Epoch   0 Batch 5261/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 5262/17275   train_loss = 4.073\n",
      "Epoch   0 Batch 5263/17275   train_loss = 6.110\n",
      "Epoch   0 Batch 5264/17275   train_loss = 3.847\n",
      "Epoch   0 Batch 5265/17275   train_loss = 5.796\n",
      "Epoch   0 Batch 5266/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 5267/17275   train_loss = 3.498\n",
      "Epoch   0 Batch 5268/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 5269/17275   train_loss = 4.181\n",
      "Epoch   0 Batch 5270/17275   train_loss = 6.058\n",
      "Epoch   0 Batch 5271/17275   train_loss = 6.881\n",
      "Epoch   0 Batch 5272/17275   train_loss = 4.156\n",
      "Epoch   0 Batch 5273/17275   train_loss = 3.458\n",
      "Epoch   0 Batch 5274/17275   train_loss = 4.814\n",
      "Epoch   0 Batch 5275/17275   train_loss = 4.747\n",
      "Epoch   0 Batch 5276/17275   train_loss = 4.070\n",
      "Epoch   0 Batch 5277/17275   train_loss = 5.140\n",
      "Epoch   0 Batch 5278/17275   train_loss = 3.210\n",
      "Epoch   0 Batch 5279/17275   train_loss = 3.073\n",
      "Epoch   0 Batch 5280/17275   train_loss = 4.121\n",
      "Epoch   0 Batch 5281/17275   train_loss = 6.493\n",
      "Epoch   0 Batch 5282/17275   train_loss = 4.482\n",
      "Epoch   0 Batch 5283/17275   train_loss = 3.221\n",
      "Epoch   0 Batch 5284/17275   train_loss = 4.034\n",
      "Epoch   0 Batch 5285/17275   train_loss = 2.224\n",
      "Epoch   0 Batch 5286/17275   train_loss = 3.465\n",
      "Epoch   0 Batch 5287/17275   train_loss = 3.701\n",
      "Epoch   0 Batch 5288/17275   train_loss = 3.503\n",
      "Epoch   0 Batch 5289/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 5290/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 5291/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 5292/17275   train_loss = 2.679\n",
      "Epoch   0 Batch 5293/17275   train_loss = 3.029\n",
      "Epoch   0 Batch 5294/17275   train_loss = 2.125\n",
      "Epoch   0 Batch 5295/17275   train_loss = 2.753\n",
      "Epoch   0 Batch 5296/17275   train_loss = 2.074\n",
      "Epoch   0 Batch 5297/17275   train_loss = 3.038\n",
      "Epoch   0 Batch 5298/17275   train_loss = 2.400\n",
      "Epoch   0 Batch 5299/17275   train_loss = 1.926\n",
      "Epoch   0 Batch 5300/17275   train_loss = 5.693\n",
      "Epoch   0 Batch 5301/17275   train_loss = 5.604\n",
      "Epoch   0 Batch 5302/17275   train_loss = 2.709\n",
      "Epoch   0 Batch 5303/17275   train_loss = 3.948\n",
      "Epoch   0 Batch 5304/17275   train_loss = 3.921\n",
      "Epoch   0 Batch 5305/17275   train_loss = 5.278\n",
      "Epoch   0 Batch 5306/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 5307/17275   train_loss = 3.113\n",
      "Epoch   0 Batch 5308/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 5309/17275   train_loss = 2.691\n",
      "Epoch   0 Batch 5310/17275   train_loss = 2.302\n",
      "Epoch   0 Batch 5311/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 5312/17275   train_loss = 4.428\n",
      "Epoch   0 Batch 5313/17275   train_loss = 3.662\n",
      "Epoch   0 Batch 5314/17275   train_loss = 3.683\n",
      "Epoch   0 Batch 5315/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 5316/17275   train_loss = 1.567\n",
      "Epoch   0 Batch 5317/17275   train_loss = 2.846\n",
      "Epoch   0 Batch 5318/17275   train_loss = 6.558\n",
      "Epoch   0 Batch 5319/17275   train_loss = 2.637\n",
      "Epoch   0 Batch 5320/17275   train_loss = 2.975\n",
      "Epoch   0 Batch 5321/17275   train_loss = 3.872\n",
      "Epoch   0 Batch 5322/17275   train_loss = 4.004\n",
      "Epoch   0 Batch 5323/17275   train_loss = 3.909\n",
      "Epoch   0 Batch 5324/17275   train_loss = 3.968\n",
      "Epoch   0 Batch 5325/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 5326/17275   train_loss = 4.280\n",
      "Epoch   0 Batch 5327/17275   train_loss = 4.763\n",
      "Epoch   0 Batch 5328/17275   train_loss = 2.960\n",
      "Epoch   0 Batch 5329/17275   train_loss = 7.090\n",
      "Epoch   0 Batch 5330/17275   train_loss = 3.785\n",
      "Epoch   0 Batch 5331/17275   train_loss = 6.158\n",
      "Epoch   0 Batch 5332/17275   train_loss = 2.524\n",
      "Epoch   0 Batch 5333/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 5334/17275   train_loss = 1.845\n",
      "Epoch   0 Batch 5335/17275   train_loss = 2.027\n",
      "Epoch   0 Batch 5336/17275   train_loss = 4.460\n",
      "Epoch   0 Batch 5337/17275   train_loss = 2.782\n",
      "Epoch   0 Batch 5338/17275   train_loss = 3.736\n",
      "Epoch   0 Batch 5339/17275   train_loss = 3.997\n",
      "Epoch   0 Batch 5340/17275   train_loss = 2.566\n",
      "Epoch   0 Batch 5341/17275   train_loss = 3.894\n",
      "Epoch   0 Batch 5342/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 5343/17275   train_loss = 3.612\n",
      "Epoch   0 Batch 5344/17275   train_loss = 1.958\n",
      "Epoch   0 Batch 5345/17275   train_loss = 3.014\n",
      "Epoch   0 Batch 5346/17275   train_loss = 2.804\n",
      "Epoch   0 Batch 5347/17275   train_loss = 3.380\n",
      "Epoch   0 Batch 5348/17275   train_loss = 4.730\n",
      "Epoch   0 Batch 5349/17275   train_loss = 1.871\n",
      "Epoch   0 Batch 5350/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 5351/17275   train_loss = 5.865\n",
      "Epoch   0 Batch 5352/17275   train_loss = 3.287\n",
      "Epoch   0 Batch 5353/17275   train_loss = 5.889\n",
      "Epoch   0 Batch 5354/17275   train_loss = 3.356\n",
      "Epoch   0 Batch 5355/17275   train_loss = 3.816\n",
      "Epoch   0 Batch 5356/17275   train_loss = 5.968\n",
      "Epoch   0 Batch 5357/17275   train_loss = 2.509\n",
      "Epoch   0 Batch 5358/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 5359/17275   train_loss = 7.003\n",
      "Epoch   0 Batch 5360/17275   train_loss = 3.666\n",
      "Epoch   0 Batch 5361/17275   train_loss = 2.233\n",
      "Epoch   0 Batch 5362/17275   train_loss = 3.803\n",
      "Epoch   0 Batch 5363/17275   train_loss = 3.800\n",
      "Epoch   0 Batch 5364/17275   train_loss = 4.581\n",
      "Epoch   0 Batch 5365/17275   train_loss = 2.366\n",
      "Epoch   0 Batch 5366/17275   train_loss = 5.542\n",
      "Epoch   0 Batch 5367/17275   train_loss = 7.401\n",
      "Epoch   0 Batch 5368/17275   train_loss = 2.188\n",
      "Epoch   0 Batch 5369/17275   train_loss = 2.623\n",
      "Epoch   0 Batch 5370/17275   train_loss = 4.425\n",
      "Epoch   0 Batch 5371/17275   train_loss = 5.724\n",
      "Epoch   0 Batch 5372/17275   train_loss = 5.854\n",
      "Epoch   0 Batch 5373/17275   train_loss = 2.037\n",
      "Epoch   0 Batch 5374/17275   train_loss = 2.455\n",
      "Epoch   0 Batch 5375/17275   train_loss = 3.550\n",
      "Epoch   0 Batch 5376/17275   train_loss = 3.402\n",
      "Epoch   0 Batch 5377/17275   train_loss = 5.671\n",
      "Epoch   0 Batch 5378/17275   train_loss = 4.637\n",
      "Epoch   0 Batch 5379/17275   train_loss = 5.928\n",
      "Epoch   0 Batch 5380/17275   train_loss = 4.282\n",
      "Epoch   0 Batch 5381/17275   train_loss = 4.470\n",
      "Epoch   0 Batch 5382/17275   train_loss = 4.523\n",
      "Epoch   0 Batch 5383/17275   train_loss = 4.579\n",
      "Epoch   0 Batch 5384/17275   train_loss = 6.277\n",
      "Epoch   0 Batch 5385/17275   train_loss = 6.851\n",
      "Epoch   0 Batch 5386/17275   train_loss = 2.188\n",
      "Epoch   0 Batch 5387/17275   train_loss = 2.730\n",
      "Epoch   0 Batch 5388/17275   train_loss = 3.630\n",
      "Epoch   0 Batch 5389/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 5390/17275   train_loss = 3.008\n",
      "Epoch   0 Batch 5391/17275   train_loss = 4.073\n",
      "Epoch   0 Batch 5392/17275   train_loss = 3.485\n",
      "Epoch   0 Batch 5393/17275   train_loss = 3.777\n",
      "Epoch   0 Batch 5394/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 5395/17275   train_loss = 2.277\n",
      "Epoch   0 Batch 5396/17275   train_loss = 5.676\n",
      "Epoch   0 Batch 5397/17275   train_loss = 4.317\n",
      "Epoch   0 Batch 5398/17275   train_loss = 6.081\n",
      "Epoch   0 Batch 5399/17275   train_loss = 6.466\n",
      "Epoch   0 Batch 5400/17275   train_loss = 4.146\n",
      "Epoch   0 Batch 5401/17275   train_loss = 2.240\n",
      "Epoch   0 Batch 5402/17275   train_loss = 3.581\n",
      "Epoch   0 Batch 5403/17275   train_loss = 2.450\n",
      "Epoch   0 Batch 5404/17275   train_loss = 6.367\n",
      "Epoch   0 Batch 5405/17275   train_loss = 2.223\n",
      "Epoch   0 Batch 5406/17275   train_loss = 5.674\n",
      "Epoch   0 Batch 5407/17275   train_loss = 6.848\n",
      "Epoch   0 Batch 5408/17275   train_loss = 2.128\n",
      "Epoch   0 Batch 5409/17275   train_loss = 3.871\n",
      "Epoch   0 Batch 5410/17275   train_loss = 2.840\n",
      "Epoch   0 Batch 5411/17275   train_loss = 3.031\n",
      "Epoch   0 Batch 5412/17275   train_loss = 2.981\n",
      "Epoch   0 Batch 5413/17275   train_loss = 2.878\n",
      "Epoch   0 Batch 5414/17275   train_loss = 1.999\n",
      "Epoch   0 Batch 5415/17275   train_loss = 2.460\n",
      "Epoch   0 Batch 5416/17275   train_loss = 4.011\n",
      "Epoch   0 Batch 5417/17275   train_loss = 2.950\n",
      "Epoch   0 Batch 5418/17275   train_loss = 6.026\n",
      "Epoch   0 Batch 5419/17275   train_loss = 9.164\n",
      "Epoch   0 Batch 5420/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 5421/17275   train_loss = 3.341\n",
      "Epoch   0 Batch 5422/17275   train_loss = 6.170\n",
      "Epoch   0 Batch 5423/17275   train_loss = 8.520\n",
      "Epoch   0 Batch 5424/17275   train_loss = 2.723\n",
      "Epoch   0 Batch 5425/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 5426/17275   train_loss = 2.808\n",
      "Epoch   0 Batch 5427/17275   train_loss = 6.047\n",
      "Epoch   0 Batch 5428/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 5429/17275   train_loss = 4.483\n",
      "Epoch   0 Batch 5430/17275   train_loss = 3.261\n",
      "Epoch   0 Batch 5431/17275   train_loss = 2.417\n",
      "Epoch   0 Batch 5432/17275   train_loss = 5.693\n",
      "Epoch   0 Batch 5433/17275   train_loss = 2.816\n",
      "Epoch   0 Batch 5434/17275   train_loss = 2.699\n",
      "Epoch   0 Batch 5435/17275   train_loss = 6.968\n",
      "Epoch   0 Batch 5436/17275   train_loss = 1.972\n",
      "Epoch   0 Batch 5437/17275   train_loss = 5.681\n",
      "Epoch   0 Batch 5438/17275   train_loss = 3.190\n",
      "Epoch   0 Batch 5439/17275   train_loss = 3.464\n",
      "Epoch   0 Batch 5440/17275   train_loss = 5.453\n",
      "Epoch   0 Batch 5441/17275   train_loss = 5.541\n",
      "Epoch   0 Batch 5442/17275   train_loss = 5.455\n",
      "Epoch   0 Batch 5443/17275   train_loss = 6.079\n",
      "Epoch   0 Batch 5444/17275   train_loss = 3.936\n",
      "Epoch   0 Batch 5445/17275   train_loss = 6.501\n",
      "Epoch   0 Batch 5446/17275   train_loss = 7.092\n",
      "Epoch   0 Batch 5447/17275   train_loss = 2.915\n",
      "Epoch   0 Batch 5448/17275   train_loss = 2.373\n",
      "Epoch   0 Batch 5449/17275   train_loss = 5.666\n",
      "Epoch   0 Batch 5450/17275   train_loss = 2.804\n",
      "Epoch   0 Batch 5451/17275   train_loss = 4.615\n",
      "Epoch   0 Batch 5452/17275   train_loss = 6.445\n",
      "Epoch   0 Batch 5453/17275   train_loss = 7.527\n",
      "Epoch   0 Batch 5454/17275   train_loss = 2.810\n",
      "Epoch   0 Batch 5455/17275   train_loss = 4.492\n",
      "Epoch   0 Batch 5456/17275   train_loss = 1.936\n",
      "Epoch   0 Batch 5457/17275   train_loss = 4.944\n",
      "Epoch   0 Batch 5458/17275   train_loss = 5.649\n",
      "Epoch   0 Batch 5459/17275   train_loss = 3.839\n",
      "Epoch   0 Batch 5460/17275   train_loss = 1.921\n",
      "Epoch   0 Batch 5461/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 5462/17275   train_loss = 6.096\n",
      "Epoch   0 Batch 5463/17275   train_loss = 4.361\n",
      "Epoch   0 Batch 5464/17275   train_loss = 5.923\n",
      "Epoch   0 Batch 5465/17275   train_loss = 4.139\n",
      "Epoch   0 Batch 5466/17275   train_loss = 3.425\n",
      "Epoch   0 Batch 5467/17275   train_loss = 2.942\n",
      "Epoch   0 Batch 5468/17275   train_loss = 3.090\n",
      "Epoch   0 Batch 5469/17275   train_loss = 2.908\n",
      "Epoch   0 Batch 5470/17275   train_loss = 2.376\n",
      "Epoch   0 Batch 5471/17275   train_loss = 5.496\n",
      "Epoch   0 Batch 5472/17275   train_loss = 3.581\n",
      "Epoch   0 Batch 5473/17275   train_loss = 7.338\n",
      "Epoch   0 Batch 5474/17275   train_loss = 4.216\n",
      "Epoch   0 Batch 5475/17275   train_loss = 5.736\n",
      "Epoch   0 Batch 5476/17275   train_loss = 2.238\n",
      "Epoch   0 Batch 5477/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 5478/17275   train_loss = 2.961\n",
      "Epoch   0 Batch 5479/17275   train_loss = 6.085\n",
      "Epoch   0 Batch 5480/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 5481/17275   train_loss = 4.704\n",
      "Epoch   0 Batch 5482/17275   train_loss = 2.507\n",
      "Epoch   0 Batch 5483/17275   train_loss = 5.745\n",
      "Epoch   0 Batch 5484/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 5485/17275   train_loss = 2.525\n",
      "Epoch   0 Batch 5486/17275   train_loss = 6.767\n",
      "Epoch   0 Batch 5487/17275   train_loss = 6.129\n",
      "Epoch   0 Batch 5488/17275   train_loss = 3.546\n",
      "Epoch   0 Batch 5489/17275   train_loss = 2.768\n",
      "Epoch   0 Batch 5490/17275   train_loss = 2.101\n",
      "Epoch   0 Batch 5491/17275   train_loss = 2.247\n",
      "Epoch   0 Batch 5492/17275   train_loss = 3.970\n",
      "Epoch   0 Batch 5493/17275   train_loss = 4.338\n",
      "Epoch   0 Batch 5494/17275   train_loss = 6.315\n",
      "Epoch   0 Batch 5495/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 5496/17275   train_loss = 6.611\n",
      "Epoch   0 Batch 5497/17275   train_loss = 3.273\n",
      "Epoch   0 Batch 5498/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 5499/17275   train_loss = 4.514\n",
      "Epoch   0 Batch 5500/17275   train_loss = 6.257\n",
      "Epoch   0 Batch 5501/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 5502/17275   train_loss = 2.800\n",
      "Epoch   0 Batch 5503/17275   train_loss = 4.153\n",
      "Epoch   0 Batch 5504/17275   train_loss = 7.110\n",
      "Epoch   0 Batch 5505/17275   train_loss = 6.075\n",
      "Epoch   0 Batch 5506/17275   train_loss = 6.031\n",
      "Epoch   0 Batch 5507/17275   train_loss = 5.636\n",
      "Epoch   0 Batch 5508/17275   train_loss = 2.692\n",
      "Epoch   0 Batch 5509/17275   train_loss = 2.885\n",
      "Epoch   0 Batch 5510/17275   train_loss = 4.236\n",
      "Epoch   0 Batch 5511/17275   train_loss = 6.386\n",
      "Epoch   0 Batch 5512/17275   train_loss = 5.611\n",
      "Epoch   0 Batch 5513/17275   train_loss = 2.221\n",
      "Epoch   0 Batch 5514/17275   train_loss = 3.098\n",
      "Epoch   0 Batch 5515/17275   train_loss = 5.160\n",
      "Epoch   0 Batch 5516/17275   train_loss = 2.740\n",
      "Epoch   0 Batch 5517/17275   train_loss = 4.727\n",
      "Epoch   0 Batch 5518/17275   train_loss = 1.986\n",
      "Epoch   0 Batch 5519/17275   train_loss = 5.538\n",
      "Epoch   0 Batch 5520/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 5521/17275   train_loss = 6.122\n",
      "Epoch   0 Batch 5522/17275   train_loss = 3.226\n",
      "Epoch   0 Batch 5523/17275   train_loss = 6.241\n",
      "Epoch   0 Batch 5524/17275   train_loss = 5.067\n",
      "Epoch   0 Batch 5525/17275   train_loss = 2.240\n",
      "Epoch   0 Batch 5526/17275   train_loss = 6.311\n",
      "Epoch   0 Batch 5527/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 5528/17275   train_loss = 4.416\n",
      "Epoch   0 Batch 5529/17275   train_loss = 4.916\n",
      "Epoch   0 Batch 5530/17275   train_loss = 3.280\n",
      "Epoch   0 Batch 5531/17275   train_loss = 5.858\n",
      "Epoch   0 Batch 5532/17275   train_loss = 5.950\n",
      "Epoch   0 Batch 5533/17275   train_loss = 7.069\n",
      "Epoch   0 Batch 5534/17275   train_loss = 2.291\n",
      "Epoch   0 Batch 5535/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 5536/17275   train_loss = 5.984\n",
      "Epoch   0 Batch 5537/17275   train_loss = 2.666\n",
      "Epoch   0 Batch 5538/17275   train_loss = 3.670\n",
      "Epoch   0 Batch 5539/17275   train_loss = 6.308\n",
      "Epoch   0 Batch 5540/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 5541/17275   train_loss = 4.574\n",
      "Epoch   0 Batch 5542/17275   train_loss = 4.503\n",
      "Epoch   0 Batch 5543/17275   train_loss = 6.285\n",
      "Epoch   0 Batch 5544/17275   train_loss = 6.042\n",
      "Epoch   0 Batch 5545/17275   train_loss = 2.131\n",
      "Epoch   0 Batch 5546/17275   train_loss = 6.263\n",
      "Epoch   0 Batch 5547/17275   train_loss = 5.715\n",
      "Epoch   0 Batch 5548/17275   train_loss = 6.567\n",
      "Epoch   0 Batch 5549/17275   train_loss = 3.570\n",
      "Epoch   0 Batch 5550/17275   train_loss = 3.552\n",
      "Epoch   0 Batch 5551/17275   train_loss = 5.038\n",
      "Epoch   0 Batch 5552/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 5553/17275   train_loss = 2.360\n",
      "Epoch   0 Batch 5554/17275   train_loss = 6.782\n",
      "Epoch   0 Batch 5555/17275   train_loss = 3.704\n",
      "Epoch   0 Batch 5556/17275   train_loss = 3.299\n",
      "Epoch   0 Batch 5557/17275   train_loss = 4.163\n",
      "Epoch   0 Batch 5558/17275   train_loss = 3.881\n",
      "Epoch   0 Batch 5559/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 5560/17275   train_loss = 3.090\n",
      "Epoch   0 Batch 5561/17275   train_loss = 3.161\n",
      "Epoch   0 Batch 5562/17275   train_loss = 3.575\n",
      "Epoch   0 Batch 5563/17275   train_loss = 7.529\n",
      "Epoch   0 Batch 5564/17275   train_loss = 2.174\n",
      "Epoch   0 Batch 5565/17275   train_loss = 5.885\n",
      "Epoch   0 Batch 5566/17275   train_loss = 3.134\n",
      "Epoch   0 Batch 5567/17275   train_loss = 2.686\n",
      "Epoch   0 Batch 5568/17275   train_loss = 5.033\n",
      "Epoch   0 Batch 5569/17275   train_loss = 3.136\n",
      "Epoch   0 Batch 5570/17275   train_loss = 6.282\n",
      "Epoch   0 Batch 5571/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 5572/17275   train_loss = 7.913\n",
      "Epoch   0 Batch 5573/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 5574/17275   train_loss = 3.402\n",
      "Epoch   0 Batch 5575/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 5576/17275   train_loss = 5.948\n",
      "Epoch   0 Batch 5577/17275   train_loss = 6.139\n",
      "Epoch   0 Batch 5578/17275   train_loss = 4.870\n",
      "Epoch   0 Batch 5579/17275   train_loss = 6.392\n",
      "Epoch   0 Batch 5580/17275   train_loss = 2.227\n",
      "Epoch   0 Batch 5581/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 5582/17275   train_loss = 5.921\n",
      "Epoch   0 Batch 5583/17275   train_loss = 5.106\n",
      "Epoch   0 Batch 5584/17275   train_loss = 2.519\n",
      "Epoch   0 Batch 5585/17275   train_loss = 4.042\n",
      "Epoch   0 Batch 5586/17275   train_loss = 3.291\n",
      "Epoch   0 Batch 5587/17275   train_loss = 8.302\n",
      "Epoch   0 Batch 5588/17275   train_loss = 2.936\n",
      "Epoch   0 Batch 5589/17275   train_loss = 3.522\n",
      "Epoch   0 Batch 5590/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 5591/17275   train_loss = 4.685\n",
      "Epoch   0 Batch 5592/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 5593/17275   train_loss = 3.439\n",
      "Epoch   0 Batch 5594/17275   train_loss = 3.849\n",
      "Epoch   0 Batch 5595/17275   train_loss = 5.642\n",
      "Epoch   0 Batch 5596/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 5597/17275   train_loss = 4.143\n",
      "Epoch   0 Batch 5598/17275   train_loss = 3.183\n",
      "Epoch   0 Batch 5599/17275   train_loss = 4.009\n",
      "Epoch   0 Batch 5600/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 5601/17275   train_loss = 5.914\n",
      "Epoch   0 Batch 5602/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 5603/17275   train_loss = 2.411\n",
      "Epoch   0 Batch 5604/17275   train_loss = 6.625\n",
      "Epoch   0 Batch 5605/17275   train_loss = 4.415\n",
      "Epoch   0 Batch 5606/17275   train_loss = 4.943\n",
      "Epoch   0 Batch 5607/17275   train_loss = 4.798\n",
      "Epoch   0 Batch 5608/17275   train_loss = 3.571\n",
      "Epoch   0 Batch 5609/17275   train_loss = 2.701\n",
      "Epoch   0 Batch 5610/17275   train_loss = 3.560\n",
      "Epoch   0 Batch 5611/17275   train_loss = 2.982\n",
      "Epoch   0 Batch 5612/17275   train_loss = 3.860\n",
      "Epoch   0 Batch 5613/17275   train_loss = 4.709\n",
      "Epoch   0 Batch 5614/17275   train_loss = 6.869\n",
      "Epoch   0 Batch 5615/17275   train_loss = 4.018\n",
      "Epoch   0 Batch 5616/17275   train_loss = 3.322\n",
      "Epoch   0 Batch 5617/17275   train_loss = 4.211\n",
      "Epoch   0 Batch 5618/17275   train_loss = 2.675\n",
      "Epoch   0 Batch 5619/17275   train_loss = 5.808\n",
      "Epoch   0 Batch 5620/17275   train_loss = 2.743\n",
      "Epoch   0 Batch 5621/17275   train_loss = 3.507\n",
      "Epoch   0 Batch 5622/17275   train_loss = 2.530\n",
      "Epoch   0 Batch 5623/17275   train_loss = 3.091\n",
      "Epoch   0 Batch 5624/17275   train_loss = 3.346\n",
      "Epoch   0 Batch 5625/17275   train_loss = 3.362\n",
      "Epoch   0 Batch 5626/17275   train_loss = 3.345\n",
      "Epoch   0 Batch 5627/17275   train_loss = 2.681\n",
      "Epoch   0 Batch 5628/17275   train_loss = 3.443\n",
      "Epoch   0 Batch 5629/17275   train_loss = 4.074\n",
      "Epoch   0 Batch 5630/17275   train_loss = 5.656\n",
      "Epoch   0 Batch 5631/17275   train_loss = 4.782\n",
      "Epoch   0 Batch 5632/17275   train_loss = 6.163\n",
      "Epoch   0 Batch 5633/17275   train_loss = 6.146\n",
      "Epoch   0 Batch 5634/17275   train_loss = 6.378\n",
      "Epoch   0 Batch 5635/17275   train_loss = 3.441\n",
      "Epoch   0 Batch 5636/17275   train_loss = 4.131\n",
      "Epoch   0 Batch 5637/17275   train_loss = 5.741\n",
      "Epoch   0 Batch 5638/17275   train_loss = 2.595\n",
      "Epoch   0 Batch 5639/17275   train_loss = 3.663\n",
      "Epoch   0 Batch 5640/17275   train_loss = 6.202\n",
      "Epoch   0 Batch 5641/17275   train_loss = 5.804\n",
      "Epoch   0 Batch 5642/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 5643/17275   train_loss = 3.553\n",
      "Epoch   0 Batch 5644/17275   train_loss = 5.766\n",
      "Epoch   0 Batch 5645/17275   train_loss = 2.494\n",
      "Epoch   0 Batch 5646/17275   train_loss = 2.987\n",
      "Epoch   0 Batch 5647/17275   train_loss = 3.538\n",
      "Epoch   0 Batch 5648/17275   train_loss = 4.224\n",
      "Epoch   0 Batch 5649/17275   train_loss = 3.315\n",
      "Epoch   0 Batch 5650/17275   train_loss = 2.393\n",
      "Epoch   0 Batch 5651/17275   train_loss = 2.964\n",
      "Epoch   0 Batch 5652/17275   train_loss = 4.337\n",
      "Epoch   0 Batch 5653/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 5654/17275   train_loss = 3.722\n",
      "Epoch   0 Batch 5655/17275   train_loss = 4.374\n",
      "Epoch   0 Batch 5656/17275   train_loss = 7.010\n",
      "Epoch   0 Batch 5657/17275   train_loss = 3.511\n",
      "Epoch   0 Batch 5658/17275   train_loss = 6.212\n",
      "Epoch   0 Batch 5659/17275   train_loss = 2.473\n",
      "Epoch   0 Batch 5660/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 5661/17275   train_loss = 2.285\n",
      "Epoch   0 Batch 5662/17275   train_loss = 2.574\n",
      "Epoch   0 Batch 5663/17275   train_loss = 3.017\n",
      "Epoch   0 Batch 5664/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 5665/17275   train_loss = 4.243\n",
      "Epoch   0 Batch 5666/17275   train_loss = 4.496\n",
      "Epoch   0 Batch 5667/17275   train_loss = 3.575\n",
      "Epoch   0 Batch 5668/17275   train_loss = 5.995\n",
      "Epoch   0 Batch 5669/17275   train_loss = 5.901\n",
      "Epoch   0 Batch 5670/17275   train_loss = 2.200\n",
      "Epoch   0 Batch 5671/17275   train_loss = 3.375\n",
      "Epoch   0 Batch 5672/17275   train_loss = 2.178\n",
      "Epoch   0 Batch 5673/17275   train_loss = 3.333\n",
      "Epoch   0 Batch 5674/17275   train_loss = 5.965\n",
      "Epoch   0 Batch 5675/17275   train_loss = 3.288\n",
      "Epoch   0 Batch 5676/17275   train_loss = 2.734\n",
      "Epoch   0 Batch 5677/17275   train_loss = 2.828\n",
      "Epoch   0 Batch 5678/17275   train_loss = 3.149\n",
      "Epoch   0 Batch 5679/17275   train_loss = 3.974\n",
      "Epoch   0 Batch 5680/17275   train_loss = 5.908\n",
      "Epoch   0 Batch 5681/17275   train_loss = 7.078\n",
      "Epoch   0 Batch 5682/17275   train_loss = 2.224\n",
      "Epoch   0 Batch 5683/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 5684/17275   train_loss = 2.437\n",
      "Epoch   0 Batch 5685/17275   train_loss = 2.149\n",
      "Epoch   0 Batch 5686/17275   train_loss = 3.945\n",
      "Epoch   0 Batch 5687/17275   train_loss = 2.838\n",
      "Epoch   0 Batch 5688/17275   train_loss = 2.128\n",
      "Epoch   0 Batch 5689/17275   train_loss = 5.759\n",
      "Epoch   0 Batch 5690/17275   train_loss = 3.746\n",
      "Epoch   0 Batch 5691/17275   train_loss = 2.116\n",
      "Epoch   0 Batch 5692/17275   train_loss = 3.411\n",
      "Epoch   0 Batch 5693/17275   train_loss = 2.866\n",
      "Epoch   0 Batch 5694/17275   train_loss = 3.922\n",
      "Epoch   0 Batch 5695/17275   train_loss = 6.637\n",
      "Epoch   0 Batch 5696/17275   train_loss = 5.386\n",
      "Epoch   0 Batch 5697/17275   train_loss = 4.191\n",
      "Epoch   0 Batch 5698/17275   train_loss = 6.074\n",
      "Epoch   0 Batch 5699/17275   train_loss = 3.395\n",
      "Epoch   0 Batch 5700/17275   train_loss = 9.252\n",
      "Epoch   0 Batch 5701/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 5702/17275   train_loss = 5.978\n",
      "Epoch   0 Batch 5703/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 5704/17275   train_loss = 4.272\n",
      "Epoch   0 Batch 5705/17275   train_loss = 5.955\n",
      "Epoch   0 Batch 5706/17275   train_loss = 2.651\n",
      "Epoch   0 Batch 5707/17275   train_loss = 2.130\n",
      "Epoch   0 Batch 5708/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 5709/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 5710/17275   train_loss = 3.959\n",
      "Epoch   0 Batch 5711/17275   train_loss = 4.354\n",
      "Epoch   0 Batch 5712/17275   train_loss = 1.959\n",
      "Epoch   0 Batch 5713/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 5714/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 5715/17275   train_loss = 3.231\n",
      "Epoch   0 Batch 5716/17275   train_loss = 5.984\n",
      "Epoch   0 Batch 5717/17275   train_loss = 6.682\n",
      "Epoch   0 Batch 5718/17275   train_loss = 3.906\n",
      "Epoch   0 Batch 5719/17275   train_loss = 6.007\n",
      "Epoch   0 Batch 5720/17275   train_loss = 4.297\n",
      "Epoch   0 Batch 5721/17275   train_loss = 5.619\n",
      "Epoch   0 Batch 5722/17275   train_loss = 5.926\n",
      "Epoch   0 Batch 5723/17275   train_loss = 3.922\n",
      "Epoch   0 Batch 5724/17275   train_loss = 6.763\n",
      "Epoch   0 Batch 5725/17275   train_loss = 2.193\n",
      "Epoch   0 Batch 5726/17275   train_loss = 2.590\n",
      "Epoch   0 Batch 5727/17275   train_loss = 3.756\n",
      "Epoch   0 Batch 5728/17275   train_loss = 3.330\n",
      "Epoch   0 Batch 5729/17275   train_loss = 6.704\n",
      "Epoch   0 Batch 5730/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 5731/17275   train_loss = 2.408\n",
      "Epoch   0 Batch 5732/17275   train_loss = 5.816\n",
      "Epoch   0 Batch 5733/17275   train_loss = 2.974\n",
      "Epoch   0 Batch 5734/17275   train_loss = 3.963\n",
      "Epoch   0 Batch 5735/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 5736/17275   train_loss = 5.737\n",
      "Epoch   0 Batch 5737/17275   train_loss = 4.411\n",
      "Epoch   0 Batch 5738/17275   train_loss = 3.087\n",
      "Epoch   0 Batch 5739/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 5740/17275   train_loss = 3.395\n",
      "Epoch   0 Batch 5741/17275   train_loss = 5.702\n",
      "Epoch   0 Batch 5742/17275   train_loss = 3.593\n",
      "Epoch   0 Batch 5743/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 5744/17275   train_loss = 5.682\n",
      "Epoch   0 Batch 5745/17275   train_loss = 2.735\n",
      "Epoch   0 Batch 5746/17275   train_loss = 5.653\n",
      "Epoch   0 Batch 5747/17275   train_loss = 2.497\n",
      "Epoch   0 Batch 5748/17275   train_loss = 3.017\n",
      "Epoch   0 Batch 5749/17275   train_loss = 2.014\n",
      "Epoch   0 Batch 5750/17275   train_loss = 2.835\n",
      "Epoch   0 Batch 5751/17275   train_loss = 5.253\n",
      "Epoch   0 Batch 5752/17275   train_loss = 3.483\n",
      "Epoch   0 Batch 5753/17275   train_loss = 3.467\n",
      "Epoch   0 Batch 5754/17275   train_loss = 3.352\n",
      "Epoch   0 Batch 5755/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 5756/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 5757/17275   train_loss = 3.869\n",
      "Epoch   0 Batch 5758/17275   train_loss = 3.765\n",
      "Epoch   0 Batch 5759/17275   train_loss = 5.721\n",
      "Epoch   0 Batch 5760/17275   train_loss = 4.067\n",
      "Epoch   0 Batch 5761/17275   train_loss = 2.821\n",
      "Epoch   0 Batch 5762/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 5763/17275   train_loss = 6.054\n",
      "Epoch   0 Batch 5764/17275   train_loss = 6.388\n",
      "Epoch   0 Batch 5765/17275   train_loss = 3.142\n",
      "Epoch   0 Batch 5766/17275   train_loss = 2.390\n",
      "Epoch   0 Batch 5767/17275   train_loss = 3.500\n",
      "Epoch   0 Batch 5768/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 5769/17275   train_loss = 6.639\n",
      "Epoch   0 Batch 5770/17275   train_loss = 3.980\n",
      "Epoch   0 Batch 5771/17275   train_loss = 4.052\n",
      "Epoch   0 Batch 5772/17275   train_loss = 3.250\n",
      "Epoch   0 Batch 5773/17275   train_loss = 7.548\n",
      "Epoch   0 Batch 5774/17275   train_loss = 4.654\n",
      "Epoch   0 Batch 5775/17275   train_loss = 3.349\n",
      "Epoch   0 Batch 5776/17275   train_loss = 5.579\n",
      "Epoch   0 Batch 5777/17275   train_loss = 6.073\n",
      "Epoch   0 Batch 5778/17275   train_loss = 6.423\n",
      "Epoch   0 Batch 5779/17275   train_loss = 6.364\n",
      "Epoch   0 Batch 5780/17275   train_loss = 3.847\n",
      "Epoch   0 Batch 5781/17275   train_loss = 3.780\n",
      "Epoch   0 Batch 5782/17275   train_loss = 3.981\n",
      "Epoch   0 Batch 5783/17275   train_loss = 4.087\n",
      "Epoch   0 Batch 5784/17275   train_loss = 3.297\n",
      "Epoch   0 Batch 5785/17275   train_loss = 2.136\n",
      "Epoch   0 Batch 5786/17275   train_loss = 2.829\n",
      "Epoch   0 Batch 5787/17275   train_loss = 3.131\n",
      "Epoch   0 Batch 5788/17275   train_loss = 3.436\n",
      "Epoch   0 Batch 5789/17275   train_loss = 5.635\n",
      "Epoch   0 Batch 5790/17275   train_loss = 3.786\n",
      "Epoch   0 Batch 5791/17275   train_loss = 3.101\n",
      "Epoch   0 Batch 5792/17275   train_loss = 4.792\n",
      "Epoch   0 Batch 5793/17275   train_loss = 4.527\n",
      "Epoch   0 Batch 5794/17275   train_loss = 4.350\n",
      "Epoch   0 Batch 5795/17275   train_loss = 3.036\n",
      "Epoch   0 Batch 5796/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 5797/17275   train_loss = 5.923\n",
      "Epoch   0 Batch 5798/17275   train_loss = 3.372\n",
      "Epoch   0 Batch 5799/17275   train_loss = 3.908\n",
      "Epoch   0 Batch 5800/17275   train_loss = 2.887\n",
      "Epoch   0 Batch 5801/17275   train_loss = 4.290\n",
      "Epoch   0 Batch 5802/17275   train_loss = 2.186\n",
      "Epoch   0 Batch 5803/17275   train_loss = 3.722\n",
      "Epoch   0 Batch 5804/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 5805/17275   train_loss = 2.458\n",
      "Epoch   0 Batch 5806/17275   train_loss = 5.844\n",
      "Epoch   0 Batch 5807/17275   train_loss = 6.660\n",
      "Epoch   0 Batch 5808/17275   train_loss = 4.169\n",
      "Epoch   0 Batch 5809/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 5810/17275   train_loss = 6.047\n",
      "Epoch   0 Batch 5811/17275   train_loss = 2.576\n",
      "Epoch   0 Batch 5812/17275   train_loss = 3.937\n",
      "Epoch   0 Batch 5813/17275   train_loss = 5.631\n",
      "Epoch   0 Batch 5814/17275   train_loss = 3.196\n",
      "Epoch   0 Batch 5815/17275   train_loss = 3.039\n",
      "Epoch   0 Batch 5816/17275   train_loss = 6.262\n",
      "Epoch   0 Batch 5817/17275   train_loss = 2.007\n",
      "Epoch   0 Batch 5818/17275   train_loss = 2.116\n",
      "Epoch   0 Batch 5819/17275   train_loss = 2.793\n",
      "Epoch   0 Batch 5820/17275   train_loss = 5.990\n",
      "Epoch   0 Batch 5821/17275   train_loss = 6.078\n",
      "Epoch   0 Batch 5822/17275   train_loss = 6.846\n",
      "Epoch   0 Batch 5823/17275   train_loss = 2.048\n",
      "Epoch   0 Batch 5824/17275   train_loss = 3.831\n",
      "Epoch   0 Batch 5825/17275   train_loss = 5.679\n",
      "Epoch   0 Batch 5826/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 5827/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 5828/17275   train_loss = 4.193\n",
      "Epoch   0 Batch 5829/17275   train_loss = 3.581\n",
      "Epoch   0 Batch 5830/17275   train_loss = 9.235\n",
      "Epoch   0 Batch 5831/17275   train_loss = 6.085\n",
      "Epoch   0 Batch 5832/17275   train_loss = 2.423\n",
      "Epoch   0 Batch 5833/17275   train_loss = 3.078\n",
      "Epoch   0 Batch 5834/17275   train_loss = 6.645\n",
      "Epoch   0 Batch 5835/17275   train_loss = 3.336\n",
      "Epoch   0 Batch 5836/17275   train_loss = 7.522\n",
      "Epoch   0 Batch 5837/17275   train_loss = 5.482\n",
      "Epoch   0 Batch 5838/17275   train_loss = 2.374\n",
      "Epoch   0 Batch 5839/17275   train_loss = 6.908\n",
      "Epoch   0 Batch 5840/17275   train_loss = 4.347\n",
      "Epoch   0 Batch 5841/17275   train_loss = 3.745\n",
      "Epoch   0 Batch 5842/17275   train_loss = 5.713\n",
      "Epoch   0 Batch 5843/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 5844/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 5845/17275   train_loss = 3.409\n",
      "Epoch   0 Batch 5846/17275   train_loss = 2.928\n",
      "Epoch   0 Batch 5847/17275   train_loss = 2.628\n",
      "Epoch   0 Batch 5848/17275   train_loss = 5.494\n",
      "Epoch   0 Batch 5849/17275   train_loss = 3.660\n",
      "Epoch   0 Batch 5850/17275   train_loss = 6.829\n",
      "Epoch   0 Batch 5851/17275   train_loss = 6.018\n",
      "Epoch   0 Batch 5852/17275   train_loss = 5.492\n",
      "Epoch   0 Batch 5853/17275   train_loss = 3.522\n",
      "Epoch   0 Batch 5854/17275   train_loss = 5.844\n",
      "Epoch   0 Batch 5855/17275   train_loss = 9.223\n",
      "Epoch   0 Batch 5856/17275   train_loss = 2.271\n",
      "Epoch   0 Batch 5857/17275   train_loss = 5.701\n",
      "Epoch   0 Batch 5858/17275   train_loss = 4.020\n",
      "Epoch   0 Batch 5859/17275   train_loss = 5.803\n",
      "Epoch   0 Batch 5860/17275   train_loss = 5.811\n",
      "Epoch   0 Batch 5861/17275   train_loss = 1.947\n",
      "Epoch   0 Batch 5862/17275   train_loss = 3.091\n",
      "Epoch   0 Batch 5863/17275   train_loss = 2.508\n",
      "Epoch   0 Batch 5864/17275   train_loss = 3.599\n",
      "Epoch   0 Batch 5865/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 5866/17275   train_loss = 4.472\n",
      "Epoch   0 Batch 5867/17275   train_loss = 5.504\n",
      "Epoch   0 Batch 5868/17275   train_loss = 4.223\n",
      "Epoch   0 Batch 5869/17275   train_loss = 3.414\n",
      "Epoch   0 Batch 5870/17275   train_loss = 4.427\n",
      "Epoch   0 Batch 5871/17275   train_loss = 4.643\n",
      "Epoch   0 Batch 5872/17275   train_loss = 3.206\n",
      "Epoch   0 Batch 5873/17275   train_loss = 1.990\n",
      "Epoch   0 Batch 5874/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 5875/17275   train_loss = 6.103\n",
      "Epoch   0 Batch 5876/17275   train_loss = 4.519\n",
      "Epoch   0 Batch 5877/17275   train_loss = 3.728\n",
      "Epoch   0 Batch 5878/17275   train_loss = 2.757\n",
      "Epoch   0 Batch 5879/17275   train_loss = 1.813\n",
      "Epoch   0 Batch 5880/17275   train_loss = 3.806\n",
      "Epoch   0 Batch 5881/17275   train_loss = 2.520\n",
      "Epoch   0 Batch 5882/17275   train_loss = 3.122\n",
      "Epoch   0 Batch 5883/17275   train_loss = 2.873\n",
      "Epoch   0 Batch 5884/17275   train_loss = 5.989\n",
      "Epoch   0 Batch 5885/17275   train_loss = 3.712\n",
      "Epoch   0 Batch 5886/17275   train_loss = 4.149\n",
      "Epoch   0 Batch 5887/17275   train_loss = 2.965\n",
      "Epoch   0 Batch 5888/17275   train_loss = 2.798\n",
      "Epoch   0 Batch 5889/17275   train_loss = 3.986\n",
      "Epoch   0 Batch 5890/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 5891/17275   train_loss = 5.960\n",
      "Epoch   0 Batch 5892/17275   train_loss = 2.562\n",
      "Epoch   0 Batch 5893/17275   train_loss = 2.746\n",
      "Epoch   0 Batch 5894/17275   train_loss = 1.681\n",
      "Epoch   0 Batch 5895/17275   train_loss = 4.184\n",
      "Epoch   0 Batch 5896/17275   train_loss = 3.635\n",
      "Epoch   0 Batch 5897/17275   train_loss = 3.901\n",
      "Epoch   0 Batch 5898/17275   train_loss = 3.959\n",
      "Epoch   0 Batch 5899/17275   train_loss = 1.934\n",
      "Epoch   0 Batch 5900/17275   train_loss = 3.311\n",
      "Epoch   0 Batch 5901/17275   train_loss = 2.613\n",
      "Epoch   0 Batch 5902/17275   train_loss = 4.912\n",
      "Epoch   0 Batch 5903/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 5904/17275   train_loss = 4.157\n",
      "Epoch   0 Batch 5905/17275   train_loss = 2.285\n",
      "Epoch   0 Batch 5906/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 5907/17275   train_loss = 3.812\n",
      "Epoch   0 Batch 5908/17275   train_loss = 3.305\n",
      "Epoch   0 Batch 5909/17275   train_loss = 3.079\n",
      "Epoch   0 Batch 5910/17275   train_loss = 4.185\n",
      "Epoch   0 Batch 5911/17275   train_loss = 6.472\n",
      "Epoch   0 Batch 5912/17275   train_loss = 3.700\n",
      "Epoch   0 Batch 5913/17275   train_loss = 6.517\n",
      "Epoch   0 Batch 5914/17275   train_loss = 2.029\n",
      "Epoch   0 Batch 5915/17275   train_loss = 4.254\n",
      "Epoch   0 Batch 5916/17275   train_loss = 3.653\n",
      "Epoch   0 Batch 5917/17275   train_loss = 3.513\n",
      "Epoch   0 Batch 5918/17275   train_loss = 3.576\n",
      "Epoch   0 Batch 5919/17275   train_loss = 6.868\n",
      "Epoch   0 Batch 5920/17275   train_loss = 2.703\n",
      "Epoch   0 Batch 5921/17275   train_loss = 4.481\n",
      "Epoch   0 Batch 5922/17275   train_loss = 2.331\n",
      "Epoch   0 Batch 5923/17275   train_loss = 6.533\n",
      "Epoch   0 Batch 5924/17275   train_loss = 5.968\n",
      "Epoch   0 Batch 5925/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 5926/17275   train_loss = 6.088\n",
      "Epoch   0 Batch 5927/17275   train_loss = 4.013\n",
      "Epoch   0 Batch 5928/17275   train_loss = 2.756\n",
      "Epoch   0 Batch 5929/17275   train_loss = 3.262\n",
      "Epoch   0 Batch 5930/17275   train_loss = 9.256\n",
      "Epoch   0 Batch 5931/17275   train_loss = 2.020\n",
      "Epoch   0 Batch 5932/17275   train_loss = 5.635\n",
      "Epoch   0 Batch 5933/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 5934/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 5935/17275   train_loss = 5.619\n",
      "Epoch   0 Batch 5936/17275   train_loss = 2.439\n",
      "Epoch   0 Batch 5937/17275   train_loss = 2.549\n",
      "Epoch   0 Batch 5938/17275   train_loss = 2.706\n",
      "Epoch   0 Batch 5939/17275   train_loss = 6.349\n",
      "Epoch   0 Batch 5940/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 5941/17275   train_loss = 5.781\n",
      "Epoch   0 Batch 5942/17275   train_loss = 6.496\n",
      "Epoch   0 Batch 5943/17275   train_loss = 5.887\n",
      "Epoch   0 Batch 5944/17275   train_loss = 6.702\n",
      "Epoch   0 Batch 5945/17275   train_loss = 5.761\n",
      "Epoch   0 Batch 5946/17275   train_loss = 3.148\n",
      "Epoch   0 Batch 5947/17275   train_loss = 5.720\n",
      "Epoch   0 Batch 5948/17275   train_loss = 3.238\n",
      "Epoch   0 Batch 5949/17275   train_loss = 2.723\n",
      "Epoch   0 Batch 5950/17275   train_loss = 6.004\n",
      "Epoch   0 Batch 5951/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 5952/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 5953/17275   train_loss = 2.409\n",
      "Epoch   0 Batch 5954/17275   train_loss = 6.207\n",
      "Epoch   0 Batch 5955/17275   train_loss = 5.338\n",
      "Epoch   0 Batch 5956/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 5957/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 5958/17275   train_loss = 6.009\n",
      "Epoch   0 Batch 5959/17275   train_loss = 3.155\n",
      "Epoch   0 Batch 5960/17275   train_loss = 6.303\n",
      "Epoch   0 Batch 5961/17275   train_loss = 5.148\n",
      "Epoch   0 Batch 5962/17275   train_loss = 3.020\n",
      "Epoch   0 Batch 5963/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 5964/17275   train_loss = 3.631\n",
      "Epoch   0 Batch 5965/17275   train_loss = 6.887\n",
      "Epoch   0 Batch 5966/17275   train_loss = 6.049\n",
      "Epoch   0 Batch 5967/17275   train_loss = 2.096\n",
      "Epoch   0 Batch 5968/17275   train_loss = 5.991\n",
      "Epoch   0 Batch 5969/17275   train_loss = 5.391\n",
      "Epoch   0 Batch 5970/17275   train_loss = 6.992\n",
      "Epoch   0 Batch 5971/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 5972/17275   train_loss = 9.254\n",
      "Epoch   0 Batch 5973/17275   train_loss = 3.211\n",
      "Epoch   0 Batch 5974/17275   train_loss = 6.158\n",
      "Epoch   0 Batch 5975/17275   train_loss = 6.545\n",
      "Epoch   0 Batch 5976/17275   train_loss = 6.455\n",
      "Epoch   0 Batch 5977/17275   train_loss = 6.271\n",
      "Epoch   0 Batch 5978/17275   train_loss = 6.765\n",
      "Epoch   0 Batch 5979/17275   train_loss = 5.961\n",
      "Epoch   0 Batch 5980/17275   train_loss = 2.840\n",
      "Epoch   0 Batch 5981/17275   train_loss = 3.391\n",
      "Epoch   0 Batch 5982/17275   train_loss = 9.226\n",
      "Epoch   0 Batch 5983/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 5984/17275   train_loss = 6.297\n",
      "Epoch   0 Batch 5985/17275   train_loss = 2.991\n",
      "Epoch   0 Batch 5986/17275   train_loss = 9.220\n",
      "Epoch   0 Batch 5987/17275   train_loss = 2.646\n",
      "Epoch   0 Batch 5988/17275   train_loss = 6.257\n",
      "Epoch   0 Batch 5989/17275   train_loss = 5.664\n",
      "Epoch   0 Batch 5990/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 5991/17275   train_loss = 2.815\n",
      "Epoch   0 Batch 5992/17275   train_loss = 3.559\n",
      "Epoch   0 Batch 5993/17275   train_loss = 4.448\n",
      "Epoch   0 Batch 5994/17275   train_loss = 3.671\n",
      "Epoch   0 Batch 5995/17275   train_loss = 2.531\n",
      "Epoch   0 Batch 5996/17275   train_loss = 9.239\n",
      "Epoch   0 Batch 5997/17275   train_loss = 2.326\n",
      "Epoch   0 Batch 5998/17275   train_loss = 2.930\n",
      "Epoch   0 Batch 5999/17275   train_loss = 3.011\n",
      "Epoch   0 Batch 6000/17275   train_loss = 2.439\n",
      "Epoch   0 Batch 6001/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 6002/17275   train_loss = 3.035\n",
      "Epoch   0 Batch 6003/17275   train_loss = 2.787\n",
      "Epoch   0 Batch 6004/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 6005/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 6006/17275   train_loss = 7.443\n",
      "Epoch   0 Batch 6007/17275   train_loss = 5.680\n",
      "Epoch   0 Batch 6008/17275   train_loss = 3.043\n",
      "Epoch   0 Batch 6009/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 6010/17275   train_loss = 3.658\n",
      "Epoch   0 Batch 6011/17275   train_loss = 3.993\n",
      "Epoch   0 Batch 6012/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 6013/17275   train_loss = 6.369\n",
      "Epoch   0 Batch 6014/17275   train_loss = 4.980\n",
      "Epoch   0 Batch 6015/17275   train_loss = 6.107\n",
      "Epoch   0 Batch 6016/17275   train_loss = 8.401\n",
      "Epoch   0 Batch 6017/17275   train_loss = 6.968\n",
      "Epoch   0 Batch 6018/17275   train_loss = 5.744\n",
      "Epoch   0 Batch 6019/17275   train_loss = 2.801\n",
      "Epoch   0 Batch 6020/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 6021/17275   train_loss = 6.082\n",
      "Epoch   0 Batch 6022/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 6023/17275   train_loss = 2.450\n",
      "Epoch   0 Batch 6024/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 6025/17275   train_loss = 5.265\n",
      "Epoch   0 Batch 6026/17275   train_loss = 5.793\n",
      "Epoch   0 Batch 6027/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 6028/17275   train_loss = 2.427\n",
      "Epoch   0 Batch 6029/17275   train_loss = 5.972\n",
      "Epoch   0 Batch 6030/17275   train_loss = 6.602\n",
      "Epoch   0 Batch 6031/17275   train_loss = 6.182\n",
      "Epoch   0 Batch 6032/17275   train_loss = 3.417\n",
      "Epoch   0 Batch 6033/17275   train_loss = 4.366\n",
      "Epoch   0 Batch 6034/17275   train_loss = 3.694\n",
      "Epoch   0 Batch 6035/17275   train_loss = 5.733\n",
      "Epoch   0 Batch 6036/17275   train_loss = 3.168\n",
      "Epoch   0 Batch 6037/17275   train_loss = 4.642\n",
      "Epoch   0 Batch 6038/17275   train_loss = 2.590\n",
      "Epoch   0 Batch 6039/17275   train_loss = 4.145\n",
      "Epoch   0 Batch 6040/17275   train_loss = 5.244\n",
      "Epoch   0 Batch 6041/17275   train_loss = 3.944\n",
      "Epoch   0 Batch 6042/17275   train_loss = 9.225\n",
      "Epoch   0 Batch 6043/17275   train_loss = 3.653\n",
      "Epoch   0 Batch 6044/17275   train_loss = 5.695\n",
      "Epoch   0 Batch 6045/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 6046/17275   train_loss = 2.650\n",
      "Epoch   0 Batch 6047/17275   train_loss = 4.492\n",
      "Epoch   0 Batch 6048/17275   train_loss = 5.417\n",
      "Epoch   0 Batch 6049/17275   train_loss = 2.758\n",
      "Epoch   0 Batch 6050/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 6051/17275   train_loss = 3.045\n",
      "Epoch   0 Batch 6052/17275   train_loss = 5.658\n",
      "Epoch   0 Batch 6053/17275   train_loss = 9.212\n",
      "Epoch   0 Batch 6054/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 6055/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 6056/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 6057/17275   train_loss = 7.408\n",
      "Epoch   0 Batch 6058/17275   train_loss = 2.846\n",
      "Epoch   0 Batch 6059/17275   train_loss = 3.429\n",
      "Epoch   0 Batch 6060/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 6061/17275   train_loss = 5.924\n",
      "Epoch   0 Batch 6062/17275   train_loss = 6.429\n",
      "Epoch   0 Batch 6063/17275   train_loss = 6.443\n",
      "Epoch   0 Batch 6064/17275   train_loss = 3.063\n",
      "Epoch   0 Batch 6065/17275   train_loss = 8.277\n",
      "Epoch   0 Batch 6066/17275   train_loss = 3.550\n",
      "Epoch   0 Batch 6067/17275   train_loss = 7.932\n",
      "Epoch   0 Batch 6068/17275   train_loss = 3.343\n",
      "Epoch   0 Batch 6069/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 6070/17275   train_loss = 3.608\n",
      "Epoch   0 Batch 6071/17275   train_loss = 5.744\n",
      "Epoch   0 Batch 6072/17275   train_loss = 3.358\n",
      "Epoch   0 Batch 6073/17275   train_loss = 4.116\n",
      "Epoch   0 Batch 6074/17275   train_loss = 2.543\n",
      "Epoch   0 Batch 6075/17275   train_loss = 6.072\n",
      "Epoch   0 Batch 6076/17275   train_loss = 3.306\n",
      "Epoch   0 Batch 6077/17275   train_loss = 3.671\n",
      "Epoch   0 Batch 6078/17275   train_loss = 4.753\n",
      "Epoch   0 Batch 6079/17275   train_loss = 2.237\n",
      "Epoch   0 Batch 6080/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 6081/17275   train_loss = 4.833\n",
      "Epoch   0 Batch 6082/17275   train_loss = 3.814\n",
      "Epoch   0 Batch 6083/17275   train_loss = 3.937\n",
      "Epoch   0 Batch 6084/17275   train_loss = 2.225\n",
      "Epoch   0 Batch 6085/17275   train_loss = 2.749\n",
      "Epoch   0 Batch 6086/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 6087/17275   train_loss = 4.091\n",
      "Epoch   0 Batch 6088/17275   train_loss = 3.074\n",
      "Epoch   0 Batch 6089/17275   train_loss = 2.624\n",
      "Epoch   0 Batch 6090/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 6091/17275   train_loss = 4.536\n",
      "Epoch   0 Batch 6092/17275   train_loss = 3.539\n",
      "Epoch   0 Batch 6093/17275   train_loss = 3.656\n",
      "Epoch   0 Batch 6094/17275   train_loss = 2.933\n",
      "Epoch   0 Batch 6095/17275   train_loss = 7.370\n",
      "Epoch   0 Batch 6096/17275   train_loss = 2.180\n",
      "Epoch   0 Batch 6097/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 6098/17275   train_loss = 6.041\n",
      "Epoch   0 Batch 6099/17275   train_loss = 2.210\n",
      "Epoch   0 Batch 6100/17275   train_loss = 2.032\n",
      "Epoch   0 Batch 6101/17275   train_loss = 3.333\n",
      "Epoch   0 Batch 6102/17275   train_loss = 2.482\n",
      "Epoch   0 Batch 6103/17275   train_loss = 2.624\n",
      "Epoch   0 Batch 6104/17275   train_loss = 2.542\n",
      "Epoch   0 Batch 6105/17275   train_loss = 4.350\n",
      "Epoch   0 Batch 6106/17275   train_loss = 2.969\n",
      "Epoch   0 Batch 6107/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 6108/17275   train_loss = 7.396\n",
      "Epoch   0 Batch 6109/17275   train_loss = 3.022\n",
      "Epoch   0 Batch 6110/17275   train_loss = 3.893\n",
      "Epoch   0 Batch 6111/17275   train_loss = 2.758\n",
      "Epoch   0 Batch 6112/17275   train_loss = 2.945\n",
      "Epoch   0 Batch 6113/17275   train_loss = 3.297\n",
      "Epoch   0 Batch 6114/17275   train_loss = 2.417\n",
      "Epoch   0 Batch 6115/17275   train_loss = 3.218\n",
      "Epoch   0 Batch 6116/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 6117/17275   train_loss = 3.744\n",
      "Epoch   0 Batch 6118/17275   train_loss = 4.983\n",
      "Epoch   0 Batch 6119/17275   train_loss = 7.574\n",
      "Epoch   0 Batch 6120/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 6121/17275   train_loss = 6.568\n",
      "Epoch   0 Batch 6122/17275   train_loss = 3.618\n",
      "Epoch   0 Batch 6123/17275   train_loss = 6.208\n",
      "Epoch   0 Batch 6124/17275   train_loss = 3.889\n",
      "Epoch   0 Batch 6125/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 6126/17275   train_loss = 6.054\n",
      "Epoch   0 Batch 6127/17275   train_loss = 3.762\n",
      "Epoch   0 Batch 6128/17275   train_loss = 2.966\n",
      "Epoch   0 Batch 6129/17275   train_loss = 6.204\n",
      "Epoch   0 Batch 6130/17275   train_loss = 3.173\n",
      "Epoch   0 Batch 6131/17275   train_loss = 3.352\n",
      "Epoch   0 Batch 6132/17275   train_loss = 5.492\n",
      "Epoch   0 Batch 6133/17275   train_loss = 4.477\n",
      "Epoch   0 Batch 6134/17275   train_loss = 4.289\n",
      "Epoch   0 Batch 6135/17275   train_loss = 3.317\n",
      "Epoch   0 Batch 6136/17275   train_loss = 6.076\n",
      "Epoch   0 Batch 6137/17275   train_loss = 2.392\n",
      "Epoch   0 Batch 6138/17275   train_loss = 2.566\n",
      "Epoch   0 Batch 6139/17275   train_loss = 5.910\n",
      "Epoch   0 Batch 6140/17275   train_loss = 2.693\n",
      "Epoch   0 Batch 6141/17275   train_loss = 3.053\n",
      "Epoch   0 Batch 6142/17275   train_loss = 3.211\n",
      "Epoch   0 Batch 6143/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 6144/17275   train_loss = 3.230\n",
      "Epoch   0 Batch 6145/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 6146/17275   train_loss = 2.670\n",
      "Epoch   0 Batch 6147/17275   train_loss = 1.945\n",
      "Epoch   0 Batch 6148/17275   train_loss = 2.477\n",
      "Epoch   0 Batch 6149/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 6150/17275   train_loss = 6.062\n",
      "Epoch   0 Batch 6151/17275   train_loss = 2.262\n",
      "Epoch   0 Batch 6152/17275   train_loss = 2.703\n",
      "Epoch   0 Batch 6153/17275   train_loss = 3.309\n",
      "Epoch   0 Batch 6154/17275   train_loss = 3.790\n",
      "Epoch   0 Batch 6155/17275   train_loss = 3.304\n",
      "Epoch   0 Batch 6156/17275   train_loss = 3.785\n",
      "Epoch   0 Batch 6157/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 6158/17275   train_loss = 4.522\n",
      "Epoch   0 Batch 6159/17275   train_loss = 5.164\n",
      "Epoch   0 Batch 6160/17275   train_loss = 4.700\n",
      "Epoch   0 Batch 6161/17275   train_loss = 2.217\n",
      "Epoch   0 Batch 6162/17275   train_loss = 3.901\n",
      "Epoch   0 Batch 6163/17275   train_loss = 4.214\n",
      "Epoch   0 Batch 6164/17275   train_loss = 3.955\n",
      "Epoch   0 Batch 6165/17275   train_loss = 6.444\n",
      "Epoch   0 Batch 6166/17275   train_loss = 2.789\n",
      "Epoch   0 Batch 6167/17275   train_loss = 2.969\n",
      "Epoch   0 Batch 6168/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 6169/17275   train_loss = 3.838\n",
      "Epoch   0 Batch 6170/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 6171/17275   train_loss = 6.151\n",
      "Epoch   0 Batch 6172/17275   train_loss = 3.034\n",
      "Epoch   0 Batch 6173/17275   train_loss = 3.182\n",
      "Epoch   0 Batch 6174/17275   train_loss = 2.398\n",
      "Epoch   0 Batch 6175/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 6176/17275   train_loss = 3.285\n",
      "Epoch   0 Batch 6177/17275   train_loss = 3.793\n",
      "Epoch   0 Batch 6178/17275   train_loss = 6.583\n",
      "Epoch   0 Batch 6179/17275   train_loss = 3.870\n",
      "Epoch   0 Batch 6180/17275   train_loss = 3.742\n",
      "Epoch   0 Batch 6181/17275   train_loss = 5.470\n",
      "Epoch   0 Batch 6182/17275   train_loss = 3.210\n",
      "Epoch   0 Batch 6183/17275   train_loss = 5.675\n",
      "Epoch   0 Batch 6184/17275   train_loss = 3.035\n",
      "Epoch   0 Batch 6185/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 6186/17275   train_loss = 5.932\n",
      "Epoch   0 Batch 6187/17275   train_loss = 5.930\n",
      "Epoch   0 Batch 6188/17275   train_loss = 3.435\n",
      "Epoch   0 Batch 6189/17275   train_loss = 6.696\n",
      "Epoch   0 Batch 6190/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 6191/17275   train_loss = 3.091\n",
      "Epoch   0 Batch 6192/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 6193/17275   train_loss = 3.189\n",
      "Epoch   0 Batch 6194/17275   train_loss = 6.319\n",
      "Epoch   0 Batch 6195/17275   train_loss = 6.196\n",
      "Epoch   0 Batch 6196/17275   train_loss = 3.096\n",
      "Epoch   0 Batch 6197/17275   train_loss = 3.156\n",
      "Epoch   0 Batch 6198/17275   train_loss = 5.672\n",
      "Epoch   0 Batch 6199/17275   train_loss = 3.884\n",
      "Epoch   0 Batch 6200/17275   train_loss = 2.950\n",
      "Epoch   0 Batch 6201/17275   train_loss = 3.010\n",
      "Epoch   0 Batch 6202/17275   train_loss = 5.673\n",
      "Epoch   0 Batch 6203/17275   train_loss = 2.475\n",
      "Epoch   0 Batch 6204/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 6205/17275   train_loss = 4.031\n",
      "Epoch   0 Batch 6206/17275   train_loss = 3.106\n",
      "Epoch   0 Batch 6207/17275   train_loss = 4.162\n",
      "Epoch   0 Batch 6208/17275   train_loss = 3.105\n",
      "Epoch   0 Batch 6209/17275   train_loss = 2.164\n",
      "Epoch   0 Batch 6210/17275   train_loss = 5.728\n",
      "Epoch   0 Batch 6211/17275   train_loss = 2.956\n",
      "Epoch   0 Batch 6212/17275   train_loss = 3.327\n",
      "Epoch   0 Batch 6213/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 6214/17275   train_loss = 4.103\n",
      "Epoch   0 Batch 6215/17275   train_loss = 4.893\n",
      "Epoch   0 Batch 6216/17275   train_loss = 5.709\n",
      "Epoch   0 Batch 6217/17275   train_loss = 4.018\n",
      "Epoch   0 Batch 6218/17275   train_loss = 5.832\n",
      "Epoch   0 Batch 6219/17275   train_loss = 2.071\n",
      "Epoch   0 Batch 6220/17275   train_loss = 6.322\n",
      "Epoch   0 Batch 6221/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 6222/17275   train_loss = 6.095\n",
      "Epoch   0 Batch 6223/17275   train_loss = 2.546\n",
      "Epoch   0 Batch 6224/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 6225/17275   train_loss = 6.069\n",
      "Epoch   0 Batch 6226/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 6227/17275   train_loss = 6.507\n",
      "Epoch   0 Batch 6228/17275   train_loss = 5.710\n",
      "Epoch   0 Batch 6229/17275   train_loss = 4.990\n",
      "Epoch   0 Batch 6230/17275   train_loss = 2.800\n",
      "Epoch   0 Batch 6231/17275   train_loss = 4.865\n",
      "Epoch   0 Batch 6232/17275   train_loss = 5.940\n",
      "Epoch   0 Batch 6233/17275   train_loss = 6.641\n",
      "Epoch   0 Batch 6234/17275   train_loss = 6.002\n",
      "Epoch   0 Batch 6235/17275   train_loss = 6.002\n",
      "Epoch   0 Batch 6236/17275   train_loss = 9.332\n",
      "Epoch   0 Batch 6237/17275   train_loss = 5.677\n",
      "Epoch   0 Batch 6238/17275   train_loss = 3.322\n",
      "Epoch   0 Batch 6239/17275   train_loss = 4.255\n",
      "Epoch   0 Batch 6240/17275   train_loss = 6.040\n",
      "Epoch   0 Batch 6241/17275   train_loss = 4.892\n",
      "Epoch   0 Batch 6242/17275   train_loss = 1.989\n",
      "Epoch   0 Batch 6243/17275   train_loss = 4.546\n",
      "Epoch   0 Batch 6244/17275   train_loss = 3.417\n",
      "Epoch   0 Batch 6245/17275   train_loss = 4.082\n",
      "Epoch   0 Batch 6246/17275   train_loss = 3.232\n",
      "Epoch   0 Batch 6247/17275   train_loss = 5.906\n",
      "Epoch   0 Batch 6248/17275   train_loss = 5.933\n",
      "Epoch   0 Batch 6249/17275   train_loss = 2.586\n",
      "Epoch   0 Batch 6250/17275   train_loss = 3.705\n",
      "Epoch   0 Batch 6251/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 6252/17275   train_loss = 2.744\n",
      "Epoch   0 Batch 6253/17275   train_loss = 5.951\n",
      "Epoch   0 Batch 6254/17275   train_loss = 4.211\n",
      "Epoch   0 Batch 6255/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 6256/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 6257/17275   train_loss = 3.041\n",
      "Epoch   0 Batch 6258/17275   train_loss = 5.539\n",
      "Epoch   0 Batch 6259/17275   train_loss = 3.762\n",
      "Epoch   0 Batch 6260/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 6261/17275   train_loss = 3.387\n",
      "Epoch   0 Batch 6262/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 6263/17275   train_loss = 3.991\n",
      "Epoch   0 Batch 6264/17275   train_loss = 4.801\n",
      "Epoch   0 Batch 6265/17275   train_loss = 6.045\n",
      "Epoch   0 Batch 6266/17275   train_loss = 2.089\n",
      "Epoch   0 Batch 6267/17275   train_loss = 4.246\n",
      "Epoch   0 Batch 6268/17275   train_loss = 4.663\n",
      "Epoch   0 Batch 6269/17275   train_loss = 2.625\n",
      "Epoch   0 Batch 6270/17275   train_loss = 4.136\n",
      "Epoch   0 Batch 6271/17275   train_loss = 2.828\n",
      "Epoch   0 Batch 6272/17275   train_loss = 2.553\n",
      "Epoch   0 Batch 6273/17275   train_loss = 5.837\n",
      "Epoch   0 Batch 6274/17275   train_loss = 3.234\n",
      "Epoch   0 Batch 6275/17275   train_loss = 3.166\n",
      "Epoch   0 Batch 6276/17275   train_loss = 3.360\n",
      "Epoch   0 Batch 6277/17275   train_loss = 4.113\n",
      "Epoch   0 Batch 6278/17275   train_loss = 6.353\n",
      "Epoch   0 Batch 6279/17275   train_loss = 3.369\n",
      "Epoch   0 Batch 6280/17275   train_loss = 2.731\n",
      "Epoch   0 Batch 6281/17275   train_loss = 4.807\n",
      "Epoch   0 Batch 6282/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 6283/17275   train_loss = 5.004\n",
      "Epoch   0 Batch 6284/17275   train_loss = 5.666\n",
      "Epoch   0 Batch 6285/17275   train_loss = 4.028\n",
      "Epoch   0 Batch 6286/17275   train_loss = 6.315\n",
      "Epoch   0 Batch 6287/17275   train_loss = 3.944\n",
      "Epoch   0 Batch 6288/17275   train_loss = 3.162\n",
      "Epoch   0 Batch 6289/17275   train_loss = 7.655\n",
      "Epoch   0 Batch 6290/17275   train_loss = 4.010\n",
      "Epoch   0 Batch 6291/17275   train_loss = 6.024\n",
      "Epoch   0 Batch 6292/17275   train_loss = 2.040\n",
      "Epoch   0 Batch 6293/17275   train_loss = 3.138\n",
      "Epoch   0 Batch 6294/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 6295/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 6296/17275   train_loss = 3.701\n",
      "Epoch   0 Batch 6297/17275   train_loss = 2.021\n",
      "Epoch   0 Batch 6298/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 6299/17275   train_loss = 6.145\n",
      "Epoch   0 Batch 6300/17275   train_loss = 9.316\n",
      "Epoch   0 Batch 6301/17275   train_loss = 6.180\n",
      "Epoch   0 Batch 6302/17275   train_loss = 4.186\n",
      "Epoch   0 Batch 6303/17275   train_loss = 1.988\n",
      "Epoch   0 Batch 6304/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 6305/17275   train_loss = 3.046\n",
      "Epoch   0 Batch 6306/17275   train_loss = 4.208\n",
      "Epoch   0 Batch 6307/17275   train_loss = 1.964\n",
      "Epoch   0 Batch 6308/17275   train_loss = 2.599\n",
      "Epoch   0 Batch 6309/17275   train_loss = 8.809\n",
      "Epoch   0 Batch 6310/17275   train_loss = 3.357\n",
      "Epoch   0 Batch 6311/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 6312/17275   train_loss = 2.411\n",
      "Epoch   0 Batch 6313/17275   train_loss = 1.841\n",
      "Epoch   0 Batch 6314/17275   train_loss = 3.573\n",
      "Epoch   0 Batch 6315/17275   train_loss = 3.993\n",
      "Epoch   0 Batch 6316/17275   train_loss = 2.982\n",
      "Epoch   0 Batch 6317/17275   train_loss = 2.288\n",
      "Epoch   0 Batch 6318/17275   train_loss = 4.138\n",
      "Epoch   0 Batch 6319/17275   train_loss = 3.695\n",
      "Epoch   0 Batch 6320/17275   train_loss = 5.526\n",
      "Epoch   0 Batch 6321/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 6322/17275   train_loss = 1.857\n",
      "Epoch   0 Batch 6323/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 6324/17275   train_loss = 2.331\n",
      "Epoch   0 Batch 6325/17275   train_loss = 4.202\n",
      "Epoch   0 Batch 6326/17275   train_loss = 5.494\n",
      "Epoch   0 Batch 6327/17275   train_loss = 5.412\n",
      "Epoch   0 Batch 6328/17275   train_loss = 3.161\n",
      "Epoch   0 Batch 6329/17275   train_loss = 3.730\n",
      "Epoch   0 Batch 6330/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 6331/17275   train_loss = 4.200\n",
      "Epoch   0 Batch 6332/17275   train_loss = 3.891\n",
      "Epoch   0 Batch 6333/17275   train_loss = 4.017\n",
      "Epoch   0 Batch 6334/17275   train_loss = 3.215\n",
      "Epoch   0 Batch 6335/17275   train_loss = 5.876\n",
      "Epoch   0 Batch 6336/17275   train_loss = 4.682\n",
      "Epoch   0 Batch 6337/17275   train_loss = 4.528\n",
      "Epoch   0 Batch 6338/17275   train_loss = 4.938\n",
      "Epoch   0 Batch 6339/17275   train_loss = 3.065\n",
      "Epoch   0 Batch 6340/17275   train_loss = 6.194\n",
      "Epoch   0 Batch 6341/17275   train_loss = 2.618\n",
      "Epoch   0 Batch 6342/17275   train_loss = 5.160\n",
      "Epoch   0 Batch 6343/17275   train_loss = 6.832\n",
      "Epoch   0 Batch 6344/17275   train_loss = 4.209\n",
      "Epoch   0 Batch 6345/17275   train_loss = 4.116\n",
      "Epoch   0 Batch 6346/17275   train_loss = 6.060\n",
      "Epoch   0 Batch 6347/17275   train_loss = 9.336\n",
      "Epoch   0 Batch 6348/17275   train_loss = 2.018\n",
      "Epoch   0 Batch 6349/17275   train_loss = 2.698\n",
      "Epoch   0 Batch 6350/17275   train_loss = 4.557\n",
      "Epoch   0 Batch 6351/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 6352/17275   train_loss = 4.284\n",
      "Epoch   0 Batch 6353/17275   train_loss = 3.803\n",
      "Epoch   0 Batch 6354/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 6355/17275   train_loss = 3.805\n",
      "Epoch   0 Batch 6356/17275   train_loss = 3.331\n",
      "Epoch   0 Batch 6357/17275   train_loss = 3.664\n",
      "Epoch   0 Batch 6358/17275   train_loss = 2.664\n",
      "Epoch   0 Batch 6359/17275   train_loss = 2.523\n",
      "Epoch   0 Batch 6360/17275   train_loss = 2.595\n",
      "Epoch   0 Batch 6361/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 6362/17275   train_loss = 3.108\n",
      "Epoch   0 Batch 6363/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 6364/17275   train_loss = 3.769\n",
      "Epoch   0 Batch 6365/17275   train_loss = 4.379\n",
      "Epoch   0 Batch 6366/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 6367/17275   train_loss = 2.417\n",
      "Epoch   0 Batch 6368/17275   train_loss = 5.447\n",
      "Epoch   0 Batch 6369/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 6370/17275   train_loss = 3.543\n",
      "Epoch   0 Batch 6371/17275   train_loss = 3.982\n",
      "Epoch   0 Batch 6372/17275   train_loss = 3.270\n",
      "Epoch   0 Batch 6373/17275   train_loss = 6.371\n",
      "Epoch   0 Batch 6374/17275   train_loss = 5.962\n",
      "Epoch   0 Batch 6375/17275   train_loss = 7.021\n",
      "Epoch   0 Batch 6376/17275   train_loss = 3.057\n",
      "Epoch   0 Batch 6377/17275   train_loss = 9.326\n",
      "Epoch   0 Batch 6378/17275   train_loss = 6.548\n",
      "Epoch   0 Batch 6379/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 6380/17275   train_loss = 2.225\n",
      "Epoch   0 Batch 6381/17275   train_loss = 4.539\n",
      "Epoch   0 Batch 6382/17275   train_loss = 2.420\n",
      "Epoch   0 Batch 6383/17275   train_loss = 3.172\n",
      "Epoch   0 Batch 6384/17275   train_loss = 3.398\n",
      "Epoch   0 Batch 6385/17275   train_loss = 4.592\n",
      "Epoch   0 Batch 6386/17275   train_loss = 6.227\n",
      "Epoch   0 Batch 6387/17275   train_loss = 3.785\n",
      "Epoch   0 Batch 6388/17275   train_loss = 4.166\n",
      "Epoch   0 Batch 6389/17275   train_loss = 3.516\n",
      "Epoch   0 Batch 6390/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 6391/17275   train_loss = 3.819\n",
      "Epoch   0 Batch 6392/17275   train_loss = 2.767\n",
      "Epoch   0 Batch 6393/17275   train_loss = 4.075\n",
      "Epoch   0 Batch 6394/17275   train_loss = 4.096\n",
      "Epoch   0 Batch 6395/17275   train_loss = 5.284\n",
      "Epoch   0 Batch 6396/17275   train_loss = 4.054\n",
      "Epoch   0 Batch 6397/17275   train_loss = 3.913\n",
      "Epoch   0 Batch 6398/17275   train_loss = 5.811\n",
      "Epoch   0 Batch 6399/17275   train_loss = 2.049\n",
      "Epoch   0 Batch 6400/17275   train_loss = 3.067\n",
      "Epoch   0 Batch 6401/17275   train_loss = 3.979\n",
      "Epoch   0 Batch 6402/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 6403/17275   train_loss = 3.847\n",
      "Epoch   0 Batch 6404/17275   train_loss = 3.267\n",
      "Epoch   0 Batch 6405/17275   train_loss = 6.139\n",
      "Epoch   0 Batch 6406/17275   train_loss = 3.015\n",
      "Epoch   0 Batch 6407/17275   train_loss = 5.785\n",
      "Epoch   0 Batch 6408/17275   train_loss = 2.017\n",
      "Epoch   0 Batch 6409/17275   train_loss = 4.744\n",
      "Epoch   0 Batch 6410/17275   train_loss = 6.690\n",
      "Epoch   0 Batch 6411/17275   train_loss = 1.997\n",
      "Epoch   0 Batch 6412/17275   train_loss = 7.197\n",
      "Epoch   0 Batch 6413/17275   train_loss = 6.142\n",
      "Epoch   0 Batch 6414/17275   train_loss = 1.963\n",
      "Epoch   0 Batch 6415/17275   train_loss = 9.355\n",
      "Epoch   0 Batch 6416/17275   train_loss = 1.931\n",
      "Epoch   0 Batch 6417/17275   train_loss = 9.365\n",
      "Epoch   0 Batch 6418/17275   train_loss = 1.891\n",
      "Epoch   0 Batch 6419/17275   train_loss = 3.420\n",
      "Epoch   0 Batch 6420/17275   train_loss = 7.163\n",
      "Epoch   0 Batch 6421/17275   train_loss = 1.817\n",
      "Epoch   0 Batch 6422/17275   train_loss = 3.054\n",
      "Epoch   0 Batch 6423/17275   train_loss = 5.833\n",
      "Epoch   0 Batch 6424/17275   train_loss = 2.813\n",
      "Epoch   0 Batch 6425/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 6426/17275   train_loss = 4.838\n",
      "Epoch   0 Batch 6427/17275   train_loss = 3.749\n",
      "Epoch   0 Batch 6428/17275   train_loss = 9.388\n",
      "Epoch   0 Batch 6429/17275   train_loss = 1.726\n",
      "Epoch   0 Batch 6430/17275   train_loss = 1.686\n",
      "Epoch   0 Batch 6431/17275   train_loss = 3.857\n",
      "Epoch   0 Batch 6432/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 6433/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 6434/17275   train_loss = 2.153\n",
      "Epoch   0 Batch 6435/17275   train_loss = 3.926\n",
      "Epoch   0 Batch 6436/17275   train_loss = 6.542\n",
      "Epoch   0 Batch 6437/17275   train_loss = 4.668\n",
      "Epoch   0 Batch 6438/17275   train_loss = 2.313\n",
      "Epoch   0 Batch 6439/17275   train_loss = 5.429\n",
      "Epoch   0 Batch 6440/17275   train_loss = 4.041\n",
      "Epoch   0 Batch 6441/17275   train_loss = 1.692\n",
      "Epoch   0 Batch 6442/17275   train_loss = 3.564\n",
      "Epoch   0 Batch 6443/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 6444/17275   train_loss = 3.258\n",
      "Epoch   0 Batch 6445/17275   train_loss = 1.701\n",
      "Epoch   0 Batch 6446/17275   train_loss = 3.389\n",
      "Epoch   0 Batch 6447/17275   train_loss = 3.080\n",
      "Epoch   0 Batch 6448/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 6449/17275   train_loss = 5.578\n",
      "Epoch   0 Batch 6450/17275   train_loss = 2.369\n",
      "Epoch   0 Batch 6451/17275   train_loss = 6.187\n",
      "Epoch   0 Batch 6452/17275   train_loss = 6.972\n",
      "Epoch   0 Batch 6453/17275   train_loss = 2.325\n",
      "Epoch   0 Batch 6454/17275   train_loss = 5.090\n",
      "Epoch   0 Batch 6455/17275   train_loss = 2.343\n",
      "Epoch   0 Batch 6456/17275   train_loss = 6.031\n",
      "Epoch   0 Batch 6457/17275   train_loss = 2.921\n",
      "Epoch   0 Batch 6458/17275   train_loss = 6.097\n",
      "Epoch   0 Batch 6459/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 6460/17275   train_loss = 4.830\n",
      "Epoch   0 Batch 6461/17275   train_loss = 3.599\n",
      "Epoch   0 Batch 6462/17275   train_loss = 3.510\n",
      "Epoch   0 Batch 6463/17275   train_loss = 2.262\n",
      "Epoch   0 Batch 6464/17275   train_loss = 5.960\n",
      "Epoch   0 Batch 6465/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 6466/17275   train_loss = 3.459\n",
      "Epoch   0 Batch 6467/17275   train_loss = 9.372\n",
      "Epoch   0 Batch 6468/17275   train_loss = 2.303\n",
      "Epoch   0 Batch 6469/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 6470/17275   train_loss = 2.934\n",
      "Epoch   0 Batch 6471/17275   train_loss = 3.358\n",
      "Epoch   0 Batch 6472/17275   train_loss = 4.102\n",
      "Epoch   0 Batch 6473/17275   train_loss = 2.936\n",
      "Epoch   0 Batch 6474/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 6475/17275   train_loss = 4.178\n",
      "Epoch   0 Batch 6476/17275   train_loss = 2.719\n",
      "Epoch   0 Batch 6477/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 6478/17275   train_loss = 3.582\n",
      "Epoch   0 Batch 6479/17275   train_loss = 6.033\n",
      "Epoch   0 Batch 6480/17275   train_loss = 2.757\n",
      "Epoch   0 Batch 6481/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 6482/17275   train_loss = 6.025\n",
      "Epoch   0 Batch 6483/17275   train_loss = 3.875\n",
      "Epoch   0 Batch 6484/17275   train_loss = 6.317\n",
      "Epoch   0 Batch 6485/17275   train_loss = 2.097\n",
      "Epoch   0 Batch 6486/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 6487/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 6488/17275   train_loss = 6.660\n",
      "Epoch   0 Batch 6489/17275   train_loss = 4.351\n",
      "Epoch   0 Batch 6490/17275   train_loss = 6.496\n",
      "Epoch   0 Batch 6491/17275   train_loss = 2.106\n",
      "Epoch   0 Batch 6492/17275   train_loss = 3.096\n",
      "Epoch   0 Batch 6493/17275   train_loss = 2.658\n",
      "Epoch   0 Batch 6494/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 6495/17275   train_loss = 5.665\n",
      "Epoch   0 Batch 6496/17275   train_loss = 3.276\n",
      "Epoch   0 Batch 6497/17275   train_loss = 4.363\n",
      "Epoch   0 Batch 6498/17275   train_loss = 6.317\n",
      "Epoch   0 Batch 6499/17275   train_loss = 7.059\n",
      "Epoch   0 Batch 6500/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 6501/17275   train_loss = 4.212\n",
      "Epoch   0 Batch 6502/17275   train_loss = 2.035\n",
      "Epoch   0 Batch 6503/17275   train_loss = 3.251\n",
      "Epoch   0 Batch 6504/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 6505/17275   train_loss = 2.554\n",
      "Epoch   0 Batch 6506/17275   train_loss = 2.305\n",
      "Epoch   0 Batch 6507/17275   train_loss = 4.122\n",
      "Epoch   0 Batch 6508/17275   train_loss = 5.908\n",
      "Epoch   0 Batch 6509/17275   train_loss = 5.756\n",
      "Epoch   0 Batch 6510/17275   train_loss = 3.365\n",
      "Epoch   0 Batch 6511/17275   train_loss = 5.954\n",
      "Epoch   0 Batch 6512/17275   train_loss = 3.200\n",
      "Epoch   0 Batch 6513/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 6514/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 6515/17275   train_loss = 4.236\n",
      "Epoch   0 Batch 6516/17275   train_loss = 5.046\n",
      "Epoch   0 Batch 6517/17275   train_loss = 2.932\n",
      "Epoch   0 Batch 6518/17275   train_loss = 5.801\n",
      "Epoch   0 Batch 6519/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 6520/17275   train_loss = 2.412\n",
      "Epoch   0 Batch 6521/17275   train_loss = 3.074\n",
      "Epoch   0 Batch 6522/17275   train_loss = 3.251\n",
      "Epoch   0 Batch 6523/17275   train_loss = 6.357\n",
      "Epoch   0 Batch 6524/17275   train_loss = 4.136\n",
      "Epoch   0 Batch 6525/17275   train_loss = 5.012\n",
      "Epoch   0 Batch 6526/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 6527/17275   train_loss = 6.424\n",
      "Epoch   0 Batch 6528/17275   train_loss = 5.623\n",
      "Epoch   0 Batch 6529/17275   train_loss = 2.341\n",
      "Epoch   0 Batch 6530/17275   train_loss = 2.636\n",
      "Epoch   0 Batch 6531/17275   train_loss = 6.215\n",
      "Epoch   0 Batch 6532/17275   train_loss = 6.645\n",
      "Epoch   0 Batch 6533/17275   train_loss = 6.179\n",
      "Epoch   0 Batch 6534/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 6535/17275   train_loss = 4.278\n",
      "Epoch   0 Batch 6536/17275   train_loss = 6.925\n",
      "Epoch   0 Batch 6537/17275   train_loss = 6.800\n",
      "Epoch   0 Batch 6538/17275   train_loss = 4.124\n",
      "Epoch   0 Batch 6539/17275   train_loss = 6.471\n",
      "Epoch   0 Batch 6540/17275   train_loss = 2.053\n",
      "Epoch   0 Batch 6541/17275   train_loss = 7.012\n",
      "Epoch   0 Batch 6542/17275   train_loss = 3.646\n",
      "Epoch   0 Batch 6543/17275   train_loss = 2.604\n",
      "Epoch   0 Batch 6544/17275   train_loss = 5.906\n",
      "Epoch   0 Batch 6545/17275   train_loss = 6.246\n",
      "Epoch   0 Batch 6546/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 6547/17275   train_loss = 3.820\n",
      "Epoch   0 Batch 6548/17275   train_loss = 2.320\n",
      "Epoch   0 Batch 6549/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 6550/17275   train_loss = 3.006\n",
      "Epoch   0 Batch 6551/17275   train_loss = 6.544\n",
      "Epoch   0 Batch 6552/17275   train_loss = 6.409\n",
      "Epoch   0 Batch 6553/17275   train_loss = 5.221\n",
      "Epoch   0 Batch 6554/17275   train_loss = 6.293\n",
      "Epoch   0 Batch 6555/17275   train_loss = 5.651\n",
      "Epoch   0 Batch 6556/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 6557/17275   train_loss = 2.610\n",
      "Epoch   0 Batch 6558/17275   train_loss = 2.616\n",
      "Epoch   0 Batch 6559/17275   train_loss = 6.043\n",
      "Epoch   0 Batch 6560/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 6561/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 6562/17275   train_loss = 7.362\n",
      "Epoch   0 Batch 6563/17275   train_loss = 4.822\n",
      "Epoch   0 Batch 6564/17275   train_loss = 3.100\n",
      "Epoch   0 Batch 6565/17275   train_loss = 3.921\n",
      "Epoch   0 Batch 6566/17275   train_loss = 4.098\n",
      "Epoch   0 Batch 6567/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 6568/17275   train_loss = 3.785\n",
      "Epoch   0 Batch 6569/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 6570/17275   train_loss = 2.734\n",
      "Epoch   0 Batch 6571/17275   train_loss = 2.255\n",
      "Epoch   0 Batch 6572/17275   train_loss = 3.666\n",
      "Epoch   0 Batch 6573/17275   train_loss = 5.749\n",
      "Epoch   0 Batch 6574/17275   train_loss = 2.662\n",
      "Epoch   0 Batch 6575/17275   train_loss = 4.397\n",
      "Epoch   0 Batch 6576/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 6577/17275   train_loss = 4.517\n",
      "Epoch   0 Batch 6578/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 6579/17275   train_loss = 4.133\n",
      "Epoch   0 Batch 6580/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 6581/17275   train_loss = 3.128\n",
      "Epoch   0 Batch 6582/17275   train_loss = 4.042\n",
      "Epoch   0 Batch 6583/17275   train_loss = 3.048\n",
      "Epoch   0 Batch 6584/17275   train_loss = 2.968\n",
      "Epoch   0 Batch 6585/17275   train_loss = 3.594\n",
      "Epoch   0 Batch 6586/17275   train_loss = 3.443\n",
      "Epoch   0 Batch 6587/17275   train_loss = 2.928\n",
      "Epoch   0 Batch 6588/17275   train_loss = 6.046\n",
      "Epoch   0 Batch 6589/17275   train_loss = 2.734\n",
      "Epoch   0 Batch 6590/17275   train_loss = 3.234\n",
      "Epoch   0 Batch 6591/17275   train_loss = 2.802\n",
      "Epoch   0 Batch 6592/17275   train_loss = 3.099\n",
      "Epoch   0 Batch 6593/17275   train_loss = 2.966\n",
      "Epoch   0 Batch 6594/17275   train_loss = 6.853\n",
      "Epoch   0 Batch 6595/17275   train_loss = 2.647\n",
      "Epoch   0 Batch 6596/17275   train_loss = 8.564\n",
      "Epoch   0 Batch 6597/17275   train_loss = 6.377\n",
      "Epoch   0 Batch 6598/17275   train_loss = 4.820\n",
      "Epoch   0 Batch 6599/17275   train_loss = 3.120\n",
      "Epoch   0 Batch 6600/17275   train_loss = 2.609\n",
      "Epoch   0 Batch 6601/17275   train_loss = 5.932\n",
      "Epoch   0 Batch 6602/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 6603/17275   train_loss = 3.188\n",
      "Epoch   0 Batch 6604/17275   train_loss = 3.076\n",
      "Epoch   0 Batch 6605/17275   train_loss = 5.593\n",
      "Epoch   0 Batch 6606/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 6607/17275   train_loss = 2.193\n",
      "Epoch   0 Batch 6608/17275   train_loss = 2.431\n",
      "Epoch   0 Batch 6609/17275   train_loss = 5.913\n",
      "Epoch   0 Batch 6610/17275   train_loss = 3.111\n",
      "Epoch   0 Batch 6611/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 6612/17275   train_loss = 2.421\n",
      "Epoch   0 Batch 6613/17275   train_loss = 3.051\n",
      "Epoch   0 Batch 6614/17275   train_loss = 2.503\n",
      "Epoch   0 Batch 6615/17275   train_loss = 2.694\n",
      "Epoch   0 Batch 6616/17275   train_loss = 2.303\n",
      "Epoch   0 Batch 6617/17275   train_loss = 3.323\n",
      "Epoch   0 Batch 6618/17275   train_loss = 2.926\n",
      "Epoch   0 Batch 6619/17275   train_loss = 2.280\n",
      "Epoch   0 Batch 6620/17275   train_loss = 5.899\n",
      "Epoch   0 Batch 6621/17275   train_loss = 3.413\n",
      "Epoch   0 Batch 6622/17275   train_loss = 2.496\n",
      "Epoch   0 Batch 6623/17275   train_loss = 2.224\n",
      "Epoch   0 Batch 6624/17275   train_loss = 3.751\n",
      "Epoch   0 Batch 6625/17275   train_loss = 6.726\n",
      "Epoch   0 Batch 6626/17275   train_loss = 3.914\n",
      "Epoch   0 Batch 6627/17275   train_loss = 1.891\n",
      "Epoch   0 Batch 6628/17275   train_loss = 2.984\n",
      "Epoch   0 Batch 6629/17275   train_loss = 2.991\n",
      "Epoch   0 Batch 6630/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 6631/17275   train_loss = 3.426\n",
      "Epoch   0 Batch 6632/17275   train_loss = 4.776\n",
      "Epoch   0 Batch 6633/17275   train_loss = 4.111\n",
      "Epoch   0 Batch 6634/17275   train_loss = 2.190\n",
      "Epoch   0 Batch 6635/17275   train_loss = 4.064\n",
      "Epoch   0 Batch 6636/17275   train_loss = 2.932\n",
      "Epoch   0 Batch 6637/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 6638/17275   train_loss = 4.047\n",
      "Epoch   0 Batch 6639/17275   train_loss = 6.637\n",
      "Epoch   0 Batch 6640/17275   train_loss = 2.709\n",
      "Epoch   0 Batch 6641/17275   train_loss = 5.656\n",
      "Epoch   0 Batch 6642/17275   train_loss = 5.882\n",
      "Epoch   0 Batch 6643/17275   train_loss = 3.820\n",
      "Epoch   0 Batch 6644/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 6645/17275   train_loss = 2.375\n",
      "Epoch   0 Batch 6646/17275   train_loss = 2.169\n",
      "Epoch   0 Batch 6647/17275   train_loss = 3.126\n",
      "Epoch   0 Batch 6648/17275   train_loss = 3.737\n",
      "Epoch   0 Batch 6649/17275   train_loss = 3.329\n",
      "Epoch   0 Batch 6650/17275   train_loss = 2.521\n",
      "Epoch   0 Batch 6651/17275   train_loss = 9.472\n",
      "Epoch   0 Batch 6652/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 6653/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 6654/17275   train_loss = 6.339\n",
      "Epoch   0 Batch 6655/17275   train_loss = 2.433\n",
      "Epoch   0 Batch 6656/17275   train_loss = 5.163\n",
      "Epoch   0 Batch 6657/17275   train_loss = 4.361\n",
      "Epoch   0 Batch 6658/17275   train_loss = 5.806\n",
      "Epoch   0 Batch 6659/17275   train_loss = 2.592\n",
      "Epoch   0 Batch 6660/17275   train_loss = 2.567\n",
      "Epoch   0 Batch 6661/17275   train_loss = 3.308\n",
      "Epoch   0 Batch 6662/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 6663/17275   train_loss = 3.726\n",
      "Epoch   0 Batch 6664/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 6665/17275   train_loss = 5.760\n",
      "Epoch   0 Batch 6666/17275   train_loss = 3.601\n",
      "Epoch   0 Batch 6667/17275   train_loss = 3.200\n",
      "Epoch   0 Batch 6668/17275   train_loss = 3.001\n",
      "Epoch   0 Batch 6669/17275   train_loss = 6.170\n",
      "Epoch   0 Batch 6670/17275   train_loss = 2.168\n",
      "Epoch   0 Batch 6671/17275   train_loss = 4.718\n",
      "Epoch   0 Batch 6672/17275   train_loss = 6.191\n",
      "Epoch   0 Batch 6673/17275   train_loss = 5.019\n",
      "Epoch   0 Batch 6674/17275   train_loss = 2.209\n",
      "Epoch   0 Batch 6675/17275   train_loss = 1.998\n",
      "Epoch   0 Batch 6676/17275   train_loss = 3.037\n",
      "Epoch   0 Batch 6677/17275   train_loss = 4.325\n",
      "Epoch   0 Batch 6678/17275   train_loss = 3.013\n",
      "Epoch   0 Batch 6679/17275   train_loss = 8.724\n",
      "Epoch   0 Batch 6680/17275   train_loss = 5.685\n",
      "Epoch   0 Batch 6681/17275   train_loss = 4.583\n",
      "Epoch   0 Batch 6682/17275   train_loss = 2.807\n",
      "Epoch   0 Batch 6683/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 6684/17275   train_loss = 4.601\n",
      "Epoch   0 Batch 6685/17275   train_loss = 2.861\n",
      "Epoch   0 Batch 6686/17275   train_loss = 3.367\n",
      "Epoch   0 Batch 6687/17275   train_loss = 3.863\n",
      "Epoch   0 Batch 6688/17275   train_loss = 4.993\n",
      "Epoch   0 Batch 6689/17275   train_loss = 2.506\n",
      "Epoch   0 Batch 6690/17275   train_loss = 3.928\n",
      "Epoch   0 Batch 6691/17275   train_loss = 6.448\n",
      "Epoch   0 Batch 6692/17275   train_loss = 2.335\n",
      "Epoch   0 Batch 6693/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 6694/17275   train_loss = 7.130\n",
      "Epoch   0 Batch 6695/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 6696/17275   train_loss = 5.024\n",
      "Epoch   0 Batch 6697/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 6698/17275   train_loss = 3.632\n",
      "Epoch   0 Batch 6699/17275   train_loss = 5.078\n",
      "Epoch   0 Batch 6700/17275   train_loss = 2.768\n",
      "Epoch   0 Batch 6701/17275   train_loss = 7.825\n",
      "Epoch   0 Batch 6702/17275   train_loss = 1.882\n",
      "Epoch   0 Batch 6703/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 6704/17275   train_loss = 5.964\n",
      "Epoch   0 Batch 6705/17275   train_loss = 3.947\n",
      "Epoch   0 Batch 6706/17275   train_loss = 3.612\n",
      "Epoch   0 Batch 6707/17275   train_loss = 3.504\n",
      "Epoch   0 Batch 6708/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 6709/17275   train_loss = 3.651\n",
      "Epoch   0 Batch 6710/17275   train_loss = 4.109\n",
      "Epoch   0 Batch 6711/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 6712/17275   train_loss = 3.246\n",
      "Epoch   0 Batch 6713/17275   train_loss = 2.348\n",
      "Epoch   0 Batch 6714/17275   train_loss = 3.873\n",
      "Epoch   0 Batch 6715/17275   train_loss = 2.061\n",
      "Epoch   0 Batch 6716/17275   train_loss = 3.928\n",
      "Epoch   0 Batch 6717/17275   train_loss = 4.251\n",
      "Epoch   0 Batch 6718/17275   train_loss = 2.649\n",
      "Epoch   0 Batch 6719/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 6720/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 6721/17275   train_loss = 2.272\n",
      "Epoch   0 Batch 6722/17275   train_loss = 2.648\n",
      "Epoch   0 Batch 6723/17275   train_loss = 5.848\n",
      "Epoch   0 Batch 6724/17275   train_loss = 3.216\n",
      "Epoch   0 Batch 6725/17275   train_loss = 2.897\n",
      "Epoch   0 Batch 6726/17275   train_loss = 4.371\n",
      "Epoch   0 Batch 6727/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 6728/17275   train_loss = 4.730\n",
      "Epoch   0 Batch 6729/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 6730/17275   train_loss = 8.414\n",
      "Epoch   0 Batch 6731/17275   train_loss = 5.669\n",
      "Epoch   0 Batch 6732/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 6733/17275   train_loss = 3.557\n",
      "Epoch   0 Batch 6734/17275   train_loss = 4.495\n",
      "Epoch   0 Batch 6735/17275   train_loss = 6.895\n",
      "Epoch   0 Batch 6736/17275   train_loss = 6.669\n",
      "Epoch   0 Batch 6737/17275   train_loss = 5.662\n",
      "Epoch   0 Batch 6738/17275   train_loss = 3.584\n",
      "Epoch   0 Batch 6739/17275   train_loss = 6.171\n",
      "Epoch   0 Batch 6740/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 6741/17275   train_loss = 4.282\n",
      "Epoch   0 Batch 6742/17275   train_loss = 3.394\n",
      "Epoch   0 Batch 6743/17275   train_loss = 1.942\n",
      "Epoch   0 Batch 6744/17275   train_loss = 2.426\n",
      "Epoch   0 Batch 6745/17275   train_loss = 1.876\n",
      "Epoch   0 Batch 6746/17275   train_loss = 2.401\n",
      "Epoch   0 Batch 6747/17275   train_loss = 6.110\n",
      "Epoch   0 Batch 6748/17275   train_loss = 9.459\n",
      "Epoch   0 Batch 6749/17275   train_loss = 6.825\n",
      "Epoch   0 Batch 6750/17275   train_loss = 2.406\n",
      "Epoch   0 Batch 6751/17275   train_loss = 2.670\n",
      "Epoch   0 Batch 6752/17275   train_loss = 6.509\n",
      "Epoch   0 Batch 6753/17275   train_loss = 3.329\n",
      "Epoch   0 Batch 6754/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 6755/17275   train_loss = 2.779\n",
      "Epoch   0 Batch 6756/17275   train_loss = 5.755\n",
      "Epoch   0 Batch 6757/17275   train_loss = 8.976\n",
      "Epoch   0 Batch 6758/17275   train_loss = 5.159\n",
      "Epoch   0 Batch 6759/17275   train_loss = 2.290\n",
      "Epoch   0 Batch 6760/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 6761/17275   train_loss = 5.873\n",
      "Epoch   0 Batch 6762/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 6763/17275   train_loss = 2.623\n",
      "Epoch   0 Batch 6764/17275   train_loss = 5.646\n",
      "Epoch   0 Batch 6765/17275   train_loss = 3.012\n",
      "Epoch   0 Batch 6766/17275   train_loss = 3.949\n",
      "Epoch   0 Batch 6767/17275   train_loss = 6.172\n",
      "Epoch   0 Batch 6768/17275   train_loss = 5.963\n",
      "Epoch   0 Batch 6769/17275   train_loss = 5.964\n",
      "Epoch   0 Batch 6770/17275   train_loss = 6.126\n",
      "Epoch   0 Batch 6771/17275   train_loss = 2.716\n",
      "Epoch   0 Batch 6772/17275   train_loss = 6.164\n",
      "Epoch   0 Batch 6773/17275   train_loss = 9.462\n",
      "Epoch   0 Batch 6774/17275   train_loss = 6.554\n",
      "Epoch   0 Batch 6775/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 6776/17275   train_loss = 3.940\n",
      "Epoch   0 Batch 6777/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 6778/17275   train_loss = 5.516\n",
      "Epoch   0 Batch 6779/17275   train_loss = 2.329\n",
      "Epoch   0 Batch 6780/17275   train_loss = 3.030\n",
      "Epoch   0 Batch 6781/17275   train_loss = 2.936\n",
      "Epoch   0 Batch 6782/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 6783/17275   train_loss = 6.531\n",
      "Epoch   0 Batch 6784/17275   train_loss = 9.439\n",
      "Epoch   0 Batch 6785/17275   train_loss = 4.396\n",
      "Epoch   0 Batch 6786/17275   train_loss = 6.123\n",
      "Epoch   0 Batch 6787/17275   train_loss = 6.693\n",
      "Epoch   0 Batch 6788/17275   train_loss = 4.726\n",
      "Epoch   0 Batch 6789/17275   train_loss = 2.188\n",
      "Epoch   0 Batch 6790/17275   train_loss = 7.075\n",
      "Epoch   0 Batch 6791/17275   train_loss = 3.492\n",
      "Epoch   0 Batch 6792/17275   train_loss = 9.422\n",
      "Epoch   0 Batch 6793/17275   train_loss = 4.200\n",
      "Epoch   0 Batch 6794/17275   train_loss = 7.056\n",
      "Epoch   0 Batch 6795/17275   train_loss = 9.411\n",
      "Epoch   0 Batch 6796/17275   train_loss = 2.467\n",
      "Epoch   0 Batch 6797/17275   train_loss = 3.541\n",
      "Epoch   0 Batch 6798/17275   train_loss = 3.902\n",
      "Epoch   0 Batch 6799/17275   train_loss = 2.664\n",
      "Epoch   0 Batch 6800/17275   train_loss = 2.080\n",
      "Epoch   0 Batch 6801/17275   train_loss = 3.071\n",
      "Epoch   0 Batch 6802/17275   train_loss = 3.224\n",
      "Epoch   0 Batch 6803/17275   train_loss = 5.698\n",
      "Epoch   0 Batch 6804/17275   train_loss = 2.611\n",
      "Epoch   0 Batch 6805/17275   train_loss = 3.475\n",
      "Epoch   0 Batch 6806/17275   train_loss = 4.919\n",
      "Epoch   0 Batch 6807/17275   train_loss = 4.775\n",
      "Epoch   0 Batch 6808/17275   train_loss = 3.556\n",
      "Epoch   0 Batch 6809/17275   train_loss = 5.647\n",
      "Epoch   0 Batch 6810/17275   train_loss = 3.374\n",
      "Epoch   0 Batch 6811/17275   train_loss = 3.746\n",
      "Epoch   0 Batch 6812/17275   train_loss = 3.491\n",
      "Epoch   0 Batch 6813/17275   train_loss = 2.536\n",
      "Epoch   0 Batch 6814/17275   train_loss = 3.094\n",
      "Epoch   0 Batch 6815/17275   train_loss = 5.873\n",
      "Epoch   0 Batch 6816/17275   train_loss = 2.854\n",
      "Epoch   0 Batch 6817/17275   train_loss = 1.995\n",
      "Epoch   0 Batch 6818/17275   train_loss = 2.911\n",
      "Epoch   0 Batch 6819/17275   train_loss = 3.698\n",
      "Epoch   0 Batch 6820/17275   train_loss = 4.622\n",
      "Epoch   0 Batch 6821/17275   train_loss = 3.637\n",
      "Epoch   0 Batch 6822/17275   train_loss = 4.904\n",
      "Epoch   0 Batch 6823/17275   train_loss = 4.055\n",
      "Epoch   0 Batch 6824/17275   train_loss = 5.661\n",
      "Epoch   0 Batch 6825/17275   train_loss = 5.992\n",
      "Epoch   0 Batch 6826/17275   train_loss = 6.694\n",
      "Epoch   0 Batch 6827/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 6828/17275   train_loss = 2.357\n",
      "Epoch   0 Batch 6829/17275   train_loss = 4.273\n",
      "Epoch   0 Batch 6830/17275   train_loss = 3.947\n",
      "Epoch   0 Batch 6831/17275   train_loss = 3.984\n",
      "Epoch   0 Batch 6832/17275   train_loss = 6.938\n",
      "Epoch   0 Batch 6833/17275   train_loss = 3.802\n",
      "Epoch   0 Batch 6834/17275   train_loss = 3.396\n",
      "Epoch   0 Batch 6835/17275   train_loss = 4.840\n",
      "Epoch   0 Batch 6836/17275   train_loss = 9.418\n",
      "Epoch   0 Batch 6837/17275   train_loss = 2.557\n",
      "Epoch   0 Batch 6838/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 6839/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 6840/17275   train_loss = 4.567\n",
      "Epoch   0 Batch 6841/17275   train_loss = 4.229\n",
      "Epoch   0 Batch 6842/17275   train_loss = 5.889\n",
      "Epoch   0 Batch 6843/17275   train_loss = 5.660\n",
      "Epoch   0 Batch 6844/17275   train_loss = 3.811\n",
      "Epoch   0 Batch 6845/17275   train_loss = 5.871\n",
      "Epoch   0 Batch 6846/17275   train_loss = 6.522\n",
      "Epoch   0 Batch 6847/17275   train_loss = 2.499\n",
      "Epoch   0 Batch 6848/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 6849/17275   train_loss = 3.155\n",
      "Epoch   0 Batch 6850/17275   train_loss = 2.749\n",
      "Epoch   0 Batch 6851/17275   train_loss = 2.532\n",
      "Epoch   0 Batch 6852/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 6853/17275   train_loss = 6.591\n",
      "Epoch   0 Batch 6854/17275   train_loss = 5.259\n",
      "Epoch   0 Batch 6855/17275   train_loss = 2.982\n",
      "Epoch   0 Batch 6856/17275   train_loss = 5.384\n",
      "Epoch   0 Batch 6857/17275   train_loss = 5.652\n",
      "Epoch   0 Batch 6858/17275   train_loss = 3.350\n",
      "Epoch   0 Batch 6859/17275   train_loss = 4.709\n",
      "Epoch   0 Batch 6860/17275   train_loss = 3.946\n",
      "Epoch   0 Batch 6861/17275   train_loss = 3.287\n",
      "Epoch   0 Batch 6862/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 6863/17275   train_loss = 5.707\n",
      "Epoch   0 Batch 6864/17275   train_loss = 4.050\n",
      "Epoch   0 Batch 6865/17275   train_loss = 6.021\n",
      "Epoch   0 Batch 6866/17275   train_loss = 4.504\n",
      "Epoch   0 Batch 6867/17275   train_loss = 2.473\n",
      "Epoch   0 Batch 6868/17275   train_loss = 2.981\n",
      "Epoch   0 Batch 6869/17275   train_loss = 6.268\n",
      "Epoch   0 Batch 6870/17275   train_loss = 6.151\n",
      "Epoch   0 Batch 6871/17275   train_loss = 3.180\n",
      "Epoch   0 Batch 6872/17275   train_loss = 2.669\n",
      "Epoch   0 Batch 6873/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 6874/17275   train_loss = 2.887\n",
      "Epoch   0 Batch 6875/17275   train_loss = 7.668\n",
      "Epoch   0 Batch 6876/17275   train_loss = 3.395\n",
      "Epoch   0 Batch 6877/17275   train_loss = 6.669\n",
      "Epoch   0 Batch 6878/17275   train_loss = 5.795\n",
      "Epoch   0 Batch 6879/17275   train_loss = 3.678\n",
      "Epoch   0 Batch 6880/17275   train_loss = 4.441\n",
      "Epoch   0 Batch 6881/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 6882/17275   train_loss = 3.791\n",
      "Epoch   0 Batch 6883/17275   train_loss = 3.873\n",
      "Epoch   0 Batch 6884/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 6885/17275   train_loss = 3.929\n",
      "Epoch   0 Batch 6886/17275   train_loss = 3.053\n",
      "Epoch   0 Batch 6887/17275   train_loss = 2.851\n",
      "Epoch   0 Batch 6888/17275   train_loss = 3.987\n",
      "Epoch   0 Batch 6889/17275   train_loss = 4.693\n",
      "Epoch   0 Batch 6890/17275   train_loss = 5.784\n",
      "Epoch   0 Batch 6891/17275   train_loss = 2.422\n",
      "Epoch   0 Batch 6892/17275   train_loss = 2.718\n",
      "Epoch   0 Batch 6893/17275   train_loss = 3.023\n",
      "Epoch   0 Batch 6894/17275   train_loss = 3.863\n",
      "Epoch   0 Batch 6895/17275   train_loss = 4.080\n",
      "Epoch   0 Batch 6896/17275   train_loss = 6.032\n",
      "Epoch   0 Batch 6897/17275   train_loss = 3.159\n",
      "Epoch   0 Batch 6898/17275   train_loss = 3.392\n",
      "Epoch   0 Batch 6899/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 6900/17275   train_loss = 3.467\n",
      "Epoch   0 Batch 6901/17275   train_loss = 2.362\n",
      "Epoch   0 Batch 6902/17275   train_loss = 4.135\n",
      "Epoch   0 Batch 6903/17275   train_loss = 6.815\n",
      "Epoch   0 Batch 6904/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 6905/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 6906/17275   train_loss = 3.522\n",
      "Epoch   0 Batch 6907/17275   train_loss = 4.098\n",
      "Epoch   0 Batch 6908/17275   train_loss = 6.110\n",
      "Epoch   0 Batch 6909/17275   train_loss = 3.928\n",
      "Epoch   0 Batch 6910/17275   train_loss = 2.580\n",
      "Epoch   0 Batch 6911/17275   train_loss = 2.830\n",
      "Epoch   0 Batch 6912/17275   train_loss = 3.443\n",
      "Epoch   0 Batch 6913/17275   train_loss = 3.563\n",
      "Epoch   0 Batch 6914/17275   train_loss = 2.947\n",
      "Epoch   0 Batch 6915/17275   train_loss = 3.825\n",
      "Epoch   0 Batch 6916/17275   train_loss = 6.023\n",
      "Epoch   0 Batch 6917/17275   train_loss = 6.403\n",
      "Epoch   0 Batch 6918/17275   train_loss = 3.223\n",
      "Epoch   0 Batch 6919/17275   train_loss = 4.060\n",
      "Epoch   0 Batch 6920/17275   train_loss = 4.010\n",
      "Epoch   0 Batch 6921/17275   train_loss = 5.952\n",
      "Epoch   0 Batch 6922/17275   train_loss = 6.241\n",
      "Epoch   0 Batch 6923/17275   train_loss = 2.535\n",
      "Epoch   0 Batch 6924/17275   train_loss = 3.802\n",
      "Epoch   0 Batch 6925/17275   train_loss = 2.845\n",
      "Epoch   0 Batch 6926/17275   train_loss = 3.646\n",
      "Epoch   0 Batch 6927/17275   train_loss = 5.162\n",
      "Epoch   0 Batch 6928/17275   train_loss = 5.854\n",
      "Epoch   0 Batch 6929/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 6930/17275   train_loss = 4.186\n",
      "Epoch   0 Batch 6931/17275   train_loss = 2.912\n",
      "Epoch   0 Batch 6932/17275   train_loss = 2.781\n",
      "Epoch   0 Batch 6933/17275   train_loss = 5.971\n",
      "Epoch   0 Batch 6934/17275   train_loss = 6.488\n",
      "Epoch   0 Batch 6935/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 6936/17275   train_loss = 3.040\n",
      "Epoch   0 Batch 6937/17275   train_loss = 2.722\n",
      "Epoch   0 Batch 6938/17275   train_loss = 3.014\n",
      "Epoch   0 Batch 6939/17275   train_loss = 3.895\n",
      "Epoch   0 Batch 6940/17275   train_loss = 4.207\n",
      "Epoch   0 Batch 6941/17275   train_loss = 4.342\n",
      "Epoch   0 Batch 6942/17275   train_loss = 3.439\n",
      "Epoch   0 Batch 6943/17275   train_loss = 6.166\n",
      "Epoch   0 Batch 6944/17275   train_loss = 3.264\n",
      "Epoch   0 Batch 6945/17275   train_loss = 6.465\n",
      "Epoch   0 Batch 6946/17275   train_loss = 4.332\n",
      "Epoch   0 Batch 6947/17275   train_loss = 2.427\n",
      "Epoch   0 Batch 6948/17275   train_loss = 3.396\n",
      "Epoch   0 Batch 6949/17275   train_loss = 4.077\n",
      "Epoch   0 Batch 6950/17275   train_loss = 9.471\n",
      "Epoch   0 Batch 6951/17275   train_loss = 6.054\n",
      "Epoch   0 Batch 6952/17275   train_loss = 2.031\n",
      "Epoch   0 Batch 6953/17275   train_loss = 2.232\n",
      "Epoch   0 Batch 6954/17275   train_loss = 6.112\n",
      "Epoch   0 Batch 6955/17275   train_loss = 3.213\n",
      "Epoch   0 Batch 6956/17275   train_loss = 4.934\n",
      "Epoch   0 Batch 6957/17275   train_loss = 2.977\n",
      "Epoch   0 Batch 6958/17275   train_loss = 2.327\n",
      "Epoch   0 Batch 6959/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 6960/17275   train_loss = 3.754\n",
      "Epoch   0 Batch 6961/17275   train_loss = 6.261\n",
      "Epoch   0 Batch 6962/17275   train_loss = 3.527\n",
      "Epoch   0 Batch 6963/17275   train_loss = 3.953\n",
      "Epoch   0 Batch 6964/17275   train_loss = 5.911\n",
      "Epoch   0 Batch 6965/17275   train_loss = 2.834\n",
      "Epoch   0 Batch 6966/17275   train_loss = 4.430\n",
      "Epoch   0 Batch 6967/17275   train_loss = 6.596\n",
      "Epoch   0 Batch 6968/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 6969/17275   train_loss = 2.039\n",
      "Epoch   0 Batch 6970/17275   train_loss = 3.446\n",
      "Epoch   0 Batch 6971/17275   train_loss = 2.859\n",
      "Epoch   0 Batch 6972/17275   train_loss = 6.140\n",
      "Epoch   0 Batch 6973/17275   train_loss = 3.032\n",
      "Epoch   0 Batch 6974/17275   train_loss = 2.655\n",
      "Epoch   0 Batch 6975/17275   train_loss = 5.079\n",
      "Epoch   0 Batch 6976/17275   train_loss = 3.467\n",
      "Epoch   0 Batch 6977/17275   train_loss = 3.339\n",
      "Epoch   0 Batch 6978/17275   train_loss = 5.176\n",
      "Epoch   0 Batch 6979/17275   train_loss = 4.725\n",
      "Epoch   0 Batch 6980/17275   train_loss = 4.852\n",
      "Epoch   0 Batch 6981/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 6982/17275   train_loss = 4.925\n",
      "Epoch   0 Batch 6983/17275   train_loss = 2.033\n",
      "Epoch   0 Batch 6984/17275   train_loss = 2.725\n",
      "Epoch   0 Batch 6985/17275   train_loss = 4.705\n",
      "Epoch   0 Batch 6986/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 6987/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 6988/17275   train_loss = 6.877\n",
      "Epoch   0 Batch 6989/17275   train_loss = 2.802\n",
      "Epoch   0 Batch 6990/17275   train_loss = 2.224\n",
      "Epoch   0 Batch 6991/17275   train_loss = 2.564\n",
      "Epoch   0 Batch 6992/17275   train_loss = 4.455\n",
      "Epoch   0 Batch 6993/17275   train_loss = 2.858\n",
      "Epoch   0 Batch 6994/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 6995/17275   train_loss = 7.256\n",
      "Epoch   0 Batch 6996/17275   train_loss = 3.627\n",
      "Epoch   0 Batch 6997/17275   train_loss = 2.793\n",
      "Epoch   0 Batch 6998/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 6999/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 7000/17275   train_loss = 2.911\n",
      "Epoch   0 Batch 7001/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 7002/17275   train_loss = 6.305\n",
      "Epoch   0 Batch 7003/17275   train_loss = 6.285\n",
      "Epoch   0 Batch 7004/17275   train_loss = 2.092\n",
      "Epoch   0 Batch 7005/17275   train_loss = 3.216\n",
      "Epoch   0 Batch 7006/17275   train_loss = 3.713\n",
      "Epoch   0 Batch 7007/17275   train_loss = 9.516\n",
      "Epoch   0 Batch 7008/17275   train_loss = 5.655\n",
      "Epoch   0 Batch 7009/17275   train_loss = 5.651\n",
      "Epoch   0 Batch 7010/17275   train_loss = 7.670\n",
      "Epoch   0 Batch 7011/17275   train_loss = 2.042\n",
      "Epoch   0 Batch 7012/17275   train_loss = 2.710\n",
      "Epoch   0 Batch 7013/17275   train_loss = 2.699\n",
      "Epoch   0 Batch 7014/17275   train_loss = 6.381\n",
      "Epoch   0 Batch 7015/17275   train_loss = 8.936\n",
      "Epoch   0 Batch 7016/17275   train_loss = 5.604\n",
      "Epoch   0 Batch 7017/17275   train_loss = 3.538\n",
      "Epoch   0 Batch 7018/17275   train_loss = 6.820\n",
      "Epoch   0 Batch 7019/17275   train_loss = 4.632\n",
      "Epoch   0 Batch 7020/17275   train_loss = 4.023\n",
      "Epoch   0 Batch 7021/17275   train_loss = 4.102\n",
      "Epoch   0 Batch 7022/17275   train_loss = 2.466\n",
      "Epoch   0 Batch 7023/17275   train_loss = 2.933\n",
      "Epoch   0 Batch 7024/17275   train_loss = 4.486\n",
      "Epoch   0 Batch 7025/17275   train_loss = 3.727\n",
      "Epoch   0 Batch 7026/17275   train_loss = 3.342\n",
      "Epoch   0 Batch 7027/17275   train_loss = 2.506\n",
      "Epoch   0 Batch 7028/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 7029/17275   train_loss = 6.077\n",
      "Epoch   0 Batch 7030/17275   train_loss = 2.553\n",
      "Epoch   0 Batch 7031/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 7032/17275   train_loss = 2.829\n",
      "Epoch   0 Batch 7033/17275   train_loss = 3.388\n",
      "Epoch   0 Batch 7034/17275   train_loss = 2.401\n",
      "Epoch   0 Batch 7035/17275   train_loss = 2.824\n",
      "Epoch   0 Batch 7036/17275   train_loss = 4.128\n",
      "Epoch   0 Batch 7037/17275   train_loss = 6.311\n",
      "Epoch   0 Batch 7038/17275   train_loss = 4.118\n",
      "Epoch   0 Batch 7039/17275   train_loss = 6.342\n",
      "Epoch   0 Batch 7040/17275   train_loss = 2.994\n",
      "Epoch   0 Batch 7041/17275   train_loss = 4.092\n",
      "Epoch   0 Batch 7042/17275   train_loss = 5.837\n",
      "Epoch   0 Batch 7043/17275   train_loss = 3.605\n",
      "Epoch   0 Batch 7044/17275   train_loss = 3.489\n",
      "Epoch   0 Batch 7045/17275   train_loss = 4.272\n",
      "Epoch   0 Batch 7046/17275   train_loss = 3.869\n",
      "Epoch   0 Batch 7047/17275   train_loss = 6.151\n",
      "Epoch   0 Batch 7048/17275   train_loss = 5.695\n",
      "Epoch   0 Batch 7049/17275   train_loss = 2.838\n",
      "Epoch   0 Batch 7050/17275   train_loss = 5.488\n",
      "Epoch   0 Batch 7051/17275   train_loss = 3.029\n",
      "Epoch   0 Batch 7052/17275   train_loss = 4.160\n",
      "Epoch   0 Batch 7053/17275   train_loss = 2.501\n",
      "Epoch   0 Batch 7054/17275   train_loss = 3.130\n",
      "Epoch   0 Batch 7055/17275   train_loss = 3.424\n",
      "Epoch   0 Batch 7056/17275   train_loss = 5.361\n",
      "Epoch   0 Batch 7057/17275   train_loss = 4.579\n",
      "Epoch   0 Batch 7058/17275   train_loss = 4.001\n",
      "Epoch   0 Batch 7059/17275   train_loss = 4.119\n",
      "Epoch   0 Batch 7060/17275   train_loss = 2.551\n",
      "Epoch   0 Batch 7061/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 7062/17275   train_loss = 5.248\n",
      "Epoch   0 Batch 7063/17275   train_loss = 4.427\n",
      "Epoch   0 Batch 7064/17275   train_loss = 2.111\n",
      "Epoch   0 Batch 7065/17275   train_loss = 2.179\n",
      "Epoch   0 Batch 7066/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 7067/17275   train_loss = 6.246\n",
      "Epoch   0 Batch 7068/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 7069/17275   train_loss = 2.857\n",
      "Epoch   0 Batch 7070/17275   train_loss = 6.051\n",
      "Epoch   0 Batch 7071/17275   train_loss = 2.018\n",
      "Epoch   0 Batch 7072/17275   train_loss = 2.584\n",
      "Epoch   0 Batch 7073/17275   train_loss = 2.835\n",
      "Epoch   0 Batch 7074/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 7075/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 7076/17275   train_loss = 3.080\n",
      "Epoch   0 Batch 7077/17275   train_loss = 3.508\n",
      "Epoch   0 Batch 7078/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 7079/17275   train_loss = 3.661\n",
      "Epoch   0 Batch 7080/17275   train_loss = 4.322\n",
      "Epoch   0 Batch 7081/17275   train_loss = 5.420\n",
      "Epoch   0 Batch 7082/17275   train_loss = 5.876\n",
      "Epoch   0 Batch 7083/17275   train_loss = 5.491\n",
      "Epoch   0 Batch 7084/17275   train_loss = 8.047\n",
      "Epoch   0 Batch 7085/17275   train_loss = 3.767\n",
      "Epoch   0 Batch 7086/17275   train_loss = 2.232\n",
      "Epoch   0 Batch 7087/17275   train_loss = 5.146\n",
      "Epoch   0 Batch 7088/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 7089/17275   train_loss = 4.302\n",
      "Epoch   0 Batch 7090/17275   train_loss = 5.610\n",
      "Epoch   0 Batch 7091/17275   train_loss = 4.477\n",
      "Epoch   0 Batch 7092/17275   train_loss = 6.675\n",
      "Epoch   0 Batch 7093/17275   train_loss = 5.320\n",
      "Epoch   0 Batch 7094/17275   train_loss = 3.619\n",
      "Epoch   0 Batch 7095/17275   train_loss = 3.934\n",
      "Epoch   0 Batch 7096/17275   train_loss = 3.151\n",
      "Epoch   0 Batch 7097/17275   train_loss = 6.883\n",
      "Epoch   0 Batch 7098/17275   train_loss = 5.816\n",
      "Epoch   0 Batch 7099/17275   train_loss = 3.843\n",
      "Epoch   0 Batch 7100/17275   train_loss = 2.701\n",
      "Epoch   0 Batch 7101/17275   train_loss = 4.596\n",
      "Epoch   0 Batch 7102/17275   train_loss = 5.868\n",
      "Epoch   0 Batch 7103/17275   train_loss = 4.306\n",
      "Epoch   0 Batch 7104/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 7105/17275   train_loss = 2.278\n",
      "Epoch   0 Batch 7106/17275   train_loss = 3.392\n",
      "Epoch   0 Batch 7107/17275   train_loss = 3.470\n",
      "Epoch   0 Batch 7108/17275   train_loss = 5.797\n",
      "Epoch   0 Batch 7109/17275   train_loss = 2.082\n",
      "Epoch   0 Batch 7110/17275   train_loss = 4.690\n",
      "Epoch   0 Batch 7111/17275   train_loss = 2.968\n",
      "Epoch   0 Batch 7112/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 7113/17275   train_loss = 3.609\n",
      "Epoch   0 Batch 7114/17275   train_loss = 2.752\n",
      "Epoch   0 Batch 7115/17275   train_loss = 2.623\n",
      "Epoch   0 Batch 7116/17275   train_loss = 7.104\n",
      "Epoch   0 Batch 7117/17275   train_loss = 1.964\n",
      "Epoch   0 Batch 7118/17275   train_loss = 3.161\n",
      "Epoch   0 Batch 7119/17275   train_loss = 6.804\n",
      "Epoch   0 Batch 7120/17275   train_loss = 2.129\n",
      "Epoch   0 Batch 7121/17275   train_loss = 7.082\n",
      "Epoch   0 Batch 7122/17275   train_loss = 9.517\n",
      "Epoch   0 Batch 7123/17275   train_loss = 2.203\n",
      "Epoch   0 Batch 7124/17275   train_loss = 2.973\n",
      "Epoch   0 Batch 7125/17275   train_loss = 5.952\n",
      "Epoch   0 Batch 7126/17275   train_loss = 3.054\n",
      "Epoch   0 Batch 7127/17275   train_loss = 3.084\n",
      "Epoch   0 Batch 7128/17275   train_loss = 3.671\n",
      "Epoch   0 Batch 7129/17275   train_loss = 2.721\n",
      "Epoch   0 Batch 7130/17275   train_loss = 1.806\n",
      "Epoch   0 Batch 7131/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 7132/17275   train_loss = 5.333\n",
      "Epoch   0 Batch 7133/17275   train_loss = 4.538\n",
      "Epoch   0 Batch 7134/17275   train_loss = 2.455\n",
      "Epoch   0 Batch 7135/17275   train_loss = 3.078\n",
      "Epoch   0 Batch 7136/17275   train_loss = 9.545\n",
      "Epoch   0 Batch 7137/17275   train_loss = 2.296\n",
      "Epoch   0 Batch 7138/17275   train_loss = 5.911\n",
      "Epoch   0 Batch 7139/17275   train_loss = 5.911\n",
      "Epoch   0 Batch 7140/17275   train_loss = 7.477\n",
      "Epoch   0 Batch 7141/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 7142/17275   train_loss = 7.190\n",
      "Epoch   0 Batch 7143/17275   train_loss = 3.859\n",
      "Epoch   0 Batch 7144/17275   train_loss = 6.713\n",
      "Epoch   0 Batch 7145/17275   train_loss = 4.865\n",
      "Epoch   0 Batch 7146/17275   train_loss = 6.981\n",
      "Epoch   0 Batch 7147/17275   train_loss = 6.716\n",
      "Epoch   0 Batch 7148/17275   train_loss = 6.805\n",
      "Epoch   0 Batch 7149/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 7150/17275   train_loss = 5.646\n",
      "Epoch   0 Batch 7151/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 7152/17275   train_loss = 1.919\n",
      "Epoch   0 Batch 7153/17275   train_loss = 1.993\n",
      "Epoch   0 Batch 7154/17275   train_loss = 6.182\n",
      "Epoch   0 Batch 7155/17275   train_loss = 3.180\n",
      "Epoch   0 Batch 7156/17275   train_loss = 8.113\n",
      "Epoch   0 Batch 7157/17275   train_loss = 2.644\n",
      "Epoch   0 Batch 7158/17275   train_loss = 6.039\n",
      "Epoch   0 Batch 7159/17275   train_loss = 8.649\n",
      "Epoch   0 Batch 7160/17275   train_loss = 2.454\n",
      "Epoch   0 Batch 7161/17275   train_loss = 5.954\n",
      "Epoch   0 Batch 7162/17275   train_loss = 6.039\n",
      "Epoch   0 Batch 7163/17275   train_loss = 2.959\n",
      "Epoch   0 Batch 7164/17275   train_loss = 6.035\n",
      "Epoch   0 Batch 7165/17275   train_loss = 6.970\n",
      "Epoch   0 Batch 7166/17275   train_loss = 3.664\n",
      "Epoch   0 Batch 7167/17275   train_loss = 2.196\n",
      "Epoch   0 Batch 7168/17275   train_loss = 3.335\n",
      "Epoch   0 Batch 7169/17275   train_loss = 5.105\n",
      "Epoch   0 Batch 7170/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 7171/17275   train_loss = 2.549\n",
      "Epoch   0 Batch 7172/17275   train_loss = 3.457\n",
      "Epoch   0 Batch 7173/17275   train_loss = 3.958\n",
      "Epoch   0 Batch 7174/17275   train_loss = 3.260\n",
      "Epoch   0 Batch 7175/17275   train_loss = 6.050\n",
      "Epoch   0 Batch 7176/17275   train_loss = 2.105\n",
      "Epoch   0 Batch 7177/17275   train_loss = 3.263\n",
      "Epoch   0 Batch 7178/17275   train_loss = 2.666\n",
      "Epoch   0 Batch 7179/17275   train_loss = 3.994\n",
      "Epoch   0 Batch 7180/17275   train_loss = 4.678\n",
      "Epoch   0 Batch 7181/17275   train_loss = 3.777\n",
      "Epoch   0 Batch 7182/17275   train_loss = 7.171\n",
      "Epoch   0 Batch 7183/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 7184/17275   train_loss = 3.583\n",
      "Epoch   0 Batch 7185/17275   train_loss = 3.445\n",
      "Epoch   0 Batch 7186/17275   train_loss = 4.412\n",
      "Epoch   0 Batch 7187/17275   train_loss = 5.027\n",
      "Epoch   0 Batch 7188/17275   train_loss = 2.447\n",
      "Epoch   0 Batch 7189/17275   train_loss = 2.472\n",
      "Epoch   0 Batch 7190/17275   train_loss = 3.973\n",
      "Epoch   0 Batch 7191/17275   train_loss = 3.722\n",
      "Epoch   0 Batch 7192/17275   train_loss = 6.587\n",
      "Epoch   0 Batch 7193/17275   train_loss = 5.941\n",
      "Epoch   0 Batch 7194/17275   train_loss = 4.073\n",
      "Epoch   0 Batch 7195/17275   train_loss = 2.791\n",
      "Epoch   0 Batch 7196/17275   train_loss = 4.241\n",
      "Epoch   0 Batch 7197/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 7198/17275   train_loss = 6.651\n",
      "Epoch   0 Batch 7199/17275   train_loss = 2.256\n",
      "Epoch   0 Batch 7200/17275   train_loss = 3.480\n",
      "Epoch   0 Batch 7201/17275   train_loss = 3.647\n",
      "Epoch   0 Batch 7202/17275   train_loss = 3.986\n",
      "Epoch   0 Batch 7203/17275   train_loss = 2.851\n",
      "Epoch   0 Batch 7204/17275   train_loss = 6.351\n",
      "Epoch   0 Batch 7205/17275   train_loss = 3.794\n",
      "Epoch   0 Batch 7206/17275   train_loss = 4.492\n",
      "Epoch   0 Batch 7207/17275   train_loss = 5.781\n",
      "Epoch   0 Batch 7208/17275   train_loss = 2.375\n",
      "Epoch   0 Batch 7209/17275   train_loss = 6.139\n",
      "Epoch   0 Batch 7210/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 7211/17275   train_loss = 2.693\n",
      "Epoch   0 Batch 7212/17275   train_loss = 3.183\n",
      "Epoch   0 Batch 7213/17275   train_loss = 6.225\n",
      "Epoch   0 Batch 7214/17275   train_loss = 7.197\n",
      "Epoch   0 Batch 7215/17275   train_loss = 5.732\n",
      "Epoch   0 Batch 7216/17275   train_loss = 2.082\n",
      "Epoch   0 Batch 7217/17275   train_loss = 2.702\n",
      "Epoch   0 Batch 7218/17275   train_loss = 3.265\n",
      "Epoch   0 Batch 7219/17275   train_loss = 4.283\n",
      "Epoch   0 Batch 7220/17275   train_loss = 3.762\n",
      "Epoch   0 Batch 7221/17275   train_loss = 2.416\n",
      "Epoch   0 Batch 7222/17275   train_loss = 1.950\n",
      "Epoch   0 Batch 7223/17275   train_loss = 2.264\n",
      "Epoch   0 Batch 7224/17275   train_loss = 4.926\n",
      "Epoch   0 Batch 7225/17275   train_loss = 2.703\n",
      "Epoch   0 Batch 7226/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 7227/17275   train_loss = 3.040\n",
      "Epoch   0 Batch 7228/17275   train_loss = 4.521\n",
      "Epoch   0 Batch 7229/17275   train_loss = 5.179\n",
      "Epoch   0 Batch 7230/17275   train_loss = 5.175\n",
      "Epoch   0 Batch 7231/17275   train_loss = 6.508\n",
      "Epoch   0 Batch 7232/17275   train_loss = 4.948\n",
      "Epoch   0 Batch 7233/17275   train_loss = 3.161\n",
      "Epoch   0 Batch 7234/17275   train_loss = 2.454\n",
      "Epoch   0 Batch 7235/17275   train_loss = 6.159\n",
      "Epoch   0 Batch 7236/17275   train_loss = 3.271\n",
      "Epoch   0 Batch 7237/17275   train_loss = 5.958\n",
      "Epoch   0 Batch 7238/17275   train_loss = 2.020\n",
      "Epoch   0 Batch 7239/17275   train_loss = 6.069\n",
      "Epoch   0 Batch 7240/17275   train_loss = 2.980\n",
      "Epoch   0 Batch 7241/17275   train_loss = 2.864\n",
      "Epoch   0 Batch 7242/17275   train_loss = 5.291\n",
      "Epoch   0 Batch 7243/17275   train_loss = 5.753\n",
      "Epoch   0 Batch 7244/17275   train_loss = 5.082\n",
      "Epoch   0 Batch 7245/17275   train_loss = 3.449\n",
      "Epoch   0 Batch 7246/17275   train_loss = 4.275\n",
      "Epoch   0 Batch 7247/17275   train_loss = 3.283\n",
      "Epoch   0 Batch 7248/17275   train_loss = 1.984\n",
      "Epoch   0 Batch 7249/17275   train_loss = 2.810\n",
      "Epoch   0 Batch 7250/17275   train_loss = 5.384\n",
      "Epoch   0 Batch 7251/17275   train_loss = 4.737\n",
      "Epoch   0 Batch 7252/17275   train_loss = 3.788\n",
      "Epoch   0 Batch 7253/17275   train_loss = 3.274\n",
      "Epoch   0 Batch 7254/17275   train_loss = 3.732\n",
      "Epoch   0 Batch 7255/17275   train_loss = 2.352\n",
      "Epoch   0 Batch 7256/17275   train_loss = 6.039\n",
      "Epoch   0 Batch 7257/17275   train_loss = 5.863\n",
      "Epoch   0 Batch 7258/17275   train_loss = 4.381\n",
      "Epoch   0 Batch 7259/17275   train_loss = 5.828\n",
      "Epoch   0 Batch 7260/17275   train_loss = 6.163\n",
      "Epoch   0 Batch 7261/17275   train_loss = 6.345\n",
      "Epoch   0 Batch 7262/17275   train_loss = 6.507\n",
      "Epoch   0 Batch 7263/17275   train_loss = 6.352\n",
      "Epoch   0 Batch 7264/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 7265/17275   train_loss = 6.354\n",
      "Epoch   0 Batch 7266/17275   train_loss = 3.683\n",
      "Epoch   0 Batch 7267/17275   train_loss = 4.653\n",
      "Epoch   0 Batch 7268/17275   train_loss = 3.413\n",
      "Epoch   0 Batch 7269/17275   train_loss = 5.823\n",
      "Epoch   0 Batch 7270/17275   train_loss = 2.393\n",
      "Epoch   0 Batch 7271/17275   train_loss = 6.060\n",
      "Epoch   0 Batch 7272/17275   train_loss = 6.060\n",
      "Epoch   0 Batch 7273/17275   train_loss = 3.562\n",
      "Epoch   0 Batch 7274/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 7275/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 7276/17275   train_loss = 6.731\n",
      "Epoch   0 Batch 7277/17275   train_loss = 2.229\n",
      "Epoch   0 Batch 7278/17275   train_loss = 3.124\n",
      "Epoch   0 Batch 7279/17275   train_loss = 3.732\n",
      "Epoch   0 Batch 7280/17275   train_loss = 3.924\n",
      "Epoch   0 Batch 7281/17275   train_loss = 4.464\n",
      "Epoch   0 Batch 7282/17275   train_loss = 6.468\n",
      "Epoch   0 Batch 7283/17275   train_loss = 2.482\n",
      "Epoch   0 Batch 7284/17275   train_loss = 5.810\n",
      "Epoch   0 Batch 7285/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 7286/17275   train_loss = 3.738\n",
      "Epoch   0 Batch 7287/17275   train_loss = 3.153\n",
      "Epoch   0 Batch 7288/17275   train_loss = 4.254\n",
      "Epoch   0 Batch 7289/17275   train_loss = 3.508\n",
      "Epoch   0 Batch 7290/17275   train_loss = 4.093\n",
      "Epoch   0 Batch 7291/17275   train_loss = 3.899\n",
      "Epoch   0 Batch 7292/17275   train_loss = 2.553\n",
      "Epoch   0 Batch 7293/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 7294/17275   train_loss = 5.979\n",
      "Epoch   0 Batch 7295/17275   train_loss = 5.985\n",
      "Epoch   0 Batch 7296/17275   train_loss = 7.341\n",
      "Epoch   0 Batch 7297/17275   train_loss = 2.173\n",
      "Epoch   0 Batch 7298/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 7299/17275   train_loss = 3.957\n",
      "Epoch   0 Batch 7300/17275   train_loss = 4.304\n",
      "Epoch   0 Batch 7301/17275   train_loss = 3.485\n",
      "Epoch   0 Batch 7302/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 7303/17275   train_loss = 4.114\n",
      "Epoch   0 Batch 7304/17275   train_loss = 4.532\n",
      "Epoch   0 Batch 7305/17275   train_loss = 3.135\n",
      "Epoch   0 Batch 7306/17275   train_loss = 2.975\n",
      "Epoch   0 Batch 7307/17275   train_loss = 2.426\n",
      "Epoch   0 Batch 7308/17275   train_loss = 3.961\n",
      "Epoch   0 Batch 7309/17275   train_loss = 5.284\n",
      "Epoch   0 Batch 7310/17275   train_loss = 6.056\n",
      "Epoch   0 Batch 7311/17275   train_loss = 7.167\n",
      "Epoch   0 Batch 7312/17275   train_loss = 5.865\n",
      "Epoch   0 Batch 7313/17275   train_loss = 2.121\n",
      "Epoch   0 Batch 7314/17275   train_loss = 6.117\n",
      "Epoch   0 Batch 7315/17275   train_loss = 3.559\n",
      "Epoch   0 Batch 7316/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 7317/17275   train_loss = 3.511\n",
      "Epoch   0 Batch 7318/17275   train_loss = 2.330\n",
      "Epoch   0 Batch 7319/17275   train_loss = 4.550\n",
      "Epoch   0 Batch 7320/17275   train_loss = 4.514\n",
      "Epoch   0 Batch 7321/17275   train_loss = 6.313\n",
      "Epoch   0 Batch 7322/17275   train_loss = 4.923\n",
      "Epoch   0 Batch 7323/17275   train_loss = 1.988\n",
      "Epoch   0 Batch 7324/17275   train_loss = 5.897\n",
      "Epoch   0 Batch 7325/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 7326/17275   train_loss = 6.019\n",
      "Epoch   0 Batch 7327/17275   train_loss = 4.115\n",
      "Epoch   0 Batch 7328/17275   train_loss = 3.531\n",
      "Epoch   0 Batch 7329/17275   train_loss = 3.921\n",
      "Epoch   0 Batch 7330/17275   train_loss = 3.252\n",
      "Epoch   0 Batch 7331/17275   train_loss = 2.380\n",
      "Epoch   0 Batch 7332/17275   train_loss = 3.273\n",
      "Epoch   0 Batch 7333/17275   train_loss = 4.684\n",
      "Epoch   0 Batch 7334/17275   train_loss = 5.323\n",
      "Epoch   0 Batch 7335/17275   train_loss = 5.717\n",
      "Epoch   0 Batch 7336/17275   train_loss = 5.709\n",
      "Epoch   0 Batch 7337/17275   train_loss = 5.704\n",
      "Epoch   0 Batch 7338/17275   train_loss = 6.667\n",
      "Epoch   0 Batch 7339/17275   train_loss = 1.899\n",
      "Epoch   0 Batch 7340/17275   train_loss = 4.770\n",
      "Epoch   0 Batch 7341/17275   train_loss = 6.047\n",
      "Epoch   0 Batch 7342/17275   train_loss = 3.183\n",
      "Epoch   0 Batch 7343/17275   train_loss = 2.256\n",
      "Epoch   0 Batch 7344/17275   train_loss = 6.014\n",
      "Epoch   0 Batch 7345/17275   train_loss = 2.990\n",
      "Epoch   0 Batch 7346/17275   train_loss = 6.803\n",
      "Epoch   0 Batch 7347/17275   train_loss = 2.576\n",
      "Epoch   0 Batch 7348/17275   train_loss = 4.024\n",
      "Epoch   0 Batch 7349/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 7350/17275   train_loss = 3.358\n",
      "Epoch   0 Batch 7351/17275   train_loss = 8.357\n",
      "Epoch   0 Batch 7352/17275   train_loss = 2.908\n",
      "Epoch   0 Batch 7353/17275   train_loss = 3.147\n",
      "Epoch   0 Batch 7354/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 7355/17275   train_loss = 3.301\n",
      "Epoch   0 Batch 7356/17275   train_loss = 3.883\n",
      "Epoch   0 Batch 7357/17275   train_loss = 6.136\n",
      "Epoch   0 Batch 7358/17275   train_loss = 3.435\n",
      "Epoch   0 Batch 7359/17275   train_loss = 3.273\n",
      "Epoch   0 Batch 7360/17275   train_loss = 2.841\n",
      "Epoch   0 Batch 7361/17275   train_loss = 2.295\n",
      "Epoch   0 Batch 7362/17275   train_loss = 3.625\n",
      "Epoch   0 Batch 7363/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 7364/17275   train_loss = 2.985\n",
      "Epoch   0 Batch 7365/17275   train_loss = 5.209\n",
      "Epoch   0 Batch 7366/17275   train_loss = 3.293\n",
      "Epoch   0 Batch 7367/17275   train_loss = 9.572\n",
      "Epoch   0 Batch 7368/17275   train_loss = 3.981\n",
      "Epoch   0 Batch 7369/17275   train_loss = 4.034\n",
      "Epoch   0 Batch 7370/17275   train_loss = 5.988\n",
      "Epoch   0 Batch 7371/17275   train_loss = 4.423\n",
      "Epoch   0 Batch 7372/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 7373/17275   train_loss = 3.841\n",
      "Epoch   0 Batch 7374/17275   train_loss = 3.972\n",
      "Epoch   0 Batch 7375/17275   train_loss = 4.862\n",
      "Epoch   0 Batch 7376/17275   train_loss = 4.815\n",
      "Epoch   0 Batch 7377/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 7378/17275   train_loss = 3.714\n",
      "Epoch   0 Batch 7379/17275   train_loss = 4.658\n",
      "Epoch   0 Batch 7380/17275   train_loss = 9.570\n",
      "Epoch   0 Batch 7381/17275   train_loss = 3.342\n",
      "Epoch   0 Batch 7382/17275   train_loss = 2.082\n",
      "Epoch   0 Batch 7383/17275   train_loss = 2.614\n",
      "Epoch   0 Batch 7384/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 7385/17275   train_loss = 3.630\n",
      "Epoch   0 Batch 7386/17275   train_loss = 2.874\n",
      "Epoch   0 Batch 7387/17275   train_loss = 3.788\n",
      "Epoch   0 Batch 7388/17275   train_loss = 2.931\n",
      "Epoch   0 Batch 7389/17275   train_loss = 5.804\n",
      "Epoch   0 Batch 7390/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 7391/17275   train_loss = 6.842\n",
      "Epoch   0 Batch 7392/17275   train_loss = 4.816\n",
      "Epoch   0 Batch 7393/17275   train_loss = 2.865\n",
      "Epoch   0 Batch 7394/17275   train_loss = 4.484\n",
      "Epoch   0 Batch 7395/17275   train_loss = 5.816\n",
      "Epoch   0 Batch 7396/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 7397/17275   train_loss = 6.920\n",
      "Epoch   0 Batch 7398/17275   train_loss = 4.534\n",
      "Epoch   0 Batch 7399/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 7400/17275   train_loss = 4.505\n",
      "Epoch   0 Batch 7401/17275   train_loss = 3.999\n",
      "Epoch   0 Batch 7402/17275   train_loss = 3.535\n",
      "Epoch   0 Batch 7403/17275   train_loss = 3.376\n",
      "Epoch   0 Batch 7404/17275   train_loss = 9.563\n",
      "Epoch   0 Batch 7405/17275   train_loss = 2.068\n",
      "Epoch   0 Batch 7406/17275   train_loss = 2.132\n",
      "Epoch   0 Batch 7407/17275   train_loss = 2.211\n",
      "Epoch   0 Batch 7408/17275   train_loss = 4.233\n",
      "Epoch   0 Batch 7409/17275   train_loss = 4.811\n",
      "Epoch   0 Batch 7410/17275   train_loss = 2.927\n",
      "Epoch   0 Batch 7411/17275   train_loss = 4.510\n",
      "Epoch   0 Batch 7412/17275   train_loss = 8.375\n",
      "Epoch   0 Batch 7413/17275   train_loss = 5.740\n",
      "Epoch   0 Batch 7414/17275   train_loss = 2.556\n",
      "Epoch   0 Batch 7415/17275   train_loss = 3.501\n",
      "Epoch   0 Batch 7416/17275   train_loss = 4.031\n",
      "Epoch   0 Batch 7417/17275   train_loss = 2.944\n",
      "Epoch   0 Batch 7418/17275   train_loss = 3.053\n",
      "Epoch   0 Batch 7419/17275   train_loss = 4.690\n",
      "Epoch   0 Batch 7420/17275   train_loss = 6.764\n",
      "Epoch   0 Batch 7421/17275   train_loss = 2.789\n",
      "Epoch   0 Batch 7422/17275   train_loss = 4.688\n",
      "Epoch   0 Batch 7423/17275   train_loss = 4.615\n",
      "Epoch   0 Batch 7424/17275   train_loss = 3.181\n",
      "Epoch   0 Batch 7425/17275   train_loss = 3.639\n",
      "Epoch   0 Batch 7426/17275   train_loss = 2.439\n",
      "Epoch   0 Batch 7427/17275   train_loss = 6.479\n",
      "Epoch   0 Batch 7428/17275   train_loss = 2.773\n",
      "Epoch   0 Batch 7429/17275   train_loss = 1.817\n",
      "Epoch   0 Batch 7430/17275   train_loss = 6.784\n",
      "Epoch   0 Batch 7431/17275   train_loss = 2.713\n",
      "Epoch   0 Batch 7432/17275   train_loss = 1.791\n",
      "Epoch   0 Batch 7433/17275   train_loss = 6.516\n",
      "Epoch   0 Batch 7434/17275   train_loss = 3.782\n",
      "Epoch   0 Batch 7435/17275   train_loss = 3.431\n",
      "Epoch   0 Batch 7436/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 7437/17275   train_loss = 1.759\n",
      "Epoch   0 Batch 7438/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 7439/17275   train_loss = 3.053\n",
      "Epoch   0 Batch 7440/17275   train_loss = 2.571\n",
      "Epoch   0 Batch 7441/17275   train_loss = 4.270\n",
      "Epoch   0 Batch 7442/17275   train_loss = 3.398\n",
      "Epoch   0 Batch 7443/17275   train_loss = 2.287\n",
      "Epoch   0 Batch 7444/17275   train_loss = 5.218\n",
      "Epoch   0 Batch 7445/17275   train_loss = 4.346\n",
      "Epoch   0 Batch 7446/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 7447/17275   train_loss = 9.637\n",
      "Epoch   0 Batch 7448/17275   train_loss = 6.721\n",
      "Epoch   0 Batch 7449/17275   train_loss = 6.610\n",
      "Epoch   0 Batch 7450/17275   train_loss = 6.289\n",
      "Epoch   0 Batch 7451/17275   train_loss = 6.832\n",
      "Epoch   0 Batch 7452/17275   train_loss = 4.427\n",
      "Epoch   0 Batch 7453/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 7454/17275   train_loss = 2.323\n",
      "Epoch   0 Batch 7455/17275   train_loss = 2.723\n",
      "Epoch   0 Batch 7456/17275   train_loss = 3.326\n",
      "Epoch   0 Batch 7457/17275   train_loss = 2.460\n",
      "Epoch   0 Batch 7458/17275   train_loss = 2.619\n",
      "Epoch   0 Batch 7459/17275   train_loss = 3.323\n",
      "Epoch   0 Batch 7460/17275   train_loss = 7.487\n",
      "Epoch   0 Batch 7461/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 7462/17275   train_loss = 5.078\n",
      "Epoch   0 Batch 7463/17275   train_loss = 7.729\n",
      "Epoch   0 Batch 7464/17275   train_loss = 4.640\n",
      "Epoch   0 Batch 7465/17275   train_loss = 2.300\n",
      "Epoch   0 Batch 7466/17275   train_loss = 6.845\n",
      "Epoch   0 Batch 7467/17275   train_loss = 6.156\n",
      "Epoch   0 Batch 7468/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 7469/17275   train_loss = 3.989\n",
      "Epoch   0 Batch 7470/17275   train_loss = 5.711\n",
      "Epoch   0 Batch 7471/17275   train_loss = 2.253\n",
      "Epoch   0 Batch 7472/17275   train_loss = 7.143\n",
      "Epoch   0 Batch 7473/17275   train_loss = 3.413\n",
      "Epoch   0 Batch 7474/17275   train_loss = 6.210\n",
      "Epoch   0 Batch 7475/17275   train_loss = 7.821\n",
      "Epoch   0 Batch 7476/17275   train_loss = 5.726\n",
      "Epoch   0 Batch 7477/17275   train_loss = 5.990\n",
      "Epoch   0 Batch 7478/17275   train_loss = 7.356\n",
      "Epoch   0 Batch 7479/17275   train_loss = 9.585\n",
      "Epoch   0 Batch 7480/17275   train_loss = 3.187\n",
      "Epoch   0 Batch 7481/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 7482/17275   train_loss = 6.327\n",
      "Epoch   0 Batch 7483/17275   train_loss = 2.646\n",
      "Epoch   0 Batch 7484/17275   train_loss = 3.025\n",
      "Epoch   0 Batch 7485/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 7486/17275   train_loss = 3.340\n",
      "Epoch   0 Batch 7487/17275   train_loss = 3.396\n",
      "Epoch   0 Batch 7488/17275   train_loss = 2.843\n",
      "Epoch   0 Batch 7489/17275   train_loss = 2.553\n",
      "Epoch   0 Batch 7490/17275   train_loss = 3.784\n",
      "Epoch   0 Batch 7491/17275   train_loss = 2.973\n",
      "Epoch   0 Batch 7492/17275   train_loss = 9.573\n",
      "Epoch   0 Batch 7493/17275   train_loss = 2.890\n",
      "Epoch   0 Batch 7494/17275   train_loss = 3.840\n",
      "Epoch   0 Batch 7495/17275   train_loss = 2.551\n",
      "Epoch   0 Batch 7496/17275   train_loss = 6.162\n",
      "Epoch   0 Batch 7497/17275   train_loss = 3.766\n",
      "Epoch   0 Batch 7498/17275   train_loss = 3.571\n",
      "Epoch   0 Batch 7499/17275   train_loss = 4.136\n",
      "Epoch   0 Batch 7500/17275   train_loss = 7.092\n",
      "Epoch   0 Batch 7501/17275   train_loss = 2.350\n",
      "Epoch   0 Batch 7502/17275   train_loss = 3.559\n",
      "Epoch   0 Batch 7503/17275   train_loss = 3.670\n",
      "Epoch   0 Batch 7504/17275   train_loss = 1.985\n",
      "Epoch   0 Batch 7505/17275   train_loss = 2.644\n",
      "Epoch   0 Batch 7506/17275   train_loss = 3.901\n",
      "Epoch   0 Batch 7507/17275   train_loss = 3.199\n",
      "Epoch   0 Batch 7508/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 7509/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 7510/17275   train_loss = 2.870\n",
      "Epoch   0 Batch 7511/17275   train_loss = 3.825\n",
      "Epoch   0 Batch 7512/17275   train_loss = 3.026\n",
      "Epoch   0 Batch 7513/17275   train_loss = 3.044\n",
      "Epoch   0 Batch 7514/17275   train_loss = 5.802\n",
      "Epoch   0 Batch 7515/17275   train_loss = 3.819\n",
      "Epoch   0 Batch 7516/17275   train_loss = 4.063\n",
      "Epoch   0 Batch 7517/17275   train_loss = 3.045\n",
      "Epoch   0 Batch 7518/17275   train_loss = 4.580\n",
      "Epoch   0 Batch 7519/17275   train_loss = 6.640\n",
      "Epoch   0 Batch 7520/17275   train_loss = 2.675\n",
      "Epoch   0 Batch 7521/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 7522/17275   train_loss = 3.124\n",
      "Epoch   0 Batch 7523/17275   train_loss = 6.143\n",
      "Epoch   0 Batch 7524/17275   train_loss = 3.628\n",
      "Epoch   0 Batch 7525/17275   train_loss = 3.079\n",
      "Epoch   0 Batch 7526/17275   train_loss = 6.500\n",
      "Epoch   0 Batch 7527/17275   train_loss = 9.609\n",
      "Epoch   0 Batch 7528/17275   train_loss = 4.153\n",
      "Epoch   0 Batch 7529/17275   train_loss = 2.314\n",
      "Epoch   0 Batch 7530/17275   train_loss = 8.532\n",
      "Epoch   0 Batch 7531/17275   train_loss = 3.763\n",
      "Epoch   0 Batch 7532/17275   train_loss = 4.180\n",
      "Epoch   0 Batch 7533/17275   train_loss = 3.286\n",
      "Epoch   0 Batch 7534/17275   train_loss = 4.197\n",
      "Epoch   0 Batch 7535/17275   train_loss = 4.697\n",
      "Epoch   0 Batch 7536/17275   train_loss = 5.622\n",
      "Epoch   0 Batch 7537/17275   train_loss = 6.804\n",
      "Epoch   0 Batch 7538/17275   train_loss = 3.886\n",
      "Epoch   0 Batch 7539/17275   train_loss = 3.426\n",
      "Epoch   0 Batch 7540/17275   train_loss = 3.423\n",
      "Epoch   0 Batch 7541/17275   train_loss = 3.810\n",
      "Epoch   0 Batch 7542/17275   train_loss = 6.101\n",
      "Epoch   0 Batch 7543/17275   train_loss = 6.362\n",
      "Epoch   0 Batch 7544/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 7545/17275   train_loss = 6.414\n",
      "Epoch   0 Batch 7546/17275   train_loss = 6.537\n",
      "Epoch   0 Batch 7547/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 7548/17275   train_loss = 2.126\n",
      "Epoch   0 Batch 7549/17275   train_loss = 4.113\n",
      "Epoch   0 Batch 7550/17275   train_loss = 6.047\n",
      "Epoch   0 Batch 7551/17275   train_loss = 3.747\n",
      "Epoch   0 Batch 7552/17275   train_loss = 2.322\n",
      "Epoch   0 Batch 7553/17275   train_loss = 6.035\n",
      "Epoch   0 Batch 7554/17275   train_loss = 9.575\n",
      "Epoch   0 Batch 7555/17275   train_loss = 6.036\n",
      "Epoch   0 Batch 7556/17275   train_loss = 5.913\n",
      "Epoch   0 Batch 7557/17275   train_loss = 5.793\n",
      "Epoch   0 Batch 7558/17275   train_loss = 5.647\n",
      "Epoch   0 Batch 7559/17275   train_loss = 2.253\n",
      "Epoch   0 Batch 7560/17275   train_loss = 2.729\n",
      "Epoch   0 Batch 7561/17275   train_loss = 5.998\n",
      "Epoch   0 Batch 7562/17275   train_loss = 3.290\n",
      "Epoch   0 Batch 7563/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 7564/17275   train_loss = 4.396\n",
      "Epoch   0 Batch 7565/17275   train_loss = 5.764\n",
      "Epoch   0 Batch 7566/17275   train_loss = 4.601\n",
      "Epoch   0 Batch 7567/17275   train_loss = 5.958\n",
      "Epoch   0 Batch 7568/17275   train_loss = 6.111\n",
      "Epoch   0 Batch 7569/17275   train_loss = 5.965\n",
      "Epoch   0 Batch 7570/17275   train_loss = 2.141\n",
      "Epoch   0 Batch 7571/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 7572/17275   train_loss = 5.877\n",
      "Epoch   0 Batch 7573/17275   train_loss = 6.199\n",
      "Epoch   0 Batch 7574/17275   train_loss = 6.116\n",
      "Epoch   0 Batch 7575/17275   train_loss = 7.050\n",
      "Epoch   0 Batch 7576/17275   train_loss = 5.826\n",
      "Epoch   0 Batch 7577/17275   train_loss = 1.980\n",
      "Epoch   0 Batch 7578/17275   train_loss = 3.432\n",
      "Epoch   0 Batch 7579/17275   train_loss = 3.639\n",
      "Epoch   0 Batch 7580/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 7581/17275   train_loss = 2.541\n",
      "Epoch   0 Batch 7582/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 7583/17275   train_loss = 4.603\n",
      "Epoch   0 Batch 7584/17275   train_loss = 3.294\n",
      "Epoch   0 Batch 7585/17275   train_loss = 2.494\n",
      "Epoch   0 Batch 7586/17275   train_loss = 3.882\n",
      "Epoch   0 Batch 7587/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 7588/17275   train_loss = 3.831\n",
      "Epoch   0 Batch 7589/17275   train_loss = 5.260\n",
      "Epoch   0 Batch 7590/17275   train_loss = 2.848\n",
      "Epoch   0 Batch 7591/17275   train_loss = 2.609\n",
      "Epoch   0 Batch 7592/17275   train_loss = 6.003\n",
      "Epoch   0 Batch 7593/17275   train_loss = 3.015\n",
      "Epoch   0 Batch 7594/17275   train_loss = 4.049\n",
      "Epoch   0 Batch 7595/17275   train_loss = 3.276\n",
      "Epoch   0 Batch 7596/17275   train_loss = 4.993\n",
      "Epoch   0 Batch 7597/17275   train_loss = 6.445\n",
      "Epoch   0 Batch 7598/17275   train_loss = 6.265\n",
      "Epoch   0 Batch 7599/17275   train_loss = 7.911\n",
      "Epoch   0 Batch 7600/17275   train_loss = 6.806\n",
      "Epoch   0 Batch 7601/17275   train_loss = 2.052\n",
      "Epoch   0 Batch 7602/17275   train_loss = 3.424\n",
      "Epoch   0 Batch 7603/17275   train_loss = 4.633\n",
      "Epoch   0 Batch 7604/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 7605/17275   train_loss = 6.203\n",
      "Epoch   0 Batch 7606/17275   train_loss = 2.014\n",
      "Epoch   0 Batch 7607/17275   train_loss = 2.781\n",
      "Epoch   0 Batch 7608/17275   train_loss = 8.620\n",
      "Epoch   0 Batch 7609/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 7610/17275   train_loss = 3.726\n",
      "Epoch   0 Batch 7611/17275   train_loss = 3.646\n",
      "Epoch   0 Batch 7612/17275   train_loss = 3.457\n",
      "Epoch   0 Batch 7613/17275   train_loss = 3.497\n",
      "Epoch   0 Batch 7614/17275   train_loss = 2.857\n",
      "Epoch   0 Batch 7615/17275   train_loss = 5.269\n",
      "Epoch   0 Batch 7616/17275   train_loss = 2.314\n",
      "Epoch   0 Batch 7617/17275   train_loss = 6.205\n",
      "Epoch   0 Batch 7618/17275   train_loss = 4.002\n",
      "Epoch   0 Batch 7619/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 7620/17275   train_loss = 4.032\n",
      "Epoch   0 Batch 7621/17275   train_loss = 3.191\n",
      "Epoch   0 Batch 7622/17275   train_loss = 3.172\n",
      "Epoch   0 Batch 7623/17275   train_loss = 3.998\n",
      "Epoch   0 Batch 7624/17275   train_loss = 4.078\n",
      "Epoch   0 Batch 7625/17275   train_loss = 4.816\n",
      "Epoch   0 Batch 7626/17275   train_loss = 2.137\n",
      "Epoch   0 Batch 7627/17275   train_loss = 2.298\n",
      "Epoch   0 Batch 7628/17275   train_loss = 2.674\n",
      "Epoch   0 Batch 7629/17275   train_loss = 4.345\n",
      "Epoch   0 Batch 7630/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 7631/17275   train_loss = 2.808\n",
      "Epoch   0 Batch 7632/17275   train_loss = 5.806\n",
      "Epoch   0 Batch 7633/17275   train_loss = 2.621\n",
      "Epoch   0 Batch 7634/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 7635/17275   train_loss = 2.906\n",
      "Epoch   0 Batch 7636/17275   train_loss = 3.332\n",
      "Epoch   0 Batch 7637/17275   train_loss = 2.514\n",
      "Epoch   0 Batch 7638/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 7639/17275   train_loss = 3.281\n",
      "Epoch   0 Batch 7640/17275   train_loss = 3.384\n",
      "Epoch   0 Batch 7641/17275   train_loss = 4.468\n",
      "Epoch   0 Batch 7642/17275   train_loss = 5.825\n",
      "Epoch   0 Batch 7643/17275   train_loss = 2.505\n",
      "Epoch   0 Batch 7644/17275   train_loss = 5.819\n",
      "Epoch   0 Batch 7645/17275   train_loss = 3.516\n",
      "Epoch   0 Batch 7646/17275   train_loss = 7.244\n",
      "Epoch   0 Batch 7647/17275   train_loss = 2.516\n",
      "Epoch   0 Batch 7648/17275   train_loss = 4.322\n",
      "Epoch   0 Batch 7649/17275   train_loss = 4.413\n",
      "Epoch   0 Batch 7650/17275   train_loss = 2.466\n",
      "Epoch   0 Batch 7651/17275   train_loss = 2.578\n",
      "Epoch   0 Batch 7652/17275   train_loss = 2.696\n",
      "Epoch   0 Batch 7653/17275   train_loss = 3.730\n",
      "Epoch   0 Batch 7654/17275   train_loss = 4.647\n",
      "Epoch   0 Batch 7655/17275   train_loss = 4.443\n",
      "Epoch   0 Batch 7656/17275   train_loss = 1.973\n",
      "Epoch   0 Batch 7657/17275   train_loss = 3.606\n",
      "Epoch   0 Batch 7658/17275   train_loss = 4.753\n",
      "Epoch   0 Batch 7659/17275   train_loss = 5.355\n",
      "Epoch   0 Batch 7660/17275   train_loss = 3.191\n",
      "Epoch   0 Batch 7661/17275   train_loss = 6.227\n",
      "Epoch   0 Batch 7662/17275   train_loss = 4.212\n",
      "Epoch   0 Batch 7663/17275   train_loss = 3.044\n",
      "Epoch   0 Batch 7664/17275   train_loss = 6.760\n",
      "Epoch   0 Batch 7665/17275   train_loss = 2.330\n",
      "Epoch   0 Batch 7666/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 7667/17275   train_loss = 7.277\n",
      "Epoch   0 Batch 7668/17275   train_loss = 2.991\n",
      "Epoch   0 Batch 7669/17275   train_loss = 3.216\n",
      "Epoch   0 Batch 7670/17275   train_loss = 5.931\n",
      "Epoch   0 Batch 7671/17275   train_loss = 2.359\n",
      "Epoch   0 Batch 7672/17275   train_loss = 9.644\n",
      "Epoch   0 Batch 7673/17275   train_loss = 2.407\n",
      "Epoch   0 Batch 7674/17275   train_loss = 6.644\n",
      "Epoch   0 Batch 7675/17275   train_loss = 2.796\n",
      "Epoch   0 Batch 7676/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 7677/17275   train_loss = 2.054\n",
      "Epoch   0 Batch 7678/17275   train_loss = 3.073\n",
      "Epoch   0 Batch 7679/17275   train_loss = 2.159\n",
      "Epoch   0 Batch 7680/17275   train_loss = 2.900\n",
      "Epoch   0 Batch 7681/17275   train_loss = 2.506\n",
      "Epoch   0 Batch 7682/17275   train_loss = 6.173\n",
      "Epoch   0 Batch 7683/17275   train_loss = 2.008\n",
      "Epoch   0 Batch 7684/17275   train_loss = 1.946\n",
      "Epoch   0 Batch 7685/17275   train_loss = 2.999\n",
      "Epoch   0 Batch 7686/17275   train_loss = 3.215\n",
      "Epoch   0 Batch 7687/17275   train_loss = 4.152\n",
      "Epoch   0 Batch 7688/17275   train_loss = 7.588\n",
      "Epoch   0 Batch 7689/17275   train_loss = 4.444\n",
      "Epoch   0 Batch 7690/17275   train_loss = 3.889\n",
      "Epoch   0 Batch 7691/17275   train_loss = 4.509\n",
      "Epoch   0 Batch 7692/17275   train_loss = 2.997\n",
      "Epoch   0 Batch 7693/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 7694/17275   train_loss = 3.925\n",
      "Epoch   0 Batch 7695/17275   train_loss = 5.167\n",
      "Epoch   0 Batch 7696/17275   train_loss = 1.901\n",
      "Epoch   0 Batch 7697/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 7698/17275   train_loss = 3.506\n",
      "Epoch   0 Batch 7699/17275   train_loss = 2.957\n",
      "Epoch   0 Batch 7700/17275   train_loss = 4.255\n",
      "Epoch   0 Batch 7701/17275   train_loss = 6.386\n",
      "Epoch   0 Batch 7702/17275   train_loss = 6.708\n",
      "Epoch   0 Batch 7703/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 7704/17275   train_loss = 4.829\n",
      "Epoch   0 Batch 7705/17275   train_loss = 4.511\n",
      "Epoch   0 Batch 7706/17275   train_loss = 7.786\n",
      "Epoch   0 Batch 7707/17275   train_loss = 1.930\n",
      "Epoch   0 Batch 7708/17275   train_loss = 3.273\n",
      "Epoch   0 Batch 7709/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 7710/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 7711/17275   train_loss = 6.202\n",
      "Epoch   0 Batch 7712/17275   train_loss = 5.780\n",
      "Epoch   0 Batch 7713/17275   train_loss = 2.235\n",
      "Epoch   0 Batch 7714/17275   train_loss = 3.187\n",
      "Epoch   0 Batch 7715/17275   train_loss = 3.936\n",
      "Epoch   0 Batch 7716/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 7717/17275   train_loss = 3.947\n",
      "Epoch   0 Batch 7718/17275   train_loss = 2.378\n",
      "Epoch   0 Batch 7719/17275   train_loss = 5.363\n",
      "Epoch   0 Batch 7720/17275   train_loss = 4.764\n",
      "Epoch   0 Batch 7721/17275   train_loss = 4.302\n",
      "Epoch   0 Batch 7722/17275   train_loss = 5.760\n",
      "Epoch   0 Batch 7723/17275   train_loss = 3.414\n",
      "Epoch   0 Batch 7724/17275   train_loss = 2.991\n",
      "Epoch   0 Batch 7725/17275   train_loss = 6.746\n",
      "Epoch   0 Batch 7726/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 7727/17275   train_loss = 7.007\n",
      "Epoch   0 Batch 7728/17275   train_loss = 2.647\n",
      "Epoch   0 Batch 7729/17275   train_loss = 2.739\n",
      "Epoch   0 Batch 7730/17275   train_loss = 3.363\n",
      "Epoch   0 Batch 7731/17275   train_loss = 5.381\n",
      "Epoch   0 Batch 7732/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 7733/17275   train_loss = 4.990\n",
      "Epoch   0 Batch 7734/17275   train_loss = 2.722\n",
      "Epoch   0 Batch 7735/17275   train_loss = 2.230\n",
      "Epoch   0 Batch 7736/17275   train_loss = 3.209\n",
      "Epoch   0 Batch 7737/17275   train_loss = 5.458\n",
      "Epoch   0 Batch 7738/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 7739/17275   train_loss = 1.875\n",
      "Epoch   0 Batch 7740/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 7741/17275   train_loss = 5.913\n",
      "Epoch   0 Batch 7742/17275   train_loss = 2.921\n",
      "Epoch   0 Batch 7743/17275   train_loss = 3.317\n",
      "Epoch   0 Batch 7744/17275   train_loss = 2.361\n",
      "Epoch   0 Batch 7745/17275   train_loss = 2.714\n",
      "Epoch   0 Batch 7746/17275   train_loss = 3.866\n",
      "Epoch   0 Batch 7747/17275   train_loss = 6.114\n",
      "Epoch   0 Batch 7748/17275   train_loss = 6.529\n",
      "Epoch   0 Batch 7749/17275   train_loss = 6.173\n",
      "Epoch   0 Batch 7750/17275   train_loss = 2.200\n",
      "Epoch   0 Batch 7751/17275   train_loss = 5.845\n",
      "Epoch   0 Batch 7752/17275   train_loss = 6.370\n",
      "Epoch   0 Batch 7753/17275   train_loss = 6.985\n",
      "Epoch   0 Batch 7754/17275   train_loss = 1.903\n",
      "Epoch   0 Batch 7755/17275   train_loss = 5.157\n",
      "Epoch   0 Batch 7756/17275   train_loss = 3.977\n",
      "Epoch   0 Batch 7757/17275   train_loss = 3.489\n",
      "Epoch   0 Batch 7758/17275   train_loss = 6.251\n",
      "Epoch   0 Batch 7759/17275   train_loss = 6.208\n",
      "Epoch   0 Batch 7760/17275   train_loss = 7.201\n",
      "Epoch   0 Batch 7761/17275   train_loss = 1.923\n",
      "Epoch   0 Batch 7762/17275   train_loss = 3.224\n",
      "Epoch   0 Batch 7763/17275   train_loss = 2.253\n",
      "Epoch   0 Batch 7764/17275   train_loss = 3.339\n",
      "Epoch   0 Batch 7765/17275   train_loss = 1.988\n",
      "Epoch   0 Batch 7766/17275   train_loss = 2.983\n",
      "Epoch   0 Batch 7767/17275   train_loss = 3.338\n",
      "Epoch   0 Batch 7768/17275   train_loss = 2.904\n",
      "Epoch   0 Batch 7769/17275   train_loss = 4.248\n",
      "Epoch   0 Batch 7770/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 7771/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 7772/17275   train_loss = 6.347\n",
      "Epoch   0 Batch 7773/17275   train_loss = 3.248\n",
      "Epoch   0 Batch 7774/17275   train_loss = 3.930\n",
      "Epoch   0 Batch 7775/17275   train_loss = 5.615\n",
      "Epoch   0 Batch 7776/17275   train_loss = 4.480\n",
      "Epoch   0 Batch 7777/17275   train_loss = 2.846\n",
      "Epoch   0 Batch 7778/17275   train_loss = 4.522\n",
      "Epoch   0 Batch 7779/17275   train_loss = 6.368\n",
      "Epoch   0 Batch 7780/17275   train_loss = 3.742\n",
      "Epoch   0 Batch 7781/17275   train_loss = 5.706\n",
      "Epoch   0 Batch 7782/17275   train_loss = 2.336\n",
      "Epoch   0 Batch 7783/17275   train_loss = 2.809\n",
      "Epoch   0 Batch 7784/17275   train_loss = 5.095\n",
      "Epoch   0 Batch 7785/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 7786/17275   train_loss = 6.525\n",
      "Epoch   0 Batch 7787/17275   train_loss = 3.519\n",
      "Epoch   0 Batch 7788/17275   train_loss = 1.878\n",
      "Epoch   0 Batch 7789/17275   train_loss = 3.735\n",
      "Epoch   0 Batch 7790/17275   train_loss = 3.020\n",
      "Epoch   0 Batch 7791/17275   train_loss = 7.319\n",
      "Epoch   0 Batch 7792/17275   train_loss = 6.751\n",
      "Epoch   0 Batch 7793/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 7794/17275   train_loss = 1.733\n",
      "Epoch   0 Batch 7795/17275   train_loss = 2.505\n",
      "Epoch   0 Batch 7796/17275   train_loss = 6.334\n",
      "Epoch   0 Batch 7797/17275   train_loss = 3.411\n",
      "Epoch   0 Batch 7798/17275   train_loss = 6.339\n",
      "Epoch   0 Batch 7799/17275   train_loss = 3.618\n",
      "Epoch   0 Batch 7800/17275   train_loss = 3.856\n",
      "Epoch   0 Batch 7801/17275   train_loss = 5.188\n",
      "Epoch   0 Batch 7802/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 7803/17275   train_loss = 2.546\n",
      "Epoch   0 Batch 7804/17275   train_loss = 4.767\n",
      "Epoch   0 Batch 7805/17275   train_loss = 3.910\n",
      "Epoch   0 Batch 7806/17275   train_loss = 2.705\n",
      "Epoch   0 Batch 7807/17275   train_loss = 4.696\n",
      "Epoch   0 Batch 7808/17275   train_loss = 2.228\n",
      "Epoch   0 Batch 7809/17275   train_loss = 4.138\n",
      "Epoch   0 Batch 7810/17275   train_loss = 2.617\n",
      "Epoch   0 Batch 7811/17275   train_loss = 6.281\n",
      "Epoch   0 Batch 7812/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 7813/17275   train_loss = 3.377\n",
      "Epoch   0 Batch 7814/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 7815/17275   train_loss = 1.929\n",
      "Epoch   0 Batch 7816/17275   train_loss = 2.889\n",
      "Epoch   0 Batch 7817/17275   train_loss = 7.054\n",
      "Epoch   0 Batch 7818/17275   train_loss = 3.166\n",
      "Epoch   0 Batch 7819/17275   train_loss = 7.380\n",
      "Epoch   0 Batch 7820/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 7821/17275   train_loss = 2.609\n",
      "Epoch   0 Batch 7822/17275   train_loss = 3.954\n",
      "Epoch   0 Batch 7823/17275   train_loss = 6.471\n",
      "Epoch   0 Batch 7824/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 7825/17275   train_loss = 3.187\n",
      "Epoch   0 Batch 7826/17275   train_loss = 3.443\n",
      "Epoch   0 Batch 7827/17275   train_loss = 3.156\n",
      "Epoch   0 Batch 7828/17275   train_loss = 6.562\n",
      "Epoch   0 Batch 7829/17275   train_loss = 4.358\n",
      "Epoch   0 Batch 7830/17275   train_loss = 3.790\n",
      "Epoch   0 Batch 7831/17275   train_loss = 1.874\n",
      "Epoch   0 Batch 7832/17275   train_loss = 2.673\n",
      "Epoch   0 Batch 7833/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 7834/17275   train_loss = 3.869\n",
      "Epoch   0 Batch 7835/17275   train_loss = 4.417\n",
      "Epoch   0 Batch 7836/17275   train_loss = 6.980\n",
      "Epoch   0 Batch 7837/17275   train_loss = 4.197\n",
      "Epoch   0 Batch 7838/17275   train_loss = 2.900\n",
      "Epoch   0 Batch 7839/17275   train_loss = 6.414\n",
      "Epoch   0 Batch 7840/17275   train_loss = 3.975\n",
      "Epoch   0 Batch 7841/17275   train_loss = 3.430\n",
      "Epoch   0 Batch 7842/17275   train_loss = 2.060\n",
      "Epoch   0 Batch 7843/17275   train_loss = 2.748\n",
      "Epoch   0 Batch 7844/17275   train_loss = 4.537\n",
      "Epoch   0 Batch 7845/17275   train_loss = 4.593\n",
      "Epoch   0 Batch 7846/17275   train_loss = 3.949\n",
      "Epoch   0 Batch 7847/17275   train_loss = 3.865\n",
      "Epoch   0 Batch 7848/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 7849/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 7850/17275   train_loss = 3.637\n",
      "Epoch   0 Batch 7851/17275   train_loss = 2.046\n",
      "Epoch   0 Batch 7852/17275   train_loss = 3.732\n",
      "Epoch   0 Batch 7853/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 7854/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 7855/17275   train_loss = 3.725\n",
      "Epoch   0 Batch 7856/17275   train_loss = 3.959\n",
      "Epoch   0 Batch 7857/17275   train_loss = 2.627\n",
      "Epoch   0 Batch 7858/17275   train_loss = 6.235\n",
      "Epoch   0 Batch 7859/17275   train_loss = 6.625\n",
      "Epoch   0 Batch 7860/17275   train_loss = 6.136\n",
      "Epoch   0 Batch 7861/17275   train_loss = 2.644\n",
      "Epoch   0 Batch 7862/17275   train_loss = 4.187\n",
      "Epoch   0 Batch 7863/17275   train_loss = 3.922\n",
      "Epoch   0 Batch 7864/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 7865/17275   train_loss = 6.295\n",
      "Epoch   0 Batch 7866/17275   train_loss = 2.193\n",
      "Epoch   0 Batch 7867/17275   train_loss = 2.620\n",
      "Epoch   0 Batch 7868/17275   train_loss = 4.080\n",
      "Epoch   0 Batch 7869/17275   train_loss = 6.273\n",
      "Epoch   0 Batch 7870/17275   train_loss = 6.534\n",
      "Epoch   0 Batch 7871/17275   train_loss = 4.331\n",
      "Epoch   0 Batch 7872/17275   train_loss = 7.115\n",
      "Epoch   0 Batch 7873/17275   train_loss = 3.997\n",
      "Epoch   0 Batch 7874/17275   train_loss = 4.579\n",
      "Epoch   0 Batch 7875/17275   train_loss = 4.153\n",
      "Epoch   0 Batch 7876/17275   train_loss = 2.815\n",
      "Epoch   0 Batch 7877/17275   train_loss = 6.032\n",
      "Epoch   0 Batch 7878/17275   train_loss = 2.881\n",
      "Epoch   0 Batch 7879/17275   train_loss = 2.273\n",
      "Epoch   0 Batch 7880/17275   train_loss = 6.200\n",
      "Epoch   0 Batch 7881/17275   train_loss = 3.111\n",
      "Epoch   0 Batch 7882/17275   train_loss = 2.895\n",
      "Epoch   0 Batch 7883/17275   train_loss = 2.552\n",
      "Epoch   0 Batch 7884/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 7885/17275   train_loss = 4.829\n",
      "Epoch   0 Batch 7886/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 7887/17275   train_loss = 3.069\n",
      "Epoch   0 Batch 7888/17275   train_loss = 3.019\n",
      "Epoch   0 Batch 7889/17275   train_loss = 6.024\n",
      "Epoch   0 Batch 7890/17275   train_loss = 9.718\n",
      "Epoch   0 Batch 7891/17275   train_loss = 2.295\n",
      "Epoch   0 Batch 7892/17275   train_loss = 2.486\n",
      "Epoch   0 Batch 7893/17275   train_loss = 5.852\n",
      "Epoch   0 Batch 7894/17275   train_loss = 2.382\n",
      "Epoch   0 Batch 7895/17275   train_loss = 9.731\n",
      "Epoch   0 Batch 7896/17275   train_loss = 1.967\n",
      "Epoch   0 Batch 7897/17275   train_loss = 1.936\n",
      "Epoch   0 Batch 7898/17275   train_loss = 3.326\n",
      "Epoch   0 Batch 7899/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 7900/17275   train_loss = 2.288\n",
      "Epoch   0 Batch 7901/17275   train_loss = 9.749\n",
      "Epoch   0 Batch 7902/17275   train_loss = 1.818\n",
      "Epoch   0 Batch 7903/17275   train_loss = 1.819\n",
      "Epoch   0 Batch 7904/17275   train_loss = 2.776\n",
      "Epoch   0 Batch 7905/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 7906/17275   train_loss = 2.184\n",
      "Epoch   0 Batch 7907/17275   train_loss = 4.218\n",
      "Epoch   0 Batch 7908/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 7909/17275   train_loss = 3.802\n",
      "Epoch   0 Batch 7910/17275   train_loss = 1.687\n",
      "Epoch   0 Batch 7911/17275   train_loss = 2.517\n",
      "Epoch   0 Batch 7912/17275   train_loss = 8.075\n",
      "Epoch   0 Batch 7913/17275   train_loss = 2.964\n",
      "Epoch   0 Batch 7914/17275   train_loss = 2.584\n",
      "Epoch   0 Batch 7915/17275   train_loss = 1.763\n",
      "Epoch   0 Batch 7916/17275   train_loss = 2.059\n",
      "Epoch   0 Batch 7917/17275   train_loss = 4.222\n",
      "Epoch   0 Batch 7918/17275   train_loss = 5.593\n",
      "Epoch   0 Batch 7919/17275   train_loss = 6.198\n",
      "Epoch   0 Batch 7920/17275   train_loss = 6.217\n",
      "Epoch   0 Batch 7921/17275   train_loss = 2.541\n",
      "Epoch   0 Batch 7922/17275   train_loss = 3.228\n",
      "Epoch   0 Batch 7923/17275   train_loss = 3.000\n",
      "Epoch   0 Batch 7924/17275   train_loss = 4.597\n",
      "Epoch   0 Batch 7925/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 7926/17275   train_loss = 6.627\n",
      "Epoch   0 Batch 7927/17275   train_loss = 6.264\n",
      "Epoch   0 Batch 7928/17275   train_loss = 1.666\n",
      "Epoch   0 Batch 7929/17275   train_loss = 2.489\n",
      "Epoch   0 Batch 7930/17275   train_loss = 3.799\n",
      "Epoch   0 Batch 7931/17275   train_loss = 2.726\n",
      "Epoch   0 Batch 7932/17275   train_loss = 3.955\n",
      "Epoch   0 Batch 7933/17275   train_loss = 3.150\n",
      "Epoch   0 Batch 7934/17275   train_loss = 2.696\n",
      "Epoch   0 Batch 7935/17275   train_loss = 4.455\n",
      "Epoch   0 Batch 7936/17275   train_loss = 1.752\n",
      "Epoch   0 Batch 7937/17275   train_loss = 3.427\n",
      "Epoch   0 Batch 7938/17275   train_loss = 3.652\n",
      "Epoch   0 Batch 7939/17275   train_loss = 3.562\n",
      "Epoch   0 Batch 7940/17275   train_loss = 3.869\n",
      "Epoch   0 Batch 7941/17275   train_loss = 4.019\n",
      "Epoch   0 Batch 7942/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 7943/17275   train_loss = 2.456\n",
      "Epoch   0 Batch 7944/17275   train_loss = 6.202\n",
      "Epoch   0 Batch 7945/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 7946/17275   train_loss = 3.589\n",
      "Epoch   0 Batch 7947/17275   train_loss = 3.222\n",
      "Epoch   0 Batch 7948/17275   train_loss = 2.473\n",
      "Epoch   0 Batch 7949/17275   train_loss = 3.807\n",
      "Epoch   0 Batch 7950/17275   train_loss = 3.345\n",
      "Epoch   0 Batch 7951/17275   train_loss = 2.821\n",
      "Epoch   0 Batch 7952/17275   train_loss = 2.345\n",
      "Epoch   0 Batch 7953/17275   train_loss = 2.105\n",
      "Epoch   0 Batch 7954/17275   train_loss = 4.749\n",
      "Epoch   0 Batch 7955/17275   train_loss = 3.025\n",
      "Epoch   0 Batch 7956/17275   train_loss = 3.165\n",
      "Epoch   0 Batch 7957/17275   train_loss = 3.151\n",
      "Epoch   0 Batch 7958/17275   train_loss = 3.674\n",
      "Epoch   0 Batch 7959/17275   train_loss = 9.801\n",
      "Epoch   0 Batch 7960/17275   train_loss = 5.895\n",
      "Epoch   0 Batch 7961/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 7962/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 7963/17275   train_loss = 6.337\n",
      "Epoch   0 Batch 7964/17275   train_loss = 5.544\n",
      "Epoch   0 Batch 7965/17275   train_loss = 5.867\n",
      "Epoch   0 Batch 7966/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 7967/17275   train_loss = 6.974\n",
      "Epoch   0 Batch 7968/17275   train_loss = 6.608\n",
      "Epoch   0 Batch 7969/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 7970/17275   train_loss = 3.226\n",
      "Epoch   0 Batch 7971/17275   train_loss = 4.021\n",
      "Epoch   0 Batch 7972/17275   train_loss = 6.404\n",
      "Epoch   0 Batch 7973/17275   train_loss = 3.620\n",
      "Epoch   0 Batch 7974/17275   train_loss = 3.387\n",
      "Epoch   0 Batch 7975/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 7976/17275   train_loss = 2.632\n",
      "Epoch   0 Batch 7977/17275   train_loss = 3.531\n",
      "Epoch   0 Batch 7978/17275   train_loss = 6.567\n",
      "Epoch   0 Batch 7979/17275   train_loss = 5.266\n",
      "Epoch   0 Batch 7980/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 7981/17275   train_loss = 6.333\n",
      "Epoch   0 Batch 7982/17275   train_loss = 3.569\n",
      "Epoch   0 Batch 7983/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 7984/17275   train_loss = 6.443\n",
      "Epoch   0 Batch 7985/17275   train_loss = 2.376\n",
      "Epoch   0 Batch 7986/17275   train_loss = 1.956\n",
      "Epoch   0 Batch 7987/17275   train_loss = 6.604\n",
      "Epoch   0 Batch 7988/17275   train_loss = 1.990\n",
      "Epoch   0 Batch 7989/17275   train_loss = 2.695\n",
      "Epoch   0 Batch 7990/17275   train_loss = 9.783\n",
      "Epoch   0 Batch 7991/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 7992/17275   train_loss = 3.093\n",
      "Epoch   0 Batch 7993/17275   train_loss = 4.631\n",
      "Epoch   0 Batch 7994/17275   train_loss = 2.385\n",
      "Epoch   0 Batch 7995/17275   train_loss = 3.446\n",
      "Epoch   0 Batch 7996/17275   train_loss = 5.962\n",
      "Epoch   0 Batch 7997/17275   train_loss = 1.916\n",
      "Epoch   0 Batch 7998/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 7999/17275   train_loss = 3.690\n",
      "Epoch   0 Batch 8000/17275   train_loss = 4.833\n",
      "Epoch   0 Batch 8001/17275   train_loss = 3.865\n",
      "Epoch   0 Batch 8002/17275   train_loss = 2.346\n",
      "Epoch   0 Batch 8003/17275   train_loss = 6.246\n",
      "Epoch   0 Batch 8004/17275   train_loss = 2.733\n",
      "Epoch   0 Batch 8005/17275   train_loss = 4.166\n",
      "Epoch   0 Batch 8006/17275   train_loss = 1.868\n",
      "Epoch   0 Batch 8007/17275   train_loss = 3.570\n",
      "Epoch   0 Batch 8008/17275   train_loss = 3.659\n",
      "Epoch   0 Batch 8009/17275   train_loss = 6.635\n",
      "Epoch   0 Batch 8010/17275   train_loss = 4.611\n",
      "Epoch   0 Batch 8011/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 8012/17275   train_loss = 3.536\n",
      "Epoch   0 Batch 8013/17275   train_loss = 3.960\n",
      "Epoch   0 Batch 8014/17275   train_loss = 2.918\n",
      "Epoch   0 Batch 8015/17275   train_loss = 4.144\n",
      "Epoch   0 Batch 8016/17275   train_loss = 3.549\n",
      "Epoch   0 Batch 8017/17275   train_loss = 4.553\n",
      "Epoch   0 Batch 8018/17275   train_loss = 2.391\n",
      "Epoch   0 Batch 8019/17275   train_loss = 6.232\n",
      "Epoch   0 Batch 8020/17275   train_loss = 5.810\n",
      "Epoch   0 Batch 8021/17275   train_loss = 4.264\n",
      "Epoch   0 Batch 8022/17275   train_loss = 4.850\n",
      "Epoch   0 Batch 8023/17275   train_loss = 2.705\n",
      "Epoch   0 Batch 8024/17275   train_loss = 9.203\n",
      "Epoch   0 Batch 8025/17275   train_loss = 2.317\n",
      "Epoch   0 Batch 8026/17275   train_loss = 6.360\n",
      "Epoch   0 Batch 8027/17275   train_loss = 2.958\n",
      "Epoch   0 Batch 8028/17275   train_loss = 8.109\n",
      "Epoch   0 Batch 8029/17275   train_loss = 2.746\n",
      "Epoch   0 Batch 8030/17275   train_loss = 4.591\n",
      "Epoch   0 Batch 8031/17275   train_loss = 3.573\n",
      "Epoch   0 Batch 8032/17275   train_loss = 5.774\n",
      "Epoch   0 Batch 8033/17275   train_loss = 3.957\n",
      "Epoch   0 Batch 8034/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 8035/17275   train_loss = 6.467\n",
      "Epoch   0 Batch 8036/17275   train_loss = 3.695\n",
      "Epoch   0 Batch 8037/17275   train_loss = 3.295\n",
      "Epoch   0 Batch 8038/17275   train_loss = 6.358\n",
      "Epoch   0 Batch 8039/17275   train_loss = 4.539\n",
      "Epoch   0 Batch 8040/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 8041/17275   train_loss = 1.846\n",
      "Epoch   0 Batch 8042/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 8043/17275   train_loss = 2.612\n",
      "Epoch   0 Batch 8044/17275   train_loss = 6.170\n",
      "Epoch   0 Batch 8045/17275   train_loss = 4.157\n",
      "Epoch   0 Batch 8046/17275   train_loss = 4.229\n",
      "Epoch   0 Batch 8047/17275   train_loss = 4.884\n",
      "Epoch   0 Batch 8048/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 8049/17275   train_loss = 3.522\n",
      "Epoch   0 Batch 8050/17275   train_loss = 8.013\n",
      "Epoch   0 Batch 8051/17275   train_loss = 2.641\n",
      "Epoch   0 Batch 8052/17275   train_loss = 5.460\n",
      "Epoch   0 Batch 8053/17275   train_loss = 6.991\n",
      "Epoch   0 Batch 8054/17275   train_loss = 3.295\n",
      "Epoch   0 Batch 8055/17275   train_loss = 3.851\n",
      "Epoch   0 Batch 8056/17275   train_loss = 2.014\n",
      "Epoch   0 Batch 8057/17275   train_loss = 2.984\n",
      "Epoch   0 Batch 8058/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 8059/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 8060/17275   train_loss = 5.801\n",
      "Epoch   0 Batch 8061/17275   train_loss = 4.085\n",
      "Epoch   0 Batch 8062/17275   train_loss = 2.962\n",
      "Epoch   0 Batch 8063/17275   train_loss = 4.777\n",
      "Epoch   0 Batch 8064/17275   train_loss = 2.034\n",
      "Epoch   0 Batch 8065/17275   train_loss = 3.445\n",
      "Epoch   0 Batch 8066/17275   train_loss = 5.803\n",
      "Epoch   0 Batch 8067/17275   train_loss = 6.558\n",
      "Epoch   0 Batch 8068/17275   train_loss = 6.731\n",
      "Epoch   0 Batch 8069/17275   train_loss = 7.226\n",
      "Epoch   0 Batch 8070/17275   train_loss = 1.999\n",
      "Epoch   0 Batch 8071/17275   train_loss = 2.204\n",
      "Epoch   0 Batch 8072/17275   train_loss = 4.901\n",
      "Epoch   0 Batch 8073/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 8074/17275   train_loss = 6.603\n",
      "Epoch   0 Batch 8075/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 8076/17275   train_loss = 4.142\n",
      "Epoch   0 Batch 8077/17275   train_loss = 6.131\n",
      "Epoch   0 Batch 8078/17275   train_loss = 3.134\n",
      "Epoch   0 Batch 8079/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 8080/17275   train_loss = 2.725\n",
      "Epoch   0 Batch 8081/17275   train_loss = 3.637\n",
      "Epoch   0 Batch 8082/17275   train_loss = 3.863\n",
      "Epoch   0 Batch 8083/17275   train_loss = 5.689\n",
      "Epoch   0 Batch 8084/17275   train_loss = 3.795\n",
      "Epoch   0 Batch 8085/17275   train_loss = 2.453\n",
      "Epoch   0 Batch 8086/17275   train_loss = 6.046\n",
      "Epoch   0 Batch 8087/17275   train_loss = 6.044\n",
      "Epoch   0 Batch 8088/17275   train_loss = 7.229\n",
      "Epoch   0 Batch 8089/17275   train_loss = 3.361\n",
      "Epoch   0 Batch 8090/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 8091/17275   train_loss = 2.361\n",
      "Epoch   0 Batch 8092/17275   train_loss = 3.916\n",
      "Epoch   0 Batch 8093/17275   train_loss = 3.180\n",
      "Epoch   0 Batch 8094/17275   train_loss = 8.053\n",
      "Epoch   0 Batch 8095/17275   train_loss = 3.042\n",
      "Epoch   0 Batch 8096/17275   train_loss = 2.782\n",
      "Epoch   0 Batch 8097/17275   train_loss = 4.029\n",
      "Epoch   0 Batch 8098/17275   train_loss = 3.943\n",
      "Epoch   0 Batch 8099/17275   train_loss = 3.523\n",
      "Epoch   0 Batch 8100/17275   train_loss = 4.249\n",
      "Epoch   0 Batch 8101/17275   train_loss = 2.687\n",
      "Epoch   0 Batch 8102/17275   train_loss = 2.896\n",
      "Epoch   0 Batch 8103/17275   train_loss = 3.815\n",
      "Epoch   0 Batch 8104/17275   train_loss = 6.351\n",
      "Epoch   0 Batch 8105/17275   train_loss = 2.482\n",
      "Epoch   0 Batch 8106/17275   train_loss = 6.010\n",
      "Epoch   0 Batch 8107/17275   train_loss = 6.008\n",
      "Epoch   0 Batch 8108/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 8109/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 8110/17275   train_loss = 3.974\n",
      "Epoch   0 Batch 8111/17275   train_loss = 2.230\n",
      "Epoch   0 Batch 8112/17275   train_loss = 3.223\n",
      "Epoch   0 Batch 8113/17275   train_loss = 3.231\n",
      "Epoch   0 Batch 8114/17275   train_loss = 2.641\n",
      "Epoch   0 Batch 8115/17275   train_loss = 2.014\n",
      "Epoch   0 Batch 8116/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 8117/17275   train_loss = 5.974\n",
      "Epoch   0 Batch 8118/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 8119/17275   train_loss = 3.121\n",
      "Epoch   0 Batch 8120/17275   train_loss = 7.410\n",
      "Epoch   0 Batch 8121/17275   train_loss = 3.121\n",
      "Epoch   0 Batch 8122/17275   train_loss = 1.956\n",
      "Epoch   0 Batch 8123/17275   train_loss = 3.109\n",
      "Epoch   0 Batch 8124/17275   train_loss = 4.620\n",
      "Epoch   0 Batch 8125/17275   train_loss = 3.498\n",
      "Epoch   0 Batch 8126/17275   train_loss = 7.085\n",
      "Epoch   0 Batch 8127/17275   train_loss = 3.036\n",
      "Epoch   0 Batch 8128/17275   train_loss = 3.794\n",
      "Epoch   0 Batch 8129/17275   train_loss = 1.958\n",
      "Epoch   0 Batch 8130/17275   train_loss = 2.268\n",
      "Epoch   0 Batch 8131/17275   train_loss = 1.804\n",
      "Epoch   0 Batch 8132/17275   train_loss = 3.305\n",
      "Epoch   0 Batch 8133/17275   train_loss = 7.865\n",
      "Epoch   0 Batch 8134/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 8135/17275   train_loss = 4.112\n",
      "Epoch   0 Batch 8136/17275   train_loss = 9.806\n",
      "Epoch   0 Batch 8137/17275   train_loss = 4.635\n",
      "Epoch   0 Batch 8138/17275   train_loss = 5.933\n",
      "Epoch   0 Batch 8139/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 8140/17275   train_loss = 3.817\n",
      "Epoch   0 Batch 8141/17275   train_loss = 1.642\n",
      "Epoch   0 Batch 8142/17275   train_loss = 4.302\n",
      "Epoch   0 Batch 8143/17275   train_loss = 3.217\n",
      "Epoch   0 Batch 8144/17275   train_loss = 4.498\n",
      "Epoch   0 Batch 8145/17275   train_loss = 6.163\n",
      "Epoch   0 Batch 8146/17275   train_loss = 2.718\n",
      "Epoch   0 Batch 8147/17275   train_loss = 2.693\n",
      "Epoch   0 Batch 8148/17275   train_loss = 2.413\n",
      "Epoch   0 Batch 8149/17275   train_loss = 2.964\n",
      "Epoch   0 Batch 8150/17275   train_loss = 2.749\n",
      "Epoch   0 Batch 8151/17275   train_loss = 6.576\n",
      "Epoch   0 Batch 8152/17275   train_loss = 4.108\n",
      "Epoch   0 Batch 8153/17275   train_loss = 1.603\n",
      "Epoch   0 Batch 8154/17275   train_loss = 1.862\n",
      "Epoch   0 Batch 8155/17275   train_loss = 2.844\n",
      "Epoch   0 Batch 8156/17275   train_loss = 6.170\n",
      "Epoch   0 Batch 8157/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 8158/17275   train_loss = 3.311\n",
      "Epoch   0 Batch 8159/17275   train_loss = 2.650\n",
      "Epoch   0 Batch 8160/17275   train_loss = 2.498\n",
      "Epoch   0 Batch 8161/17275   train_loss = 3.206\n",
      "Epoch   0 Batch 8162/17275   train_loss = 7.726\n",
      "Epoch   0 Batch 8163/17275   train_loss = 4.659\n",
      "Epoch   0 Batch 8164/17275   train_loss = 7.729\n",
      "Epoch   0 Batch 8165/17275   train_loss = 6.165\n",
      "Epoch   0 Batch 8166/17275   train_loss = 4.282\n",
      "Epoch   0 Batch 8167/17275   train_loss = 8.097\n",
      "Epoch   0 Batch 8168/17275   train_loss = 9.852\n",
      "Epoch   0 Batch 8169/17275   train_loss = 4.063\n",
      "Epoch   0 Batch 8170/17275   train_loss = 6.512\n",
      "Epoch   0 Batch 8171/17275   train_loss = 7.946\n",
      "Epoch   0 Batch 8172/17275   train_loss = 4.042\n",
      "Epoch   0 Batch 8173/17275   train_loss = 2.911\n",
      "Epoch   0 Batch 8174/17275   train_loss = 6.454\n",
      "Epoch   0 Batch 8175/17275   train_loss = 3.983\n",
      "Epoch   0 Batch 8176/17275   train_loss = 7.931\n",
      "Epoch   0 Batch 8177/17275   train_loss = 1.894\n",
      "Epoch   0 Batch 8178/17275   train_loss = 2.002\n",
      "Epoch   0 Batch 8179/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 8180/17275   train_loss = 4.454\n",
      "Epoch   0 Batch 8181/17275   train_loss = 4.987\n",
      "Epoch   0 Batch 8182/17275   train_loss = 4.590\n",
      "Epoch   0 Batch 8183/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 8184/17275   train_loss = 5.144\n",
      "Epoch   0 Batch 8185/17275   train_loss = 9.802\n",
      "Epoch   0 Batch 8186/17275   train_loss = 5.171\n",
      "Epoch   0 Batch 8187/17275   train_loss = 6.790\n",
      "Epoch   0 Batch 8188/17275   train_loss = 6.009\n",
      "Epoch   0 Batch 8189/17275   train_loss = 2.224\n",
      "Epoch   0 Batch 8190/17275   train_loss = 4.886\n",
      "Epoch   0 Batch 8191/17275   train_loss = 7.448\n",
      "Epoch   0 Batch 8192/17275   train_loss = 8.928\n",
      "Epoch   0 Batch 8193/17275   train_loss = 7.314\n",
      "Epoch   0 Batch 8194/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 8195/17275   train_loss = 4.563\n",
      "Epoch   0 Batch 8196/17275   train_loss = 4.036\n",
      "Epoch   0 Batch 8197/17275   train_loss = 5.266\n",
      "Epoch   0 Batch 8198/17275   train_loss = 2.180\n",
      "Epoch   0 Batch 8199/17275   train_loss = 4.215\n",
      "Epoch   0 Batch 8200/17275   train_loss = 6.204\n",
      "Epoch   0 Batch 8201/17275   train_loss = 2.478\n",
      "Epoch   0 Batch 8202/17275   train_loss = 3.889\n",
      "Epoch   0 Batch 8203/17275   train_loss = 2.658\n",
      "Epoch   0 Batch 8204/17275   train_loss = 3.107\n",
      "Epoch   0 Batch 8205/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 8206/17275   train_loss = 4.307\n",
      "Epoch   0 Batch 8207/17275   train_loss = 2.075\n",
      "Epoch   0 Batch 8208/17275   train_loss = 2.815\n",
      "Epoch   0 Batch 8209/17275   train_loss = 6.930\n",
      "Epoch   0 Batch 8210/17275   train_loss = 6.167\n",
      "Epoch   0 Batch 8211/17275   train_loss = 5.079\n",
      "Epoch   0 Batch 8212/17275   train_loss = 2.391\n",
      "Epoch   0 Batch 8213/17275   train_loss = 3.169\n",
      "Epoch   0 Batch 8214/17275   train_loss = 4.643\n",
      "Epoch   0 Batch 8215/17275   train_loss = 5.180\n",
      "Epoch   0 Batch 8216/17275   train_loss = 7.612\n",
      "Epoch   0 Batch 8217/17275   train_loss = 3.998\n",
      "Epoch   0 Batch 8218/17275   train_loss = 4.304\n",
      "Epoch   0 Batch 8219/17275   train_loss = 2.523\n",
      "Epoch   0 Batch 8220/17275   train_loss = 2.329\n",
      "Epoch   0 Batch 8221/17275   train_loss = 3.617\n",
      "Epoch   0 Batch 8222/17275   train_loss = 4.808\n",
      "Epoch   0 Batch 8223/17275   train_loss = 3.365\n",
      "Epoch   0 Batch 8224/17275   train_loss = 5.166\n",
      "Epoch   0 Batch 8225/17275   train_loss = 6.517\n",
      "Epoch   0 Batch 8226/17275   train_loss = 4.165\n",
      "Epoch   0 Batch 8227/17275   train_loss = 3.041\n",
      "Epoch   0 Batch 8228/17275   train_loss = 4.034\n",
      "Epoch   0 Batch 8229/17275   train_loss = 3.228\n",
      "Epoch   0 Batch 8230/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 8231/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 8232/17275   train_loss = 2.377\n",
      "Epoch   0 Batch 8233/17275   train_loss = 4.307\n",
      "Epoch   0 Batch 8234/17275   train_loss = 4.048\n",
      "Epoch   0 Batch 8235/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 8236/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 8237/17275   train_loss = 6.811\n",
      "Epoch   0 Batch 8238/17275   train_loss = 3.110\n",
      "Epoch   0 Batch 8239/17275   train_loss = 4.950\n",
      "Epoch   0 Batch 8240/17275   train_loss = 4.679\n",
      "Epoch   0 Batch 8241/17275   train_loss = 4.062\n",
      "Epoch   0 Batch 8242/17275   train_loss = 2.130\n",
      "Epoch   0 Batch 8243/17275   train_loss = 4.723\n",
      "Epoch   0 Batch 8244/17275   train_loss = 6.751\n",
      "Epoch   0 Batch 8245/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 8246/17275   train_loss = 2.705\n",
      "Epoch   0 Batch 8247/17275   train_loss = 6.625\n",
      "Epoch   0 Batch 8248/17275   train_loss = 2.965\n",
      "Epoch   0 Batch 8249/17275   train_loss = 3.396\n",
      "Epoch   0 Batch 8250/17275   train_loss = 3.238\n",
      "Epoch   0 Batch 8251/17275   train_loss = 2.515\n",
      "Epoch   0 Batch 8252/17275   train_loss = 3.895\n",
      "Epoch   0 Batch 8253/17275   train_loss = 2.593\n",
      "Epoch   0 Batch 8254/17275   train_loss = 6.069\n",
      "Epoch   0 Batch 8255/17275   train_loss = 5.967\n",
      "Epoch   0 Batch 8256/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 8257/17275   train_loss = 3.562\n",
      "Epoch   0 Batch 8258/17275   train_loss = 3.167\n",
      "Epoch   0 Batch 8259/17275   train_loss = 4.261\n",
      "Epoch   0 Batch 8260/17275   train_loss = 5.947\n",
      "Epoch   0 Batch 8261/17275   train_loss = 2.978\n",
      "Epoch   0 Batch 8262/17275   train_loss = 4.234\n",
      "Epoch   0 Batch 8263/17275   train_loss = 5.215\n",
      "Epoch   0 Batch 8264/17275   train_loss = 3.282\n",
      "Epoch   0 Batch 8265/17275   train_loss = 7.056\n",
      "Epoch   0 Batch 8266/17275   train_loss = 6.630\n",
      "Epoch   0 Batch 8267/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 8268/17275   train_loss = 5.927\n",
      "Epoch   0 Batch 8269/17275   train_loss = 3.559\n",
      "Epoch   0 Batch 8270/17275   train_loss = 6.201\n",
      "Epoch   0 Batch 8271/17275   train_loss = 3.285\n",
      "Epoch   0 Batch 8272/17275   train_loss = 4.082\n",
      "Epoch   0 Batch 8273/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 8274/17275   train_loss = 3.042\n",
      "Epoch   0 Batch 8275/17275   train_loss = 2.485\n",
      "Epoch   0 Batch 8276/17275   train_loss = 6.199\n",
      "Epoch   0 Batch 8277/17275   train_loss = 3.196\n",
      "Epoch   0 Batch 8278/17275   train_loss = 3.200\n",
      "Epoch   0 Batch 8279/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 8280/17275   train_loss = 2.840\n",
      "Epoch   0 Batch 8281/17275   train_loss = 6.559\n",
      "Epoch   0 Batch 8282/17275   train_loss = 4.195\n",
      "Epoch   0 Batch 8283/17275   train_loss = 4.057\n",
      "Epoch   0 Batch 8284/17275   train_loss = 2.053\n",
      "Epoch   0 Batch 8285/17275   train_loss = 7.534\n",
      "Epoch   0 Batch 8286/17275   train_loss = 3.961\n",
      "Epoch   0 Batch 8287/17275   train_loss = 4.998\n",
      "Epoch   0 Batch 8288/17275   train_loss = 4.146\n",
      "Epoch   0 Batch 8289/17275   train_loss = 4.102\n",
      "Epoch   0 Batch 8290/17275   train_loss = 3.600\n",
      "Epoch   0 Batch 8291/17275   train_loss = 3.422\n",
      "Epoch   0 Batch 8292/17275   train_loss = 4.020\n",
      "Epoch   0 Batch 8293/17275   train_loss = 3.584\n",
      "Epoch   0 Batch 8294/17275   train_loss = 4.165\n",
      "Epoch   0 Batch 8295/17275   train_loss = 5.941\n",
      "Epoch   0 Batch 8296/17275   train_loss = 3.398\n",
      "Epoch   0 Batch 8297/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 8298/17275   train_loss = 5.339\n",
      "Epoch   0 Batch 8299/17275   train_loss = 6.178\n",
      "Epoch   0 Batch 8300/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 8301/17275   train_loss = 3.771\n",
      "Epoch   0 Batch 8302/17275   train_loss = 5.512\n",
      "Epoch   0 Batch 8303/17275   train_loss = 5.380\n",
      "Epoch   0 Batch 8304/17275   train_loss = 5.875\n",
      "Epoch   0 Batch 8305/17275   train_loss = 2.870\n",
      "Epoch   0 Batch 8306/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 8307/17275   train_loss = 3.132\n",
      "Epoch   0 Batch 8308/17275   train_loss = 3.963\n",
      "Epoch   0 Batch 8309/17275   train_loss = 6.435\n",
      "Epoch   0 Batch 8310/17275   train_loss = 4.334\n",
      "Epoch   0 Batch 8311/17275   train_loss = 6.467\n",
      "Epoch   0 Batch 8312/17275   train_loss = 4.354\n",
      "Epoch   0 Batch 8313/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 8314/17275   train_loss = 5.539\n",
      "Epoch   0 Batch 8315/17275   train_loss = 3.514\n",
      "Epoch   0 Batch 8316/17275   train_loss = 2.584\n",
      "Epoch   0 Batch 8317/17275   train_loss = 2.716\n",
      "Epoch   0 Batch 8318/17275   train_loss = 5.292\n",
      "Epoch   0 Batch 8319/17275   train_loss = 3.159\n",
      "Epoch   0 Batch 8320/17275   train_loss = 6.184\n",
      "Epoch   0 Batch 8321/17275   train_loss = 3.920\n",
      "Epoch   0 Batch 8322/17275   train_loss = 5.114\n",
      "Epoch   0 Batch 8323/17275   train_loss = 6.709\n",
      "Epoch   0 Batch 8324/17275   train_loss = 4.361\n",
      "Epoch   0 Batch 8325/17275   train_loss = 2.401\n",
      "Epoch   0 Batch 8326/17275   train_loss = 3.379\n",
      "Epoch   0 Batch 8327/17275   train_loss = 4.746\n",
      "Epoch   0 Batch 8328/17275   train_loss = 3.491\n",
      "Epoch   0 Batch 8329/17275   train_loss = 7.224\n",
      "Epoch   0 Batch 8330/17275   train_loss = 3.194\n",
      "Epoch   0 Batch 8331/17275   train_loss = 3.150\n",
      "Epoch   0 Batch 8332/17275   train_loss = 4.194\n",
      "Epoch   0 Batch 8333/17275   train_loss = 4.283\n",
      "Epoch   0 Batch 8334/17275   train_loss = 4.522\n",
      "Epoch   0 Batch 8335/17275   train_loss = 9.798\n",
      "Epoch   0 Batch 8336/17275   train_loss = 5.939\n",
      "Epoch   0 Batch 8337/17275   train_loss = 2.844\n",
      "Epoch   0 Batch 8338/17275   train_loss = 6.221\n",
      "Epoch   0 Batch 8339/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 8340/17275   train_loss = 3.516\n",
      "Epoch   0 Batch 8341/17275   train_loss = 3.391\n",
      "Epoch   0 Batch 8342/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 8343/17275   train_loss = 3.662\n",
      "Epoch   0 Batch 8344/17275   train_loss = 2.543\n",
      "Epoch   0 Batch 8345/17275   train_loss = 4.229\n",
      "Epoch   0 Batch 8346/17275   train_loss = 3.315\n",
      "Epoch   0 Batch 8347/17275   train_loss = 3.319\n",
      "Epoch   0 Batch 8348/17275   train_loss = 4.956\n",
      "Epoch   0 Batch 8349/17275   train_loss = 2.532\n",
      "Epoch   0 Batch 8350/17275   train_loss = 2.778\n",
      "Epoch   0 Batch 8351/17275   train_loss = 6.605\n",
      "Epoch   0 Batch 8352/17275   train_loss = 2.493\n",
      "Epoch   0 Batch 8353/17275   train_loss = 5.782\n",
      "Epoch   0 Batch 8354/17275   train_loss = 6.673\n",
      "Epoch   0 Batch 8355/17275   train_loss = 3.475\n",
      "Epoch   0 Batch 8356/17275   train_loss = 4.661\n",
      "Epoch   0 Batch 8357/17275   train_loss = 2.157\n",
      "Epoch   0 Batch 8358/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 8359/17275   train_loss = 2.556\n",
      "Epoch   0 Batch 8360/17275   train_loss = 3.363\n",
      "Epoch   0 Batch 8361/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 8362/17275   train_loss = 3.059\n",
      "Epoch   0 Batch 8363/17275   train_loss = 3.111\n",
      "Epoch   0 Batch 8364/17275   train_loss = 5.395\n",
      "Epoch   0 Batch 8365/17275   train_loss = 2.238\n",
      "Epoch   0 Batch 8366/17275   train_loss = 3.620\n",
      "Epoch   0 Batch 8367/17275   train_loss = 3.404\n",
      "Epoch   0 Batch 8368/17275   train_loss = 6.290\n",
      "Epoch   0 Batch 8369/17275   train_loss = 3.250\n",
      "Epoch   0 Batch 8370/17275   train_loss = 6.270\n",
      "Epoch   0 Batch 8371/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 8372/17275   train_loss = 4.213\n",
      "Epoch   0 Batch 8373/17275   train_loss = 4.484\n",
      "Epoch   0 Batch 8374/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 8375/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 8376/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 8377/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 8378/17275   train_loss = 4.229\n",
      "Epoch   0 Batch 8379/17275   train_loss = 7.001\n",
      "Epoch   0 Batch 8380/17275   train_loss = 2.690\n",
      "Epoch   0 Batch 8381/17275   train_loss = 9.859\n",
      "Epoch   0 Batch 8382/17275   train_loss = 6.529\n",
      "Epoch   0 Batch 8383/17275   train_loss = 6.657\n",
      "Epoch   0 Batch 8384/17275   train_loss = 6.428\n",
      "Epoch   0 Batch 8385/17275   train_loss = 6.361\n",
      "Epoch   0 Batch 8386/17275   train_loss = 3.405\n",
      "Epoch   0 Batch 8387/17275   train_loss = 9.844\n",
      "Epoch   0 Batch 8388/17275   train_loss = 3.077\n",
      "Epoch   0 Batch 8389/17275   train_loss = 9.840\n",
      "Epoch   0 Batch 8390/17275   train_loss = 2.302\n",
      "Epoch   0 Batch 8391/17275   train_loss = 2.686\n",
      "Epoch   0 Batch 8392/17275   train_loss = 8.563\n",
      "Epoch   0 Batch 8393/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 8394/17275   train_loss = 3.950\n",
      "Epoch   0 Batch 8395/17275   train_loss = 2.896\n",
      "Epoch   0 Batch 8396/17275   train_loss = 2.546\n",
      "Epoch   0 Batch 8397/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 8398/17275   train_loss = 3.757\n",
      "Epoch   0 Batch 8399/17275   train_loss = 3.128\n",
      "Epoch   0 Batch 8400/17275   train_loss = 2.807\n",
      "Epoch   0 Batch 8401/17275   train_loss = 2.758\n",
      "Epoch   0 Batch 8402/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 8403/17275   train_loss = 6.598\n",
      "Epoch   0 Batch 8404/17275   train_loss = 2.748\n",
      "Epoch   0 Batch 8405/17275   train_loss = 2.616\n",
      "Epoch   0 Batch 8406/17275   train_loss = 3.345\n",
      "Epoch   0 Batch 8407/17275   train_loss = 4.202\n",
      "Epoch   0 Batch 8408/17275   train_loss = 4.661\n",
      "Epoch   0 Batch 8409/17275   train_loss = 5.316\n",
      "Epoch   0 Batch 8410/17275   train_loss = 2.619\n",
      "Epoch   0 Batch 8411/17275   train_loss = 2.791\n",
      "Epoch   0 Batch 8412/17275   train_loss = 3.914\n",
      "Epoch   0 Batch 8413/17275   train_loss = 4.498\n",
      "Epoch   0 Batch 8414/17275   train_loss = 3.301\n",
      "Epoch   0 Batch 8415/17275   train_loss = 3.545\n",
      "Epoch   0 Batch 8416/17275   train_loss = 3.170\n",
      "Epoch   0 Batch 8417/17275   train_loss = 3.265\n",
      "Epoch   0 Batch 8418/17275   train_loss = 7.240\n",
      "Epoch   0 Batch 8419/17275   train_loss = 2.423\n",
      "Epoch   0 Batch 8420/17275   train_loss = 5.961\n",
      "Epoch   0 Batch 8421/17275   train_loss = 6.251\n",
      "Epoch   0 Batch 8422/17275   train_loss = 6.359\n",
      "Epoch   0 Batch 8423/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 8424/17275   train_loss = 5.127\n",
      "Epoch   0 Batch 8425/17275   train_loss = 2.639\n",
      "Epoch   0 Batch 8426/17275   train_loss = 6.168\n",
      "Epoch   0 Batch 8427/17275   train_loss = 3.226\n",
      "Epoch   0 Batch 8428/17275   train_loss = 2.527\n",
      "Epoch   0 Batch 8429/17275   train_loss = 3.645\n",
      "Epoch   0 Batch 8430/17275   train_loss = 3.489\n",
      "Epoch   0 Batch 8431/17275   train_loss = 4.151\n",
      "Epoch   0 Batch 8432/17275   train_loss = 3.642\n",
      "Epoch   0 Batch 8433/17275   train_loss = 6.655\n",
      "Epoch   0 Batch 8434/17275   train_loss = 6.269\n",
      "Epoch   0 Batch 8435/17275   train_loss = 6.097\n",
      "Epoch   0 Batch 8436/17275   train_loss = 6.082\n",
      "Epoch   0 Batch 8437/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 8438/17275   train_loss = 8.196\n",
      "Epoch   0 Batch 8439/17275   train_loss = 6.193\n",
      "Epoch   0 Batch 8440/17275   train_loss = 6.009\n",
      "Epoch   0 Batch 8441/17275   train_loss = 6.263\n",
      "Epoch   0 Batch 8442/17275   train_loss = 2.425\n",
      "Epoch   0 Batch 8443/17275   train_loss = 6.130\n",
      "Epoch   0 Batch 8444/17275   train_loss = 4.115\n",
      "Epoch   0 Batch 8445/17275   train_loss = 7.404\n",
      "Epoch   0 Batch 8446/17275   train_loss = 4.196\n",
      "Epoch   0 Batch 8447/17275   train_loss = 2.198\n",
      "Epoch   0 Batch 8448/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 8449/17275   train_loss = 3.852\n",
      "Epoch   0 Batch 8450/17275   train_loss = 2.924\n",
      "Epoch   0 Batch 8451/17275   train_loss = 2.748\n",
      "Epoch   0 Batch 8452/17275   train_loss = 3.179\n",
      "Epoch   0 Batch 8453/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 8454/17275   train_loss = 4.272\n",
      "Epoch   0 Batch 8455/17275   train_loss = 6.422\n",
      "Epoch   0 Batch 8456/17275   train_loss = 3.175\n",
      "Epoch   0 Batch 8457/17275   train_loss = 2.281\n",
      "Epoch   0 Batch 8458/17275   train_loss = 6.256\n",
      "Epoch   0 Batch 8459/17275   train_loss = 3.923\n",
      "Epoch   0 Batch 8460/17275   train_loss = 4.411\n",
      "Epoch   0 Batch 8461/17275   train_loss = 4.094\n",
      "Epoch   0 Batch 8462/17275   train_loss = 4.771\n",
      "Epoch   0 Batch 8463/17275   train_loss = 3.647\n",
      "Epoch   0 Batch 8464/17275   train_loss = 2.354\n",
      "Epoch   0 Batch 8465/17275   train_loss = 6.214\n",
      "Epoch   0 Batch 8466/17275   train_loss = 3.921\n",
      "Epoch   0 Batch 8467/17275   train_loss = 5.015\n",
      "Epoch   0 Batch 8468/17275   train_loss = 3.707\n",
      "Epoch   0 Batch 8469/17275   train_loss = 4.374\n",
      "Epoch   0 Batch 8470/17275   train_loss = 6.849\n",
      "Epoch   0 Batch 8471/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 8472/17275   train_loss = 2.286\n",
      "Epoch   0 Batch 8473/17275   train_loss = 3.585\n",
      "Epoch   0 Batch 8474/17275   train_loss = 4.472\n",
      "Epoch   0 Batch 8475/17275   train_loss = 2.619\n",
      "Epoch   0 Batch 8476/17275   train_loss = 6.785\n",
      "Epoch   0 Batch 8477/17275   train_loss = 2.053\n",
      "Epoch   0 Batch 8478/17275   train_loss = 4.028\n",
      "Epoch   0 Batch 8479/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 8480/17275   train_loss = 5.795\n",
      "Epoch   0 Batch 8481/17275   train_loss = 2.299\n",
      "Epoch   0 Batch 8482/17275   train_loss = 5.899\n",
      "Epoch   0 Batch 8483/17275   train_loss = 7.203\n",
      "Epoch   0 Batch 8484/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 8485/17275   train_loss = 3.807\n",
      "Epoch   0 Batch 8486/17275   train_loss = 4.269\n",
      "Epoch   0 Batch 8487/17275   train_loss = 7.466\n",
      "Epoch   0 Batch 8488/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 8489/17275   train_loss = 4.757\n",
      "Epoch   0 Batch 8490/17275   train_loss = 4.318\n",
      "Epoch   0 Batch 8491/17275   train_loss = 6.515\n",
      "Epoch   0 Batch 8492/17275   train_loss = 5.884\n",
      "Epoch   0 Batch 8493/17275   train_loss = 1.914\n",
      "Epoch   0 Batch 8494/17275   train_loss = 4.668\n",
      "Epoch   0 Batch 8495/17275   train_loss = 2.211\n",
      "Epoch   0 Batch 8496/17275   train_loss = 9.848\n",
      "Epoch   0 Batch 8497/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 8498/17275   train_loss = 2.161\n",
      "Epoch   0 Batch 8499/17275   train_loss = 9.419\n",
      "Epoch   0 Batch 8500/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 8501/17275   train_loss = 3.984\n",
      "Epoch   0 Batch 8502/17275   train_loss = 5.141\n",
      "Epoch   0 Batch 8503/17275   train_loss = 2.968\n",
      "Epoch   0 Batch 8504/17275   train_loss = 7.238\n",
      "Epoch   0 Batch 8505/17275   train_loss = 3.040\n",
      "Epoch   0 Batch 8506/17275   train_loss = 6.279\n",
      "Epoch   0 Batch 8507/17275   train_loss = 6.742\n",
      "Epoch   0 Batch 8508/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 8509/17275   train_loss = 3.200\n",
      "Epoch   0 Batch 8510/17275   train_loss = 3.812\n",
      "Epoch   0 Batch 8511/17275   train_loss = 1.739\n",
      "Epoch   0 Batch 8512/17275   train_loss = 1.724\n",
      "Epoch   0 Batch 8513/17275   train_loss = 4.284\n",
      "Epoch   0 Batch 8514/17275   train_loss = 4.532\n",
      "Epoch   0 Batch 8515/17275   train_loss = 6.137\n",
      "Epoch   0 Batch 8516/17275   train_loss = 9.864\n",
      "Epoch   0 Batch 8517/17275   train_loss = 7.237\n",
      "Epoch   0 Batch 8518/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 8519/17275   train_loss = 6.877\n",
      "Epoch   0 Batch 8520/17275   train_loss = 6.804\n",
      "Epoch   0 Batch 8521/17275   train_loss = 9.873\n",
      "Epoch   0 Batch 8522/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 8523/17275   train_loss = 6.109\n",
      "Epoch   0 Batch 8524/17275   train_loss = 3.987\n",
      "Epoch   0 Batch 8525/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 8526/17275   train_loss = 5.278\n",
      "Epoch   0 Batch 8527/17275   train_loss = 4.939\n",
      "Epoch   0 Batch 8528/17275   train_loss = 7.493\n",
      "Epoch   0 Batch 8529/17275   train_loss = 4.132\n",
      "Epoch   0 Batch 8530/17275   train_loss = 6.885\n",
      "Epoch   0 Batch 8531/17275   train_loss = 5.754\n",
      "Epoch   0 Batch 8532/17275   train_loss = 6.111\n",
      "Epoch   0 Batch 8533/17275   train_loss = 6.551\n",
      "Epoch   0 Batch 8534/17275   train_loss = 9.853\n",
      "Epoch   0 Batch 8535/17275   train_loss = 2.000\n",
      "Epoch   0 Batch 8536/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 8537/17275   train_loss = 7.469\n",
      "Epoch   0 Batch 8538/17275   train_loss = 2.716\n",
      "Epoch   0 Batch 8539/17275   train_loss = 4.761\n",
      "Epoch   0 Batch 8540/17275   train_loss = 4.734\n",
      "Epoch   0 Batch 8541/17275   train_loss = 4.771\n",
      "Epoch   0 Batch 8542/17275   train_loss = 4.513\n",
      "Epoch   0 Batch 8543/17275   train_loss = 4.904\n",
      "Epoch   0 Batch 8544/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 8545/17275   train_loss = 5.722\n",
      "Epoch   0 Batch 8546/17275   train_loss = 4.347\n",
      "Epoch   0 Batch 8547/17275   train_loss = 6.017\n",
      "Epoch   0 Batch 8548/17275   train_loss = 6.752\n",
      "Epoch   0 Batch 8549/17275   train_loss = 3.847\n",
      "Epoch   0 Batch 8550/17275   train_loss = 2.929\n",
      "Epoch   0 Batch 8551/17275   train_loss = 5.815\n",
      "Epoch   0 Batch 8552/17275   train_loss = 2.262\n",
      "Epoch   0 Batch 8553/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 8554/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 8555/17275   train_loss = 2.211\n",
      "Epoch   0 Batch 8556/17275   train_loss = 5.899\n",
      "Epoch   0 Batch 8557/17275   train_loss = 2.223\n",
      "Epoch   0 Batch 8558/17275   train_loss = 4.111\n",
      "Epoch   0 Batch 8559/17275   train_loss = 5.534\n",
      "Epoch   0 Batch 8560/17275   train_loss = 7.272\n",
      "Epoch   0 Batch 8561/17275   train_loss = 4.026\n",
      "Epoch   0 Batch 8562/17275   train_loss = 6.167\n",
      "Epoch   0 Batch 8563/17275   train_loss = 5.870\n",
      "Epoch   0 Batch 8564/17275   train_loss = 3.361\n",
      "Epoch   0 Batch 8565/17275   train_loss = 6.269\n",
      "Epoch   0 Batch 8566/17275   train_loss = 6.275\n",
      "Epoch   0 Batch 8567/17275   train_loss = 7.833\n",
      "Epoch   0 Batch 8568/17275   train_loss = 5.353\n",
      "Epoch   0 Batch 8569/17275   train_loss = 3.316\n",
      "Epoch   0 Batch 8570/17275   train_loss = 1.979\n",
      "Epoch   0 Batch 8571/17275   train_loss = 1.850\n",
      "Epoch   0 Batch 8572/17275   train_loss = 2.057\n",
      "Epoch   0 Batch 8573/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 8574/17275   train_loss = 7.702\n",
      "Epoch   0 Batch 8575/17275   train_loss = 1.700\n",
      "Epoch   0 Batch 8576/17275   train_loss = 5.748\n",
      "Epoch   0 Batch 8577/17275   train_loss = 2.890\n",
      "Epoch   0 Batch 8578/17275   train_loss = 2.512\n",
      "Epoch   0 Batch 8579/17275   train_loss = 3.733\n",
      "Epoch   0 Batch 8580/17275   train_loss = 3.328\n",
      "Epoch   0 Batch 8581/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 8582/17275   train_loss = 2.412\n",
      "Epoch   0 Batch 8583/17275   train_loss = 3.858\n",
      "Epoch   0 Batch 8584/17275   train_loss = 2.282\n",
      "Epoch   0 Batch 8585/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 8586/17275   train_loss = 6.163\n",
      "Epoch   0 Batch 8587/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 8588/17275   train_loss = 2.805\n",
      "Epoch   0 Batch 8589/17275   train_loss = 3.695\n",
      "Epoch   0 Batch 8590/17275   train_loss = 6.292\n",
      "Epoch   0 Batch 8591/17275   train_loss = 4.547\n",
      "Epoch   0 Batch 8592/17275   train_loss = 8.328\n",
      "Epoch   0 Batch 8593/17275   train_loss = 4.038\n",
      "Epoch   0 Batch 8594/17275   train_loss = 3.399\n",
      "Epoch   0 Batch 8595/17275   train_loss = 3.327\n",
      "Epoch   0 Batch 8596/17275   train_loss = 3.514\n",
      "Epoch   0 Batch 8597/17275   train_loss = 3.936\n",
      "Epoch   0 Batch 8598/17275   train_loss = 3.705\n",
      "Epoch   0 Batch 8599/17275   train_loss = 2.843\n",
      "Epoch   0 Batch 8600/17275   train_loss = 2.615\n",
      "Epoch   0 Batch 8601/17275   train_loss = 5.174\n",
      "Epoch   0 Batch 8602/17275   train_loss = 2.378\n",
      "Epoch   0 Batch 8603/17275   train_loss = 3.216\n",
      "Epoch   0 Batch 8604/17275   train_loss = 3.356\n",
      "Epoch   0 Batch 8605/17275   train_loss = 3.385\n",
      "Epoch   0 Batch 8606/17275   train_loss = 6.267\n",
      "Epoch   0 Batch 8607/17275   train_loss = 2.959\n",
      "Epoch   0 Batch 8608/17275   train_loss = 5.052\n",
      "Epoch   0 Batch 8609/17275   train_loss = 3.755\n",
      "Epoch   0 Batch 8610/17275   train_loss = 5.272\n",
      "Epoch   0 Batch 8611/17275   train_loss = 3.569\n",
      "Epoch   0 Batch 8612/17275   train_loss = 4.486\n",
      "Epoch   0 Batch 8613/17275   train_loss = 4.046\n",
      "Epoch   0 Batch 8614/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 8615/17275   train_loss = 2.596\n",
      "Epoch   0 Batch 8616/17275   train_loss = 3.262\n",
      "Epoch   0 Batch 8617/17275   train_loss = 3.875\n",
      "Epoch   0 Batch 8618/17275   train_loss = 3.806\n",
      "Epoch   0 Batch 8619/17275   train_loss = 4.525\n",
      "Epoch   0 Batch 8620/17275   train_loss = 4.643\n",
      "Epoch   0 Batch 8621/17275   train_loss = 2.824\n",
      "Epoch   0 Batch 8622/17275   train_loss = 5.990\n",
      "Epoch   0 Batch 8623/17275   train_loss = 3.156\n",
      "Epoch   0 Batch 8624/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 8625/17275   train_loss = 2.691\n",
      "Epoch   0 Batch 8626/17275   train_loss = 5.228\n",
      "Epoch   0 Batch 8627/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 8628/17275   train_loss = 9.815\n",
      "Epoch   0 Batch 8629/17275   train_loss = 6.424\n",
      "Epoch   0 Batch 8630/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 8631/17275   train_loss = 3.146\n",
      "Epoch   0 Batch 8632/17275   train_loss = 3.288\n",
      "Epoch   0 Batch 8633/17275   train_loss = 6.579\n",
      "Epoch   0 Batch 8634/17275   train_loss = 3.820\n",
      "Epoch   0 Batch 8635/17275   train_loss = 3.306\n",
      "Epoch   0 Batch 8636/17275   train_loss = 6.524\n",
      "Epoch   0 Batch 8637/17275   train_loss = 9.818\n",
      "Epoch   0 Batch 8638/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 8639/17275   train_loss = 9.818\n",
      "Epoch   0 Batch 8640/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 8641/17275   train_loss = 3.472\n",
      "Epoch   0 Batch 8642/17275   train_loss = 3.991\n",
      "Epoch   0 Batch 8643/17275   train_loss = 2.757\n",
      "Epoch   0 Batch 8644/17275   train_loss = 3.577\n",
      "Epoch   0 Batch 8645/17275   train_loss = 2.107\n",
      "Epoch   0 Batch 8646/17275   train_loss = 3.240\n",
      "Epoch   0 Batch 8647/17275   train_loss = 2.494\n",
      "Epoch   0 Batch 8648/17275   train_loss = 4.329\n",
      "Epoch   0 Batch 8649/17275   train_loss = 2.233\n",
      "Epoch   0 Batch 8650/17275   train_loss = 3.707\n",
      "Epoch   0 Batch 8651/17275   train_loss = 6.238\n",
      "Epoch   0 Batch 8652/17275   train_loss = 3.382\n",
      "Epoch   0 Batch 8653/17275   train_loss = 4.519\n",
      "Epoch   0 Batch 8654/17275   train_loss = 4.292\n",
      "Epoch   0 Batch 8655/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 8656/17275   train_loss = 4.002\n",
      "Epoch   0 Batch 8657/17275   train_loss = 6.822\n",
      "Epoch   0 Batch 8658/17275   train_loss = 2.894\n",
      "Epoch   0 Batch 8659/17275   train_loss = 2.511\n",
      "Epoch   0 Batch 8660/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 8661/17275   train_loss = 3.160\n",
      "Epoch   0 Batch 8662/17275   train_loss = 3.718\n",
      "Epoch   0 Batch 8663/17275   train_loss = 3.468\n",
      "Epoch   0 Batch 8664/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 8665/17275   train_loss = 3.065\n",
      "Epoch   0 Batch 8666/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 8667/17275   train_loss = 7.712\n",
      "Epoch   0 Batch 8668/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 8669/17275   train_loss = 2.816\n",
      "Epoch   0 Batch 8670/17275   train_loss = 4.836\n",
      "Epoch   0 Batch 8671/17275   train_loss = 2.507\n",
      "Epoch   0 Batch 8672/17275   train_loss = 2.897\n",
      "Epoch   0 Batch 8673/17275   train_loss = 2.772\n",
      "Epoch   0 Batch 8674/17275   train_loss = 4.292\n",
      "Epoch   0 Batch 8675/17275   train_loss = 3.456\n",
      "Epoch   0 Batch 8676/17275   train_loss = 6.861\n",
      "Epoch   0 Batch 8677/17275   train_loss = 8.250\n",
      "Epoch   0 Batch 8678/17275   train_loss = 2.598\n",
      "Epoch   0 Batch 8679/17275   train_loss = 7.976\n",
      "Epoch   0 Batch 8680/17275   train_loss = 2.619\n",
      "Epoch   0 Batch 8681/17275   train_loss = 3.407\n",
      "Epoch   0 Batch 8682/17275   train_loss = 2.507\n",
      "Epoch   0 Batch 8683/17275   train_loss = 7.744\n",
      "Epoch   0 Batch 8684/17275   train_loss = 3.234\n",
      "Epoch   0 Batch 8685/17275   train_loss = 5.976\n",
      "Epoch   0 Batch 8686/17275   train_loss = 3.926\n",
      "Epoch   0 Batch 8687/17275   train_loss = 5.114\n",
      "Epoch   0 Batch 8688/17275   train_loss = 4.549\n",
      "Epoch   0 Batch 8689/17275   train_loss = 4.198\n",
      "Epoch   0 Batch 8690/17275   train_loss = 3.122\n",
      "Epoch   0 Batch 8691/17275   train_loss = 2.803\n",
      "Epoch   0 Batch 8692/17275   train_loss = 2.804\n",
      "Epoch   0 Batch 8693/17275   train_loss = 4.695\n",
      "Epoch   0 Batch 8694/17275   train_loss = 2.859\n",
      "Epoch   0 Batch 8695/17275   train_loss = 4.888\n",
      "Epoch   0 Batch 8696/17275   train_loss = 4.138\n",
      "Epoch   0 Batch 8697/17275   train_loss = 2.163\n",
      "Epoch   0 Batch 8698/17275   train_loss = 2.758\n",
      "Epoch   0 Batch 8699/17275   train_loss = 4.914\n",
      "Epoch   0 Batch 8700/17275   train_loss = 2.781\n",
      "Epoch   0 Batch 8701/17275   train_loss = 2.308\n",
      "Epoch   0 Batch 8702/17275   train_loss = 5.062\n",
      "Epoch   0 Batch 8703/17275   train_loss = 3.593\n",
      "Epoch   0 Batch 8704/17275   train_loss = 9.858\n",
      "Epoch   0 Batch 8705/17275   train_loss = 2.741\n",
      "Epoch   0 Batch 8706/17275   train_loss = 3.601\n",
      "Epoch   0 Batch 8707/17275   train_loss = 4.612\n",
      "Epoch   0 Batch 8708/17275   train_loss = 4.189\n",
      "Epoch   0 Batch 8709/17275   train_loss = 5.026\n",
      "Epoch   0 Batch 8710/17275   train_loss = 2.718\n",
      "Epoch   0 Batch 8711/17275   train_loss = 4.258\n",
      "Epoch   0 Batch 8712/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 8713/17275   train_loss = 5.921\n",
      "Epoch   0 Batch 8714/17275   train_loss = 6.703\n",
      "Epoch   0 Batch 8715/17275   train_loss = 2.068\n",
      "Epoch   0 Batch 8716/17275   train_loss = 2.913\n",
      "Epoch   0 Batch 8717/17275   train_loss = 2.536\n",
      "Epoch   0 Batch 8718/17275   train_loss = 4.152\n",
      "Epoch   0 Batch 8719/17275   train_loss = 2.934\n",
      "Epoch   0 Batch 8720/17275   train_loss = 6.954\n",
      "Epoch   0 Batch 8721/17275   train_loss = 4.476\n",
      "Epoch   0 Batch 8722/17275   train_loss = 3.690\n",
      "Epoch   0 Batch 8723/17275   train_loss = 3.886\n",
      "Epoch   0 Batch 8724/17275   train_loss = 3.207\n",
      "Epoch   0 Batch 8725/17275   train_loss = 3.218\n",
      "Epoch   0 Batch 8726/17275   train_loss = 2.806\n",
      "Epoch   0 Batch 8727/17275   train_loss = 3.268\n",
      "Epoch   0 Batch 8728/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 8729/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 8730/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 8731/17275   train_loss = 3.933\n",
      "Epoch   0 Batch 8732/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 8733/17275   train_loss = 3.998\n",
      "Epoch   0 Batch 8734/17275   train_loss = 2.030\n",
      "Epoch   0 Batch 8735/17275   train_loss = 2.578\n",
      "Epoch   0 Batch 8736/17275   train_loss = 4.494\n",
      "Epoch   0 Batch 8737/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 8738/17275   train_loss = 3.364\n",
      "Epoch   0 Batch 8739/17275   train_loss = 1.951\n",
      "Epoch   0 Batch 8740/17275   train_loss = 2.481\n",
      "Epoch   0 Batch 8741/17275   train_loss = 2.420\n",
      "Epoch   0 Batch 8742/17275   train_loss = 3.769\n",
      "Epoch   0 Batch 8743/17275   train_loss = 2.897\n",
      "Epoch   0 Batch 8744/17275   train_loss = 3.641\n",
      "Epoch   0 Batch 8745/17275   train_loss = 2.822\n",
      "Epoch   0 Batch 8746/17275   train_loss = 4.587\n",
      "Epoch   0 Batch 8747/17275   train_loss = 2.977\n",
      "Epoch   0 Batch 8748/17275   train_loss = 6.621\n",
      "Epoch   0 Batch 8749/17275   train_loss = 5.229\n",
      "Epoch   0 Batch 8750/17275   train_loss = 1.702\n",
      "Epoch   0 Batch 8751/17275   train_loss = 5.824\n",
      "Epoch   0 Batch 8752/17275   train_loss = 3.296\n",
      "Epoch   0 Batch 8753/17275   train_loss = 2.752\n",
      "Epoch   0 Batch 8754/17275   train_loss = 2.975\n",
      "Epoch   0 Batch 8755/17275   train_loss = 3.767\n",
      "Epoch   0 Batch 8756/17275   train_loss = 4.754\n",
      "Epoch   0 Batch 8757/17275   train_loss = 5.927\n",
      "Epoch   0 Batch 8758/17275   train_loss = 3.998\n",
      "Epoch   0 Batch 8759/17275   train_loss = 3.094\n",
      "Epoch   0 Batch 8760/17275   train_loss = 3.609\n",
      "Epoch   0 Batch 8761/17275   train_loss = 7.500\n",
      "Epoch   0 Batch 8762/17275   train_loss = 2.950\n",
      "Epoch   0 Batch 8763/17275   train_loss = 7.128\n",
      "Epoch   0 Batch 8764/17275   train_loss = 1.620\n",
      "Epoch   0 Batch 8765/17275   train_loss = 3.397\n",
      "Epoch   0 Batch 8766/17275   train_loss = 3.960\n",
      "Epoch   0 Batch 8767/17275   train_loss = 2.715\n",
      "Epoch   0 Batch 8768/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 8769/17275   train_loss = 4.637\n",
      "Epoch   0 Batch 8770/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 8771/17275   train_loss = 3.237\n",
      "Epoch   0 Batch 8772/17275   train_loss = 2.546\n",
      "Epoch   0 Batch 8773/17275   train_loss = 4.454\n",
      "Epoch   0 Batch 8774/17275   train_loss = 4.975\n",
      "Epoch   0 Batch 8775/17275   train_loss = 4.180\n",
      "Epoch   0 Batch 8776/17275   train_loss = 4.717\n",
      "Epoch   0 Batch 8777/17275   train_loss = 4.061\n",
      "Epoch   0 Batch 8778/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 8779/17275   train_loss = 5.802\n",
      "Epoch   0 Batch 8780/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 8781/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 8782/17275   train_loss = 3.179\n",
      "Epoch   0 Batch 8783/17275   train_loss = 2.968\n",
      "Epoch   0 Batch 8784/17275   train_loss = 3.179\n",
      "Epoch   0 Batch 8785/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 8786/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 8787/17275   train_loss = 4.499\n",
      "Epoch   0 Batch 8788/17275   train_loss = 7.297\n",
      "Epoch   0 Batch 8789/17275   train_loss = 2.079\n",
      "Epoch   0 Batch 8790/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 8791/17275   train_loss = 4.748\n",
      "Epoch   0 Batch 8792/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 8793/17275   train_loss = 4.388\n",
      "Epoch   0 Batch 8794/17275   train_loss = 1.731\n",
      "Epoch   0 Batch 8795/17275   train_loss = 2.169\n",
      "Epoch   0 Batch 8796/17275   train_loss = 4.843\n",
      "Epoch   0 Batch 8797/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 8798/17275   train_loss = 4.952\n",
      "Epoch   0 Batch 8799/17275   train_loss = 2.156\n",
      "Epoch   0 Batch 8800/17275   train_loss = 3.537\n",
      "Epoch   0 Batch 8801/17275   train_loss = 3.648\n",
      "Epoch   0 Batch 8802/17275   train_loss = 3.181\n",
      "Epoch   0 Batch 8803/17275   train_loss = 2.929\n",
      "Epoch   0 Batch 8804/17275   train_loss = 3.920\n",
      "Epoch   0 Batch 8805/17275   train_loss = 3.620\n",
      "Epoch   0 Batch 8806/17275   train_loss = 5.826\n",
      "Epoch   0 Batch 8807/17275   train_loss = 2.500\n",
      "Epoch   0 Batch 8808/17275   train_loss = 7.196\n",
      "Epoch   0 Batch 8809/17275   train_loss = 6.463\n",
      "Epoch   0 Batch 8810/17275   train_loss = 6.601\n",
      "Epoch   0 Batch 8811/17275   train_loss = 4.307\n",
      "Epoch   0 Batch 8812/17275   train_loss = 2.445\n",
      "Epoch   0 Batch 8813/17275   train_loss = 6.344\n",
      "Epoch   0 Batch 8814/17275   train_loss = 3.169\n",
      "Epoch   0 Batch 8815/17275   train_loss = 2.900\n",
      "Epoch   0 Batch 8816/17275   train_loss = 2.980\n",
      "Epoch   0 Batch 8817/17275   train_loss = 3.610\n",
      "Epoch   0 Batch 8818/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 8819/17275   train_loss = 6.370\n",
      "Epoch   0 Batch 8820/17275   train_loss = 3.594\n",
      "Epoch   0 Batch 8821/17275   train_loss = 4.328\n",
      "Epoch   0 Batch 8822/17275   train_loss = 4.770\n",
      "Epoch   0 Batch 8823/17275   train_loss = 2.111\n",
      "Epoch   0 Batch 8824/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 8825/17275   train_loss = 3.509\n",
      "Epoch   0 Batch 8826/17275   train_loss = 3.336\n",
      "Epoch   0 Batch 8827/17275   train_loss = 2.506\n",
      "Epoch   0 Batch 8828/17275   train_loss = 5.673\n",
      "Epoch   0 Batch 8829/17275   train_loss = 6.388\n",
      "Epoch   0 Batch 8830/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 8831/17275   train_loss = 4.958\n",
      "Epoch   0 Batch 8832/17275   train_loss = 3.726\n",
      "Epoch   0 Batch 8833/17275   train_loss = 2.143\n",
      "Epoch   0 Batch 8834/17275   train_loss = 2.981\n",
      "Epoch   0 Batch 8835/17275   train_loss = 2.372\n",
      "Epoch   0 Batch 8836/17275   train_loss = 3.761\n",
      "Epoch   0 Batch 8837/17275   train_loss = 5.435\n",
      "Epoch   0 Batch 8838/17275   train_loss = 2.367\n",
      "Epoch   0 Batch 8839/17275   train_loss = 4.976\n",
      "Epoch   0 Batch 8840/17275   train_loss = 4.117\n",
      "Epoch   0 Batch 8841/17275   train_loss = 3.379\n",
      "Epoch   0 Batch 8842/17275   train_loss = 6.955\n",
      "Epoch   0 Batch 8843/17275   train_loss = 2.050\n",
      "Epoch   0 Batch 8844/17275   train_loss = 2.495\n",
      "Epoch   0 Batch 8845/17275   train_loss = 5.526\n",
      "Epoch   0 Batch 8846/17275   train_loss = 1.981\n",
      "Epoch   0 Batch 8847/17275   train_loss = 2.679\n",
      "Epoch   0 Batch 8848/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 8849/17275   train_loss = 2.791\n",
      "Epoch   0 Batch 8850/17275   train_loss = 3.425\n",
      "Epoch   0 Batch 8851/17275   train_loss = 3.749\n",
      "Epoch   0 Batch 8852/17275   train_loss = 5.123\n",
      "Epoch   0 Batch 8853/17275   train_loss = 3.109\n",
      "Epoch   0 Batch 8854/17275   train_loss = 6.382\n",
      "Epoch   0 Batch 8855/17275   train_loss = 3.281\n",
      "Epoch   0 Batch 8856/17275   train_loss = 2.030\n",
      "Epoch   0 Batch 8857/17275   train_loss = 4.370\n",
      "Epoch   0 Batch 8858/17275   train_loss = 3.429\n",
      "Epoch   0 Batch 8859/17275   train_loss = 2.768\n",
      "Epoch   0 Batch 8860/17275   train_loss = 3.118\n",
      "Epoch   0 Batch 8861/17275   train_loss = 4.083\n",
      "Epoch   0 Batch 8862/17275   train_loss = 3.286\n",
      "Epoch   0 Batch 8863/17275   train_loss = 2.639\n",
      "Epoch   0 Batch 8864/17275   train_loss = 6.359\n",
      "Epoch   0 Batch 8865/17275   train_loss = 2.646\n",
      "Epoch   0 Batch 8866/17275   train_loss = 7.466\n",
      "Epoch   0 Batch 8867/17275   train_loss = 1.995\n",
      "Epoch   0 Batch 8868/17275   train_loss = 3.633\n",
      "Epoch   0 Batch 8869/17275   train_loss = 2.626\n",
      "Epoch   0 Batch 8870/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 8871/17275   train_loss = 3.790\n",
      "Epoch   0 Batch 8872/17275   train_loss = 6.349\n",
      "Epoch   0 Batch 8873/17275   train_loss = 4.631\n",
      "Epoch   0 Batch 8874/17275   train_loss = 4.221\n",
      "Epoch   0 Batch 8875/17275   train_loss = 3.400\n",
      "Epoch   0 Batch 8876/17275   train_loss = 4.724\n",
      "Epoch   0 Batch 8877/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 8878/17275   train_loss = 4.088\n",
      "Epoch   0 Batch 8879/17275   train_loss = 3.491\n",
      "Epoch   0 Batch 8880/17275   train_loss = 4.981\n",
      "Epoch   0 Batch 8881/17275   train_loss = 2.378\n",
      "Epoch   0 Batch 8882/17275   train_loss = 4.468\n",
      "Epoch   0 Batch 8883/17275   train_loss = 2.440\n",
      "Epoch   0 Batch 8884/17275   train_loss = 6.319\n",
      "Epoch   0 Batch 8885/17275   train_loss = 3.028\n",
      "Epoch   0 Batch 8886/17275   train_loss = 2.144\n",
      "Epoch   0 Batch 8887/17275   train_loss = 3.213\n",
      "Epoch   0 Batch 8888/17275   train_loss = 3.612\n",
      "Epoch   0 Batch 8889/17275   train_loss = 3.695\n",
      "Epoch   0 Batch 8890/17275   train_loss = 4.065\n",
      "Epoch   0 Batch 8891/17275   train_loss = 1.988\n",
      "Epoch   0 Batch 8892/17275   train_loss = 2.381\n",
      "Epoch   0 Batch 8893/17275   train_loss = 4.283\n",
      "Epoch   0 Batch 8894/17275   train_loss = 4.808\n",
      "Epoch   0 Batch 8895/17275   train_loss = 4.347\n",
      "Epoch   0 Batch 8896/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 8897/17275   train_loss = 3.379\n",
      "Epoch   0 Batch 8898/17275   train_loss = 2.519\n",
      "Epoch   0 Batch 8899/17275   train_loss = 6.302\n",
      "Epoch   0 Batch 8900/17275   train_loss = 3.035\n",
      "Epoch   0 Batch 8901/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 8902/17275   train_loss = 2.060\n",
      "Epoch   0 Batch 8903/17275   train_loss = 2.592\n",
      "Epoch   0 Batch 8904/17275   train_loss = 5.232\n",
      "Epoch   0 Batch 8905/17275   train_loss = 3.874\n",
      "Epoch   0 Batch 8906/17275   train_loss = 2.926\n",
      "Epoch   0 Batch 8907/17275   train_loss = 2.533\n",
      "Epoch   0 Batch 8908/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 8909/17275   train_loss = 3.903\n",
      "Epoch   0 Batch 8910/17275   train_loss = 5.936\n",
      "Epoch   0 Batch 8911/17275   train_loss = 6.279\n",
      "Epoch   0 Batch 8912/17275   train_loss = 3.620\n",
      "Epoch   0 Batch 8913/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 8914/17275   train_loss = 6.421\n",
      "Epoch   0 Batch 8915/17275   train_loss = 6.644\n",
      "Epoch   0 Batch 8916/17275   train_loss = 2.445\n",
      "Epoch   0 Batch 8917/17275   train_loss = 3.753\n",
      "Epoch   0 Batch 8918/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 8919/17275   train_loss = 6.833\n",
      "Epoch   0 Batch 8920/17275   train_loss = 2.135\n",
      "Epoch   0 Batch 8921/17275   train_loss = 2.993\n",
      "Epoch   0 Batch 8922/17275   train_loss = 1.909\n",
      "Epoch   0 Batch 8923/17275   train_loss = 2.394\n",
      "Epoch   0 Batch 8924/17275   train_loss = 3.724\n",
      "Epoch   0 Batch 8925/17275   train_loss = 1.837\n",
      "Epoch   0 Batch 8926/17275   train_loss = 2.680\n",
      "Epoch   0 Batch 8927/17275   train_loss = 2.498\n",
      "Epoch   0 Batch 8928/17275   train_loss = 3.550\n",
      "Epoch   0 Batch 8929/17275   train_loss = 3.511\n",
      "Epoch   0 Batch 8930/17275   train_loss = 3.175\n",
      "Epoch   0 Batch 8931/17275   train_loss = 4.523\n",
      "Epoch   0 Batch 8932/17275   train_loss = 2.608\n",
      "Epoch   0 Batch 8933/17275   train_loss = 6.557\n",
      "Epoch   0 Batch 8934/17275   train_loss = 3.881\n",
      "Epoch   0 Batch 8935/17275   train_loss = 4.765\n",
      "Epoch   0 Batch 8936/17275   train_loss = 2.363\n",
      "Epoch   0 Batch 8937/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 8938/17275   train_loss = 3.138\n",
      "Epoch   0 Batch 8939/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 8940/17275   train_loss = 7.330\n",
      "Epoch   0 Batch 8941/17275   train_loss = 5.217\n",
      "Epoch   0 Batch 8942/17275   train_loss = 2.734\n",
      "Epoch   0 Batch 8943/17275   train_loss = 1.917\n",
      "Epoch   0 Batch 8944/17275   train_loss = 3.179\n",
      "Epoch   0 Batch 8945/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 8946/17275   train_loss = 5.046\n",
      "Epoch   0 Batch 8947/17275   train_loss = 2.385\n",
      "Epoch   0 Batch 8948/17275   train_loss = 3.846\n",
      "Epoch   0 Batch 8949/17275   train_loss = 2.963\n",
      "Epoch   0 Batch 8950/17275   train_loss = 2.874\n",
      "Epoch   0 Batch 8951/17275   train_loss = 5.018\n",
      "Epoch   0 Batch 8952/17275   train_loss = 5.528\n",
      "Epoch   0 Batch 8953/17275   train_loss = 2.197\n",
      "Epoch   0 Batch 8954/17275   train_loss = 4.356\n",
      "Epoch   0 Batch 8955/17275   train_loss = 2.869\n",
      "Epoch   0 Batch 8956/17275   train_loss = 6.437\n",
      "Epoch   0 Batch 8957/17275   train_loss = 3.146\n",
      "Epoch   0 Batch 8958/17275   train_loss = 3.653\n",
      "Epoch   0 Batch 8959/17275   train_loss = 2.877\n",
      "Epoch   0 Batch 8960/17275   train_loss = 2.019\n",
      "Epoch   0 Batch 8961/17275   train_loss = 3.136\n",
      "Epoch   0 Batch 8962/17275   train_loss = 3.461\n",
      "Epoch   0 Batch 8963/17275   train_loss = 4.592\n",
      "Epoch   0 Batch 8964/17275   train_loss = 2.286\n",
      "Epoch   0 Batch 8965/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 8966/17275   train_loss = 8.271\n",
      "Epoch   0 Batch 8967/17275   train_loss = 3.310\n",
      "Epoch   0 Batch 8968/17275   train_loss = 5.146\n",
      "Epoch   0 Batch 8969/17275   train_loss = 6.657\n",
      "Epoch   0 Batch 8970/17275   train_loss = 3.856\n",
      "Epoch   0 Batch 8971/17275   train_loss = 3.743\n",
      "Epoch   0 Batch 8972/17275   train_loss = 10.064\n",
      "Epoch   0 Batch 8973/17275   train_loss = 10.062\n",
      "Epoch   0 Batch 8974/17275   train_loss = 2.309\n",
      "Epoch   0 Batch 8975/17275   train_loss = 3.248\n",
      "Epoch   0 Batch 8976/17275   train_loss = 3.699\n",
      "Epoch   0 Batch 8977/17275   train_loss = 4.280\n",
      "Epoch   0 Batch 8978/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 8979/17275   train_loss = 2.429\n",
      "Epoch   0 Batch 8980/17275   train_loss = 3.155\n",
      "Epoch   0 Batch 8981/17275   train_loss = 5.461\n",
      "Epoch   0 Batch 8982/17275   train_loss = 3.466\n",
      "Epoch   0 Batch 8983/17275   train_loss = 4.519\n",
      "Epoch   0 Batch 8984/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 8985/17275   train_loss = 2.559\n",
      "Epoch   0 Batch 8986/17275   train_loss = 2.446\n",
      "Epoch   0 Batch 8987/17275   train_loss = 2.906\n",
      "Epoch   0 Batch 8988/17275   train_loss = 2.328\n",
      "Epoch   0 Batch 8989/17275   train_loss = 6.864\n",
      "Epoch   0 Batch 8990/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 8991/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 8992/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 8993/17275   train_loss = 2.928\n",
      "Epoch   0 Batch 8994/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 8995/17275   train_loss = 2.607\n",
      "Epoch   0 Batch 8996/17275   train_loss = 4.649\n",
      "Epoch   0 Batch 8997/17275   train_loss = 4.170\n",
      "Epoch   0 Batch 8998/17275   train_loss = 6.060\n",
      "Epoch   0 Batch 8999/17275   train_loss = 2.579\n",
      "Epoch   0 Batch 9000/17275   train_loss = 2.850\n",
      "Epoch   0 Batch 9001/17275   train_loss = 2.352\n",
      "Epoch   0 Batch 9002/17275   train_loss = 6.596\n",
      "Epoch   0 Batch 9003/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 9004/17275   train_loss = 10.090\n",
      "Epoch   0 Batch 9005/17275   train_loss = 3.302\n",
      "Epoch   0 Batch 9006/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 9007/17275   train_loss = 8.054\n",
      "Epoch   0 Batch 9008/17275   train_loss = 5.208\n",
      "Epoch   0 Batch 9009/17275   train_loss = 1.990\n",
      "Epoch   0 Batch 9010/17275   train_loss = 2.152\n",
      "Epoch   0 Batch 9011/17275   train_loss = 6.360\n",
      "Epoch   0 Batch 9012/17275   train_loss = 2.416\n",
      "Epoch   0 Batch 9013/17275   train_loss = 8.269\n",
      "Epoch   0 Batch 9014/17275   train_loss = 7.252\n",
      "Epoch   0 Batch 9015/17275   train_loss = 4.899\n",
      "Epoch   0 Batch 9016/17275   train_loss = 5.987\n",
      "Epoch   0 Batch 9017/17275   train_loss = 4.095\n",
      "Epoch   0 Batch 9018/17275   train_loss = 7.283\n",
      "Epoch   0 Batch 9019/17275   train_loss = 3.310\n",
      "Epoch   0 Batch 9020/17275   train_loss = 3.182\n",
      "Epoch   0 Batch 9021/17275   train_loss = 2.599\n",
      "Epoch   0 Batch 9022/17275   train_loss = 3.870\n",
      "Epoch   0 Batch 9023/17275   train_loss = 4.522\n",
      "Epoch   0 Batch 9024/17275   train_loss = 2.875\n",
      "Epoch   0 Batch 9025/17275   train_loss = 3.528\n",
      "Epoch   0 Batch 9026/17275   train_loss = 7.011\n",
      "Epoch   0 Batch 9027/17275   train_loss = 4.026\n",
      "Epoch   0 Batch 9028/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 9029/17275   train_loss = 4.946\n",
      "Epoch   0 Batch 9030/17275   train_loss = 4.469\n",
      "Epoch   0 Batch 9031/17275   train_loss = 2.430\n",
      "Epoch   0 Batch 9032/17275   train_loss = 1.715\n",
      "Epoch   0 Batch 9033/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 9034/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 9035/17275   train_loss = 6.525\n",
      "Epoch   0 Batch 9036/17275   train_loss = 4.144\n",
      "Epoch   0 Batch 9037/17275   train_loss = 3.119\n",
      "Epoch   0 Batch 9038/17275   train_loss = 4.735\n",
      "Epoch   0 Batch 9039/17275   train_loss = 4.324\n",
      "Epoch   0 Batch 9040/17275   train_loss = 4.603\n",
      "Epoch   0 Batch 9041/17275   train_loss = 3.207\n",
      "Epoch   0 Batch 9042/17275   train_loss = 3.698\n",
      "Epoch   0 Batch 9043/17275   train_loss = 3.788\n",
      "Epoch   0 Batch 9044/17275   train_loss = 5.266\n",
      "Epoch   0 Batch 9045/17275   train_loss = 3.382\n",
      "Epoch   0 Batch 9046/17275   train_loss = 4.767\n",
      "Epoch   0 Batch 9047/17275   train_loss = 2.543\n",
      "Epoch   0 Batch 9048/17275   train_loss = 6.175\n",
      "Epoch   0 Batch 9049/17275   train_loss = 6.926\n",
      "Epoch   0 Batch 9050/17275   train_loss = 3.698\n",
      "Epoch   0 Batch 9051/17275   train_loss = 3.501\n",
      "Epoch   0 Batch 9052/17275   train_loss = 2.401\n",
      "Epoch   0 Batch 9053/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 9054/17275   train_loss = 3.644\n",
      "Epoch   0 Batch 9055/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 9056/17275   train_loss = 6.063\n",
      "Epoch   0 Batch 9057/17275   train_loss = 6.370\n",
      "Epoch   0 Batch 9058/17275   train_loss = 3.999\n",
      "Epoch   0 Batch 9059/17275   train_loss = 1.689\n",
      "Epoch   0 Batch 9060/17275   train_loss = 1.986\n",
      "Epoch   0 Batch 9061/17275   train_loss = 3.272\n",
      "Epoch   0 Batch 9062/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 9063/17275   train_loss = 2.486\n",
      "Epoch   0 Batch 9064/17275   train_loss = 3.921\n",
      "Epoch   0 Batch 9065/17275   train_loss = 6.559\n",
      "Epoch   0 Batch 9066/17275   train_loss = 3.703\n",
      "Epoch   0 Batch 9067/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 9068/17275   train_loss = 6.777\n",
      "Epoch   0 Batch 9069/17275   train_loss = 2.617\n",
      "Epoch   0 Batch 9070/17275   train_loss = 5.450\n",
      "Epoch   0 Batch 9071/17275   train_loss = 5.199\n",
      "Epoch   0 Batch 9072/17275   train_loss = 3.188\n",
      "Epoch   0 Batch 9073/17275   train_loss = 3.130\n",
      "Epoch   0 Batch 9074/17275   train_loss = 2.984\n",
      "Epoch   0 Batch 9075/17275   train_loss = 3.287\n",
      "Epoch   0 Batch 9076/17275   train_loss = 2.653\n",
      "Epoch   0 Batch 9077/17275   train_loss = 7.396\n",
      "Epoch   0 Batch 9078/17275   train_loss = 4.458\n",
      "Epoch   0 Batch 9079/17275   train_loss = 3.079\n",
      "Epoch   0 Batch 9080/17275   train_loss = 5.028\n",
      "Epoch   0 Batch 9081/17275   train_loss = 4.060\n",
      "Epoch   0 Batch 9082/17275   train_loss = 4.536\n",
      "Epoch   0 Batch 9083/17275   train_loss = 5.093\n",
      "Epoch   0 Batch 9084/17275   train_loss = 2.016\n",
      "Epoch   0 Batch 9085/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 9086/17275   train_loss = 2.916\n",
      "Epoch   0 Batch 9087/17275   train_loss = 3.093\n",
      "Epoch   0 Batch 9088/17275   train_loss = 3.885\n",
      "Epoch   0 Batch 9089/17275   train_loss = 4.241\n",
      "Epoch   0 Batch 9090/17275   train_loss = 5.920\n",
      "Epoch   0 Batch 9091/17275   train_loss = 4.155\n",
      "Epoch   0 Batch 9092/17275   train_loss = 4.270\n",
      "Epoch   0 Batch 9093/17275   train_loss = 10.056\n",
      "Epoch   0 Batch 9094/17275   train_loss = 4.719\n",
      "Epoch   0 Batch 9095/17275   train_loss = 3.046\n",
      "Epoch   0 Batch 9096/17275   train_loss = 3.082\n",
      "Epoch   0 Batch 9097/17275   train_loss = 4.141\n",
      "Epoch   0 Batch 9098/17275   train_loss = 3.899\n",
      "Epoch   0 Batch 9099/17275   train_loss = 6.704\n",
      "Epoch   0 Batch 9100/17275   train_loss = 2.462\n",
      "Epoch   0 Batch 9101/17275   train_loss = 7.351\n",
      "Epoch   0 Batch 9102/17275   train_loss = 6.562\n",
      "Epoch   0 Batch 9103/17275   train_loss = 1.860\n",
      "Epoch   0 Batch 9104/17275   train_loss = 5.796\n",
      "Epoch   0 Batch 9105/17275   train_loss = 2.256\n",
      "Epoch   0 Batch 9106/17275   train_loss = 3.548\n",
      "Epoch   0 Batch 9107/17275   train_loss = 4.553\n",
      "Epoch   0 Batch 9108/17275   train_loss = 3.471\n",
      "Epoch   0 Batch 9109/17275   train_loss = 6.727\n",
      "Epoch   0 Batch 9110/17275   train_loss = 1.778\n",
      "Epoch   0 Batch 9111/17275   train_loss = 2.090\n",
      "Epoch   0 Batch 9112/17275   train_loss = 5.150\n",
      "Epoch   0 Batch 9113/17275   train_loss = 6.510\n",
      "Epoch   0 Batch 9114/17275   train_loss = 2.420\n",
      "Epoch   0 Batch 9115/17275   train_loss = 1.670\n",
      "Epoch   0 Batch 9116/17275   train_loss = 2.581\n",
      "Epoch   0 Batch 9117/17275   train_loss = 4.273\n",
      "Epoch   0 Batch 9118/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 9119/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 9120/17275   train_loss = 2.670\n",
      "Epoch   0 Batch 9121/17275   train_loss = 6.579\n",
      "Epoch   0 Batch 9122/17275   train_loss = 3.975\n",
      "Epoch   0 Batch 9123/17275   train_loss = 5.810\n",
      "Epoch   0 Batch 9124/17275   train_loss = 1.532\n",
      "Epoch   0 Batch 9125/17275   train_loss = 4.520\n",
      "Epoch   0 Batch 9126/17275   train_loss = 6.372\n",
      "Epoch   0 Batch 9127/17275   train_loss = 3.050\n",
      "Epoch   0 Batch 9128/17275   train_loss = 4.123\n",
      "Epoch   0 Batch 9129/17275   train_loss = 1.905\n",
      "Epoch   0 Batch 9130/17275   train_loss = 2.614\n",
      "Epoch   0 Batch 9131/17275   train_loss = 3.054\n",
      "Epoch   0 Batch 9132/17275   train_loss = 3.967\n",
      "Epoch   0 Batch 9133/17275   train_loss = 8.754\n",
      "Epoch   0 Batch 9134/17275   train_loss = 4.720\n",
      "Epoch   0 Batch 9135/17275   train_loss = 3.876\n",
      "Epoch   0 Batch 9136/17275   train_loss = 4.614\n",
      "Epoch   0 Batch 9137/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 9138/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 9139/17275   train_loss = 3.270\n",
      "Epoch   0 Batch 9140/17275   train_loss = 7.407\n",
      "Epoch   0 Batch 9141/17275   train_loss = 7.252\n",
      "Epoch   0 Batch 9142/17275   train_loss = 2.517\n",
      "Epoch   0 Batch 9143/17275   train_loss = 2.620\n",
      "Epoch   0 Batch 9144/17275   train_loss = 1.621\n",
      "Epoch   0 Batch 9145/17275   train_loss = 4.001\n",
      "Epoch   0 Batch 9146/17275   train_loss = 2.658\n",
      "Epoch   0 Batch 9147/17275   train_loss = 3.640\n",
      "Epoch   0 Batch 9148/17275   train_loss = 5.103\n",
      "Epoch   0 Batch 9149/17275   train_loss = 3.818\n",
      "Epoch   0 Batch 9150/17275   train_loss = 2.813\n",
      "Epoch   0 Batch 9151/17275   train_loss = 3.288\n",
      "Epoch   0 Batch 9152/17275   train_loss = 2.567\n",
      "Epoch   0 Batch 9153/17275   train_loss = 2.783\n",
      "Epoch   0 Batch 9154/17275   train_loss = 3.475\n",
      "Epoch   0 Batch 9155/17275   train_loss = 1.901\n",
      "Epoch   0 Batch 9156/17275   train_loss = 2.080\n",
      "Epoch   0 Batch 9157/17275   train_loss = 1.622\n",
      "Epoch   0 Batch 9158/17275   train_loss = 2.782\n",
      "Epoch   0 Batch 9159/17275   train_loss = 4.325\n",
      "Epoch   0 Batch 9160/17275   train_loss = 3.782\n",
      "Epoch   0 Batch 9161/17275   train_loss = 1.563\n",
      "Epoch   0 Batch 9162/17275   train_loss = 6.589\n",
      "Epoch   0 Batch 9163/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 9164/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 9165/17275   train_loss = 4.405\n",
      "Epoch   0 Batch 9166/17275   train_loss = 6.610\n",
      "Epoch   0 Batch 9167/17275   train_loss = 1.831\n",
      "Epoch   0 Batch 9168/17275   train_loss = 5.389\n",
      "Epoch   0 Batch 9169/17275   train_loss = 2.976\n",
      "Epoch   0 Batch 9170/17275   train_loss = 1.820\n",
      "Epoch   0 Batch 9171/17275   train_loss = 3.595\n",
      "Epoch   0 Batch 9172/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 9173/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 9174/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 9175/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 9176/17275   train_loss = 3.764\n",
      "Epoch   0 Batch 9177/17275   train_loss = 5.840\n",
      "Epoch   0 Batch 9178/17275   train_loss = 3.327\n",
      "Epoch   0 Batch 9179/17275   train_loss = 4.747\n",
      "Epoch   0 Batch 9180/17275   train_loss = 3.993\n",
      "Epoch   0 Batch 9181/17275   train_loss = 2.722\n",
      "Epoch   0 Batch 9182/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 9183/17275   train_loss = 4.027\n",
      "Epoch   0 Batch 9184/17275   train_loss = 5.959\n",
      "Epoch   0 Batch 9185/17275   train_loss = 1.854\n",
      "Epoch   0 Batch 9186/17275   train_loss = 2.898\n",
      "Epoch   0 Batch 9187/17275   train_loss = 3.123\n",
      "Epoch   0 Batch 9188/17275   train_loss = 2.354\n",
      "Epoch   0 Batch 9189/17275   train_loss = 3.839\n",
      "Epoch   0 Batch 9190/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 9191/17275   train_loss = 3.003\n",
      "Epoch   0 Batch 9192/17275   train_loss = 4.368\n",
      "Epoch   0 Batch 9193/17275   train_loss = 5.475\n",
      "Epoch   0 Batch 9194/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 9195/17275   train_loss = 2.450\n",
      "Epoch   0 Batch 9196/17275   train_loss = 5.229\n",
      "Epoch   0 Batch 9197/17275   train_loss = 2.629\n",
      "Epoch   0 Batch 9198/17275   train_loss = 3.800\n",
      "Epoch   0 Batch 9199/17275   train_loss = 4.372\n",
      "Epoch   0 Batch 9200/17275   train_loss = 4.728\n",
      "Epoch   0 Batch 9201/17275   train_loss = 2.055\n",
      "Epoch   0 Batch 9202/17275   train_loss = 2.429\n",
      "Epoch   0 Batch 9203/17275   train_loss = 6.996\n",
      "Epoch   0 Batch 9204/17275   train_loss = 6.294\n",
      "Epoch   0 Batch 9205/17275   train_loss = 3.859\n",
      "Epoch   0 Batch 9206/17275   train_loss = 2.237\n",
      "Epoch   0 Batch 9207/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 9208/17275   train_loss = 4.246\n",
      "Epoch   0 Batch 9209/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 9210/17275   train_loss = 2.805\n",
      "Epoch   0 Batch 9211/17275   train_loss = 6.164\n",
      "Epoch   0 Batch 9212/17275   train_loss = 2.386\n",
      "Epoch   0 Batch 9213/17275   train_loss = 2.649\n",
      "Epoch   0 Batch 9214/17275   train_loss = 2.880\n",
      "Epoch   0 Batch 9215/17275   train_loss = 4.189\n",
      "Epoch   0 Batch 9216/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 9217/17275   train_loss = 3.203\n",
      "Epoch   0 Batch 9218/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 9219/17275   train_loss = 3.310\n",
      "Epoch   0 Batch 9220/17275   train_loss = 2.665\n",
      "Epoch   0 Batch 9221/17275   train_loss = 6.132\n",
      "Epoch   0 Batch 9222/17275   train_loss = 4.172\n",
      "Epoch   0 Batch 9223/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 9224/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 9225/17275   train_loss = 4.349\n",
      "Epoch   0 Batch 9226/17275   train_loss = 6.112\n",
      "Epoch   0 Batch 9227/17275   train_loss = 6.110\n",
      "Epoch   0 Batch 9228/17275   train_loss = 2.095\n",
      "Epoch   0 Batch 9229/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 9230/17275   train_loss = 3.664\n",
      "Epoch   0 Batch 9231/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 9232/17275   train_loss = 4.071\n",
      "Epoch   0 Batch 9233/17275   train_loss = 3.878\n",
      "Epoch   0 Batch 9234/17275   train_loss = 2.171\n",
      "Epoch   0 Batch 9235/17275   train_loss = 2.896\n",
      "Epoch   0 Batch 9236/17275   train_loss = 3.723\n",
      "Epoch   0 Batch 9237/17275   train_loss = 2.176\n",
      "Epoch   0 Batch 9238/17275   train_loss = 2.725\n",
      "Epoch   0 Batch 9239/17275   train_loss = 2.695\n",
      "Epoch   0 Batch 9240/17275   train_loss = 4.429\n",
      "Epoch   0 Batch 9241/17275   train_loss = 6.142\n",
      "Epoch   0 Batch 9242/17275   train_loss = 2.092\n",
      "Epoch   0 Batch 9243/17275   train_loss = 2.517\n",
      "Epoch   0 Batch 9244/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 9245/17275   train_loss = 1.977\n",
      "Epoch   0 Batch 9246/17275   train_loss = 9.848\n",
      "Epoch   0 Batch 9247/17275   train_loss = 1.874\n",
      "Epoch   0 Batch 9248/17275   train_loss = 5.998\n",
      "Epoch   0 Batch 9249/17275   train_loss = 6.125\n",
      "Epoch   0 Batch 9250/17275   train_loss = 1.697\n",
      "Epoch   0 Batch 9251/17275   train_loss = 1.839\n",
      "Epoch   0 Batch 9252/17275   train_loss = 3.941\n",
      "Epoch   0 Batch 9253/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 9254/17275   train_loss = 2.312\n",
      "Epoch   0 Batch 9255/17275   train_loss = 6.361\n",
      "Epoch   0 Batch 9256/17275   train_loss = 4.633\n",
      "Epoch   0 Batch 9257/17275   train_loss = 2.079\n",
      "Epoch   0 Batch 9258/17275   train_loss = 2.849\n",
      "Epoch   0 Batch 9259/17275   train_loss = 2.625\n",
      "Epoch   0 Batch 9260/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 9261/17275   train_loss = 3.895\n",
      "Epoch   0 Batch 9262/17275   train_loss = 8.152\n",
      "Epoch   0 Batch 9263/17275   train_loss = 5.831\n",
      "Epoch   0 Batch 9264/17275   train_loss = 3.533\n",
      "Epoch   0 Batch 9265/17275   train_loss = 8.018\n",
      "Epoch   0 Batch 9266/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 9267/17275   train_loss = 2.502\n",
      "Epoch   0 Batch 9268/17275   train_loss = 4.127\n",
      "Epoch   0 Batch 9269/17275   train_loss = 3.718\n",
      "Epoch   0 Batch 9270/17275   train_loss = 4.978\n",
      "Epoch   0 Batch 9271/17275   train_loss = 4.778\n",
      "Epoch   0 Batch 9272/17275   train_loss = 2.262\n",
      "Epoch   0 Batch 9273/17275   train_loss = 2.285\n",
      "Epoch   0 Batch 9274/17275   train_loss = 6.381\n",
      "Epoch   0 Batch 9275/17275   train_loss = 3.906\n",
      "Epoch   0 Batch 9276/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 9277/17275   train_loss = 6.349\n",
      "Epoch   0 Batch 9278/17275   train_loss = 2.466\n",
      "Epoch   0 Batch 9279/17275   train_loss = 3.552\n",
      "Epoch   0 Batch 9280/17275   train_loss = 3.123\n",
      "Epoch   0 Batch 9281/17275   train_loss = 2.315\n",
      "Epoch   0 Batch 9282/17275   train_loss = 6.285\n",
      "Epoch   0 Batch 9283/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 9284/17275   train_loss = 6.231\n",
      "Epoch   0 Batch 9285/17275   train_loss = 3.114\n",
      "Epoch   0 Batch 9286/17275   train_loss = 4.333\n",
      "Epoch   0 Batch 9287/17275   train_loss = 2.854\n",
      "Epoch   0 Batch 9288/17275   train_loss = 3.875\n",
      "Epoch   0 Batch 9289/17275   train_loss = 3.365\n",
      "Epoch   0 Batch 9290/17275   train_loss = 3.962\n",
      "Epoch   0 Batch 9291/17275   train_loss = 6.197\n",
      "Epoch   0 Batch 9292/17275   train_loss = 2.449\n",
      "Epoch   0 Batch 9293/17275   train_loss = 6.159\n",
      "Epoch   0 Batch 9294/17275   train_loss = 7.097\n",
      "Epoch   0 Batch 9295/17275   train_loss = 2.437\n",
      "Epoch   0 Batch 9296/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 9297/17275   train_loss = 2.313\n",
      "Epoch   0 Batch 9298/17275   train_loss = 2.272\n",
      "Epoch   0 Batch 9299/17275   train_loss = 2.210\n",
      "Epoch   0 Batch 9300/17275   train_loss = 5.558\n",
      "Epoch   0 Batch 9301/17275   train_loss = 7.283\n",
      "Epoch   0 Batch 9302/17275   train_loss = 3.874\n",
      "Epoch   0 Batch 9303/17275   train_loss = 4.858\n",
      "Epoch   0 Batch 9304/17275   train_loss = 6.883\n",
      "Epoch   0 Batch 9305/17275   train_loss = 3.150\n",
      "Epoch   0 Batch 9306/17275   train_loss = 3.700\n",
      "Epoch   0 Batch 9307/17275   train_loss = 4.409\n",
      "Epoch   0 Batch 9308/17275   train_loss = 2.267\n",
      "Epoch   0 Batch 9309/17275   train_loss = 2.459\n",
      "Epoch   0 Batch 9310/17275   train_loss = 7.429\n",
      "Epoch   0 Batch 9311/17275   train_loss = 6.561\n",
      "Epoch   0 Batch 9312/17275   train_loss = 4.480\n",
      "Epoch   0 Batch 9313/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 9314/17275   train_loss = 2.864\n",
      "Epoch   0 Batch 9315/17275   train_loss = 3.356\n",
      "Epoch   0 Batch 9316/17275   train_loss = 3.747\n",
      "Epoch   0 Batch 9317/17275   train_loss = 7.018\n",
      "Epoch   0 Batch 9318/17275   train_loss = 3.144\n",
      "Epoch   0 Batch 9319/17275   train_loss = 3.878\n",
      "Epoch   0 Batch 9320/17275   train_loss = 1.979\n",
      "Epoch   0 Batch 9321/17275   train_loss = 3.973\n",
      "Epoch   0 Batch 9322/17275   train_loss = 3.420\n",
      "Epoch   0 Batch 9323/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 9324/17275   train_loss = 2.802\n",
      "Epoch   0 Batch 9325/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 9326/17275   train_loss = 4.164\n",
      "Epoch   0 Batch 9327/17275   train_loss = 4.227\n",
      "Epoch   0 Batch 9328/17275   train_loss = 6.161\n",
      "Epoch   0 Batch 9329/17275   train_loss = 3.252\n",
      "Epoch   0 Batch 9330/17275   train_loss = 5.289\n",
      "Epoch   0 Batch 9331/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 9332/17275   train_loss = 7.351\n",
      "Epoch   0 Batch 9333/17275   train_loss = 1.924\n",
      "Epoch   0 Batch 9334/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 9335/17275   train_loss = 2.562\n",
      "Epoch   0 Batch 9336/17275   train_loss = 3.851\n",
      "Epoch   0 Batch 9337/17275   train_loss = 4.769\n",
      "Epoch   0 Batch 9338/17275   train_loss = 3.778\n",
      "Epoch   0 Batch 9339/17275   train_loss = 3.511\n",
      "Epoch   0 Batch 9340/17275   train_loss = 5.532\n",
      "Epoch   0 Batch 9341/17275   train_loss = 2.364\n",
      "Epoch   0 Batch 9342/17275   train_loss = 6.461\n",
      "Epoch   0 Batch 9343/17275   train_loss = 1.938\n",
      "Epoch   0 Batch 9344/17275   train_loss = 4.139\n",
      "Epoch   0 Batch 9345/17275   train_loss = 6.444\n",
      "Epoch   0 Batch 9346/17275   train_loss = 8.359\n",
      "Epoch   0 Batch 9347/17275   train_loss = 10.142\n",
      "Epoch   0 Batch 9348/17275   train_loss = 5.410\n",
      "Epoch   0 Batch 9349/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 9350/17275   train_loss = 3.123\n",
      "Epoch   0 Batch 9351/17275   train_loss = 2.930\n",
      "Epoch   0 Batch 9352/17275   train_loss = 2.493\n",
      "Epoch   0 Batch 9353/17275   train_loss = 2.345\n",
      "Epoch   0 Batch 9354/17275   train_loss = 4.344\n",
      "Epoch   0 Batch 9355/17275   train_loss = 4.185\n",
      "Epoch   0 Batch 9356/17275   train_loss = 3.695\n",
      "Epoch   0 Batch 9357/17275   train_loss = 2.839\n",
      "Epoch   0 Batch 9358/17275   train_loss = 3.970\n",
      "Epoch   0 Batch 9359/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 9360/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 9361/17275   train_loss = 7.529\n",
      "Epoch   0 Batch 9362/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 9363/17275   train_loss = 2.440\n",
      "Epoch   0 Batch 9364/17275   train_loss = 3.186\n",
      "Epoch   0 Batch 9365/17275   train_loss = 7.034\n",
      "Epoch   0 Batch 9366/17275   train_loss = 3.225\n",
      "Epoch   0 Batch 9367/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 9368/17275   train_loss = 1.891\n",
      "Epoch   0 Batch 9369/17275   train_loss = 5.994\n",
      "Epoch   0 Batch 9370/17275   train_loss = 1.833\n",
      "Epoch   0 Batch 9371/17275   train_loss = 7.018\n",
      "Epoch   0 Batch 9372/17275   train_loss = 2.505\n",
      "Epoch   0 Batch 9373/17275   train_loss = 2.129\n",
      "Epoch   0 Batch 9374/17275   train_loss = 2.404\n",
      "Epoch   0 Batch 9375/17275   train_loss = 4.694\n",
      "Epoch   0 Batch 9376/17275   train_loss = 3.790\n",
      "Epoch   0 Batch 9377/17275   train_loss = 3.464\n",
      "Epoch   0 Batch 9378/17275   train_loss = 4.482\n",
      "Epoch   0 Batch 9379/17275   train_loss = 7.200\n",
      "Epoch   0 Batch 9380/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 9381/17275   train_loss = 8.044\n",
      "Epoch   0 Batch 9382/17275   train_loss = 3.954\n",
      "Epoch   0 Batch 9383/17275   train_loss = 7.047\n",
      "Epoch   0 Batch 9384/17275   train_loss = 5.006\n",
      "Epoch   0 Batch 9385/17275   train_loss = 3.514\n",
      "Epoch   0 Batch 9386/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 9387/17275   train_loss = 2.424\n",
      "Epoch   0 Batch 9388/17275   train_loss = 5.405\n",
      "Epoch   0 Batch 9389/17275   train_loss = 3.408\n",
      "Epoch   0 Batch 9390/17275   train_loss = 3.141\n",
      "Epoch   0 Batch 9391/17275   train_loss = 3.078\n",
      "Epoch   0 Batch 9392/17275   train_loss = 1.652\n",
      "Epoch   0 Batch 9393/17275   train_loss = 2.691\n",
      "Epoch   0 Batch 9394/17275   train_loss = 4.409\n",
      "Epoch   0 Batch 9395/17275   train_loss = 6.804\n",
      "Epoch   0 Batch 9396/17275   train_loss = 3.736\n",
      "Epoch   0 Batch 9397/17275   train_loss = 4.200\n",
      "Epoch   0 Batch 9398/17275   train_loss = 4.459\n",
      "Epoch   0 Batch 9399/17275   train_loss = 4.155\n",
      "Epoch   0 Batch 9400/17275   train_loss = 7.053\n",
      "Epoch   0 Batch 9401/17275   train_loss = 1.856\n",
      "Epoch   0 Batch 9402/17275   train_loss = 3.845\n",
      "Epoch   0 Batch 9403/17275   train_loss = 4.770\n",
      "Epoch   0 Batch 9404/17275   train_loss = 6.604\n",
      "Epoch   0 Batch 9405/17275   train_loss = 3.031\n",
      "Epoch   0 Batch 9406/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 9407/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 9408/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 9409/17275   train_loss = 2.388\n",
      "Epoch   0 Batch 9410/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 9411/17275   train_loss = 3.101\n",
      "Epoch   0 Batch 9412/17275   train_loss = 3.797\n",
      "Epoch   0 Batch 9413/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 9414/17275   train_loss = 3.782\n",
      "Epoch   0 Batch 9415/17275   train_loss = 4.898\n",
      "Epoch   0 Batch 9416/17275   train_loss = 5.965\n",
      "Epoch   0 Batch 9417/17275   train_loss = 4.221\n",
      "Epoch   0 Batch 9418/17275   train_loss = 7.701\n",
      "Epoch   0 Batch 9419/17275   train_loss = 1.829\n",
      "Epoch   0 Batch 9420/17275   train_loss = 3.846\n",
      "Epoch   0 Batch 9421/17275   train_loss = 3.207\n",
      "Epoch   0 Batch 9422/17275   train_loss = 5.958\n",
      "Epoch   0 Batch 9423/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 9424/17275   train_loss = 3.159\n",
      "Epoch   0 Batch 9425/17275   train_loss = 2.345\n",
      "Epoch   0 Batch 9426/17275   train_loss = 3.082\n",
      "Epoch   0 Batch 9427/17275   train_loss = 2.622\n",
      "Epoch   0 Batch 9428/17275   train_loss = 4.453\n",
      "Epoch   0 Batch 9429/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 9430/17275   train_loss = 5.278\n",
      "Epoch   0 Batch 9431/17275   train_loss = 2.398\n",
      "Epoch   0 Batch 9432/17275   train_loss = 1.749\n",
      "Epoch   0 Batch 9433/17275   train_loss = 6.142\n",
      "Epoch   0 Batch 9434/17275   train_loss = 4.294\n",
      "Epoch   0 Batch 9435/17275   train_loss = 2.639\n",
      "Epoch   0 Batch 9436/17275   train_loss = 10.151\n",
      "Epoch   0 Batch 9437/17275   train_loss = 6.447\n",
      "Epoch   0 Batch 9438/17275   train_loss = 8.343\n",
      "Epoch   0 Batch 9439/17275   train_loss = 1.903\n",
      "Epoch   0 Batch 9440/17275   train_loss = 2.782\n",
      "Epoch   0 Batch 9441/17275   train_loss = 6.405\n",
      "Epoch   0 Batch 9442/17275   train_loss = 3.487\n",
      "Epoch   0 Batch 9443/17275   train_loss = 4.762\n",
      "Epoch   0 Batch 9444/17275   train_loss = 2.432\n",
      "Epoch   0 Batch 9445/17275   train_loss = 6.323\n",
      "Epoch   0 Batch 9446/17275   train_loss = 4.165\n",
      "Epoch   0 Batch 9447/17275   train_loss = 4.001\n",
      "Epoch   0 Batch 9448/17275   train_loss = 2.835\n",
      "Epoch   0 Batch 9449/17275   train_loss = 3.676\n",
      "Epoch   0 Batch 9450/17275   train_loss = 2.889\n",
      "Epoch   0 Batch 9451/17275   train_loss = 3.272\n",
      "Epoch   0 Batch 9452/17275   train_loss = 2.376\n",
      "Epoch   0 Batch 9453/17275   train_loss = 3.944\n",
      "Epoch   0 Batch 9454/17275   train_loss = 5.371\n",
      "Epoch   0 Batch 9455/17275   train_loss = 8.514\n",
      "Epoch   0 Batch 9456/17275   train_loss = 3.175\n",
      "Epoch   0 Batch 9457/17275   train_loss = 3.872\n",
      "Epoch   0 Batch 9458/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 9459/17275   train_loss = 6.575\n",
      "Epoch   0 Batch 9460/17275   train_loss = 2.102\n",
      "Epoch   0 Batch 9461/17275   train_loss = 3.173\n",
      "Epoch   0 Batch 9462/17275   train_loss = 2.581\n",
      "Epoch   0 Batch 9463/17275   train_loss = 4.350\n",
      "Epoch   0 Batch 9464/17275   train_loss = 5.183\n",
      "Epoch   0 Batch 9465/17275   train_loss = 5.656\n",
      "Epoch   0 Batch 9466/17275   train_loss = 3.537\n",
      "Epoch   0 Batch 9467/17275   train_loss = 3.212\n",
      "Epoch   0 Batch 9468/17275   train_loss = 4.036\n",
      "Epoch   0 Batch 9469/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 9470/17275   train_loss = 3.097\n",
      "Epoch   0 Batch 9471/17275   train_loss = 6.852\n",
      "Epoch   0 Batch 9472/17275   train_loss = 5.569\n",
      "Epoch   0 Batch 9473/17275   train_loss = 6.145\n",
      "Epoch   0 Batch 9474/17275   train_loss = 6.431\n",
      "Epoch   0 Batch 9475/17275   train_loss = 4.709\n",
      "Epoch   0 Batch 9476/17275   train_loss = 3.902\n",
      "Epoch   0 Batch 9477/17275   train_loss = 3.204\n",
      "Epoch   0 Batch 9478/17275   train_loss = 6.133\n",
      "Epoch   0 Batch 9479/17275   train_loss = 2.976\n",
      "Epoch   0 Batch 9480/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 9481/17275   train_loss = 2.280\n",
      "Epoch   0 Batch 9482/17275   train_loss = 5.185\n",
      "Epoch   0 Batch 9483/17275   train_loss = 2.360\n",
      "Epoch   0 Batch 9484/17275   train_loss = 3.181\n",
      "Epoch   0 Batch 9485/17275   train_loss = 3.771\n",
      "Epoch   0 Batch 9486/17275   train_loss = 3.697\n",
      "Epoch   0 Batch 9487/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 9488/17275   train_loss = 2.773\n",
      "Epoch   0 Batch 9489/17275   train_loss = 6.308\n",
      "Epoch   0 Batch 9490/17275   train_loss = 3.331\n",
      "Epoch   0 Batch 9491/17275   train_loss = 6.701\n",
      "Epoch   0 Batch 9492/17275   train_loss = 4.572\n",
      "Epoch   0 Batch 9493/17275   train_loss = 2.611\n",
      "Epoch   0 Batch 9494/17275   train_loss = 2.016\n",
      "Epoch   0 Batch 9495/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 9496/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 9497/17275   train_loss = 3.772\n",
      "Epoch   0 Batch 9498/17275   train_loss = 3.388\n",
      "Epoch   0 Batch 9499/17275   train_loss = 3.871\n",
      "Epoch   0 Batch 9500/17275   train_loss = 4.368\n",
      "Epoch   0 Batch 9501/17275   train_loss = 6.591\n",
      "Epoch   0 Batch 9502/17275   train_loss = 3.712\n",
      "Epoch   0 Batch 9503/17275   train_loss = 7.227\n",
      "Epoch   0 Batch 9504/17275   train_loss = 2.143\n",
      "Epoch   0 Batch 9505/17275   train_loss = 3.106\n",
      "Epoch   0 Batch 9506/17275   train_loss = 3.802\n",
      "Epoch   0 Batch 9507/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 9508/17275   train_loss = 3.040\n",
      "Epoch   0 Batch 9509/17275   train_loss = 10.168\n",
      "Epoch   0 Batch 9510/17275   train_loss = 3.574\n",
      "Epoch   0 Batch 9511/17275   train_loss = 6.935\n",
      "Epoch   0 Batch 9512/17275   train_loss = 2.102\n",
      "Epoch   0 Batch 9513/17275   train_loss = 4.120\n",
      "Epoch   0 Batch 9514/17275   train_loss = 6.963\n",
      "Epoch   0 Batch 9515/17275   train_loss = 4.035\n",
      "Epoch   0 Batch 9516/17275   train_loss = 3.766\n",
      "Epoch   0 Batch 9517/17275   train_loss = 2.285\n",
      "Epoch   0 Batch 9518/17275   train_loss = 6.200\n",
      "Epoch   0 Batch 9519/17275   train_loss = 3.511\n",
      "Epoch   0 Batch 9520/17275   train_loss = 2.705\n",
      "Epoch   0 Batch 9521/17275   train_loss = 6.083\n",
      "Epoch   0 Batch 9522/17275   train_loss = 2.129\n",
      "Epoch   0 Batch 9523/17275   train_loss = 3.240\n",
      "Epoch   0 Batch 9524/17275   train_loss = 2.106\n",
      "Epoch   0 Batch 9525/17275   train_loss = 2.090\n",
      "Epoch   0 Batch 9526/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 9527/17275   train_loss = 3.176\n",
      "Epoch   0 Batch 9528/17275   train_loss = 4.569\n",
      "Epoch   0 Batch 9529/17275   train_loss = 6.919\n",
      "Epoch   0 Batch 9530/17275   train_loss = 6.200\n",
      "Epoch   0 Batch 9531/17275   train_loss = 2.274\n",
      "Epoch   0 Batch 9532/17275   train_loss = 3.368\n",
      "Epoch   0 Batch 9533/17275   train_loss = 3.346\n",
      "Epoch   0 Batch 9534/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 9535/17275   train_loss = 6.602\n",
      "Epoch   0 Batch 9536/17275   train_loss = 3.169\n",
      "Epoch   0 Batch 9537/17275   train_loss = 4.792\n",
      "Epoch   0 Batch 9538/17275   train_loss = 4.191\n",
      "Epoch   0 Batch 9539/17275   train_loss = 2.101\n",
      "Epoch   0 Batch 9540/17275   train_loss = 7.745\n",
      "Epoch   0 Batch 9541/17275   train_loss = 5.531\n",
      "Epoch   0 Batch 9542/17275   train_loss = 2.664\n",
      "Epoch   0 Batch 9543/17275   train_loss = 2.847\n",
      "Epoch   0 Batch 9544/17275   train_loss = 7.498\n",
      "Epoch   0 Batch 9545/17275   train_loss = 4.600\n",
      "Epoch   0 Batch 9546/17275   train_loss = 5.456\n",
      "Epoch   0 Batch 9547/17275   train_loss = 3.309\n",
      "Epoch   0 Batch 9548/17275   train_loss = 7.022\n",
      "Epoch   0 Batch 9549/17275   train_loss = 4.009\n",
      "Epoch   0 Batch 9550/17275   train_loss = 6.147\n",
      "Epoch   0 Batch 9551/17275   train_loss = 8.184\n",
      "Epoch   0 Batch 9552/17275   train_loss = 3.491\n",
      "Epoch   0 Batch 9553/17275   train_loss = 7.442\n",
      "Epoch   0 Batch 9554/17275   train_loss = 4.449\n",
      "Epoch   0 Batch 9555/17275   train_loss = 7.495\n",
      "Epoch   0 Batch 9556/17275   train_loss = 2.105\n",
      "Epoch   0 Batch 9557/17275   train_loss = 6.057\n",
      "Epoch   0 Batch 9558/17275   train_loss = 5.947\n",
      "Epoch   0 Batch 9559/17275   train_loss = 6.821\n",
      "Epoch   0 Batch 9560/17275   train_loss = 2.088\n",
      "Epoch   0 Batch 9561/17275   train_loss = 3.277\n",
      "Epoch   0 Batch 9562/17275   train_loss = 2.870\n",
      "Epoch   0 Batch 9563/17275   train_loss = 4.629\n",
      "Epoch   0 Batch 9564/17275   train_loss = 8.098\n",
      "Epoch   0 Batch 9565/17275   train_loss = 3.634\n",
      "Epoch   0 Batch 9566/17275   train_loss = 10.128\n",
      "Epoch   0 Batch 9567/17275   train_loss = 3.957\n",
      "Epoch   0 Batch 9568/17275   train_loss = 2.049\n",
      "Epoch   0 Batch 9569/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 9570/17275   train_loss = 2.919\n",
      "Epoch   0 Batch 9571/17275   train_loss = 6.182\n",
      "Epoch   0 Batch 9572/17275   train_loss = 2.782\n",
      "Epoch   0 Batch 9573/17275   train_loss = 7.508\n",
      "Epoch   0 Batch 9574/17275   train_loss = 2.019\n",
      "Epoch   0 Batch 9575/17275   train_loss = 2.048\n",
      "Epoch   0 Batch 9576/17275   train_loss = 2.758\n",
      "Epoch   0 Batch 9577/17275   train_loss = 3.668\n",
      "Epoch   0 Batch 9578/17275   train_loss = 6.618\n",
      "Epoch   0 Batch 9579/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 9580/17275   train_loss = 6.142\n",
      "Epoch   0 Batch 9581/17275   train_loss = 2.627\n",
      "Epoch   0 Batch 9582/17275   train_loss = 2.196\n",
      "Epoch   0 Batch 9583/17275   train_loss = 4.357\n",
      "Epoch   0 Batch 9584/17275   train_loss = 2.941\n",
      "Epoch   0 Batch 9585/17275   train_loss = 3.976\n",
      "Epoch   0 Batch 9586/17275   train_loss = 6.843\n",
      "Epoch   0 Batch 9587/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 9588/17275   train_loss = 6.435\n",
      "Epoch   0 Batch 9589/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 9590/17275   train_loss = 7.137\n",
      "Epoch   0 Batch 9591/17275   train_loss = 6.656\n",
      "Epoch   0 Batch 9592/17275   train_loss = 1.905\n",
      "Epoch   0 Batch 9593/17275   train_loss = 2.229\n",
      "Epoch   0 Batch 9594/17275   train_loss = 6.361\n",
      "Epoch   0 Batch 9595/17275   train_loss = 4.626\n",
      "Epoch   0 Batch 9596/17275   train_loss = 4.945\n",
      "Epoch   0 Batch 9597/17275   train_loss = 2.124\n",
      "Epoch   0 Batch 9598/17275   train_loss = 6.293\n",
      "Epoch   0 Batch 9599/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 9600/17275   train_loss = 2.694\n",
      "Epoch   0 Batch 9601/17275   train_loss = 3.315\n",
      "Epoch   0 Batch 9602/17275   train_loss = 3.898\n",
      "Epoch   0 Batch 9603/17275   train_loss = 3.098\n",
      "Epoch   0 Batch 9604/17275   train_loss = 2.414\n",
      "Epoch   0 Batch 9605/17275   train_loss = 3.583\n",
      "Epoch   0 Batch 9606/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 9607/17275   train_loss = 2.780\n",
      "Epoch   0 Batch 9608/17275   train_loss = 4.623\n",
      "Epoch   0 Batch 9609/17275   train_loss = 3.693\n",
      "Epoch   0 Batch 9610/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 9611/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 9612/17275   train_loss = 2.413\n",
      "Epoch   0 Batch 9613/17275   train_loss = 3.334\n",
      "Epoch   0 Batch 9614/17275   train_loss = 7.147\n",
      "Epoch   0 Batch 9615/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 9616/17275   train_loss = 4.491\n",
      "Epoch   0 Batch 9617/17275   train_loss = 4.392\n",
      "Epoch   0 Batch 9618/17275   train_loss = 3.823\n",
      "Epoch   0 Batch 9619/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 9620/17275   train_loss = 6.790\n",
      "Epoch   0 Batch 9621/17275   train_loss = 6.515\n",
      "Epoch   0 Batch 9622/17275   train_loss = 2.934\n",
      "Epoch   0 Batch 9623/17275   train_loss = 10.171\n",
      "Epoch   0 Batch 9624/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 9625/17275   train_loss = 2.104\n",
      "Epoch   0 Batch 9626/17275   train_loss = 2.558\n",
      "Epoch   0 Batch 9627/17275   train_loss = 5.166\n",
      "Epoch   0 Batch 9628/17275   train_loss = 3.555\n",
      "Epoch   0 Batch 9629/17275   train_loss = 5.543\n",
      "Epoch   0 Batch 9630/17275   train_loss = 3.317\n",
      "Epoch   0 Batch 9631/17275   train_loss = 2.527\n",
      "Epoch   0 Batch 9632/17275   train_loss = 3.327\n",
      "Epoch   0 Batch 9633/17275   train_loss = 4.772\n",
      "Epoch   0 Batch 9634/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 9635/17275   train_loss = 2.986\n",
      "Epoch   0 Batch 9636/17275   train_loss = 3.507\n",
      "Epoch   0 Batch 9637/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 9638/17275   train_loss = 2.458\n",
      "Epoch   0 Batch 9639/17275   train_loss = 3.296\n",
      "Epoch   0 Batch 9640/17275   train_loss = 2.397\n",
      "Epoch   0 Batch 9641/17275   train_loss = 3.376\n",
      "Epoch   0 Batch 9642/17275   train_loss = 3.182\n",
      "Epoch   0 Batch 9643/17275   train_loss = 3.373\n",
      "Epoch   0 Batch 9644/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 9645/17275   train_loss = 4.881\n",
      "Epoch   0 Batch 9646/17275   train_loss = 6.433\n",
      "Epoch   0 Batch 9647/17275   train_loss = 3.903\n",
      "Epoch   0 Batch 9648/17275   train_loss = 2.608\n",
      "Epoch   0 Batch 9649/17275   train_loss = 2.538\n",
      "Epoch   0 Batch 9650/17275   train_loss = 10.191\n",
      "Epoch   0 Batch 9651/17275   train_loss = 6.367\n",
      "Epoch   0 Batch 9652/17275   train_loss = 4.761\n",
      "Epoch   0 Batch 9653/17275   train_loss = 2.527\n",
      "Epoch   0 Batch 9654/17275   train_loss = 3.718\n",
      "Epoch   0 Batch 9655/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 9656/17275   train_loss = 3.019\n",
      "Epoch   0 Batch 9657/17275   train_loss = 2.636\n",
      "Epoch   0 Batch 9658/17275   train_loss = 5.022\n",
      "Epoch   0 Batch 9659/17275   train_loss = 3.057\n",
      "Epoch   0 Batch 9660/17275   train_loss = 3.674\n",
      "Epoch   0 Batch 9661/17275   train_loss = 2.236\n",
      "Epoch   0 Batch 9662/17275   train_loss = 3.707\n",
      "Epoch   0 Batch 9663/17275   train_loss = 4.752\n",
      "Epoch   0 Batch 9664/17275   train_loss = 6.358\n",
      "Epoch   0 Batch 9665/17275   train_loss = 3.335\n",
      "Epoch   0 Batch 9666/17275   train_loss = 3.000\n",
      "Epoch   0 Batch 9667/17275   train_loss = 2.559\n",
      "Epoch   0 Batch 9668/17275   train_loss = 2.258\n",
      "Epoch   0 Batch 9669/17275   train_loss = 3.347\n",
      "Epoch   0 Batch 9670/17275   train_loss = 7.730\n",
      "Epoch   0 Batch 9671/17275   train_loss = 3.366\n",
      "Epoch   0 Batch 9672/17275   train_loss = 4.889\n",
      "Epoch   0 Batch 9673/17275   train_loss = 2.145\n",
      "Epoch   0 Batch 9674/17275   train_loss = 6.316\n",
      "Epoch   0 Batch 9675/17275   train_loss = 3.618\n",
      "Epoch   0 Batch 9676/17275   train_loss = 3.600\n",
      "Epoch   0 Batch 9677/17275   train_loss = 2.131\n",
      "Epoch   0 Batch 9678/17275   train_loss = 6.361\n",
      "Epoch   0 Batch 9679/17275   train_loss = 8.765\n",
      "Epoch   0 Batch 9680/17275   train_loss = 4.113\n",
      "Epoch   0 Batch 9681/17275   train_loss = 8.110\n",
      "Epoch   0 Batch 9682/17275   train_loss = 7.015\n",
      "Epoch   0 Batch 9683/17275   train_loss = 6.624\n",
      "Epoch   0 Batch 9684/17275   train_loss = 6.224\n",
      "Epoch   0 Batch 9685/17275   train_loss = 6.087\n",
      "Epoch   0 Batch 9686/17275   train_loss = 7.134\n",
      "Epoch   0 Batch 9687/17275   train_loss = 3.973\n",
      "Epoch   0 Batch 9688/17275   train_loss = 6.824\n",
      "Epoch   0 Batch 9689/17275   train_loss = 2.181\n",
      "Epoch   0 Batch 9690/17275   train_loss = 2.041\n",
      "Epoch   0 Batch 9691/17275   train_loss = 6.530\n",
      "Epoch   0 Batch 9692/17275   train_loss = 3.800\n",
      "Epoch   0 Batch 9693/17275   train_loss = 3.923\n",
      "Epoch   0 Batch 9694/17275   train_loss = 6.761\n",
      "Epoch   0 Batch 9695/17275   train_loss = 3.864\n",
      "Epoch   0 Batch 9696/17275   train_loss = 1.906\n",
      "Epoch   0 Batch 9697/17275   train_loss = 2.915\n",
      "Epoch   0 Batch 9698/17275   train_loss = 3.824\n",
      "Epoch   0 Batch 9699/17275   train_loss = 10.204\n",
      "Epoch   0 Batch 9700/17275   train_loss = 2.481\n",
      "Epoch   0 Batch 9701/17275   train_loss = 1.928\n",
      "Epoch   0 Batch 9702/17275   train_loss = 3.094\n",
      "Epoch   0 Batch 9703/17275   train_loss = 6.401\n",
      "Epoch   0 Batch 9704/17275   train_loss = 3.450\n",
      "Epoch   0 Batch 9705/17275   train_loss = 8.374\n",
      "Epoch   0 Batch 9706/17275   train_loss = 7.372\n",
      "Epoch   0 Batch 9707/17275   train_loss = 5.573\n",
      "Epoch   0 Batch 9708/17275   train_loss = 1.792\n",
      "Epoch   0 Batch 9709/17275   train_loss = 4.001\n",
      "Epoch   0 Batch 9710/17275   train_loss = 2.701\n",
      "Epoch   0 Batch 9711/17275   train_loss = 2.080\n",
      "Epoch   0 Batch 9712/17275   train_loss = 4.070\n",
      "Epoch   0 Batch 9713/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 9714/17275   train_loss = 7.243\n",
      "Epoch   0 Batch 9715/17275   train_loss = 6.352\n",
      "Epoch   0 Batch 9716/17275   train_loss = 4.562\n",
      "Epoch   0 Batch 9717/17275   train_loss = 6.924\n",
      "Epoch   0 Batch 9718/17275   train_loss = 7.162\n",
      "Epoch   0 Batch 9719/17275   train_loss = 1.779\n",
      "Epoch   0 Batch 9720/17275   train_loss = 3.270\n",
      "Epoch   0 Batch 9721/17275   train_loss = 4.977\n",
      "Epoch   0 Batch 9722/17275   train_loss = 2.682\n",
      "Epoch   0 Batch 9723/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 9724/17275   train_loss = 6.617\n",
      "Epoch   0 Batch 9725/17275   train_loss = 4.336\n",
      "Epoch   0 Batch 9726/17275   train_loss = 4.379\n",
      "Epoch   0 Batch 9727/17275   train_loss = 3.499\n",
      "Epoch   0 Batch 9728/17275   train_loss = 3.810\n",
      "Epoch   0 Batch 9729/17275   train_loss = 1.705\n",
      "Epoch   0 Batch 9730/17275   train_loss = 2.482\n",
      "Epoch   0 Batch 9731/17275   train_loss = 4.766\n",
      "Epoch   0 Batch 9732/17275   train_loss = 3.851\n",
      "Epoch   0 Batch 9733/17275   train_loss = 3.031\n",
      "Epoch   0 Batch 9734/17275   train_loss = 2.848\n",
      "Epoch   0 Batch 9735/17275   train_loss = 2.798\n",
      "Epoch   0 Batch 9736/17275   train_loss = 2.725\n",
      "Epoch   0 Batch 9737/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 9738/17275   train_loss = 4.327\n",
      "Epoch   0 Batch 9739/17275   train_loss = 2.906\n",
      "Epoch   0 Batch 9740/17275   train_loss = 4.260\n",
      "Epoch   0 Batch 9741/17275   train_loss = 3.746\n",
      "Epoch   0 Batch 9742/17275   train_loss = 4.934\n",
      "Epoch   0 Batch 9743/17275   train_loss = 5.980\n",
      "Epoch   0 Batch 9744/17275   train_loss = 7.943\n",
      "Epoch   0 Batch 9745/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 9746/17275   train_loss = 3.745\n",
      "Epoch   0 Batch 9747/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 9748/17275   train_loss = 7.987\n",
      "Epoch   0 Batch 9749/17275   train_loss = 5.991\n",
      "Epoch   0 Batch 9750/17275   train_loss = 3.448\n",
      "Epoch   0 Batch 9751/17275   train_loss = 3.921\n",
      "Epoch   0 Batch 9752/17275   train_loss = 7.554\n",
      "Epoch   0 Batch 9753/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 9754/17275   train_loss = 6.337\n",
      "Epoch   0 Batch 9755/17275   train_loss = 6.275\n",
      "Epoch   0 Batch 9756/17275   train_loss = 6.009\n",
      "Epoch   0 Batch 9757/17275   train_loss = 1.819\n",
      "Epoch   0 Batch 9758/17275   train_loss = 2.597\n",
      "Epoch   0 Batch 9759/17275   train_loss = 6.496\n",
      "Epoch   0 Batch 9760/17275   train_loss = 6.493\n",
      "Epoch   0 Batch 9761/17275   train_loss = 1.774\n",
      "Epoch   0 Batch 9762/17275   train_loss = 1.956\n",
      "Epoch   0 Batch 9763/17275   train_loss = 3.515\n",
      "Epoch   0 Batch 9764/17275   train_loss = 6.541\n",
      "Epoch   0 Batch 9765/17275   train_loss = 6.853\n",
      "Epoch   0 Batch 9766/17275   train_loss = 6.200\n",
      "Epoch   0 Batch 9767/17275   train_loss = 2.682\n",
      "Epoch   0 Batch 9768/17275   train_loss = 6.192\n",
      "Epoch   0 Batch 9769/17275   train_loss = 6.203\n",
      "Epoch   0 Batch 9770/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 9771/17275   train_loss = 5.937\n",
      "Epoch   0 Batch 9772/17275   train_loss = 2.554\n",
      "Epoch   0 Batch 9773/17275   train_loss = 6.929\n",
      "Epoch   0 Batch 9774/17275   train_loss = 2.926\n",
      "Epoch   0 Batch 9775/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 9776/17275   train_loss = 7.634\n",
      "Epoch   0 Batch 9777/17275   train_loss = 6.468\n",
      "Epoch   0 Batch 9778/17275   train_loss = 1.761\n",
      "Epoch   0 Batch 9779/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 9780/17275   train_loss = 3.450\n",
      "Epoch   0 Batch 9781/17275   train_loss = 3.384\n",
      "Epoch   0 Batch 9782/17275   train_loss = 10.261\n",
      "Epoch   0 Batch 9783/17275   train_loss = 1.767\n",
      "Epoch   0 Batch 9784/17275   train_loss = 1.842\n",
      "Epoch   0 Batch 9785/17275   train_loss = 2.189\n",
      "Epoch   0 Batch 9786/17275   train_loss = 3.916\n",
      "Epoch   0 Batch 9787/17275   train_loss = 2.757\n",
      "Epoch   0 Batch 9788/17275   train_loss = 5.248\n",
      "Epoch   0 Batch 9789/17275   train_loss = 5.314\n",
      "Epoch   0 Batch 9790/17275   train_loss = 5.385\n",
      "Epoch   0 Batch 9791/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 9792/17275   train_loss = 2.749\n",
      "Epoch   0 Batch 9793/17275   train_loss = 3.800\n",
      "Epoch   0 Batch 9794/17275   train_loss = 3.050\n",
      "Epoch   0 Batch 9795/17275   train_loss = 6.092\n",
      "Epoch   0 Batch 9796/17275   train_loss = 5.430\n",
      "Epoch   0 Batch 9797/17275   train_loss = 4.081\n",
      "Epoch   0 Batch 9798/17275   train_loss = 2.977\n",
      "Epoch   0 Batch 9799/17275   train_loss = 3.759\n",
      "Epoch   0 Batch 9800/17275   train_loss = 2.497\n",
      "Epoch   0 Batch 9801/17275   train_loss = 1.710\n",
      "Epoch   0 Batch 9802/17275   train_loss = 2.926\n",
      "Epoch   0 Batch 9803/17275   train_loss = 1.668\n",
      "Epoch   0 Batch 9804/17275   train_loss = 2.514\n",
      "Epoch   0 Batch 9805/17275   train_loss = 3.373\n",
      "Epoch   0 Batch 9806/17275   train_loss = 5.032\n",
      "Epoch   0 Batch 9807/17275   train_loss = 2.633\n",
      "Epoch   0 Batch 9808/17275   train_loss = 3.827\n",
      "Epoch   0 Batch 9809/17275   train_loss = 3.427\n",
      "Epoch   0 Batch 9810/17275   train_loss = 3.696\n",
      "Epoch   0 Batch 9811/17275   train_loss = 5.039\n",
      "Epoch   0 Batch 9812/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 9813/17275   train_loss = 3.987\n",
      "Epoch   0 Batch 9814/17275   train_loss = 3.669\n",
      "Epoch   0 Batch 9815/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 9816/17275   train_loss = 6.609\n",
      "Epoch   0 Batch 9817/17275   train_loss = 6.606\n",
      "Epoch   0 Batch 9818/17275   train_loss = 2.765\n",
      "Epoch   0 Batch 9819/17275   train_loss = 3.067\n",
      "Epoch   0 Batch 9820/17275   train_loss = 3.032\n",
      "Epoch   0 Batch 9821/17275   train_loss = 5.900\n",
      "Epoch   0 Batch 9822/17275   train_loss = 5.859\n",
      "Epoch   0 Batch 9823/17275   train_loss = 3.243\n",
      "Epoch   0 Batch 9824/17275   train_loss = 9.130\n",
      "Epoch   0 Batch 9825/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 9826/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 9827/17275   train_loss = 4.765\n",
      "Epoch   0 Batch 9828/17275   train_loss = 2.927\n",
      "Epoch   0 Batch 9829/17275   train_loss = 6.188\n",
      "Epoch   0 Batch 9830/17275   train_loss = 6.353\n",
      "Epoch   0 Batch 9831/17275   train_loss = 6.479\n",
      "Epoch   0 Batch 9832/17275   train_loss = 1.616\n",
      "Epoch   0 Batch 9833/17275   train_loss = 2.037\n",
      "Epoch   0 Batch 9834/17275   train_loss = 3.922\n",
      "Epoch   0 Batch 9835/17275   train_loss = 6.195\n",
      "Epoch   0 Batch 9836/17275   train_loss = 7.172\n",
      "Epoch   0 Batch 9837/17275   train_loss = 6.293\n",
      "Epoch   0 Batch 9838/17275   train_loss = 5.936\n",
      "Epoch   0 Batch 9839/17275   train_loss = 2.651\n",
      "Epoch   0 Batch 9840/17275   train_loss = 6.672\n",
      "Epoch   0 Batch 9841/17275   train_loss = 2.662\n",
      "Epoch   0 Batch 9842/17275   train_loss = 7.293\n",
      "Epoch   0 Batch 9843/17275   train_loss = 3.561\n",
      "Epoch   0 Batch 9844/17275   train_loss = 7.369\n",
      "Epoch   0 Batch 9845/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 9846/17275   train_loss = 2.330\n",
      "Epoch   0 Batch 9847/17275   train_loss = 2.973\n",
      "Epoch   0 Batch 9848/17275   train_loss = 4.623\n",
      "Epoch   0 Batch 9849/17275   train_loss = 3.124\n",
      "Epoch   0 Batch 9850/17275   train_loss = 4.402\n",
      "Epoch   0 Batch 9851/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 9852/17275   train_loss = 2.993\n",
      "Epoch   0 Batch 9853/17275   train_loss = 4.085\n",
      "Epoch   0 Batch 9854/17275   train_loss = 10.223\n",
      "Epoch   0 Batch 9855/17275   train_loss = 4.759\n",
      "Epoch   0 Batch 9856/17275   train_loss = 1.880\n",
      "Epoch   0 Batch 9857/17275   train_loss = 3.808\n",
      "Epoch   0 Batch 9858/17275   train_loss = 6.877\n",
      "Epoch   0 Batch 9859/17275   train_loss = 6.114\n",
      "Epoch   0 Batch 9860/17275   train_loss = 7.530\n",
      "Epoch   0 Batch 9861/17275   train_loss = 2.861\n",
      "Epoch   0 Batch 9862/17275   train_loss = 3.050\n",
      "Epoch   0 Batch 9863/17275   train_loss = 2.864\n",
      "Epoch   0 Batch 9864/17275   train_loss = 10.211\n",
      "Epoch   0 Batch 9865/17275   train_loss = 2.529\n",
      "Epoch   0 Batch 9866/17275   train_loss = 2.453\n",
      "Epoch   0 Batch 9867/17275   train_loss = 2.686\n",
      "Epoch   0 Batch 9868/17275   train_loss = 6.693\n",
      "Epoch   0 Batch 9869/17275   train_loss = 10.215\n",
      "Epoch   0 Batch 9870/17275   train_loss = 3.159\n",
      "Epoch   0 Batch 9871/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 9872/17275   train_loss = 6.409\n",
      "Epoch   0 Batch 9873/17275   train_loss = 1.873\n",
      "Epoch   0 Batch 9874/17275   train_loss = 3.523\n",
      "Epoch   0 Batch 9875/17275   train_loss = 2.982\n",
      "Epoch   0 Batch 9876/17275   train_loss = 6.502\n",
      "Epoch   0 Batch 9877/17275   train_loss = 2.332\n",
      "Epoch   0 Batch 9878/17275   train_loss = 6.907\n",
      "Epoch   0 Batch 9879/17275   train_loss = 5.495\n",
      "Epoch   0 Batch 9880/17275   train_loss = 2.261\n",
      "Epoch   0 Batch 9881/17275   train_loss = 4.030\n",
      "Epoch   0 Batch 9882/17275   train_loss = 3.377\n",
      "Epoch   0 Batch 9883/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 9884/17275   train_loss = 8.221\n",
      "Epoch   0 Batch 9885/17275   train_loss = 6.714\n",
      "Epoch   0 Batch 9886/17275   train_loss = 7.575\n",
      "Epoch   0 Batch 9887/17275   train_loss = 5.151\n",
      "Epoch   0 Batch 9888/17275   train_loss = 7.508\n",
      "Epoch   0 Batch 9889/17275   train_loss = 6.973\n",
      "Epoch   0 Batch 9890/17275   train_loss = 7.282\n",
      "Epoch   0 Batch 9891/17275   train_loss = 4.075\n",
      "Epoch   0 Batch 9892/17275   train_loss = 7.397\n",
      "Epoch   0 Batch 9893/17275   train_loss = 1.887\n",
      "Epoch   0 Batch 9894/17275   train_loss = 1.940\n",
      "Epoch   0 Batch 9895/17275   train_loss = 3.732\n",
      "Epoch   0 Batch 9896/17275   train_loss = 4.827\n",
      "Epoch   0 Batch 9897/17275   train_loss = 3.090\n",
      "Epoch   0 Batch 9898/17275   train_loss = 4.029\n",
      "Epoch   0 Batch 9899/17275   train_loss = 2.796\n",
      "Epoch   0 Batch 9900/17275   train_loss = 4.585\n",
      "Epoch   0 Batch 9901/17275   train_loss = 4.577\n",
      "Epoch   0 Batch 9902/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 9903/17275   train_loss = 2.718\n",
      "Epoch   0 Batch 9904/17275   train_loss = 2.714\n",
      "Epoch   0 Batch 9905/17275   train_loss = 4.169\n",
      "Epoch   0 Batch 9906/17275   train_loss = 4.247\n",
      "Epoch   0 Batch 9907/17275   train_loss = 7.739\n",
      "Epoch   0 Batch 9908/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 9909/17275   train_loss = 2.259\n",
      "Epoch   0 Batch 9910/17275   train_loss = 6.293\n",
      "Epoch   0 Batch 9911/17275   train_loss = 3.833\n",
      "Epoch   0 Batch 9912/17275   train_loss = 6.942\n",
      "Epoch   0 Batch 9913/17275   train_loss = 3.648\n",
      "Epoch   0 Batch 9914/17275   train_loss = 1.875\n",
      "Epoch   0 Batch 9915/17275   train_loss = 3.194\n",
      "Epoch   0 Batch 9916/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 9917/17275   train_loss = 3.221\n",
      "Epoch   0 Batch 9918/17275   train_loss = 7.808\n",
      "Epoch   0 Batch 9919/17275   train_loss = 3.682\n",
      "Epoch   0 Batch 9920/17275   train_loss = 5.418\n",
      "Epoch   0 Batch 9921/17275   train_loss = 7.196\n",
      "Epoch   0 Batch 9922/17275   train_loss = 6.023\n",
      "Epoch   0 Batch 9923/17275   train_loss = 1.875\n",
      "Epoch   0 Batch 9924/17275   train_loss = 2.458\n",
      "Epoch   0 Batch 9925/17275   train_loss = 6.424\n",
      "Epoch   0 Batch 9926/17275   train_loss = 4.277\n",
      "Epoch   0 Batch 9927/17275   train_loss = 2.281\n",
      "Epoch   0 Batch 9928/17275   train_loss = 3.822\n",
      "Epoch   0 Batch 9929/17275   train_loss = 6.302\n",
      "Epoch   0 Batch 9930/17275   train_loss = 3.837\n",
      "Epoch   0 Batch 9931/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 9932/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 9933/17275   train_loss = 2.506\n",
      "Epoch   0 Batch 9934/17275   train_loss = 2.896\n",
      "Epoch   0 Batch 9935/17275   train_loss = 2.677\n",
      "Epoch   0 Batch 9936/17275   train_loss = 6.317\n",
      "Epoch   0 Batch 9937/17275   train_loss = 6.685\n",
      "Epoch   0 Batch 9938/17275   train_loss = 4.476\n",
      "Epoch   0 Batch 9939/17275   train_loss = 6.285\n",
      "Epoch   0 Batch 9940/17275   train_loss = 6.183\n",
      "Epoch   0 Batch 9941/17275   train_loss = 4.295\n",
      "Epoch   0 Batch 9942/17275   train_loss = 4.109\n",
      "Epoch   0 Batch 9943/17275   train_loss = 5.046\n",
      "Epoch   0 Batch 9944/17275   train_loss = 6.830\n",
      "Epoch   0 Batch 9945/17275   train_loss = 4.684\n",
      "Epoch   0 Batch 9946/17275   train_loss = 4.206\n",
      "Epoch   0 Batch 9947/17275   train_loss = 2.838\n",
      "Epoch   0 Batch 9948/17275   train_loss = 4.164\n",
      "Epoch   0 Batch 9949/17275   train_loss = 2.328\n",
      "Epoch   0 Batch 9950/17275   train_loss = 6.271\n",
      "Epoch   0 Batch 9951/17275   train_loss = 3.834\n",
      "Epoch   0 Batch 9952/17275   train_loss = 10.172\n",
      "Epoch   0 Batch 9953/17275   train_loss = 6.486\n",
      "Epoch   0 Batch 9954/17275   train_loss = 2.241\n",
      "Epoch   0 Batch 9955/17275   train_loss = 2.666\n",
      "Epoch   0 Batch 9956/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 9957/17275   train_loss = 4.561\n",
      "Epoch   0 Batch 9958/17275   train_loss = 5.316\n",
      "Epoch   0 Batch 9959/17275   train_loss = 5.889\n",
      "Epoch   0 Batch 9960/17275   train_loss = 4.405\n",
      "Epoch   0 Batch 9961/17275   train_loss = 2.489\n",
      "Epoch   0 Batch 9962/17275   train_loss = 6.314\n",
      "Epoch   0 Batch 9963/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 9964/17275   train_loss = 4.908\n",
      "Epoch   0 Batch 9965/17275   train_loss = 2.140\n",
      "Epoch   0 Batch 9966/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 9967/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 9968/17275   train_loss = 3.923\n",
      "Epoch   0 Batch 9969/17275   train_loss = 3.628\n",
      "Epoch   0 Batch 9970/17275   train_loss = 2.133\n",
      "Epoch   0 Batch 9971/17275   train_loss = 2.605\n",
      "Epoch   0 Batch 9972/17275   train_loss = 4.461\n",
      "Epoch   0 Batch 9973/17275   train_loss = 2.558\n",
      "Epoch   0 Batch 9974/17275   train_loss = 3.113\n",
      "Epoch   0 Batch 9975/17275   train_loss = 2.311\n",
      "Epoch   0 Batch 9976/17275   train_loss = 6.269\n",
      "Epoch   0 Batch 9977/17275   train_loss = 4.132\n",
      "Epoch   0 Batch 9978/17275   train_loss = 2.278\n",
      "Epoch   0 Batch 9979/17275   train_loss = 4.345\n",
      "Epoch   0 Batch 9980/17275   train_loss = 4.390\n",
      "Epoch   0 Batch 9981/17275   train_loss = 3.336\n",
      "Epoch   0 Batch 9982/17275   train_loss = 3.692\n",
      "Epoch   0 Batch 9983/17275   train_loss = 2.763\n",
      "Epoch   0 Batch 9984/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 9985/17275   train_loss = 4.015\n",
      "Epoch   0 Batch 9986/17275   train_loss = 3.101\n",
      "Epoch   0 Batch 9987/17275   train_loss = 4.223\n",
      "Epoch   0 Batch 9988/17275   train_loss = 3.069\n",
      "Epoch   0 Batch 9989/17275   train_loss = 2.832\n",
      "Epoch   0 Batch 9990/17275   train_loss = 6.116\n",
      "Epoch   0 Batch 9991/17275   train_loss = 3.949\n",
      "Epoch   0 Batch 9992/17275   train_loss = 5.327\n",
      "Epoch   0 Batch 9993/17275   train_loss = 4.433\n",
      "Epoch   0 Batch 9994/17275   train_loss = 1.989\n",
      "Epoch   0 Batch 9995/17275   train_loss = 7.157\n",
      "Epoch   0 Batch 9996/17275   train_loss = 3.616\n",
      "Epoch   0 Batch 9997/17275   train_loss = 4.918\n",
      "Epoch   0 Batch 9998/17275   train_loss = 3.449\n",
      "Epoch   0 Batch 9999/17275   train_loss = 2.807\n",
      "Epoch   0 Batch 10000/17275   train_loss = 6.071\n",
      "Epoch   0 Batch 10001/17275   train_loss = 2.843\n",
      "Epoch   0 Batch 10002/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 10003/17275   train_loss = 6.863\n",
      "Epoch   0 Batch 10004/17275   train_loss = 1.900\n",
      "Epoch   0 Batch 10005/17275   train_loss = 6.322\n",
      "Epoch   0 Batch 10006/17275   train_loss = 6.322\n",
      "Epoch   0 Batch 10007/17275   train_loss = 3.160\n",
      "Epoch   0 Batch 10008/17275   train_loss = 3.261\n",
      "Epoch   0 Batch 10009/17275   train_loss = 2.498\n",
      "Epoch   0 Batch 10010/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 10011/17275   train_loss = 3.067\n",
      "Epoch   0 Batch 10012/17275   train_loss = 3.875\n",
      "Epoch   0 Batch 10013/17275   train_loss = 3.466\n",
      "Epoch   0 Batch 10014/17275   train_loss = 10.224\n",
      "Epoch   0 Batch 10015/17275   train_loss = 3.492\n",
      "Epoch   0 Batch 10016/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 10017/17275   train_loss = 2.753\n",
      "Epoch   0 Batch 10018/17275   train_loss = 7.469\n",
      "Epoch   0 Batch 10019/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 10020/17275   train_loss = 3.752\n",
      "Epoch   0 Batch 10021/17275   train_loss = 3.692\n",
      "Epoch   0 Batch 10022/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 10023/17275   train_loss = 6.088\n",
      "Epoch   0 Batch 10024/17275   train_loss = 3.571\n",
      "Epoch   0 Batch 10025/17275   train_loss = 3.958\n",
      "Epoch   0 Batch 10026/17275   train_loss = 6.893\n",
      "Epoch   0 Batch 10027/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 10028/17275   train_loss = 3.678\n",
      "Epoch   0 Batch 10029/17275   train_loss = 3.573\n",
      "Epoch   0 Batch 10030/17275   train_loss = 1.968\n",
      "Epoch   0 Batch 10031/17275   train_loss = 3.290\n",
      "Epoch   0 Batch 10032/17275   train_loss = 2.518\n",
      "Epoch   0 Batch 10033/17275   train_loss = 3.611\n",
      "Epoch   0 Batch 10034/17275   train_loss = 3.541\n",
      "Epoch   0 Batch 10035/17275   train_loss = 4.041\n",
      "Epoch   0 Batch 10036/17275   train_loss = 4.092\n",
      "Epoch   0 Batch 10037/17275   train_loss = 2.986\n",
      "Epoch   0 Batch 10038/17275   train_loss = 3.336\n",
      "Epoch   0 Batch 10039/17275   train_loss = 3.096\n",
      "Epoch   0 Batch 10040/17275   train_loss = 3.837\n",
      "Epoch   0 Batch 10041/17275   train_loss = 4.038\n",
      "Epoch   0 Batch 10042/17275   train_loss = 3.322\n",
      "Epoch   0 Batch 10043/17275   train_loss = 3.224\n",
      "Epoch   0 Batch 10044/17275   train_loss = 2.100\n",
      "Epoch   0 Batch 10045/17275   train_loss = 2.535\n",
      "Epoch   0 Batch 10046/17275   train_loss = 3.038\n",
      "Epoch   0 Batch 10047/17275   train_loss = 3.564\n",
      "Epoch   0 Batch 10048/17275   train_loss = 4.281\n",
      "Epoch   0 Batch 10049/17275   train_loss = 2.304\n",
      "Epoch   0 Batch 10050/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 10051/17275   train_loss = 2.907\n",
      "Epoch   0 Batch 10052/17275   train_loss = 7.430\n",
      "Epoch   0 Batch 10053/17275   train_loss = 3.323\n",
      "Epoch   0 Batch 10054/17275   train_loss = 4.507\n",
      "Epoch   0 Batch 10055/17275   train_loss = 7.038\n",
      "Epoch   0 Batch 10056/17275   train_loss = 2.027\n",
      "Epoch   0 Batch 10057/17275   train_loss = 3.561\n",
      "Epoch   0 Batch 10058/17275   train_loss = 4.538\n",
      "Epoch   0 Batch 10059/17275   train_loss = 5.993\n",
      "Epoch   0 Batch 10060/17275   train_loss = 2.738\n",
      "Epoch   0 Batch 10061/17275   train_loss = 6.486\n",
      "Epoch   0 Batch 10062/17275   train_loss = 4.997\n",
      "Epoch   0 Batch 10063/17275   train_loss = 3.773\n",
      "Epoch   0 Batch 10064/17275   train_loss = 6.131\n",
      "Epoch   0 Batch 10065/17275   train_loss = 2.447\n",
      "Epoch   0 Batch 10066/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 10067/17275   train_loss = 3.358\n",
      "Epoch   0 Batch 10068/17275   train_loss = 3.005\n",
      "Epoch   0 Batch 10069/17275   train_loss = 8.687\n",
      "Epoch   0 Batch 10070/17275   train_loss = 2.958\n",
      "Epoch   0 Batch 10071/17275   train_loss = 6.170\n",
      "Epoch   0 Batch 10072/17275   train_loss = 2.624\n",
      "Epoch   0 Batch 10073/17275   train_loss = 5.370\n",
      "Epoch   0 Batch 10074/17275   train_loss = 6.144\n",
      "Epoch   0 Batch 10075/17275   train_loss = 10.264\n",
      "Epoch   0 Batch 10076/17275   train_loss = 2.792\n",
      "Epoch   0 Batch 10077/17275   train_loss = 1.970\n",
      "Epoch   0 Batch 10078/17275   train_loss = 2.763\n",
      "Epoch   0 Batch 10079/17275   train_loss = 5.344\n",
      "Epoch   0 Batch 10080/17275   train_loss = 3.264\n",
      "Epoch   0 Batch 10081/17275   train_loss = 2.708\n",
      "Epoch   0 Batch 10082/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 10083/17275   train_loss = 4.527\n",
      "Epoch   0 Batch 10084/17275   train_loss = 2.959\n",
      "Epoch   0 Batch 10085/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 10086/17275   train_loss = 2.729\n",
      "Epoch   0 Batch 10087/17275   train_loss = 2.649\n",
      "Epoch   0 Batch 10088/17275   train_loss = 3.827\n",
      "Epoch   0 Batch 10089/17275   train_loss = 3.459\n",
      "Epoch   0 Batch 10090/17275   train_loss = 6.500\n",
      "Epoch   0 Batch 10091/17275   train_loss = 5.928\n",
      "Epoch   0 Batch 10092/17275   train_loss = 2.343\n",
      "Epoch   0 Batch 10093/17275   train_loss = 6.528\n",
      "Epoch   0 Batch 10094/17275   train_loss = 5.347\n",
      "Epoch   0 Batch 10095/17275   train_loss = 5.383\n",
      "Epoch   0 Batch 10096/17275   train_loss = 4.813\n",
      "Epoch   0 Batch 10097/17275   train_loss = 2.710\n",
      "Epoch   0 Batch 10098/17275   train_loss = 3.496\n",
      "Epoch   0 Batch 10099/17275   train_loss = 6.464\n",
      "Epoch   0 Batch 10100/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 10101/17275   train_loss = 3.860\n",
      "Epoch   0 Batch 10102/17275   train_loss = 5.702\n",
      "Epoch   0 Batch 10103/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 10104/17275   train_loss = 4.481\n",
      "Epoch   0 Batch 10105/17275   train_loss = 6.562\n",
      "Epoch   0 Batch 10106/17275   train_loss = 5.296\n",
      "Epoch   0 Batch 10107/17275   train_loss = 4.436\n",
      "Epoch   0 Batch 10108/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 10109/17275   train_loss = 2.294\n",
      "Epoch   0 Batch 10110/17275   train_loss = 3.589\n",
      "Epoch   0 Batch 10111/17275   train_loss = 6.976\n",
      "Epoch   0 Batch 10112/17275   train_loss = 6.508\n",
      "Epoch   0 Batch 10113/17275   train_loss = 2.938\n",
      "Epoch   0 Batch 10114/17275   train_loss = 2.872\n",
      "Epoch   0 Batch 10115/17275   train_loss = 6.407\n",
      "Epoch   0 Batch 10116/17275   train_loss = 3.697\n",
      "Epoch   0 Batch 10117/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 10118/17275   train_loss = 4.003\n",
      "Epoch   0 Batch 10119/17275   train_loss = 9.310\n",
      "Epoch   0 Batch 10120/17275   train_loss = 10.259\n",
      "Epoch   0 Batch 10121/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 10122/17275   train_loss = 4.282\n",
      "Epoch   0 Batch 10123/17275   train_loss = 6.993\n",
      "Epoch   0 Batch 10124/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 10125/17275   train_loss = 7.215\n",
      "Epoch   0 Batch 10126/17275   train_loss = 6.556\n",
      "Epoch   0 Batch 10127/17275   train_loss = 5.478\n",
      "Epoch   0 Batch 10128/17275   train_loss = 4.218\n",
      "Epoch   0 Batch 10129/17275   train_loss = 2.111\n",
      "Epoch   0 Batch 10130/17275   train_loss = 2.299\n",
      "Epoch   0 Batch 10131/17275   train_loss = 6.498\n",
      "Epoch   0 Batch 10132/17275   train_loss = 3.199\n",
      "Epoch   0 Batch 10133/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 10134/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 10135/17275   train_loss = 2.015\n",
      "Epoch   0 Batch 10136/17275   train_loss = 3.886\n",
      "Epoch   0 Batch 10137/17275   train_loss = 2.848\n",
      "Epoch   0 Batch 10138/17275   train_loss = 3.368\n",
      "Epoch   0 Batch 10139/17275   train_loss = 3.862\n",
      "Epoch   0 Batch 10140/17275   train_loss = 2.662\n",
      "Epoch   0 Batch 10141/17275   train_loss = 5.483\n",
      "Epoch   0 Batch 10142/17275   train_loss = 2.662\n",
      "Epoch   0 Batch 10143/17275   train_loss = 3.583\n",
      "Epoch   0 Batch 10144/17275   train_loss = 3.812\n",
      "Epoch   0 Batch 10145/17275   train_loss = 6.569\n",
      "Epoch   0 Batch 10146/17275   train_loss = 3.625\n",
      "Epoch   0 Batch 10147/17275   train_loss = 2.963\n",
      "Epoch   0 Batch 10148/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 10149/17275   train_loss = 2.866\n",
      "Epoch   0 Batch 10150/17275   train_loss = 5.056\n",
      "Epoch   0 Batch 10151/17275   train_loss = 6.101\n",
      "Epoch   0 Batch 10152/17275   train_loss = 2.369\n",
      "Epoch   0 Batch 10153/17275   train_loss = 4.419\n",
      "Epoch   0 Batch 10154/17275   train_loss = 3.045\n",
      "Epoch   0 Batch 10155/17275   train_loss = 2.394\n",
      "Epoch   0 Batch 10156/17275   train_loss = 3.433\n",
      "Epoch   0 Batch 10157/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 10158/17275   train_loss = 2.671\n",
      "Epoch   0 Batch 10159/17275   train_loss = 3.103\n",
      "Epoch   0 Batch 10160/17275   train_loss = 3.744\n",
      "Epoch   0 Batch 10161/17275   train_loss = 4.717\n",
      "Epoch   0 Batch 10162/17275   train_loss = 6.531\n",
      "Epoch   0 Batch 10163/17275   train_loss = 2.342\n",
      "Epoch   0 Batch 10164/17275   train_loss = 2.854\n",
      "Epoch   0 Batch 10165/17275   train_loss = 3.844\n",
      "Epoch   0 Batch 10166/17275   train_loss = 3.112\n",
      "Epoch   0 Batch 10167/17275   train_loss = 8.280\n",
      "Epoch   0 Batch 10168/17275   train_loss = 3.424\n",
      "Epoch   0 Batch 10169/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 10170/17275   train_loss = 6.946\n",
      "Epoch   0 Batch 10171/17275   train_loss = 3.215\n",
      "Epoch   0 Batch 10172/17275   train_loss = 4.166\n",
      "Epoch   0 Batch 10173/17275   train_loss = 4.666\n",
      "Epoch   0 Batch 10174/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 10175/17275   train_loss = 2.574\n",
      "Epoch   0 Batch 10176/17275   train_loss = 6.374\n",
      "Epoch   0 Batch 10177/17275   train_loss = 5.147\n",
      "Epoch   0 Batch 10178/17275   train_loss = 2.950\n",
      "Epoch   0 Batch 10179/17275   train_loss = 2.549\n",
      "Epoch   0 Batch 10180/17275   train_loss = 3.972\n",
      "Epoch   0 Batch 10181/17275   train_loss = 3.773\n",
      "Epoch   0 Batch 10182/17275   train_loss = 3.710\n",
      "Epoch   0 Batch 10183/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 10184/17275   train_loss = 2.152\n",
      "Epoch   0 Batch 10185/17275   train_loss = 2.497\n",
      "Epoch   0 Batch 10186/17275   train_loss = 6.274\n",
      "Epoch   0 Batch 10187/17275   train_loss = 2.947\n",
      "Epoch   0 Batch 10188/17275   train_loss = 2.776\n",
      "Epoch   0 Batch 10189/17275   train_loss = 3.880\n",
      "Epoch   0 Batch 10190/17275   train_loss = 3.362\n",
      "Epoch   0 Batch 10191/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 10192/17275   train_loss = 6.774\n",
      "Epoch   0 Batch 10193/17275   train_loss = 3.568\n",
      "Epoch   0 Batch 10194/17275   train_loss = 4.986\n",
      "Epoch   0 Batch 10195/17275   train_loss = 4.623\n",
      "Epoch   0 Batch 10196/17275   train_loss = 4.130\n",
      "Epoch   0 Batch 10197/17275   train_loss = 3.979\n",
      "Epoch   0 Batch 10198/17275   train_loss = 5.905\n",
      "Epoch   0 Batch 10199/17275   train_loss = 3.556\n",
      "Epoch   0 Batch 10200/17275   train_loss = 6.429\n",
      "Epoch   0 Batch 10201/17275   train_loss = 4.277\n",
      "Epoch   0 Batch 10202/17275   train_loss = 6.629\n",
      "Epoch   0 Batch 10203/17275   train_loss = 2.979\n",
      "Epoch   0 Batch 10204/17275   train_loss = 6.751\n",
      "Epoch   0 Batch 10205/17275   train_loss = 2.380\n",
      "Epoch   0 Batch 10206/17275   train_loss = 4.255\n",
      "Epoch   0 Batch 10207/17275   train_loss = 3.068\n",
      "Epoch   0 Batch 10208/17275   train_loss = 6.296\n",
      "Epoch   0 Batch 10209/17275   train_loss = 10.287\n",
      "Epoch   0 Batch 10210/17275   train_loss = 2.975\n",
      "Epoch   0 Batch 10211/17275   train_loss = 2.721\n",
      "Epoch   0 Batch 10212/17275   train_loss = 4.722\n",
      "Epoch   0 Batch 10213/17275   train_loss = 3.420\n",
      "Epoch   0 Batch 10214/17275   train_loss = 3.147\n",
      "Epoch   0 Batch 10215/17275   train_loss = 2.996\n",
      "Epoch   0 Batch 10216/17275   train_loss = 6.132\n",
      "Epoch   0 Batch 10217/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 10218/17275   train_loss = 5.188\n",
      "Epoch   0 Batch 10219/17275   train_loss = 6.280\n",
      "Epoch   0 Batch 10220/17275   train_loss = 2.992\n",
      "Epoch   0 Batch 10221/17275   train_loss = 3.689\n",
      "Epoch   0 Batch 10222/17275   train_loss = 3.559\n",
      "Epoch   0 Batch 10223/17275   train_loss = 5.560\n",
      "Epoch   0 Batch 10224/17275   train_loss = 6.890\n",
      "Epoch   0 Batch 10225/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 10226/17275   train_loss = 5.776\n",
      "Epoch   0 Batch 10227/17275   train_loss = 7.237\n",
      "Epoch   0 Batch 10228/17275   train_loss = 2.203\n",
      "Epoch   0 Batch 10229/17275   train_loss = 4.123\n",
      "Epoch   0 Batch 10230/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 10231/17275   train_loss = 4.006\n",
      "Epoch   0 Batch 10232/17275   train_loss = 6.745\n",
      "Epoch   0 Batch 10233/17275   train_loss = 2.550\n",
      "Epoch   0 Batch 10234/17275   train_loss = 3.427\n",
      "Epoch   0 Batch 10235/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 10236/17275   train_loss = 4.136\n",
      "Epoch   0 Batch 10237/17275   train_loss = 2.576\n",
      "Epoch   0 Batch 10238/17275   train_loss = 3.582\n",
      "Epoch   0 Batch 10239/17275   train_loss = 3.212\n",
      "Epoch   0 Batch 10240/17275   train_loss = 6.197\n",
      "Epoch   0 Batch 10241/17275   train_loss = 6.411\n",
      "Epoch   0 Batch 10242/17275   train_loss = 4.656\n",
      "Epoch   0 Batch 10243/17275   train_loss = 3.285\n",
      "Epoch   0 Batch 10244/17275   train_loss = 4.627\n",
      "Epoch   0 Batch 10245/17275   train_loss = 2.119\n",
      "Epoch   0 Batch 10246/17275   train_loss = 4.263\n",
      "Epoch   0 Batch 10247/17275   train_loss = 3.361\n",
      "Epoch   0 Batch 10248/17275   train_loss = 2.753\n",
      "Epoch   0 Batch 10249/17275   train_loss = 7.028\n",
      "Epoch   0 Batch 10250/17275   train_loss = 10.285\n",
      "Epoch   0 Batch 10251/17275   train_loss = 6.259\n",
      "Epoch   0 Batch 10252/17275   train_loss = 5.078\n",
      "Epoch   0 Batch 10253/17275   train_loss = 8.415\n",
      "Epoch   0 Batch 10254/17275   train_loss = 6.151\n",
      "Epoch   0 Batch 10255/17275   train_loss = 2.347\n",
      "Epoch   0 Batch 10256/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 10257/17275   train_loss = 2.717\n",
      "Epoch   0 Batch 10258/17275   train_loss = 2.904\n",
      "Epoch   0 Batch 10259/17275   train_loss = 3.910\n",
      "Epoch   0 Batch 10260/17275   train_loss = 5.719\n",
      "Epoch   0 Batch 10261/17275   train_loss = 5.561\n",
      "Epoch   0 Batch 10262/17275   train_loss = 2.625\n",
      "Epoch   0 Batch 10263/17275   train_loss = 4.115\n",
      "Epoch   0 Batch 10264/17275   train_loss = 2.231\n",
      "Epoch   0 Batch 10265/17275   train_loss = 2.385\n",
      "Epoch   0 Batch 10266/17275   train_loss = 6.285\n",
      "Epoch   0 Batch 10267/17275   train_loss = 4.597\n",
      "Epoch   0 Batch 10268/17275   train_loss = 3.881\n",
      "Epoch   0 Batch 10269/17275   train_loss = 2.016\n",
      "Epoch   0 Batch 10270/17275   train_loss = 3.306\n",
      "Epoch   0 Batch 10271/17275   train_loss = 6.629\n",
      "Epoch   0 Batch 10272/17275   train_loss = 6.631\n",
      "Epoch   0 Batch 10273/17275   train_loss = 4.488\n",
      "Epoch   0 Batch 10274/17275   train_loss = 4.762\n",
      "Epoch   0 Batch 10275/17275   train_loss = 3.642\n",
      "Epoch   0 Batch 10276/17275   train_loss = 1.996\n",
      "Epoch   0 Batch 10277/17275   train_loss = 3.389\n",
      "Epoch   0 Batch 10278/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 10279/17275   train_loss = 3.374\n",
      "Epoch   0 Batch 10280/17275   train_loss = 3.704\n",
      "Epoch   0 Batch 10281/17275   train_loss = 3.679\n",
      "Epoch   0 Batch 10282/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 10283/17275   train_loss = 2.094\n",
      "Epoch   0 Batch 10284/17275   train_loss = 2.549\n",
      "Epoch   0 Batch 10285/17275   train_loss = 6.251\n",
      "Epoch   0 Batch 10286/17275   train_loss = 3.322\n",
      "Epoch   0 Batch 10287/17275   train_loss = 6.467\n",
      "Epoch   0 Batch 10288/17275   train_loss = 3.619\n",
      "Epoch   0 Batch 10289/17275   train_loss = 4.408\n",
      "Epoch   0 Batch 10290/17275   train_loss = 4.849\n",
      "Epoch   0 Batch 10291/17275   train_loss = 5.316\n",
      "Epoch   0 Batch 10292/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 10293/17275   train_loss = 4.376\n",
      "Epoch   0 Batch 10294/17275   train_loss = 3.253\n",
      "Epoch   0 Batch 10295/17275   train_loss = 4.041\n",
      "Epoch   0 Batch 10296/17275   train_loss = 6.684\n",
      "Epoch   0 Batch 10297/17275   train_loss = 2.372\n",
      "Epoch   0 Batch 10298/17275   train_loss = 4.157\n",
      "Epoch   0 Batch 10299/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 10300/17275   train_loss = 7.808\n",
      "Epoch   0 Batch 10301/17275   train_loss = 1.916\n",
      "Epoch   0 Batch 10302/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 10303/17275   train_loss = 3.611\n",
      "Epoch   0 Batch 10304/17275   train_loss = 2.512\n",
      "Epoch   0 Batch 10305/17275   train_loss = 6.421\n",
      "Epoch   0 Batch 10306/17275   train_loss = 3.917\n",
      "Epoch   0 Batch 10307/17275   train_loss = 2.260\n",
      "Epoch   0 Batch 10308/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 10309/17275   train_loss = 2.574\n",
      "Epoch   0 Batch 10310/17275   train_loss = 7.130\n",
      "Epoch   0 Batch 10311/17275   train_loss = 6.282\n",
      "Epoch   0 Batch 10312/17275   train_loss = 4.288\n",
      "Epoch   0 Batch 10313/17275   train_loss = 6.744\n",
      "Epoch   0 Batch 10314/17275   train_loss = 6.965\n",
      "Epoch   0 Batch 10315/17275   train_loss = 1.944\n",
      "Epoch   0 Batch 10316/17275   train_loss = 3.502\n",
      "Epoch   0 Batch 10317/17275   train_loss = 3.174\n",
      "Epoch   0 Batch 10318/17275   train_loss = 4.389\n",
      "Epoch   0 Batch 10319/17275   train_loss = 3.134\n",
      "Epoch   0 Batch 10320/17275   train_loss = 2.293\n",
      "Epoch   0 Batch 10321/17275   train_loss = 4.266\n",
      "Epoch   0 Batch 10322/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 10323/17275   train_loss = 2.203\n",
      "Epoch   0 Batch 10324/17275   train_loss = 6.496\n",
      "Epoch   0 Batch 10325/17275   train_loss = 6.426\n",
      "Epoch   0 Batch 10326/17275   train_loss = 6.413\n",
      "Epoch   0 Batch 10327/17275   train_loss = 3.188\n",
      "Epoch   0 Batch 10328/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 10329/17275   train_loss = 3.438\n",
      "Epoch   0 Batch 10330/17275   train_loss = 10.332\n",
      "Epoch   0 Batch 10331/17275   train_loss = 3.148\n",
      "Epoch   0 Batch 10332/17275   train_loss = 2.779\n",
      "Epoch   0 Batch 10333/17275   train_loss = 6.355\n",
      "Epoch   0 Batch 10334/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 10335/17275   train_loss = 3.705\n",
      "Epoch   0 Batch 10336/17275   train_loss = 6.210\n",
      "Epoch   0 Batch 10337/17275   train_loss = 5.924\n",
      "Epoch   0 Batch 10338/17275   train_loss = 2.186\n",
      "Epoch   0 Batch 10339/17275   train_loss = 2.509\n",
      "Epoch   0 Batch 10340/17275   train_loss = 10.328\n",
      "Epoch   0 Batch 10341/17275   train_loss = 2.984\n",
      "Epoch   0 Batch 10342/17275   train_loss = 3.132\n",
      "Epoch   0 Batch 10343/17275   train_loss = 3.714\n",
      "Epoch   0 Batch 10344/17275   train_loss = 6.300\n",
      "Epoch   0 Batch 10345/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 10346/17275   train_loss = 2.061\n",
      "Epoch   0 Batch 10347/17275   train_loss = 4.819\n",
      "Epoch   0 Batch 10348/17275   train_loss = 4.422\n",
      "Epoch   0 Batch 10349/17275   train_loss = 1.990\n",
      "Epoch   0 Batch 10350/17275   train_loss = 2.554\n",
      "Epoch   0 Batch 10351/17275   train_loss = 3.449\n",
      "Epoch   0 Batch 10352/17275   train_loss = 5.879\n",
      "Epoch   0 Batch 10353/17275   train_loss = 1.841\n",
      "Epoch   0 Batch 10354/17275   train_loss = 2.599\n",
      "Epoch   0 Batch 10355/17275   train_loss = 4.666\n",
      "Epoch   0 Batch 10356/17275   train_loss = 3.389\n",
      "Epoch   0 Batch 10357/17275   train_loss = 5.287\n",
      "Epoch   0 Batch 10358/17275   train_loss = 3.219\n",
      "Epoch   0 Batch 10359/17275   train_loss = 1.606\n",
      "Epoch   0 Batch 10360/17275   train_loss = 3.766\n",
      "Epoch   0 Batch 10361/17275   train_loss = 3.988\n",
      "Epoch   0 Batch 10362/17275   train_loss = 4.129\n",
      "Epoch   0 Batch 10363/17275   train_loss = 2.879\n",
      "Epoch   0 Batch 10364/17275   train_loss = 3.767\n",
      "Epoch   0 Batch 10365/17275   train_loss = 5.693\n",
      "Epoch   0 Batch 10366/17275   train_loss = 6.449\n",
      "Epoch   0 Batch 10367/17275   train_loss = 10.357\n",
      "Epoch   0 Batch 10368/17275   train_loss = 6.450\n",
      "Epoch   0 Batch 10369/17275   train_loss = 2.417\n",
      "Epoch   0 Batch 10370/17275   train_loss = 3.040\n",
      "Epoch   0 Batch 10371/17275   train_loss = 3.468\n",
      "Epoch   0 Batch 10372/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 10373/17275   train_loss = 8.569\n",
      "Epoch   0 Batch 10374/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 10375/17275   train_loss = 9.542\n",
      "Epoch   0 Batch 10376/17275   train_loss = 7.604\n",
      "Epoch   0 Batch 10377/17275   train_loss = 6.226\n",
      "Epoch   0 Batch 10378/17275   train_loss = 6.112\n",
      "Epoch   0 Batch 10379/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 10380/17275   train_loss = 6.832\n",
      "Epoch   0 Batch 10381/17275   train_loss = 3.201\n",
      "Epoch   0 Batch 10382/17275   train_loss = 4.010\n",
      "Epoch   0 Batch 10383/17275   train_loss = 7.010\n",
      "Epoch   0 Batch 10384/17275   train_loss = 7.038\n",
      "Epoch   0 Batch 10385/17275   train_loss = 2.554\n",
      "Epoch   0 Batch 10386/17275   train_loss = 4.486\n",
      "Epoch   0 Batch 10387/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 10388/17275   train_loss = 5.450\n",
      "Epoch   0 Batch 10389/17275   train_loss = 2.641\n",
      "Epoch   0 Batch 10390/17275   train_loss = 2.919\n",
      "Epoch   0 Batch 10391/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 10392/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 10393/17275   train_loss = 6.411\n",
      "Epoch   0 Batch 10394/17275   train_loss = 4.307\n",
      "Epoch   0 Batch 10395/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 10396/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 10397/17275   train_loss = 3.005\n",
      "Epoch   0 Batch 10398/17275   train_loss = 3.243\n",
      "Epoch   0 Batch 10399/17275   train_loss = 4.880\n",
      "Epoch   0 Batch 10400/17275   train_loss = 2.386\n",
      "Epoch   0 Batch 10401/17275   train_loss = 2.527\n",
      "Epoch   0 Batch 10402/17275   train_loss = 2.811\n",
      "Epoch   0 Batch 10403/17275   train_loss = 3.553\n",
      "Epoch   0 Batch 10404/17275   train_loss = 3.640\n",
      "Epoch   0 Batch 10405/17275   train_loss = 3.130\n",
      "Epoch   0 Batch 10406/17275   train_loss = 2.230\n",
      "Epoch   0 Batch 10407/17275   train_loss = 6.408\n",
      "Epoch   0 Batch 10408/17275   train_loss = 7.064\n",
      "Epoch   0 Batch 10409/17275   train_loss = 6.404\n",
      "Epoch   0 Batch 10410/17275   train_loss = 2.859\n",
      "Epoch   0 Batch 10411/17275   train_loss = 6.190\n",
      "Epoch   0 Batch 10412/17275   train_loss = 7.514\n",
      "Epoch   0 Batch 10413/17275   train_loss = 2.642\n",
      "Epoch   0 Batch 10414/17275   train_loss = 4.592\n",
      "Epoch   0 Batch 10415/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 10416/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 10417/17275   train_loss = 3.483\n",
      "Epoch   0 Batch 10418/17275   train_loss = 6.393\n",
      "Epoch   0 Batch 10419/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 10420/17275   train_loss = 2.143\n",
      "Epoch   0 Batch 10421/17275   train_loss = 5.747\n",
      "Epoch   0 Batch 10422/17275   train_loss = 7.308\n",
      "Epoch   0 Batch 10423/17275   train_loss = 7.272\n",
      "Epoch   0 Batch 10424/17275   train_loss = 6.366\n",
      "Epoch   0 Batch 10425/17275   train_loss = 7.812\n",
      "Epoch   0 Batch 10426/17275   train_loss = 3.286\n",
      "Epoch   0 Batch 10427/17275   train_loss = 3.879\n",
      "Epoch   0 Batch 10428/17275   train_loss = 3.187\n",
      "Epoch   0 Batch 10429/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 10430/17275   train_loss = 4.173\n",
      "Epoch   0 Batch 10431/17275   train_loss = 1.935\n",
      "Epoch   0 Batch 10432/17275   train_loss = 3.206\n",
      "Epoch   0 Batch 10433/17275   train_loss = 1.882\n",
      "Epoch   0 Batch 10434/17275   train_loss = 3.012\n",
      "Epoch   0 Batch 10435/17275   train_loss = 1.788\n",
      "Epoch   0 Batch 10436/17275   train_loss = 1.964\n",
      "Epoch   0 Batch 10437/17275   train_loss = 5.180\n",
      "Epoch   0 Batch 10438/17275   train_loss = 3.740\n",
      "Epoch   0 Batch 10439/17275   train_loss = 7.480\n",
      "Epoch   0 Batch 10440/17275   train_loss = 7.515\n",
      "Epoch   0 Batch 10441/17275   train_loss = 7.032\n",
      "Epoch   0 Batch 10442/17275   train_loss = 5.938\n",
      "Epoch   0 Batch 10443/17275   train_loss = 4.859\n",
      "Epoch   0 Batch 10444/17275   train_loss = 3.501\n",
      "Epoch   0 Batch 10445/17275   train_loss = 3.709\n",
      "Epoch   0 Batch 10446/17275   train_loss = 2.795\n",
      "Epoch   0 Batch 10447/17275   train_loss = 3.250\n",
      "Epoch   0 Batch 10448/17275   train_loss = 3.162\n",
      "Epoch   0 Batch 10449/17275   train_loss = 7.571\n",
      "Epoch   0 Batch 10450/17275   train_loss = 2.288\n",
      "Epoch   0 Batch 10451/17275   train_loss = 2.806\n",
      "Epoch   0 Batch 10452/17275   train_loss = 5.082\n",
      "Epoch   0 Batch 10453/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 10454/17275   train_loss = 4.389\n",
      "Epoch   0 Batch 10455/17275   train_loss = 5.964\n",
      "Epoch   0 Batch 10456/17275   train_loss = 2.558\n",
      "Epoch   0 Batch 10457/17275   train_loss = 2.765\n",
      "Epoch   0 Batch 10458/17275   train_loss = 6.067\n",
      "Epoch   0 Batch 10459/17275   train_loss = 2.130\n",
      "Epoch   0 Batch 10460/17275   train_loss = 6.239\n",
      "Epoch   0 Batch 10461/17275   train_loss = 6.528\n",
      "Epoch   0 Batch 10462/17275   train_loss = 2.764\n",
      "Epoch   0 Batch 10463/17275   train_loss = 5.335\n",
      "Epoch   0 Batch 10464/17275   train_loss = 4.324\n",
      "Epoch   0 Batch 10465/17275   train_loss = 6.782\n",
      "Epoch   0 Batch 10466/17275   train_loss = 2.562\n",
      "Epoch   0 Batch 10467/17275   train_loss = 3.462\n",
      "Epoch   0 Batch 10468/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 10469/17275   train_loss = 4.040\n",
      "Epoch   0 Batch 10470/17275   train_loss = 2.447\n",
      "Epoch   0 Batch 10471/17275   train_loss = 1.838\n",
      "Epoch   0 Batch 10472/17275   train_loss = 2.340\n",
      "Epoch   0 Batch 10473/17275   train_loss = 3.444\n",
      "Epoch   0 Batch 10474/17275   train_loss = 7.129\n",
      "Epoch   0 Batch 10475/17275   train_loss = 6.342\n",
      "Epoch   0 Batch 10476/17275   train_loss = 3.998\n",
      "Epoch   0 Batch 10477/17275   train_loss = 2.047\n",
      "Epoch   0 Batch 10478/17275   train_loss = 5.382\n",
      "Epoch   0 Batch 10479/17275   train_loss = 2.083\n",
      "Epoch   0 Batch 10480/17275   train_loss = 6.508\n",
      "Epoch   0 Batch 10481/17275   train_loss = 3.134\n",
      "Epoch   0 Batch 10482/17275   train_loss = 7.086\n",
      "Epoch   0 Batch 10483/17275   train_loss = 8.544\n",
      "Epoch   0 Batch 10484/17275   train_loss = 5.829\n",
      "Epoch   0 Batch 10485/17275   train_loss = 10.355\n",
      "Epoch   0 Batch 10486/17275   train_loss = 6.811\n",
      "Epoch   0 Batch 10487/17275   train_loss = 3.431\n",
      "Epoch   0 Batch 10488/17275   train_loss = 6.081\n",
      "Epoch   0 Batch 10489/17275   train_loss = 2.510\n",
      "Epoch   0 Batch 10490/17275   train_loss = 6.282\n",
      "Epoch   0 Batch 10491/17275   train_loss = 5.906\n",
      "Epoch   0 Batch 10492/17275   train_loss = 6.081\n",
      "Epoch   0 Batch 10493/17275   train_loss = 10.335\n",
      "Epoch   0 Batch 10494/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 10495/17275   train_loss = 6.028\n",
      "Epoch   0 Batch 10496/17275   train_loss = 5.804\n",
      "Epoch   0 Batch 10497/17275   train_loss = 3.123\n",
      "Epoch   0 Batch 10498/17275   train_loss = 5.195\n",
      "Epoch   0 Batch 10499/17275   train_loss = 2.007\n",
      "Epoch   0 Batch 10500/17275   train_loss = 6.252\n",
      "Epoch   0 Batch 10501/17275   train_loss = 3.192\n",
      "Epoch   0 Batch 10502/17275   train_loss = 4.527\n",
      "Epoch   0 Batch 10503/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 10504/17275   train_loss = 3.498\n",
      "Epoch   0 Batch 10505/17275   train_loss = 6.195\n",
      "Epoch   0 Batch 10506/17275   train_loss = 3.097\n",
      "Epoch   0 Batch 10507/17275   train_loss = 4.720\n",
      "Epoch   0 Batch 10508/17275   train_loss = 3.407\n",
      "Epoch   0 Batch 10509/17275   train_loss = 3.546\n",
      "Epoch   0 Batch 10510/17275   train_loss = 3.875\n",
      "Epoch   0 Batch 10511/17275   train_loss = 4.513\n",
      "Epoch   0 Batch 10512/17275   train_loss = 2.613\n",
      "Epoch   0 Batch 10513/17275   train_loss = 3.265\n",
      "Epoch   0 Batch 10514/17275   train_loss = 3.641\n",
      "Epoch   0 Batch 10515/17275   train_loss = 2.038\n",
      "Epoch   0 Batch 10516/17275   train_loss = 3.597\n",
      "Epoch   0 Batch 10517/17275   train_loss = 4.729\n",
      "Epoch   0 Batch 10518/17275   train_loss = 5.931\n",
      "Epoch   0 Batch 10519/17275   train_loss = 6.550\n",
      "Epoch   0 Batch 10520/17275   train_loss = 3.351\n",
      "Epoch   0 Batch 10521/17275   train_loss = 2.053\n",
      "Epoch   0 Batch 10522/17275   train_loss = 7.459\n",
      "Epoch   0 Batch 10523/17275   train_loss = 3.902\n",
      "Epoch   0 Batch 10524/17275   train_loss = 2.786\n",
      "Epoch   0 Batch 10525/17275   train_loss = 5.528\n",
      "Epoch   0 Batch 10526/17275   train_loss = 2.836\n",
      "Epoch   0 Batch 10527/17275   train_loss = 5.008\n",
      "Epoch   0 Batch 10528/17275   train_loss = 4.020\n",
      "Epoch   0 Batch 10529/17275   train_loss = 10.310\n",
      "Epoch   0 Batch 10530/17275   train_loss = 2.023\n",
      "Epoch   0 Batch 10531/17275   train_loss = 6.589\n",
      "Epoch   0 Batch 10532/17275   train_loss = 3.166\n",
      "Epoch   0 Batch 10533/17275   train_loss = 8.443\n",
      "Epoch   0 Batch 10534/17275   train_loss = 3.751\n",
      "Epoch   0 Batch 10535/17275   train_loss = 2.853\n",
      "Epoch   0 Batch 10536/17275   train_loss = 2.744\n",
      "Epoch   0 Batch 10537/17275   train_loss = 3.703\n",
      "Epoch   0 Batch 10538/17275   train_loss = 5.270\n",
      "Epoch   0 Batch 10539/17275   train_loss = 2.590\n",
      "Epoch   0 Batch 10540/17275   train_loss = 3.546\n",
      "Epoch   0 Batch 10541/17275   train_loss = 5.111\n",
      "Epoch   0 Batch 10542/17275   train_loss = 4.097\n",
      "Epoch   0 Batch 10543/17275   train_loss = 2.467\n",
      "Epoch   0 Batch 10544/17275   train_loss = 6.327\n",
      "Epoch   0 Batch 10545/17275   train_loss = 3.079\n",
      "Epoch   0 Batch 10546/17275   train_loss = 4.206\n",
      "Epoch   0 Batch 10547/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 10548/17275   train_loss = 2.953\n",
      "Epoch   0 Batch 10549/17275   train_loss = 6.231\n",
      "Epoch   0 Batch 10550/17275   train_loss = 4.581\n",
      "Epoch   0 Batch 10551/17275   train_loss = 3.263\n",
      "Epoch   0 Batch 10552/17275   train_loss = 4.027\n",
      "Epoch   0 Batch 10553/17275   train_loss = 6.130\n",
      "Epoch   0 Batch 10554/17275   train_loss = 3.628\n",
      "Epoch   0 Batch 10555/17275   train_loss = 3.991\n",
      "Epoch   0 Batch 10556/17275   train_loss = 4.165\n",
      "Epoch   0 Batch 10557/17275   train_loss = 2.362\n",
      "Epoch   0 Batch 10558/17275   train_loss = 5.961\n",
      "Epoch   0 Batch 10559/17275   train_loss = 2.503\n",
      "Epoch   0 Batch 10560/17275   train_loss = 3.046\n",
      "Epoch   0 Batch 10561/17275   train_loss = 2.668\n",
      "Epoch   0 Batch 10562/17275   train_loss = 5.436\n",
      "Epoch   0 Batch 10563/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 10564/17275   train_loss = 2.262\n",
      "Epoch   0 Batch 10565/17275   train_loss = 3.636\n",
      "Epoch   0 Batch 10566/17275   train_loss = 4.308\n",
      "Epoch   0 Batch 10567/17275   train_loss = 6.756\n",
      "Epoch   0 Batch 10568/17275   train_loss = 6.185\n",
      "Epoch   0 Batch 10569/17275   train_loss = 2.293\n",
      "Epoch   0 Batch 10570/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 10571/17275   train_loss = 2.255\n",
      "Epoch   0 Batch 10572/17275   train_loss = 3.179\n",
      "Epoch   0 Batch 10573/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 10574/17275   train_loss = 3.257\n",
      "Epoch   0 Batch 10575/17275   train_loss = 2.903\n",
      "Epoch   0 Batch 10576/17275   train_loss = 4.478\n",
      "Epoch   0 Batch 10577/17275   train_loss = 3.506\n",
      "Epoch   0 Batch 10578/17275   train_loss = 6.780\n",
      "Epoch   0 Batch 10579/17275   train_loss = 2.831\n",
      "Epoch   0 Batch 10580/17275   train_loss = 3.034\n",
      "Epoch   0 Batch 10581/17275   train_loss = 2.151\n",
      "Epoch   0 Batch 10582/17275   train_loss = 2.964\n",
      "Epoch   0 Batch 10583/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 10584/17275   train_loss = 3.081\n",
      "Epoch   0 Batch 10585/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 10586/17275   train_loss = 3.851\n",
      "Epoch   0 Batch 10587/17275   train_loss = 7.081\n",
      "Epoch   0 Batch 10588/17275   train_loss = 6.468\n",
      "Epoch   0 Batch 10589/17275   train_loss = 5.297\n",
      "Epoch   0 Batch 10590/17275   train_loss = 4.337\n",
      "Epoch   0 Batch 10591/17275   train_loss = 4.451\n",
      "Epoch   0 Batch 10592/17275   train_loss = 4.818\n",
      "Epoch   0 Batch 10593/17275   train_loss = 10.360\n",
      "Epoch   0 Batch 10594/17275   train_loss = 6.447\n",
      "Epoch   0 Batch 10595/17275   train_loss = 3.498\n",
      "Epoch   0 Batch 10596/17275   train_loss = 2.531\n",
      "Epoch   0 Batch 10597/17275   train_loss = 3.470\n",
      "Epoch   0 Batch 10598/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 10599/17275   train_loss = 3.032\n",
      "Epoch   0 Batch 10600/17275   train_loss = 3.659\n",
      "Epoch   0 Batch 10601/17275   train_loss = 4.465\n",
      "Epoch   0 Batch 10602/17275   train_loss = 6.404\n",
      "Epoch   0 Batch 10603/17275   train_loss = 4.630\n",
      "Epoch   0 Batch 10604/17275   train_loss = 3.221\n",
      "Epoch   0 Batch 10605/17275   train_loss = 3.696\n",
      "Epoch   0 Batch 10606/17275   train_loss = 5.284\n",
      "Epoch   0 Batch 10607/17275   train_loss = 5.735\n",
      "Epoch   0 Batch 10608/17275   train_loss = 5.673\n",
      "Epoch   0 Batch 10609/17275   train_loss = 5.960\n",
      "Epoch   0 Batch 10610/17275   train_loss = 2.170\n",
      "Epoch   0 Batch 10611/17275   train_loss = 2.435\n",
      "Epoch   0 Batch 10612/17275   train_loss = 2.550\n",
      "Epoch   0 Batch 10613/17275   train_loss = 3.839\n",
      "Epoch   0 Batch 10614/17275   train_loss = 2.930\n",
      "Epoch   0 Batch 10615/17275   train_loss = 3.854\n",
      "Epoch   0 Batch 10616/17275   train_loss = 7.066\n",
      "Epoch   0 Batch 10617/17275   train_loss = 2.246\n",
      "Epoch   0 Batch 10618/17275   train_loss = 2.049\n",
      "Epoch   0 Batch 10619/17275   train_loss = 8.501\n",
      "Epoch   0 Batch 10620/17275   train_loss = 5.177\n",
      "Epoch   0 Batch 10621/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 10622/17275   train_loss = 2.152\n",
      "Epoch   0 Batch 10623/17275   train_loss = 4.786\n",
      "Epoch   0 Batch 10624/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 10625/17275   train_loss = 4.322\n",
      "Epoch   0 Batch 10626/17275   train_loss = 6.189\n",
      "Epoch   0 Batch 10627/17275   train_loss = 4.265\n",
      "Epoch   0 Batch 10628/17275   train_loss = 4.778\n",
      "Epoch   0 Batch 10629/17275   train_loss = 3.364\n",
      "Epoch   0 Batch 10630/17275   train_loss = 4.337\n",
      "Epoch   0 Batch 10631/17275   train_loss = 4.588\n",
      "Epoch   0 Batch 10632/17275   train_loss = 2.995\n",
      "Epoch   0 Batch 10633/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 10634/17275   train_loss = 5.982\n",
      "Epoch   0 Batch 10635/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 10636/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 10637/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 10638/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 10639/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 10640/17275   train_loss = 6.234\n",
      "Epoch   0 Batch 10641/17275   train_loss = 4.276\n",
      "Epoch   0 Batch 10642/17275   train_loss = 1.926\n",
      "Epoch   0 Batch 10643/17275   train_loss = 2.213\n",
      "Epoch   0 Batch 10644/17275   train_loss = 2.428\n",
      "Epoch   0 Batch 10645/17275   train_loss = 3.575\n",
      "Epoch   0 Batch 10646/17275   train_loss = 3.395\n",
      "Epoch   0 Batch 10647/17275   train_loss = 3.129\n",
      "Epoch   0 Batch 10648/17275   train_loss = 3.835\n",
      "Epoch   0 Batch 10649/17275   train_loss = 6.741\n",
      "Epoch   0 Batch 10650/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 10651/17275   train_loss = 5.248\n",
      "Epoch   0 Batch 10652/17275   train_loss = 3.752\n",
      "Epoch   0 Batch 10653/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 10654/17275   train_loss = 2.531\n",
      "Epoch   0 Batch 10655/17275   train_loss = 6.357\n",
      "Epoch   0 Batch 10656/17275   train_loss = 5.472\n",
      "Epoch   0 Batch 10657/17275   train_loss = 3.521\n",
      "Epoch   0 Batch 10658/17275   train_loss = 4.404\n",
      "Epoch   0 Batch 10659/17275   train_loss = 6.662\n",
      "Epoch   0 Batch 10660/17275   train_loss = 7.394\n",
      "Epoch   0 Batch 10661/17275   train_loss = 3.193\n",
      "Epoch   0 Batch 10662/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 10663/17275   train_loss = 9.495\n",
      "Epoch   0 Batch 10664/17275   train_loss = 2.124\n",
      "Epoch   0 Batch 10665/17275   train_loss = 3.183\n",
      "Epoch   0 Batch 10666/17275   train_loss = 4.198\n",
      "Epoch   0 Batch 10667/17275   train_loss = 4.807\n",
      "Epoch   0 Batch 10668/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 10669/17275   train_loss = 7.060\n",
      "Epoch   0 Batch 10670/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 10671/17275   train_loss = 3.636\n",
      "Epoch   0 Batch 10672/17275   train_loss = 2.391\n",
      "Epoch   0 Batch 10673/17275   train_loss = 6.260\n",
      "Epoch   0 Batch 10674/17275   train_loss = 3.934\n",
      "Epoch   0 Batch 10675/17275   train_loss = 2.765\n",
      "Epoch   0 Batch 10676/17275   train_loss = 6.255\n",
      "Epoch   0 Batch 10677/17275   train_loss = 2.438\n",
      "Epoch   0 Batch 10678/17275   train_loss = 3.335\n",
      "Epoch   0 Batch 10679/17275   train_loss = 3.739\n",
      "Epoch   0 Batch 10680/17275   train_loss = 3.261\n",
      "Epoch   0 Batch 10681/17275   train_loss = 3.703\n",
      "Epoch   0 Batch 10682/17275   train_loss = 7.764\n",
      "Epoch   0 Batch 10683/17275   train_loss = 6.175\n",
      "Epoch   0 Batch 10684/17275   train_loss = 5.255\n",
      "Epoch   0 Batch 10685/17275   train_loss = 3.741\n",
      "Epoch   0 Batch 10686/17275   train_loss = 3.334\n",
      "Epoch   0 Batch 10687/17275   train_loss = 3.556\n",
      "Epoch   0 Batch 10688/17275   train_loss = 3.362\n",
      "Epoch   0 Batch 10689/17275   train_loss = 3.771\n",
      "Epoch   0 Batch 10690/17275   train_loss = 6.985\n",
      "Epoch   0 Batch 10691/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 10692/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 10693/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 10694/17275   train_loss = 8.096\n",
      "Epoch   0 Batch 10695/17275   train_loss = 4.262\n",
      "Epoch   0 Batch 10696/17275   train_loss = 2.026\n",
      "Epoch   0 Batch 10697/17275   train_loss = 3.889\n",
      "Epoch   0 Batch 10698/17275   train_loss = 3.403\n",
      "Epoch   0 Batch 10699/17275   train_loss = 4.276\n",
      "Epoch   0 Batch 10700/17275   train_loss = 2.344\n",
      "Epoch   0 Batch 10701/17275   train_loss = 2.154\n",
      "Epoch   0 Batch 10702/17275   train_loss = 6.249\n",
      "Epoch   0 Batch 10703/17275   train_loss = 6.930\n",
      "Epoch   0 Batch 10704/17275   train_loss = 6.496\n",
      "Epoch   0 Batch 10705/17275   train_loss = 7.024\n",
      "Epoch   0 Batch 10706/17275   train_loss = 4.158\n",
      "Epoch   0 Batch 10707/17275   train_loss = 2.649\n",
      "Epoch   0 Batch 10708/17275   train_loss = 6.814\n",
      "Epoch   0 Batch 10709/17275   train_loss = 6.612\n",
      "Epoch   0 Batch 10710/17275   train_loss = 2.005\n",
      "Epoch   0 Batch 10711/17275   train_loss = 5.870\n",
      "Epoch   0 Batch 10712/17275   train_loss = 3.599\n",
      "Epoch   0 Batch 10713/17275   train_loss = 3.283\n",
      "Epoch   0 Batch 10714/17275   train_loss = 2.308\n",
      "Epoch   0 Batch 10715/17275   train_loss = 6.541\n",
      "Epoch   0 Batch 10716/17275   train_loss = 6.539\n",
      "Epoch   0 Batch 10717/17275   train_loss = 2.969\n",
      "Epoch   0 Batch 10718/17275   train_loss = 2.369\n",
      "Epoch   0 Batch 10719/17275   train_loss = 4.014\n",
      "Epoch   0 Batch 10720/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 10721/17275   train_loss = 3.295\n",
      "Epoch   0 Batch 10722/17275   train_loss = 3.553\n",
      "Epoch   0 Batch 10723/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 10724/17275   train_loss = 7.258\n",
      "Epoch   0 Batch 10725/17275   train_loss = 2.757\n",
      "Epoch   0 Batch 10726/17275   train_loss = 3.225\n",
      "Epoch   0 Batch 10727/17275   train_loss = 4.320\n",
      "Epoch   0 Batch 10728/17275   train_loss = 3.428\n",
      "Epoch   0 Batch 10729/17275   train_loss = 2.978\n",
      "Epoch   0 Batch 10730/17275   train_loss = 2.824\n",
      "Epoch   0 Batch 10731/17275   train_loss = 4.649\n",
      "Epoch   0 Batch 10732/17275   train_loss = 6.989\n",
      "Epoch   0 Batch 10733/17275   train_loss = 5.705\n",
      "Epoch   0 Batch 10734/17275   train_loss = 3.814\n",
      "Epoch   0 Batch 10735/17275   train_loss = 10.399\n",
      "Epoch   0 Batch 10736/17275   train_loss = 1.985\n",
      "Epoch   0 Batch 10737/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 10738/17275   train_loss = 5.154\n",
      "Epoch   0 Batch 10739/17275   train_loss = 2.995\n",
      "Epoch   0 Batch 10740/17275   train_loss = 2.964\n",
      "Epoch   0 Batch 10741/17275   train_loss = 4.293\n",
      "Epoch   0 Batch 10742/17275   train_loss = 2.778\n",
      "Epoch   0 Batch 10743/17275   train_loss = 3.778\n",
      "Epoch   0 Batch 10744/17275   train_loss = 2.908\n",
      "Epoch   0 Batch 10745/17275   train_loss = 3.873\n",
      "Epoch   0 Batch 10746/17275   train_loss = 7.037\n",
      "Epoch   0 Batch 10747/17275   train_loss = 6.720\n",
      "Epoch   0 Batch 10748/17275   train_loss = 6.676\n",
      "Epoch   0 Batch 10749/17275   train_loss = 6.833\n",
      "Epoch   0 Batch 10750/17275   train_loss = 6.203\n",
      "Epoch   0 Batch 10751/17275   train_loss = 2.734\n",
      "Epoch   0 Batch 10752/17275   train_loss = 4.371\n",
      "Epoch   0 Batch 10753/17275   train_loss = 3.239\n",
      "Epoch   0 Batch 10754/17275   train_loss = 2.050\n",
      "Epoch   0 Batch 10755/17275   train_loss = 2.956\n",
      "Epoch   0 Batch 10756/17275   train_loss = 6.684\n",
      "Epoch   0 Batch 10757/17275   train_loss = 8.182\n",
      "Epoch   0 Batch 10758/17275   train_loss = 2.381\n",
      "Epoch   0 Batch 10759/17275   train_loss = 4.759\n",
      "Epoch   0 Batch 10760/17275   train_loss = 3.663\n",
      "Epoch   0 Batch 10761/17275   train_loss = 7.734\n",
      "Epoch   0 Batch 10762/17275   train_loss = 2.045\n",
      "Epoch   0 Batch 10763/17275   train_loss = 2.662\n",
      "Epoch   0 Batch 10764/17275   train_loss = 4.525\n",
      "Epoch   0 Batch 10765/17275   train_loss = 3.063\n",
      "Epoch   0 Batch 10766/17275   train_loss = 7.010\n",
      "Epoch   0 Batch 10767/17275   train_loss = 2.410\n",
      "Epoch   0 Batch 10768/17275   train_loss = 4.447\n",
      "Epoch   0 Batch 10769/17275   train_loss = 6.388\n",
      "Epoch   0 Batch 10770/17275   train_loss = 3.604\n",
      "Epoch   0 Batch 10771/17275   train_loss = 6.551\n",
      "Epoch   0 Batch 10772/17275   train_loss = 2.247\n",
      "Epoch   0 Batch 10773/17275   train_loss = 5.518\n",
      "Epoch   0 Batch 10774/17275   train_loss = 5.519\n",
      "Epoch   0 Batch 10775/17275   train_loss = 2.600\n",
      "Epoch   0 Batch 10776/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 10777/17275   train_loss = 3.103\n",
      "Epoch   0 Batch 10778/17275   train_loss = 2.370\n",
      "Epoch   0 Batch 10779/17275   train_loss = 5.562\n",
      "Epoch   0 Batch 10780/17275   train_loss = 3.418\n",
      "Epoch   0 Batch 10781/17275   train_loss = 3.210\n",
      "Epoch   0 Batch 10782/17275   train_loss = 2.781\n",
      "Epoch   0 Batch 10783/17275   train_loss = 3.682\n",
      "Epoch   0 Batch 10784/17275   train_loss = 2.551\n",
      "Epoch   0 Batch 10785/17275   train_loss = 6.299\n",
      "Epoch   0 Batch 10786/17275   train_loss = 3.476\n",
      "Epoch   0 Batch 10787/17275   train_loss = 2.958\n",
      "Epoch   0 Batch 10788/17275   train_loss = 3.385\n",
      "Epoch   0 Batch 10789/17275   train_loss = 4.027\n",
      "Epoch   0 Batch 10790/17275   train_loss = 2.040\n",
      "Epoch   0 Batch 10791/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 10792/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 10793/17275   train_loss = 2.487\n",
      "Epoch   0 Batch 10794/17275   train_loss = 6.227\n",
      "Epoch   0 Batch 10795/17275   train_loss = 4.189\n",
      "Epoch   0 Batch 10796/17275   train_loss = 6.197\n",
      "Epoch   0 Batch 10797/17275   train_loss = 2.956\n",
      "Epoch   0 Batch 10798/17275   train_loss = 2.484\n",
      "Epoch   0 Batch 10799/17275   train_loss = 6.376\n",
      "Epoch   0 Batch 10800/17275   train_loss = 3.951\n",
      "Epoch   0 Batch 10801/17275   train_loss = 4.428\n",
      "Epoch   0 Batch 10802/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 10803/17275   train_loss = 6.978\n",
      "Epoch   0 Batch 10804/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 10805/17275   train_loss = 4.194\n",
      "Epoch   0 Batch 10806/17275   train_loss = 2.460\n",
      "Epoch   0 Batch 10807/17275   train_loss = 6.516\n",
      "Epoch   0 Batch 10808/17275   train_loss = 3.306\n",
      "Epoch   0 Batch 10809/17275   train_loss = 7.850\n",
      "Epoch   0 Batch 10810/17275   train_loss = 2.240\n",
      "Epoch   0 Batch 10811/17275   train_loss = 2.613\n",
      "Epoch   0 Batch 10812/17275   train_loss = 4.528\n",
      "Epoch   0 Batch 10813/17275   train_loss = 6.255\n",
      "Epoch   0 Batch 10814/17275   train_loss = 6.164\n",
      "Epoch   0 Batch 10815/17275   train_loss = 6.037\n",
      "Epoch   0 Batch 10816/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 10817/17275   train_loss = 3.711\n",
      "Epoch   0 Batch 10818/17275   train_loss = 3.827\n",
      "Epoch   0 Batch 10819/17275   train_loss = 4.137\n",
      "Epoch   0 Batch 10820/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 10821/17275   train_loss = 4.361\n",
      "Epoch   0 Batch 10822/17275   train_loss = 2.903\n",
      "Epoch   0 Batch 10823/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 10824/17275   train_loss = 3.258\n",
      "Epoch   0 Batch 10825/17275   train_loss = 7.036\n",
      "Epoch   0 Batch 10826/17275   train_loss = 2.482\n",
      "Epoch   0 Batch 10827/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 10828/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 10829/17275   train_loss = 3.978\n",
      "Epoch   0 Batch 10830/17275   train_loss = 4.541\n",
      "Epoch   0 Batch 10831/17275   train_loss = 3.714\n",
      "Epoch   0 Batch 10832/17275   train_loss = 6.928\n",
      "Epoch   0 Batch 10833/17275   train_loss = 3.200\n",
      "Epoch   0 Batch 10834/17275   train_loss = 3.570\n",
      "Epoch   0 Batch 10835/17275   train_loss = 3.860\n",
      "Epoch   0 Batch 10836/17275   train_loss = 2.176\n",
      "Epoch   0 Batch 10837/17275   train_loss = 1.924\n",
      "Epoch   0 Batch 10838/17275   train_loss = 3.228\n",
      "Epoch   0 Batch 10839/17275   train_loss = 5.183\n",
      "Epoch   0 Batch 10840/17275   train_loss = 6.296\n",
      "Epoch   0 Batch 10841/17275   train_loss = 2.386\n",
      "Epoch   0 Batch 10842/17275   train_loss = 5.549\n",
      "Epoch   0 Batch 10843/17275   train_loss = 4.356\n",
      "Epoch   0 Batch 10844/17275   train_loss = 4.091\n",
      "Epoch   0 Batch 10845/17275   train_loss = 2.138\n",
      "Epoch   0 Batch 10846/17275   train_loss = 7.219\n",
      "Epoch   0 Batch 10847/17275   train_loss = 5.092\n",
      "Epoch   0 Batch 10848/17275   train_loss = 4.910\n",
      "Epoch   0 Batch 10849/17275   train_loss = 4.223\n",
      "Epoch   0 Batch 10850/17275   train_loss = 6.087\n",
      "Epoch   0 Batch 10851/17275   train_loss = 2.655\n",
      "Epoch   0 Batch 10852/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 10853/17275   train_loss = 1.893\n",
      "Epoch   0 Batch 10854/17275   train_loss = 2.597\n",
      "Epoch   0 Batch 10855/17275   train_loss = 10.441\n",
      "Epoch   0 Batch 10856/17275   train_loss = 6.455\n",
      "Epoch   0 Batch 10857/17275   train_loss = 3.448\n",
      "Epoch   0 Batch 10858/17275   train_loss = 3.264\n",
      "Epoch   0 Batch 10859/17275   train_loss = 2.056\n",
      "Epoch   0 Batch 10860/17275   train_loss = 7.924\n",
      "Epoch   0 Batch 10861/17275   train_loss = 4.531\n",
      "Epoch   0 Batch 10862/17275   train_loss = 3.968\n",
      "Epoch   0 Batch 10863/17275   train_loss = 7.579\n",
      "Epoch   0 Batch 10864/17275   train_loss = 6.201\n",
      "Epoch   0 Batch 10865/17275   train_loss = 6.078\n",
      "Epoch   0 Batch 10866/17275   train_loss = 6.977\n",
      "Epoch   0 Batch 10867/17275   train_loss = 3.372\n",
      "Epoch   0 Batch 10868/17275   train_loss = 6.610\n",
      "Epoch   0 Batch 10869/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 10870/17275   train_loss = 4.628\n",
      "Epoch   0 Batch 10871/17275   train_loss = 6.182\n",
      "Epoch   0 Batch 10872/17275   train_loss = 2.167\n",
      "Epoch   0 Batch 10873/17275   train_loss = 4.299\n",
      "Epoch   0 Batch 10874/17275   train_loss = 7.058\n",
      "Epoch   0 Batch 10875/17275   train_loss = 4.096\n",
      "Epoch   0 Batch 10876/17275   train_loss = 7.391\n",
      "Epoch   0 Batch 10877/17275   train_loss = 3.792\n",
      "Epoch   0 Batch 10878/17275   train_loss = 5.200\n",
      "Epoch   0 Batch 10879/17275   train_loss = 1.891\n",
      "Epoch   0 Batch 10880/17275   train_loss = 5.687\n",
      "Epoch   0 Batch 10881/17275   train_loss = 6.926\n",
      "Epoch   0 Batch 10882/17275   train_loss = 6.456\n",
      "Epoch   0 Batch 10883/17275   train_loss = 3.752\n",
      "Epoch   0 Batch 10884/17275   train_loss = 4.629\n",
      "Epoch   0 Batch 10885/17275   train_loss = 1.911\n",
      "Epoch   0 Batch 10886/17275   train_loss = 3.159\n",
      "Epoch   0 Batch 10887/17275   train_loss = 9.240\n",
      "Epoch   0 Batch 10888/17275   train_loss = 2.981\n",
      "Epoch   0 Batch 10889/17275   train_loss = 3.258\n",
      "Epoch   0 Batch 10890/17275   train_loss = 1.916\n",
      "Epoch   0 Batch 10891/17275   train_loss = 3.097\n",
      "Epoch   0 Batch 10892/17275   train_loss = 7.868\n",
      "Epoch   0 Batch 10893/17275   train_loss = 3.627\n",
      "Epoch   0 Batch 10894/17275   train_loss = 3.873\n",
      "Epoch   0 Batch 10895/17275   train_loss = 4.137\n",
      "Epoch   0 Batch 10896/17275   train_loss = 3.305\n",
      "Epoch   0 Batch 10897/17275   train_loss = 3.270\n",
      "Epoch   0 Batch 10898/17275   train_loss = 3.823\n",
      "Epoch   0 Batch 10899/17275   train_loss = 3.846\n",
      "Epoch   0 Batch 10900/17275   train_loss = 6.381\n",
      "Epoch   0 Batch 10901/17275   train_loss = 3.173\n",
      "Epoch   0 Batch 10902/17275   train_loss = 2.712\n",
      "Epoch   0 Batch 10903/17275   train_loss = 4.550\n",
      "Epoch   0 Batch 10904/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 10905/17275   train_loss = 4.229\n",
      "Epoch   0 Batch 10906/17275   train_loss = 3.969\n",
      "Epoch   0 Batch 10907/17275   train_loss = 3.147\n",
      "Epoch   0 Batch 10908/17275   train_loss = 7.570\n",
      "Epoch   0 Batch 10909/17275   train_loss = 4.398\n",
      "Epoch   0 Batch 10910/17275   train_loss = 1.951\n",
      "Epoch   0 Batch 10911/17275   train_loss = 2.954\n",
      "Epoch   0 Batch 10912/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 10913/17275   train_loss = 3.138\n",
      "Epoch   0 Batch 10914/17275   train_loss = 3.467\n",
      "Epoch   0 Batch 10915/17275   train_loss = 3.151\n",
      "Epoch   0 Batch 10916/17275   train_loss = 4.427\n",
      "Epoch   0 Batch 10917/17275   train_loss = 3.274\n",
      "Epoch   0 Batch 10918/17275   train_loss = 2.355\n",
      "Epoch   0 Batch 10919/17275   train_loss = 3.149\n",
      "Epoch   0 Batch 10920/17275   train_loss = 3.945\n",
      "Epoch   0 Batch 10921/17275   train_loss = 2.903\n",
      "Epoch   0 Batch 10922/17275   train_loss = 5.574\n",
      "Epoch   0 Batch 10923/17275   train_loss = 3.375\n",
      "Epoch   0 Batch 10924/17275   train_loss = 4.406\n",
      "Epoch   0 Batch 10925/17275   train_loss = 3.837\n",
      "Epoch   0 Batch 10926/17275   train_loss = 7.040\n",
      "Epoch   0 Batch 10927/17275   train_loss = 3.141\n",
      "Epoch   0 Batch 10928/17275   train_loss = 3.573\n",
      "Epoch   0 Batch 10929/17275   train_loss = 4.598\n",
      "Epoch   0 Batch 10930/17275   train_loss = 4.160\n",
      "Epoch   0 Batch 10931/17275   train_loss = 3.434\n",
      "Epoch   0 Batch 10932/17275   train_loss = 4.863\n",
      "Epoch   0 Batch 10933/17275   train_loss = 4.339\n",
      "Epoch   0 Batch 10934/17275   train_loss = 4.490\n",
      "Epoch   0 Batch 10935/17275   train_loss = 2.706\n",
      "Epoch   0 Batch 10936/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 10937/17275   train_loss = 2.959\n",
      "Epoch   0 Batch 10938/17275   train_loss = 3.261\n",
      "Epoch   0 Batch 10939/17275   train_loss = 3.006\n",
      "Epoch   0 Batch 10940/17275   train_loss = 3.094\n",
      "Epoch   0 Batch 10941/17275   train_loss = 2.455\n",
      "Epoch   0 Batch 10942/17275   train_loss = 2.685\n",
      "Epoch   0 Batch 10943/17275   train_loss = 2.578\n",
      "Epoch   0 Batch 10944/17275   train_loss = 5.120\n",
      "Epoch   0 Batch 10945/17275   train_loss = 7.663\n",
      "Epoch   0 Batch 10946/17275   train_loss = 3.024\n",
      "Epoch   0 Batch 10947/17275   train_loss = 2.172\n",
      "Epoch   0 Batch 10948/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 10949/17275   train_loss = 8.626\n",
      "Epoch   0 Batch 10950/17275   train_loss = 3.465\n",
      "Epoch   0 Batch 10951/17275   train_loss = 4.116\n",
      "Epoch   0 Batch 10952/17275   train_loss = 3.825\n",
      "Epoch   0 Batch 10953/17275   train_loss = 3.391\n",
      "Epoch   0 Batch 10954/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 10955/17275   train_loss = 3.545\n",
      "Epoch   0 Batch 10956/17275   train_loss = 3.324\n",
      "Epoch   0 Batch 10957/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 10958/17275   train_loss = 5.066\n",
      "Epoch   0 Batch 10959/17275   train_loss = 6.817\n",
      "Epoch   0 Batch 10960/17275   train_loss = 2.164\n",
      "Epoch   0 Batch 10961/17275   train_loss = 6.657\n",
      "Epoch   0 Batch 10962/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 10963/17275   train_loss = 2.725\n",
      "Epoch   0 Batch 10964/17275   train_loss = 3.555\n",
      "Epoch   0 Batch 10965/17275   train_loss = 3.538\n",
      "Epoch   0 Batch 10966/17275   train_loss = 5.259\n",
      "Epoch   0 Batch 10967/17275   train_loss = 2.496\n",
      "Epoch   0 Batch 10968/17275   train_loss = 4.347\n",
      "Epoch   0 Batch 10969/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 10970/17275   train_loss = 7.172\n",
      "Epoch   0 Batch 10971/17275   train_loss = 2.134\n",
      "Epoch   0 Batch 10972/17275   train_loss = 2.021\n",
      "Epoch   0 Batch 10973/17275   train_loss = 3.217\n",
      "Epoch   0 Batch 10974/17275   train_loss = 4.844\n",
      "Epoch   0 Batch 10975/17275   train_loss = 4.182\n",
      "Epoch   0 Batch 10976/17275   train_loss = 3.691\n",
      "Epoch   0 Batch 10977/17275   train_loss = 2.555\n",
      "Epoch   0 Batch 10978/17275   train_loss = 6.496\n",
      "Epoch   0 Batch 10979/17275   train_loss = 2.900\n",
      "Epoch   0 Batch 10980/17275   train_loss = 4.589\n",
      "Epoch   0 Batch 10981/17275   train_loss = 2.030\n",
      "Epoch   0 Batch 10982/17275   train_loss = 1.793\n",
      "Epoch   0 Batch 10983/17275   train_loss = 3.268\n",
      "Epoch   0 Batch 10984/17275   train_loss = 2.848\n",
      "Epoch   0 Batch 10985/17275   train_loss = 7.160\n",
      "Epoch   0 Batch 10986/17275   train_loss = 2.892\n",
      "Epoch   0 Batch 10987/17275   train_loss = 7.388\n",
      "Epoch   0 Batch 10988/17275   train_loss = 3.225\n",
      "Epoch   0 Batch 10989/17275   train_loss = 4.156\n",
      "Epoch   0 Batch 10990/17275   train_loss = 3.629\n",
      "Epoch   0 Batch 10991/17275   train_loss = 4.090\n",
      "Epoch   0 Batch 10992/17275   train_loss = 6.289\n",
      "Epoch   0 Batch 10993/17275   train_loss = 6.269\n",
      "Epoch   0 Batch 10994/17275   train_loss = 6.931\n",
      "Epoch   0 Batch 10995/17275   train_loss = 6.351\n",
      "Epoch   0 Batch 10996/17275   train_loss = 2.380\n",
      "Epoch   0 Batch 10997/17275   train_loss = 2.964\n",
      "Epoch   0 Batch 10998/17275   train_loss = 3.052\n",
      "Epoch   0 Batch 10999/17275   train_loss = 3.969\n",
      "Epoch   0 Batch 11000/17275   train_loss = 6.939\n",
      "Epoch   0 Batch 11001/17275   train_loss = 3.074\n",
      "Epoch   0 Batch 11002/17275   train_loss = 5.153\n",
      "Epoch   0 Batch 11003/17275   train_loss = 2.369\n",
      "Epoch   0 Batch 11004/17275   train_loss = 2.768\n",
      "Epoch   0 Batch 11005/17275   train_loss = 5.937\n",
      "Epoch   0 Batch 11006/17275   train_loss = 4.100\n",
      "Epoch   0 Batch 11007/17275   train_loss = 2.295\n",
      "Epoch   0 Batch 11008/17275   train_loss = 7.611\n",
      "Epoch   0 Batch 11009/17275   train_loss = 2.331\n",
      "Epoch   0 Batch 11010/17275   train_loss = 4.913\n",
      "Epoch   0 Batch 11011/17275   train_loss = 2.715\n",
      "Epoch   0 Batch 11012/17275   train_loss = 6.690\n",
      "Epoch   0 Batch 11013/17275   train_loss = 3.764\n",
      "Epoch   0 Batch 11014/17275   train_loss = 6.896\n",
      "Epoch   0 Batch 11015/17275   train_loss = 10.527\n",
      "Epoch   0 Batch 11016/17275   train_loss = 6.734\n",
      "Epoch   0 Batch 11017/17275   train_loss = 4.158\n",
      "Epoch   0 Batch 11018/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 11019/17275   train_loss = 3.944\n",
      "Epoch   0 Batch 11020/17275   train_loss = 2.524\n",
      "Epoch   0 Batch 11021/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 11022/17275   train_loss = 4.753\n",
      "Epoch   0 Batch 11023/17275   train_loss = 6.361\n",
      "Epoch   0 Batch 11024/17275   train_loss = 6.931\n",
      "Epoch   0 Batch 11025/17275   train_loss = 2.279\n",
      "Epoch   0 Batch 11026/17275   train_loss = 6.837\n",
      "Epoch   0 Batch 11027/17275   train_loss = 4.676\n",
      "Epoch   0 Batch 11028/17275   train_loss = 3.460\n",
      "Epoch   0 Batch 11029/17275   train_loss = 6.716\n",
      "Epoch   0 Batch 11030/17275   train_loss = 6.582\n",
      "Epoch   0 Batch 11031/17275   train_loss = 6.672\n",
      "Epoch   0 Batch 11032/17275   train_loss = 4.131\n",
      "Epoch   0 Batch 11033/17275   train_loss = 6.320\n",
      "Epoch   0 Batch 11034/17275   train_loss = 6.312\n",
      "Epoch   0 Batch 11035/17275   train_loss = 4.304\n",
      "Epoch   0 Batch 11036/17275   train_loss = 10.451\n",
      "Epoch   0 Batch 11037/17275   train_loss = 3.556\n",
      "Epoch   0 Batch 11038/17275   train_loss = 2.488\n",
      "Epoch   0 Batch 11039/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 11040/17275   train_loss = 4.683\n",
      "Epoch   0 Batch 11041/17275   train_loss = 2.516\n",
      "Epoch   0 Batch 11042/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 11043/17275   train_loss = 2.413\n",
      "Epoch   0 Batch 11044/17275   train_loss = 3.594\n",
      "Epoch   0 Batch 11045/17275   train_loss = 3.544\n",
      "Epoch   0 Batch 11046/17275   train_loss = 4.564\n",
      "Epoch   0 Batch 11047/17275   train_loss = 6.839\n",
      "Epoch   0 Batch 11048/17275   train_loss = 7.106\n",
      "Epoch   0 Batch 11049/17275   train_loss = 6.807\n",
      "Epoch   0 Batch 11050/17275   train_loss = 6.729\n",
      "Epoch   0 Batch 11051/17275   train_loss = 2.070\n",
      "Epoch   0 Batch 11052/17275   train_loss = 3.079\n",
      "Epoch   0 Batch 11053/17275   train_loss = 2.787\n",
      "Epoch   0 Batch 11054/17275   train_loss = 6.570\n",
      "Epoch   0 Batch 11055/17275   train_loss = 3.182\n",
      "Epoch   0 Batch 11056/17275   train_loss = 2.797\n",
      "Epoch   0 Batch 11057/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 11058/17275   train_loss = 2.575\n",
      "Epoch   0 Batch 11059/17275   train_loss = 3.691\n",
      "Epoch   0 Batch 11060/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 11061/17275   train_loss = 6.618\n",
      "Epoch   0 Batch 11062/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 11063/17275   train_loss = 2.979\n",
      "Epoch   0 Batch 11064/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 11065/17275   train_loss = 4.503\n",
      "Epoch   0 Batch 11066/17275   train_loss = 6.261\n",
      "Epoch   0 Batch 11067/17275   train_loss = 2.023\n",
      "Epoch   0 Batch 11068/17275   train_loss = 2.000\n",
      "Epoch   0 Batch 11069/17275   train_loss = 2.642\n",
      "Epoch   0 Batch 11070/17275   train_loss = 5.145\n",
      "Epoch   0 Batch 11071/17275   train_loss = 3.290\n",
      "Epoch   0 Batch 11072/17275   train_loss = 3.335\n",
      "Epoch   0 Batch 11073/17275   train_loss = 4.031\n",
      "Epoch   0 Batch 11074/17275   train_loss = 5.049\n",
      "Epoch   0 Batch 11075/17275   train_loss = 3.106\n",
      "Epoch   0 Batch 11076/17275   train_loss = 4.534\n",
      "Epoch   0 Batch 11077/17275   train_loss = 1.969\n",
      "Epoch   0 Batch 11078/17275   train_loss = 3.234\n",
      "Epoch   0 Batch 11079/17275   train_loss = 3.511\n",
      "Epoch   0 Batch 11080/17275   train_loss = 1.945\n",
      "Epoch   0 Batch 11081/17275   train_loss = 4.280\n",
      "Epoch   0 Batch 11082/17275   train_loss = 3.042\n",
      "Epoch   0 Batch 11083/17275   train_loss = 4.345\n",
      "Epoch   0 Batch 11084/17275   train_loss = 3.931\n",
      "Epoch   0 Batch 11085/17275   train_loss = 3.808\n",
      "Epoch   0 Batch 11086/17275   train_loss = 3.656\n",
      "Epoch   0 Batch 11087/17275   train_loss = 3.482\n",
      "Epoch   0 Batch 11088/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 11089/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 11090/17275   train_loss = 2.876\n",
      "Epoch   0 Batch 11091/17275   train_loss = 2.658\n",
      "Epoch   0 Batch 11092/17275   train_loss = 2.437\n",
      "Epoch   0 Batch 11093/17275   train_loss = 2.217\n",
      "Epoch   0 Batch 11094/17275   train_loss = 2.314\n",
      "Epoch   0 Batch 11095/17275   train_loss = 3.606\n",
      "Epoch   0 Batch 11096/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 11097/17275   train_loss = 3.833\n",
      "Epoch   0 Batch 11098/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 11099/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 11100/17275   train_loss = 4.322\n",
      "Epoch   0 Batch 11101/17275   train_loss = 4.601\n",
      "Epoch   0 Batch 11102/17275   train_loss = 4.190\n",
      "Epoch   0 Batch 11103/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 11104/17275   train_loss = 4.598\n",
      "Epoch   0 Batch 11105/17275   train_loss = 5.627\n",
      "Epoch   0 Batch 11106/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 11107/17275   train_loss = 10.695\n",
      "Epoch   0 Batch 11108/17275   train_loss = 6.495\n",
      "Epoch   0 Batch 11109/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 11110/17275   train_loss = 2.991\n",
      "Epoch   0 Batch 11111/17275   train_loss = 4.967\n",
      "Epoch   0 Batch 11112/17275   train_loss = 3.101\n",
      "Epoch   0 Batch 11113/17275   train_loss = 2.374\n",
      "Epoch   0 Batch 11114/17275   train_loss = 2.904\n",
      "Epoch   0 Batch 11115/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 11116/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 11117/17275   train_loss = 4.228\n",
      "Epoch   0 Batch 11118/17275   train_loss = 2.805\n",
      "Epoch   0 Batch 11119/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 11120/17275   train_loss = 3.589\n",
      "Epoch   0 Batch 11121/17275   train_loss = 2.069\n",
      "Epoch   0 Batch 11122/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 11123/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 11124/17275   train_loss = 2.042\n",
      "Epoch   0 Batch 11125/17275   train_loss = 2.751\n",
      "Epoch   0 Batch 11126/17275   train_loss = 3.411\n",
      "Epoch   0 Batch 11127/17275   train_loss = 2.454\n",
      "Epoch   0 Batch 11128/17275   train_loss = 3.180\n",
      "Epoch   0 Batch 11129/17275   train_loss = 2.532\n",
      "Epoch   0 Batch 11130/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 11131/17275   train_loss = 2.930\n",
      "Epoch   0 Batch 11132/17275   train_loss = 3.128\n",
      "Epoch   0 Batch 11133/17275   train_loss = 2.431\n",
      "Epoch   0 Batch 11134/17275   train_loss = 2.248\n",
      "Epoch   0 Batch 11135/17275   train_loss = 4.718\n",
      "Epoch   0 Batch 11136/17275   train_loss = 3.024\n",
      "Epoch   0 Batch 11137/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 11138/17275   train_loss = 4.217\n",
      "Epoch   0 Batch 11139/17275   train_loss = 4.201\n",
      "Epoch   0 Batch 11140/17275   train_loss = 2.678\n",
      "Epoch   0 Batch 11141/17275   train_loss = 1.881\n",
      "Epoch   0 Batch 11142/17275   train_loss = 2.068\n",
      "Epoch   0 Batch 11143/17275   train_loss = 2.610\n",
      "Epoch   0 Batch 11144/17275   train_loss = 5.502\n",
      "Epoch   0 Batch 11145/17275   train_loss = 3.377\n",
      "Epoch   0 Batch 11146/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 11147/17275   train_loss = 7.708\n",
      "Epoch   0 Batch 11148/17275   train_loss = 4.777\n",
      "Epoch   0 Batch 11149/17275   train_loss = 6.868\n",
      "Epoch   0 Batch 11150/17275   train_loss = 6.087\n",
      "Epoch   0 Batch 11151/17275   train_loss = 6.949\n",
      "Epoch   0 Batch 11152/17275   train_loss = 4.202\n",
      "Epoch   0 Batch 11153/17275   train_loss = 6.454\n",
      "Epoch   0 Batch 11154/17275   train_loss = 3.746\n",
      "Epoch   0 Batch 11155/17275   train_loss = 10.635\n",
      "Epoch   0 Batch 11156/17275   train_loss = 6.917\n",
      "Epoch   0 Batch 11157/17275   train_loss = 2.805\n",
      "Epoch   0 Batch 11158/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 11159/17275   train_loss = 3.923\n",
      "Epoch   0 Batch 11160/17275   train_loss = 3.641\n",
      "Epoch   0 Batch 11161/17275   train_loss = 1.869\n",
      "Epoch   0 Batch 11162/17275   train_loss = 7.166\n",
      "Epoch   0 Batch 11163/17275   train_loss = 8.362\n",
      "Epoch   0 Batch 11164/17275   train_loss = 7.005\n",
      "Epoch   0 Batch 11165/17275   train_loss = 5.527\n",
      "Epoch   0 Batch 11166/17275   train_loss = 5.809\n",
      "Epoch   0 Batch 11167/17275   train_loss = 6.625\n",
      "Epoch   0 Batch 11168/17275   train_loss = 7.630\n",
      "Epoch   0 Batch 11169/17275   train_loss = 6.313\n",
      "Epoch   0 Batch 11170/17275   train_loss = 3.483\n",
      "Epoch   0 Batch 11171/17275   train_loss = 3.340\n",
      "Epoch   0 Batch 11172/17275   train_loss = 2.672\n",
      "Epoch   0 Batch 11173/17275   train_loss = 4.573\n",
      "Epoch   0 Batch 11174/17275   train_loss = 9.830\n",
      "Epoch   0 Batch 11175/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 11176/17275   train_loss = 7.610\n",
      "Epoch   0 Batch 11177/17275   train_loss = 2.410\n",
      "Epoch   0 Batch 11178/17275   train_loss = 7.048\n",
      "Epoch   0 Batch 11179/17275   train_loss = 6.703\n",
      "Epoch   0 Batch 11180/17275   train_loss = 6.734\n",
      "Epoch   0 Batch 11181/17275   train_loss = 7.167\n",
      "Epoch   0 Batch 11182/17275   train_loss = 6.427\n",
      "Epoch   0 Batch 11183/17275   train_loss = 2.702\n",
      "Epoch   0 Batch 11184/17275   train_loss = 4.682\n",
      "Epoch   0 Batch 11185/17275   train_loss = 2.745\n",
      "Epoch   0 Batch 11186/17275   train_loss = 4.084\n",
      "Epoch   0 Batch 11187/17275   train_loss = 2.051\n",
      "Epoch   0 Batch 11188/17275   train_loss = 4.116\n",
      "Epoch   0 Batch 11189/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 11190/17275   train_loss = 4.885\n",
      "Epoch   0 Batch 11191/17275   train_loss = 3.743\n",
      "Epoch   0 Batch 11192/17275   train_loss = 5.647\n",
      "Epoch   0 Batch 11193/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 11194/17275   train_loss = 6.928\n",
      "Epoch   0 Batch 11195/17275   train_loss = 3.147\n",
      "Epoch   0 Batch 11196/17275   train_loss = 4.294\n",
      "Epoch   0 Batch 11197/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 11198/17275   train_loss = 2.459\n",
      "Epoch   0 Batch 11199/17275   train_loss = 4.845\n",
      "Epoch   0 Batch 11200/17275   train_loss = 3.546\n",
      "Epoch   0 Batch 11201/17275   train_loss = 3.631\n",
      "Epoch   0 Batch 11202/17275   train_loss = 3.142\n",
      "Epoch   0 Batch 11203/17275   train_loss = 5.532\n",
      "Epoch   0 Batch 11204/17275   train_loss = 3.177\n",
      "Epoch   0 Batch 11205/17275   train_loss = 6.514\n",
      "Epoch   0 Batch 11206/17275   train_loss = 4.090\n",
      "Epoch   0 Batch 11207/17275   train_loss = 6.329\n",
      "Epoch   0 Batch 11208/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 11209/17275   train_loss = 2.023\n",
      "Epoch   0 Batch 11210/17275   train_loss = 5.596\n",
      "Epoch   0 Batch 11211/17275   train_loss = 4.477\n",
      "Epoch   0 Batch 11212/17275   train_loss = 2.571\n",
      "Epoch   0 Batch 11213/17275   train_loss = 2.471\n",
      "Epoch   0 Batch 11214/17275   train_loss = 4.613\n",
      "Epoch   0 Batch 11215/17275   train_loss = 4.155\n",
      "Epoch   0 Batch 11216/17275   train_loss = 3.495\n",
      "Epoch   0 Batch 11217/17275   train_loss = 3.322\n",
      "Epoch   0 Batch 11218/17275   train_loss = 1.960\n",
      "Epoch   0 Batch 11219/17275   train_loss = 6.628\n",
      "Epoch   0 Batch 11220/17275   train_loss = 6.727\n",
      "Epoch   0 Batch 11221/17275   train_loss = 2.999\n",
      "Epoch   0 Batch 11222/17275   train_loss = 3.608\n",
      "Epoch   0 Batch 11223/17275   train_loss = 6.636\n",
      "Epoch   0 Batch 11224/17275   train_loss = 1.993\n",
      "Epoch   0 Batch 11225/17275   train_loss = 2.739\n",
      "Epoch   0 Batch 11226/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 11227/17275   train_loss = 3.906\n",
      "Epoch   0 Batch 11228/17275   train_loss = 3.517\n",
      "Epoch   0 Batch 11229/17275   train_loss = 6.574\n",
      "Epoch   0 Batch 11230/17275   train_loss = 5.440\n",
      "Epoch   0 Batch 11231/17275   train_loss = 2.329\n",
      "Epoch   0 Batch 11232/17275   train_loss = 4.022\n",
      "Epoch   0 Batch 11233/17275   train_loss = 3.763\n",
      "Epoch   0 Batch 11234/17275   train_loss = 1.998\n",
      "Epoch   0 Batch 11235/17275   train_loss = 3.219\n",
      "Epoch   0 Batch 11236/17275   train_loss = 6.546\n",
      "Epoch   0 Batch 11237/17275   train_loss = 7.201\n",
      "Epoch   0 Batch 11238/17275   train_loss = 4.892\n",
      "Epoch   0 Batch 11239/17275   train_loss = 4.078\n",
      "Epoch   0 Batch 11240/17275   train_loss = 2.349\n",
      "Epoch   0 Batch 11241/17275   train_loss = 3.213\n",
      "Epoch   0 Batch 11242/17275   train_loss = 10.522\n",
      "Epoch   0 Batch 11243/17275   train_loss = 5.377\n",
      "Epoch   0 Batch 11244/17275   train_loss = 3.199\n",
      "Epoch   0 Batch 11245/17275   train_loss = 3.562\n",
      "Epoch   0 Batch 11246/17275   train_loss = 3.862\n",
      "Epoch   0 Batch 11247/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 11248/17275   train_loss = 6.465\n",
      "Epoch   0 Batch 11249/17275   train_loss = 6.509\n",
      "Epoch   0 Batch 11250/17275   train_loss = 1.966\n",
      "Epoch   0 Batch 11251/17275   train_loss = 2.371\n",
      "Epoch   0 Batch 11252/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 11253/17275   train_loss = 2.756\n",
      "Epoch   0 Batch 11254/17275   train_loss = 1.937\n",
      "Epoch   0 Batch 11255/17275   train_loss = 2.324\n",
      "Epoch   0 Batch 11256/17275   train_loss = 3.015\n",
      "Epoch   0 Batch 11257/17275   train_loss = 4.314\n",
      "Epoch   0 Batch 11258/17275   train_loss = 7.056\n",
      "Epoch   0 Batch 11259/17275   train_loss = 6.482\n",
      "Epoch   0 Batch 11260/17275   train_loss = 3.943\n",
      "Epoch   0 Batch 11261/17275   train_loss = 7.185\n",
      "Epoch   0 Batch 11262/17275   train_loss = 2.634\n",
      "Epoch   0 Batch 11263/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 11264/17275   train_loss = 3.391\n",
      "Epoch   0 Batch 11265/17275   train_loss = 1.896\n",
      "Epoch   0 Batch 11266/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 11267/17275   train_loss = 2.598\n",
      "Epoch   0 Batch 11268/17275   train_loss = 7.293\n",
      "Epoch   0 Batch 11269/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 11270/17275   train_loss = 4.639\n",
      "Epoch   0 Batch 11271/17275   train_loss = 4.135\n",
      "Epoch   0 Batch 11272/17275   train_loss = 2.306\n",
      "Epoch   0 Batch 11273/17275   train_loss = 3.610\n",
      "Epoch   0 Batch 11274/17275   train_loss = 4.349\n",
      "Epoch   0 Batch 11275/17275   train_loss = 2.429\n",
      "Epoch   0 Batch 11276/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 11277/17275   train_loss = 4.308\n",
      "Epoch   0 Batch 11278/17275   train_loss = 4.449\n",
      "Epoch   0 Batch 11279/17275   train_loss = 4.283\n",
      "Epoch   0 Batch 11280/17275   train_loss = 3.297\n",
      "Epoch   0 Batch 11281/17275   train_loss = 4.212\n",
      "Epoch   0 Batch 11282/17275   train_loss = 4.123\n",
      "Epoch   0 Batch 11283/17275   train_loss = 6.650\n",
      "Epoch   0 Batch 11284/17275   train_loss = 3.880\n",
      "Epoch   0 Batch 11285/17275   train_loss = 1.936\n",
      "Epoch   0 Batch 11286/17275   train_loss = 4.182\n",
      "Epoch   0 Batch 11287/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 11288/17275   train_loss = 3.695\n",
      "Epoch   0 Batch 11289/17275   train_loss = 4.003\n",
      "Epoch   0 Batch 11290/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 11291/17275   train_loss = 7.996\n",
      "Epoch   0 Batch 11292/17275   train_loss = 3.825\n",
      "Epoch   0 Batch 11293/17275   train_loss = 3.396\n",
      "Epoch   0 Batch 11294/17275   train_loss = 3.293\n",
      "Epoch   0 Batch 11295/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 11296/17275   train_loss = 6.513\n",
      "Epoch   0 Batch 11297/17275   train_loss = 3.935\n",
      "Epoch   0 Batch 11298/17275   train_loss = 3.674\n",
      "Epoch   0 Batch 11299/17275   train_loss = 3.096\n",
      "Epoch   0 Batch 11300/17275   train_loss = 7.082\n",
      "Epoch   0 Batch 11301/17275   train_loss = 1.845\n",
      "Epoch   0 Batch 11302/17275   train_loss = 4.584\n",
      "Epoch   0 Batch 11303/17275   train_loss = 2.976\n",
      "Epoch   0 Batch 11304/17275   train_loss = 2.754\n",
      "Epoch   0 Batch 11305/17275   train_loss = 2.828\n",
      "Epoch   0 Batch 11306/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 11307/17275   train_loss = 3.821\n",
      "Epoch   0 Batch 11308/17275   train_loss = 3.988\n",
      "Epoch   0 Batch 11309/17275   train_loss = 6.638\n",
      "Epoch   0 Batch 11310/17275   train_loss = 4.515\n",
      "Epoch   0 Batch 11311/17275   train_loss = 7.137\n",
      "Epoch   0 Batch 11312/17275   train_loss = 4.687\n",
      "Epoch   0 Batch 11313/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 11314/17275   train_loss = 4.772\n",
      "Epoch   0 Batch 11315/17275   train_loss = 6.793\n",
      "Epoch   0 Batch 11316/17275   train_loss = 2.267\n",
      "Epoch   0 Batch 11317/17275   train_loss = 3.414\n",
      "Epoch   0 Batch 11318/17275   train_loss = 3.147\n",
      "Epoch   0 Batch 11319/17275   train_loss = 2.802\n",
      "Epoch   0 Batch 11320/17275   train_loss = 7.129\n",
      "Epoch   0 Batch 11321/17275   train_loss = 3.859\n",
      "Epoch   0 Batch 11322/17275   train_loss = 2.746\n",
      "Epoch   0 Batch 11323/17275   train_loss = 3.556\n",
      "Epoch   0 Batch 11324/17275   train_loss = 4.464\n",
      "Epoch   0 Batch 11325/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 11326/17275   train_loss = 3.993\n",
      "Epoch   0 Batch 11327/17275   train_loss = 2.539\n",
      "Epoch   0 Batch 11328/17275   train_loss = 7.302\n",
      "Epoch   0 Batch 11329/17275   train_loss = 2.042\n",
      "Epoch   0 Batch 11330/17275   train_loss = 2.566\n",
      "Epoch   0 Batch 11331/17275   train_loss = 6.385\n",
      "Epoch   0 Batch 11332/17275   train_loss = 6.484\n",
      "Epoch   0 Batch 11333/17275   train_loss = 3.704\n",
      "Epoch   0 Batch 11334/17275   train_loss = 5.735\n",
      "Epoch   0 Batch 11335/17275   train_loss = 3.772\n",
      "Epoch   0 Batch 11336/17275   train_loss = 2.555\n",
      "Epoch   0 Batch 11337/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 11338/17275   train_loss = 3.330\n",
      "Epoch   0 Batch 11339/17275   train_loss = 4.368\n",
      "Epoch   0 Batch 11340/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 11341/17275   train_loss = 4.217\n",
      "Epoch   0 Batch 11342/17275   train_loss = 2.619\n",
      "Epoch   0 Batch 11343/17275   train_loss = 5.280\n",
      "Epoch   0 Batch 11344/17275   train_loss = 3.375\n",
      "Epoch   0 Batch 11345/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 11346/17275   train_loss = 3.127\n",
      "Epoch   0 Batch 11347/17275   train_loss = 10.545\n",
      "Epoch   0 Batch 11348/17275   train_loss = 2.102\n",
      "Epoch   0 Batch 11349/17275   train_loss = 3.094\n",
      "Epoch   0 Batch 11350/17275   train_loss = 10.115\n",
      "Epoch   0 Batch 11351/17275   train_loss = 3.224\n",
      "Epoch   0 Batch 11352/17275   train_loss = 3.229\n",
      "Epoch   0 Batch 11353/17275   train_loss = 2.918\n",
      "Epoch   0 Batch 11354/17275   train_loss = 2.319\n",
      "Epoch   0 Batch 11355/17275   train_loss = 6.013\n",
      "Epoch   0 Batch 11356/17275   train_loss = 6.984\n",
      "Epoch   0 Batch 11357/17275   train_loss = 2.089\n",
      "Epoch   0 Batch 11358/17275   train_loss = 2.941\n",
      "Epoch   0 Batch 11359/17275   train_loss = 4.020\n",
      "Epoch   0 Batch 11360/17275   train_loss = 3.914\n",
      "Epoch   0 Batch 11361/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 11362/17275   train_loss = 2.838\n",
      "Epoch   0 Batch 11363/17275   train_loss = 9.031\n",
      "Epoch   0 Batch 11364/17275   train_loss = 2.610\n",
      "Epoch   0 Batch 11365/17275   train_loss = 6.988\n",
      "Epoch   0 Batch 11366/17275   train_loss = 7.146\n",
      "Epoch   0 Batch 11367/17275   train_loss = 2.667\n",
      "Epoch   0 Batch 11368/17275   train_loss = 6.657\n",
      "Epoch   0 Batch 11369/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 11370/17275   train_loss = 6.271\n",
      "Epoch   0 Batch 11371/17275   train_loss = 2.407\n",
      "Epoch   0 Batch 11372/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 11373/17275   train_loss = 6.733\n",
      "Epoch   0 Batch 11374/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 11375/17275   train_loss = 3.176\n",
      "Epoch   0 Batch 11376/17275   train_loss = 4.644\n",
      "Epoch   0 Batch 11377/17275   train_loss = 3.132\n",
      "Epoch   0 Batch 11378/17275   train_loss = 7.783\n",
      "Epoch   0 Batch 11379/17275   train_loss = 3.120\n",
      "Epoch   0 Batch 11380/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 11381/17275   train_loss = 2.887\n",
      "Epoch   0 Batch 11382/17275   train_loss = 3.941\n",
      "Epoch   0 Batch 11383/17275   train_loss = 3.438\n",
      "Epoch   0 Batch 11384/17275   train_loss = 4.733\n",
      "Epoch   0 Batch 11385/17275   train_loss = 4.635\n",
      "Epoch   0 Batch 11386/17275   train_loss = 2.364\n",
      "Epoch   0 Batch 11387/17275   train_loss = 2.576\n",
      "Epoch   0 Batch 11388/17275   train_loss = 3.772\n",
      "Epoch   0 Batch 11389/17275   train_loss = 3.394\n",
      "Epoch   0 Batch 11390/17275   train_loss = 4.485\n",
      "Epoch   0 Batch 11391/17275   train_loss = 7.201\n",
      "Epoch   0 Batch 11392/17275   train_loss = 3.814\n",
      "Epoch   0 Batch 11393/17275   train_loss = 4.048\n",
      "Epoch   0 Batch 11394/17275   train_loss = 2.155\n",
      "Epoch   0 Batch 11395/17275   train_loss = 3.069\n",
      "Epoch   0 Batch 11396/17275   train_loss = 2.197\n",
      "Epoch   0 Batch 11397/17275   train_loss = 3.405\n",
      "Epoch   0 Batch 11398/17275   train_loss = 7.244\n",
      "Epoch   0 Batch 11399/17275   train_loss = 3.193\n",
      "Epoch   0 Batch 11400/17275   train_loss = 9.787\n",
      "Epoch   0 Batch 11401/17275   train_loss = 3.100\n",
      "Epoch   0 Batch 11402/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 11403/17275   train_loss = 2.381\n",
      "Epoch   0 Batch 11404/17275   train_loss = 2.609\n",
      "Epoch   0 Batch 11405/17275   train_loss = 3.939\n",
      "Epoch   0 Batch 11406/17275   train_loss = 4.983\n",
      "Epoch   0 Batch 11407/17275   train_loss = 3.395\n",
      "Epoch   0 Batch 11408/17275   train_loss = 2.142\n",
      "Epoch   0 Batch 11409/17275   train_loss = 3.044\n",
      "Epoch   0 Batch 11410/17275   train_loss = 3.113\n",
      "Epoch   0 Batch 11411/17275   train_loss = 3.618\n",
      "Epoch   0 Batch 11412/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 11413/17275   train_loss = 2.491\n",
      "Epoch   0 Batch 11414/17275   train_loss = 5.959\n",
      "Epoch   0 Batch 11415/17275   train_loss = 6.399\n",
      "Epoch   0 Batch 11416/17275   train_loss = 4.024\n",
      "Epoch   0 Batch 11417/17275   train_loss = 5.398\n",
      "Epoch   0 Batch 11418/17275   train_loss = 3.612\n",
      "Epoch   0 Batch 11419/17275   train_loss = 7.868\n",
      "Epoch   0 Batch 11420/17275   train_loss = 3.120\n",
      "Epoch   0 Batch 11421/17275   train_loss = 8.691\n",
      "Epoch   0 Batch 11422/17275   train_loss = 2.199\n",
      "Epoch   0 Batch 11423/17275   train_loss = 2.228\n",
      "Epoch   0 Batch 11424/17275   train_loss = 2.461\n",
      "Epoch   0 Batch 11425/17275   train_loss = 3.529\n",
      "Epoch   0 Batch 11426/17275   train_loss = 3.095\n",
      "Epoch   0 Batch 11427/17275   train_loss = 7.984\n",
      "Epoch   0 Batch 11428/17275   train_loss = 2.065\n",
      "Epoch   0 Batch 11429/17275   train_loss = 2.150\n",
      "Epoch   0 Batch 11430/17275   train_loss = 6.438\n",
      "Epoch   0 Batch 11431/17275   train_loss = 3.122\n",
      "Epoch   0 Batch 11432/17275   train_loss = 4.346\n",
      "Epoch   0 Batch 11433/17275   train_loss = 5.320\n",
      "Epoch   0 Batch 11434/17275   train_loss = 2.667\n",
      "Epoch   0 Batch 11435/17275   train_loss = 5.422\n",
      "Epoch   0 Batch 11436/17275   train_loss = 4.256\n",
      "Epoch   0 Batch 11437/17275   train_loss = 3.544\n",
      "Epoch   0 Batch 11438/17275   train_loss = 7.316\n",
      "Epoch   0 Batch 11439/17275   train_loss = 6.606\n",
      "Epoch   0 Batch 11440/17275   train_loss = 2.609\n",
      "Epoch   0 Batch 11441/17275   train_loss = 1.821\n",
      "Epoch   0 Batch 11442/17275   train_loss = 2.269\n",
      "Epoch   0 Batch 11443/17275   train_loss = 2.413\n",
      "Epoch   0 Batch 11444/17275   train_loss = 3.436\n",
      "Epoch   0 Batch 11445/17275   train_loss = 3.733\n",
      "Epoch   0 Batch 11446/17275   train_loss = 2.863\n",
      "Epoch   0 Batch 11447/17275   train_loss = 2.448\n",
      "Epoch   0 Batch 11448/17275   train_loss = 8.701\n",
      "Epoch   0 Batch 11449/17275   train_loss = 3.282\n",
      "Epoch   0 Batch 11450/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 11451/17275   train_loss = 8.386\n",
      "Epoch   0 Batch 11452/17275   train_loss = 1.893\n",
      "Epoch   0 Batch 11453/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 11454/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 11455/17275   train_loss = 2.138\n",
      "Epoch   0 Batch 11456/17275   train_loss = 3.918\n",
      "Epoch   0 Batch 11457/17275   train_loss = 3.302\n",
      "Epoch   0 Batch 11458/17275   train_loss = 6.140\n",
      "Epoch   0 Batch 11459/17275   train_loss = 4.357\n",
      "Epoch   0 Batch 11460/17275   train_loss = 6.075\n",
      "Epoch   0 Batch 11461/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 11462/17275   train_loss = 5.095\n",
      "Epoch   0 Batch 11463/17275   train_loss = 1.843\n",
      "Epoch   0 Batch 11464/17275   train_loss = 4.642\n",
      "Epoch   0 Batch 11465/17275   train_loss = 6.991\n",
      "Epoch   0 Batch 11466/17275   train_loss = 2.647\n",
      "Epoch   0 Batch 11467/17275   train_loss = 3.969\n",
      "Epoch   0 Batch 11468/17275   train_loss = 4.097\n",
      "Epoch   0 Batch 11469/17275   train_loss = 4.354\n",
      "Epoch   0 Batch 11470/17275   train_loss = 4.029\n",
      "Epoch   0 Batch 11471/17275   train_loss = 4.268\n",
      "Epoch   0 Batch 11472/17275   train_loss = 4.953\n",
      "Epoch   0 Batch 11473/17275   train_loss = 6.573\n",
      "Epoch   0 Batch 11474/17275   train_loss = 3.914\n",
      "Epoch   0 Batch 11475/17275   train_loss = 1.883\n",
      "Epoch   0 Batch 11476/17275   train_loss = 2.639\n",
      "Epoch   0 Batch 11477/17275   train_loss = 7.166\n",
      "Epoch   0 Batch 11478/17275   train_loss = 3.422\n",
      "Epoch   0 Batch 11479/17275   train_loss = 3.503\n",
      "Epoch   0 Batch 11480/17275   train_loss = 2.348\n",
      "Epoch   0 Batch 11481/17275   train_loss = 5.198\n",
      "Epoch   0 Batch 11482/17275   train_loss = 6.807\n",
      "Epoch   0 Batch 11483/17275   train_loss = 6.193\n",
      "Epoch   0 Batch 11484/17275   train_loss = 2.393\n",
      "Epoch   0 Batch 11485/17275   train_loss = 6.636\n",
      "Epoch   0 Batch 11486/17275   train_loss = 6.416\n",
      "Epoch   0 Batch 11487/17275   train_loss = 4.042\n",
      "Epoch   0 Batch 11488/17275   train_loss = 3.201\n",
      "Epoch   0 Batch 11489/17275   train_loss = 3.119\n",
      "Epoch   0 Batch 11490/17275   train_loss = 3.262\n",
      "Epoch   0 Batch 11491/17275   train_loss = 1.886\n",
      "Epoch   0 Batch 11492/17275   train_loss = 3.699\n",
      "Epoch   0 Batch 11493/17275   train_loss = 1.862\n",
      "Epoch   0 Batch 11494/17275   train_loss = 3.528\n",
      "Epoch   0 Batch 11495/17275   train_loss = 5.374\n",
      "Epoch   0 Batch 11496/17275   train_loss = 4.884\n",
      "Epoch   0 Batch 11497/17275   train_loss = 5.190\n",
      "Epoch   0 Batch 11498/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 11499/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 11500/17275   train_loss = 4.556\n",
      "Epoch   0 Batch 11501/17275   train_loss = 4.800\n",
      "Epoch   0 Batch 11502/17275   train_loss = 4.294\n",
      "Epoch   0 Batch 11503/17275   train_loss = 9.351\n",
      "Epoch   0 Batch 11504/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 11505/17275   train_loss = 10.457\n",
      "Epoch   0 Batch 11506/17275   train_loss = 7.781\n",
      "Epoch   0 Batch 11507/17275   train_loss = 6.079\n",
      "Epoch   0 Batch 11508/17275   train_loss = 4.045\n",
      "Epoch   0 Batch 11509/17275   train_loss = 4.395\n",
      "Epoch   0 Batch 11510/17275   train_loss = 7.658\n",
      "Epoch   0 Batch 11511/17275   train_loss = 7.332\n",
      "Epoch   0 Batch 11512/17275   train_loss = 6.089\n",
      "Epoch   0 Batch 11513/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 11514/17275   train_loss = 3.821\n",
      "Epoch   0 Batch 11515/17275   train_loss = 3.716\n",
      "Epoch   0 Batch 11516/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 11517/17275   train_loss = 4.371\n",
      "Epoch   0 Batch 11518/17275   train_loss = 6.321\n",
      "Epoch   0 Batch 11519/17275   train_loss = 3.501\n",
      "Epoch   0 Batch 11520/17275   train_loss = 4.360\n",
      "Epoch   0 Batch 11521/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 11522/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 11523/17275   train_loss = 6.942\n",
      "Epoch   0 Batch 11524/17275   train_loss = 1.891\n",
      "Epoch   0 Batch 11525/17275   train_loss = 3.151\n",
      "Epoch   0 Batch 11526/17275   train_loss = 3.977\n",
      "Epoch   0 Batch 11527/17275   train_loss = 3.959\n",
      "Epoch   0 Batch 11528/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 11529/17275   train_loss = 5.787\n",
      "Epoch   0 Batch 11530/17275   train_loss = 1.765\n",
      "Epoch   0 Batch 11531/17275   train_loss = 6.567\n",
      "Epoch   0 Batch 11532/17275   train_loss = 4.779\n",
      "Epoch   0 Batch 11533/17275   train_loss = 2.598\n",
      "Epoch   0 Batch 11534/17275   train_loss = 2.608\n",
      "Epoch   0 Batch 11535/17275   train_loss = 3.133\n",
      "Epoch   0 Batch 11536/17275   train_loss = 6.940\n",
      "Epoch   0 Batch 11537/17275   train_loss = 3.110\n",
      "Epoch   0 Batch 11538/17275   train_loss = 3.411\n",
      "Epoch   0 Batch 11539/17275   train_loss = 2.683\n",
      "Epoch   0 Batch 11540/17275   train_loss = 7.159\n",
      "Epoch   0 Batch 11541/17275   train_loss = 10.574\n",
      "Epoch   0 Batch 11542/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 11543/17275   train_loss = 4.328\n",
      "Epoch   0 Batch 11544/17275   train_loss = 3.539\n",
      "Epoch   0 Batch 11545/17275   train_loss = 4.200\n",
      "Epoch   0 Batch 11546/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 11547/17275   train_loss = 2.626\n",
      "Epoch   0 Batch 11548/17275   train_loss = 4.303\n",
      "Epoch   0 Batch 11549/17275   train_loss = 3.994\n",
      "Epoch   0 Batch 11550/17275   train_loss = 4.038\n",
      "Epoch   0 Batch 11551/17275   train_loss = 5.370\n",
      "Epoch   0 Batch 11552/17275   train_loss = 2.679\n",
      "Epoch   0 Batch 11553/17275   train_loss = 3.521\n",
      "Epoch   0 Batch 11554/17275   train_loss = 4.207\n",
      "Epoch   0 Batch 11555/17275   train_loss = 3.658\n",
      "Epoch   0 Batch 11556/17275   train_loss = 4.837\n",
      "Epoch   0 Batch 11557/17275   train_loss = 8.541\n",
      "Epoch   0 Batch 11558/17275   train_loss = 2.576\n",
      "Epoch   0 Batch 11559/17275   train_loss = 3.239\n",
      "Epoch   0 Batch 11560/17275   train_loss = 3.261\n",
      "Epoch   0 Batch 11561/17275   train_loss = 4.713\n",
      "Epoch   0 Batch 11562/17275   train_loss = 2.622\n",
      "Epoch   0 Batch 11563/17275   train_loss = 10.559\n",
      "Epoch   0 Batch 11564/17275   train_loss = 2.457\n",
      "Epoch   0 Batch 11565/17275   train_loss = 3.866\n",
      "Epoch   0 Batch 11566/17275   train_loss = 3.057\n",
      "Epoch   0 Batch 11567/17275   train_loss = 5.034\n",
      "Epoch   0 Batch 11568/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 11569/17275   train_loss = 9.805\n",
      "Epoch   0 Batch 11570/17275   train_loss = 4.872\n",
      "Epoch   0 Batch 11571/17275   train_loss = 6.990\n",
      "Epoch   0 Batch 11572/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 11573/17275   train_loss = 5.609\n",
      "Epoch   0 Batch 11574/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 11575/17275   train_loss = 2.377\n",
      "Epoch   0 Batch 11576/17275   train_loss = 4.491\n",
      "Epoch   0 Batch 11577/17275   train_loss = 3.387\n",
      "Epoch   0 Batch 11578/17275   train_loss = 2.728\n",
      "Epoch   0 Batch 11579/17275   train_loss = 4.762\n",
      "Epoch   0 Batch 11580/17275   train_loss = 7.902\n",
      "Epoch   0 Batch 11581/17275   train_loss = 3.145\n",
      "Epoch   0 Batch 11582/17275   train_loss = 10.556\n",
      "Epoch   0 Batch 11583/17275   train_loss = 2.953\n",
      "Epoch   0 Batch 11584/17275   train_loss = 2.525\n",
      "Epoch   0 Batch 11585/17275   train_loss = 4.741\n",
      "Epoch   0 Batch 11586/17275   train_loss = 6.771\n",
      "Epoch   0 Batch 11587/17275   train_loss = 3.241\n",
      "Epoch   0 Batch 11588/17275   train_loss = 6.828\n",
      "Epoch   0 Batch 11589/17275   train_loss = 6.301\n",
      "Epoch   0 Batch 11590/17275   train_loss = 2.236\n",
      "Epoch   0 Batch 11591/17275   train_loss = 3.796\n",
      "Epoch   0 Batch 11592/17275   train_loss = 6.016\n",
      "Epoch   0 Batch 11593/17275   train_loss = 2.425\n",
      "Epoch   0 Batch 11594/17275   train_loss = 2.881\n",
      "Epoch   0 Batch 11595/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 11596/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 11597/17275   train_loss = 4.203\n",
      "Epoch   0 Batch 11598/17275   train_loss = 3.244\n",
      "Epoch   0 Batch 11599/17275   train_loss = 4.553\n",
      "Epoch   0 Batch 11600/17275   train_loss = 6.274\n",
      "Epoch   0 Batch 11601/17275   train_loss = 2.634\n",
      "Epoch   0 Batch 11602/17275   train_loss = 2.992\n",
      "Epoch   0 Batch 11603/17275   train_loss = 7.244\n",
      "Epoch   0 Batch 11604/17275   train_loss = 3.807\n",
      "Epoch   0 Batch 11605/17275   train_loss = 2.204\n",
      "Epoch   0 Batch 11606/17275   train_loss = 3.676\n",
      "Epoch   0 Batch 11607/17275   train_loss = 3.449\n",
      "Epoch   0 Batch 11608/17275   train_loss = 3.859\n",
      "Epoch   0 Batch 11609/17275   train_loss = 2.235\n",
      "Epoch   0 Batch 11610/17275   train_loss = 3.941\n",
      "Epoch   0 Batch 11611/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 11612/17275   train_loss = 6.385\n",
      "Epoch   0 Batch 11613/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 11614/17275   train_loss = 2.837\n",
      "Epoch   0 Batch 11615/17275   train_loss = 3.286\n",
      "Epoch   0 Batch 11616/17275   train_loss = 2.854\n",
      "Epoch   0 Batch 11617/17275   train_loss = 4.290\n",
      "Epoch   0 Batch 11618/17275   train_loss = 4.285\n",
      "Epoch   0 Batch 11619/17275   train_loss = 7.638\n",
      "Epoch   0 Batch 11620/17275   train_loss = 6.706\n",
      "Epoch   0 Batch 11621/17275   train_loss = 6.276\n",
      "Epoch   0 Batch 11622/17275   train_loss = 2.783\n",
      "Epoch   0 Batch 11623/17275   train_loss = 4.915\n",
      "Epoch   0 Batch 11624/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 11625/17275   train_loss = 4.408\n",
      "Epoch   0 Batch 11626/17275   train_loss = 3.190\n",
      "Epoch   0 Batch 11627/17275   train_loss = 2.789\n",
      "Epoch   0 Batch 11628/17275   train_loss = 4.422\n",
      "Epoch   0 Batch 11629/17275   train_loss = 3.405\n",
      "Epoch   0 Batch 11630/17275   train_loss = 2.292\n",
      "Epoch   0 Batch 11631/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 11632/17275   train_loss = 3.399\n",
      "Epoch   0 Batch 11633/17275   train_loss = 3.361\n",
      "Epoch   0 Batch 11634/17275   train_loss = 3.034\n",
      "Epoch   0 Batch 11635/17275   train_loss = 2.624\n",
      "Epoch   0 Batch 11636/17275   train_loss = 2.462\n",
      "Epoch   0 Batch 11637/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 11638/17275   train_loss = 6.132\n",
      "Epoch   0 Batch 11639/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 11640/17275   train_loss = 2.325\n",
      "Epoch   0 Batch 11641/17275   train_loss = 6.628\n",
      "Epoch   0 Batch 11642/17275   train_loss = 3.610\n",
      "Epoch   0 Batch 11643/17275   train_loss = 4.077\n",
      "Epoch   0 Batch 11644/17275   train_loss = 4.167\n",
      "Epoch   0 Batch 11645/17275   train_loss = 6.873\n",
      "Epoch   0 Batch 11646/17275   train_loss = 3.480\n",
      "Epoch   0 Batch 11647/17275   train_loss = 9.406\n",
      "Epoch   0 Batch 11648/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 11649/17275   train_loss = 3.364\n",
      "Epoch   0 Batch 11650/17275   train_loss = 2.728\n",
      "Epoch   0 Batch 11651/17275   train_loss = 6.709\n",
      "Epoch   0 Batch 11652/17275   train_loss = 4.128\n",
      "Epoch   0 Batch 11653/17275   train_loss = 2.437\n",
      "Epoch   0 Batch 11654/17275   train_loss = 2.840\n",
      "Epoch   0 Batch 11655/17275   train_loss = 5.011\n",
      "Epoch   0 Batch 11656/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 11657/17275   train_loss = 3.283\n",
      "Epoch   0 Batch 11658/17275   train_loss = 6.269\n",
      "Epoch   0 Batch 11659/17275   train_loss = 2.935\n",
      "Epoch   0 Batch 11660/17275   train_loss = 4.058\n",
      "Epoch   0 Batch 11661/17275   train_loss = 7.373\n",
      "Epoch   0 Batch 11662/17275   train_loss = 2.845\n",
      "Epoch   0 Batch 11663/17275   train_loss = 4.031\n",
      "Epoch   0 Batch 11664/17275   train_loss = 7.522\n",
      "Epoch   0 Batch 11665/17275   train_loss = 6.603\n",
      "Epoch   0 Batch 11666/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 11667/17275   train_loss = 2.331\n",
      "Epoch   0 Batch 11668/17275   train_loss = 3.570\n",
      "Epoch   0 Batch 11669/17275   train_loss = 3.349\n",
      "Epoch   0 Batch 11670/17275   train_loss = 4.518\n",
      "Epoch   0 Batch 11671/17275   train_loss = 3.508\n",
      "Epoch   0 Batch 11672/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 11673/17275   train_loss = 3.728\n",
      "Epoch   0 Batch 11674/17275   train_loss = 6.980\n",
      "Epoch   0 Batch 11675/17275   train_loss = 2.586\n",
      "Epoch   0 Batch 11676/17275   train_loss = 5.524\n",
      "Epoch   0 Batch 11677/17275   train_loss = 3.602\n",
      "Epoch   0 Batch 11678/17275   train_loss = 6.540\n",
      "Epoch   0 Batch 11679/17275   train_loss = 8.601\n",
      "Epoch   0 Batch 11680/17275   train_loss = 5.047\n",
      "Epoch   0 Batch 11681/17275   train_loss = 8.052\n",
      "Epoch   0 Batch 11682/17275   train_loss = 4.355\n",
      "Epoch   0 Batch 11683/17275   train_loss = 3.621\n",
      "Epoch   0 Batch 11684/17275   train_loss = 2.353\n",
      "Epoch   0 Batch 11685/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 11686/17275   train_loss = 4.685\n",
      "Epoch   0 Batch 11687/17275   train_loss = 2.199\n",
      "Epoch   0 Batch 11688/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 11689/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 11690/17275   train_loss = 2.864\n",
      "Epoch   0 Batch 11691/17275   train_loss = 3.560\n",
      "Epoch   0 Batch 11692/17275   train_loss = 4.647\n",
      "Epoch   0 Batch 11693/17275   train_loss = 7.530\n",
      "Epoch   0 Batch 11694/17275   train_loss = 6.375\n",
      "Epoch   0 Batch 11695/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 11696/17275   train_loss = 3.627\n",
      "Epoch   0 Batch 11697/17275   train_loss = 9.090\n",
      "Epoch   0 Batch 11698/17275   train_loss = 2.415\n",
      "Epoch   0 Batch 11699/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 11700/17275   train_loss = 3.183\n",
      "Epoch   0 Batch 11701/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 11702/17275   train_loss = 4.268\n",
      "Epoch   0 Batch 11703/17275   train_loss = 2.233\n",
      "Epoch   0 Batch 11704/17275   train_loss = 2.604\n",
      "Epoch   0 Batch 11705/17275   train_loss = 3.780\n",
      "Epoch   0 Batch 11706/17275   train_loss = 7.990\n",
      "Epoch   0 Batch 11707/17275   train_loss = 3.485\n",
      "Epoch   0 Batch 11708/17275   train_loss = 2.611\n",
      "Epoch   0 Batch 11709/17275   train_loss = 5.584\n",
      "Epoch   0 Batch 11710/17275   train_loss = 4.470\n",
      "Epoch   0 Batch 11711/17275   train_loss = 2.359\n",
      "Epoch   0 Batch 11712/17275   train_loss = 2.691\n",
      "Epoch   0 Batch 11713/17275   train_loss = 3.728\n",
      "Epoch   0 Batch 11714/17275   train_loss = 2.641\n",
      "Epoch   0 Batch 11715/17275   train_loss = 3.119\n",
      "Epoch   0 Batch 11716/17275   train_loss = 4.195\n",
      "Epoch   0 Batch 11717/17275   train_loss = 10.603\n",
      "Epoch   0 Batch 11718/17275   train_loss = 2.116\n",
      "Epoch   0 Batch 11719/17275   train_loss = 2.811\n",
      "Epoch   0 Batch 11720/17275   train_loss = 10.389\n",
      "Epoch   0 Batch 11721/17275   train_loss = 2.997\n",
      "Epoch   0 Batch 11722/17275   train_loss = 2.414\n",
      "Epoch   0 Batch 11723/17275   train_loss = 6.778\n",
      "Epoch   0 Batch 11724/17275   train_loss = 7.163\n",
      "Epoch   0 Batch 11725/17275   train_loss = 6.298\n",
      "Epoch   0 Batch 11726/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 11727/17275   train_loss = 2.300\n",
      "Epoch   0 Batch 11728/17275   train_loss = 3.349\n",
      "Epoch   0 Batch 11729/17275   train_loss = 4.391\n",
      "Epoch   0 Batch 11730/17275   train_loss = 7.045\n",
      "Epoch   0 Batch 11731/17275   train_loss = 3.861\n",
      "Epoch   0 Batch 11732/17275   train_loss = 3.149\n",
      "Epoch   0 Batch 11733/17275   train_loss = 7.441\n",
      "Epoch   0 Batch 11734/17275   train_loss = 2.610\n",
      "Epoch   0 Batch 11735/17275   train_loss = 2.376\n",
      "Epoch   0 Batch 11736/17275   train_loss = 2.818\n",
      "Epoch   0 Batch 11737/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 11738/17275   train_loss = 4.328\n",
      "Epoch   0 Batch 11739/17275   train_loss = 4.728\n",
      "Epoch   0 Batch 11740/17275   train_loss = 3.190\n",
      "Epoch   0 Batch 11741/17275   train_loss = 6.243\n",
      "Epoch   0 Batch 11742/17275   train_loss = 2.760\n",
      "Epoch   0 Batch 11743/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 11744/17275   train_loss = 4.499\n",
      "Epoch   0 Batch 11745/17275   train_loss = 3.833\n",
      "Epoch   0 Batch 11746/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 11747/17275   train_loss = 5.146\n",
      "Epoch   0 Batch 11748/17275   train_loss = 6.649\n",
      "Epoch   0 Batch 11749/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 11750/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 11751/17275   train_loss = 6.366\n",
      "Epoch   0 Batch 11752/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 11753/17275   train_loss = 4.328\n",
      "Epoch   0 Batch 11754/17275   train_loss = 6.917\n",
      "Epoch   0 Batch 11755/17275   train_loss = 3.691\n",
      "Epoch   0 Batch 11756/17275   train_loss = 3.606\n",
      "Epoch   0 Batch 11757/17275   train_loss = 2.390\n",
      "Epoch   0 Batch 11758/17275   train_loss = 2.616\n",
      "Epoch   0 Batch 11759/17275   train_loss = 2.044\n",
      "Epoch   0 Batch 11760/17275   train_loss = 10.640\n",
      "Epoch   0 Batch 11761/17275   train_loss = 1.987\n",
      "Epoch   0 Batch 11762/17275   train_loss = 3.927\n",
      "Epoch   0 Batch 11763/17275   train_loss = 1.893\n",
      "Epoch   0 Batch 11764/17275   train_loss = 2.797\n",
      "Epoch   0 Batch 11765/17275   train_loss = 1.764\n",
      "Epoch   0 Batch 11766/17275   train_loss = 1.959\n",
      "Epoch   0 Batch 11767/17275   train_loss = 3.364\n",
      "Epoch   0 Batch 11768/17275   train_loss = 2.537\n",
      "Epoch   0 Batch 11769/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 11770/17275   train_loss = 7.038\n",
      "Epoch   0 Batch 11771/17275   train_loss = 2.445\n",
      "Epoch   0 Batch 11772/17275   train_loss = 2.584\n",
      "Epoch   0 Batch 11773/17275   train_loss = 4.950\n",
      "Epoch   0 Batch 11774/17275   train_loss = 3.994\n",
      "Epoch   0 Batch 11775/17275   train_loss = 3.830\n",
      "Epoch   0 Batch 11776/17275   train_loss = 4.806\n",
      "Epoch   0 Batch 11777/17275   train_loss = 3.068\n",
      "Epoch   0 Batch 11778/17275   train_loss = 4.889\n",
      "Epoch   0 Batch 11779/17275   train_loss = 2.971\n",
      "Epoch   0 Batch 11780/17275   train_loss = 2.694\n",
      "Epoch   0 Batch 11781/17275   train_loss = 7.228\n",
      "Epoch   0 Batch 11782/17275   train_loss = 2.527\n",
      "Epoch   0 Batch 11783/17275   train_loss = 3.988\n",
      "Epoch   0 Batch 11784/17275   train_loss = 6.831\n",
      "Epoch   0 Batch 11785/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 11786/17275   train_loss = 3.994\n",
      "Epoch   0 Batch 11787/17275   train_loss = 3.555\n",
      "Epoch   0 Batch 11788/17275   train_loss = 3.436\n",
      "Epoch   0 Batch 11789/17275   train_loss = 4.944\n",
      "Epoch   0 Batch 11790/17275   train_loss = 6.454\n",
      "Epoch   0 Batch 11791/17275   train_loss = 3.906\n",
      "Epoch   0 Batch 11792/17275   train_loss = 2.430\n",
      "Epoch   0 Batch 11793/17275   train_loss = 2.422\n",
      "Epoch   0 Batch 11794/17275   train_loss = 4.899\n",
      "Epoch   0 Batch 11795/17275   train_loss = 3.381\n",
      "Epoch   0 Batch 11796/17275   train_loss = 3.607\n",
      "Epoch   0 Batch 11797/17275   train_loss = 6.744\n",
      "Epoch   0 Batch 11798/17275   train_loss = 3.765\n",
      "Epoch   0 Batch 11799/17275   train_loss = 3.487\n",
      "Epoch   0 Batch 11800/17275   train_loss = 2.719\n",
      "Epoch   0 Batch 11801/17275   train_loss = 2.837\n",
      "Epoch   0 Batch 11802/17275   train_loss = 3.321\n",
      "Epoch   0 Batch 11803/17275   train_loss = 3.040\n",
      "Epoch   0 Batch 11804/17275   train_loss = 2.897\n",
      "Epoch   0 Batch 11805/17275   train_loss = 3.479\n",
      "Epoch   0 Batch 11806/17275   train_loss = 4.985\n",
      "Epoch   0 Batch 11807/17275   train_loss = 3.506\n",
      "Epoch   0 Batch 11808/17275   train_loss = 2.250\n",
      "Epoch   0 Batch 11809/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 11810/17275   train_loss = 3.883\n",
      "Epoch   0 Batch 11811/17275   train_loss = 4.190\n",
      "Epoch   0 Batch 11812/17275   train_loss = 7.026\n",
      "Epoch   0 Batch 11813/17275   train_loss = 3.383\n",
      "Epoch   0 Batch 11814/17275   train_loss = 2.227\n",
      "Epoch   0 Batch 11815/17275   train_loss = 3.414\n",
      "Epoch   0 Batch 11816/17275   train_loss = 3.582\n",
      "Epoch   0 Batch 11817/17275   train_loss = 3.497\n",
      "Epoch   0 Batch 11818/17275   train_loss = 7.754\n",
      "Epoch   0 Batch 11819/17275   train_loss = 4.189\n",
      "Epoch   0 Batch 11820/17275   train_loss = 2.671\n",
      "Epoch   0 Batch 11821/17275   train_loss = 2.686\n",
      "Epoch   0 Batch 11822/17275   train_loss = 2.564\n",
      "Epoch   0 Batch 11823/17275   train_loss = 4.878\n",
      "Epoch   0 Batch 11824/17275   train_loss = 4.014\n",
      "Epoch   0 Batch 11825/17275   train_loss = 7.065\n",
      "Epoch   0 Batch 11826/17275   train_loss = 2.639\n",
      "Epoch   0 Batch 11827/17275   train_loss = 3.221\n",
      "Epoch   0 Batch 11828/17275   train_loss = 3.648\n",
      "Epoch   0 Batch 11829/17275   train_loss = 3.385\n",
      "Epoch   0 Batch 11830/17275   train_loss = 10.673\n",
      "Epoch   0 Batch 11831/17275   train_loss = 2.392\n",
      "Epoch   0 Batch 11832/17275   train_loss = 6.823\n",
      "Epoch   0 Batch 11833/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 11834/17275   train_loss = 7.384\n",
      "Epoch   0 Batch 11835/17275   train_loss = 4.818\n",
      "Epoch   0 Batch 11836/17275   train_loss = 3.399\n",
      "Epoch   0 Batch 11837/17275   train_loss = 2.602\n",
      "Epoch   0 Batch 11838/17275   train_loss = 2.456\n",
      "Epoch   0 Batch 11839/17275   train_loss = 3.683\n",
      "Epoch   0 Batch 11840/17275   train_loss = 3.777\n",
      "Epoch   0 Batch 11841/17275   train_loss = 3.336\n",
      "Epoch   0 Batch 11842/17275   train_loss = 4.068\n",
      "Epoch   0 Batch 11843/17275   train_loss = 2.936\n",
      "Epoch   0 Batch 11844/17275   train_loss = 6.896\n",
      "Epoch   0 Batch 11845/17275   train_loss = 2.691\n",
      "Epoch   0 Batch 11846/17275   train_loss = 2.922\n",
      "Epoch   0 Batch 11847/17275   train_loss = 6.728\n",
      "Epoch   0 Batch 11848/17275   train_loss = 7.508\n",
      "Epoch   0 Batch 11849/17275   train_loss = 2.535\n",
      "Epoch   0 Batch 11850/17275   train_loss = 6.706\n",
      "Epoch   0 Batch 11851/17275   train_loss = 4.709\n",
      "Epoch   0 Batch 11852/17275   train_loss = 1.778\n",
      "Epoch   0 Batch 11853/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 11854/17275   train_loss = 3.472\n",
      "Epoch   0 Batch 11855/17275   train_loss = 5.905\n",
      "Epoch   0 Batch 11856/17275   train_loss = 1.701\n",
      "Epoch   0 Batch 11857/17275   train_loss = 1.935\n",
      "Epoch   0 Batch 11858/17275   train_loss = 6.901\n",
      "Epoch   0 Batch 11859/17275   train_loss = 6.155\n",
      "Epoch   0 Batch 11860/17275   train_loss = 1.582\n",
      "Epoch   0 Batch 11861/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 11862/17275   train_loss = 4.665\n",
      "Epoch   0 Batch 11863/17275   train_loss = 6.924\n",
      "Epoch   0 Batch 11864/17275   train_loss = 6.091\n",
      "Epoch   0 Batch 11865/17275   train_loss = 2.443\n",
      "Epoch   0 Batch 11866/17275   train_loss = 3.499\n",
      "Epoch   0 Batch 11867/17275   train_loss = 4.370\n",
      "Epoch   0 Batch 11868/17275   train_loss = 3.444\n",
      "Epoch   0 Batch 11869/17275   train_loss = 3.647\n",
      "Epoch   0 Batch 11870/17275   train_loss = 3.259\n",
      "Epoch   0 Batch 11871/17275   train_loss = 2.632\n",
      "Epoch   0 Batch 11872/17275   train_loss = 3.592\n",
      "Epoch   0 Batch 11873/17275   train_loss = 6.890\n",
      "Epoch   0 Batch 11874/17275   train_loss = 3.561\n",
      "Epoch   0 Batch 11875/17275   train_loss = 1.753\n",
      "Epoch   0 Batch 11876/17275   train_loss = 3.756\n",
      "Epoch   0 Batch 11877/17275   train_loss = 4.035\n",
      "Epoch   0 Batch 11878/17275   train_loss = 1.754\n",
      "Epoch   0 Batch 11879/17275   train_loss = 3.378\n",
      "Epoch   0 Batch 11880/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 11881/17275   train_loss = 1.750\n",
      "Epoch   0 Batch 11882/17275   train_loss = 3.473\n",
      "Epoch   0 Batch 11883/17275   train_loss = 2.695\n",
      "Epoch   0 Batch 11884/17275   train_loss = 2.382\n",
      "Epoch   0 Batch 11885/17275   train_loss = 4.790\n",
      "Epoch   0 Batch 11886/17275   train_loss = 2.577\n",
      "Epoch   0 Batch 11887/17275   train_loss = 4.359\n",
      "Epoch   0 Batch 11888/17275   train_loss = 7.371\n",
      "Epoch   0 Batch 11889/17275   train_loss = 4.914\n",
      "Epoch   0 Batch 11890/17275   train_loss = 4.093\n",
      "Epoch   0 Batch 11891/17275   train_loss = 3.861\n",
      "Epoch   0 Batch 11892/17275   train_loss = 4.170\n",
      "Epoch   0 Batch 11893/17275   train_loss = 5.550\n",
      "Epoch   0 Batch 11894/17275   train_loss = 7.234\n",
      "Epoch   0 Batch 11895/17275   train_loss = 4.737\n",
      "Epoch   0 Batch 11896/17275   train_loss = 4.058\n",
      "Epoch   0 Batch 11897/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 11898/17275   train_loss = 7.531\n",
      "Epoch   0 Batch 11899/17275   train_loss = 3.209\n",
      "Epoch   0 Batch 11900/17275   train_loss = 2.326\n",
      "Epoch   0 Batch 11901/17275   train_loss = 1.659\n",
      "Epoch   0 Batch 11902/17275   train_loss = 3.936\n",
      "Epoch   0 Batch 11903/17275   train_loss = 3.319\n",
      "Epoch   0 Batch 11904/17275   train_loss = 3.364\n",
      "Epoch   0 Batch 11905/17275   train_loss = 3.502\n",
      "Epoch   0 Batch 11906/17275   train_loss = 4.115\n",
      "Epoch   0 Batch 11907/17275   train_loss = 10.702\n",
      "Epoch   0 Batch 11908/17275   train_loss = 7.331\n",
      "Epoch   0 Batch 11909/17275   train_loss = 5.445\n",
      "Epoch   0 Batch 11910/17275   train_loss = 3.382\n",
      "Epoch   0 Batch 11911/17275   train_loss = 7.334\n",
      "Epoch   0 Batch 11912/17275   train_loss = 1.891\n",
      "Epoch   0 Batch 11913/17275   train_loss = 4.799\n",
      "Epoch   0 Batch 11914/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 11915/17275   train_loss = 4.821\n",
      "Epoch   0 Batch 11916/17275   train_loss = 4.980\n",
      "Epoch   0 Batch 11917/17275   train_loss = 4.031\n",
      "Epoch   0 Batch 11918/17275   train_loss = 3.673\n",
      "Epoch   0 Batch 11919/17275   train_loss = 2.938\n",
      "Epoch   0 Batch 11920/17275   train_loss = 4.711\n",
      "Epoch   0 Batch 11921/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 11922/17275   train_loss = 4.427\n",
      "Epoch   0 Batch 11923/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 11924/17275   train_loss = 2.799\n",
      "Epoch   0 Batch 11925/17275   train_loss = 6.237\n",
      "Epoch   0 Batch 11926/17275   train_loss = 2.448\n",
      "Epoch   0 Batch 11927/17275   train_loss = 4.387\n",
      "Epoch   0 Batch 11928/17275   train_loss = 3.179\n",
      "Epoch   0 Batch 11929/17275   train_loss = 2.596\n",
      "Epoch   0 Batch 11930/17275   train_loss = 4.188\n",
      "Epoch   0 Batch 11931/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 11932/17275   train_loss = 2.456\n",
      "Epoch   0 Batch 11933/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 11934/17275   train_loss = 4.616\n",
      "Epoch   0 Batch 11935/17275   train_loss = 3.031\n",
      "Epoch   0 Batch 11936/17275   train_loss = 5.779\n",
      "Epoch   0 Batch 11937/17275   train_loss = 2.420\n",
      "Epoch   0 Batch 11938/17275   train_loss = 5.551\n",
      "Epoch   0 Batch 11939/17275   train_loss = 3.504\n",
      "Epoch   0 Batch 11940/17275   train_loss = 2.644\n",
      "Epoch   0 Batch 11941/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 11942/17275   train_loss = 6.447\n",
      "Epoch   0 Batch 11943/17275   train_loss = 3.451\n",
      "Epoch   0 Batch 11944/17275   train_loss = 5.003\n",
      "Epoch   0 Batch 11945/17275   train_loss = 3.735\n",
      "Epoch   0 Batch 11946/17275   train_loss = 6.802\n",
      "Epoch   0 Batch 11947/17275   train_loss = 3.876\n",
      "Epoch   0 Batch 11948/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 11949/17275   train_loss = 3.678\n",
      "Epoch   0 Batch 11950/17275   train_loss = 3.652\n",
      "Epoch   0 Batch 11951/17275   train_loss = 2.489\n",
      "Epoch   0 Batch 11952/17275   train_loss = 3.309\n",
      "Epoch   0 Batch 11953/17275   train_loss = 3.012\n",
      "Epoch   0 Batch 11954/17275   train_loss = 3.232\n",
      "Epoch   0 Batch 11955/17275   train_loss = 4.695\n",
      "Epoch   0 Batch 11956/17275   train_loss = 4.980\n",
      "Epoch   0 Batch 11957/17275   train_loss = 2.998\n",
      "Epoch   0 Batch 11958/17275   train_loss = 3.194\n",
      "Epoch   0 Batch 11959/17275   train_loss = 5.170\n",
      "Epoch   0 Batch 11960/17275   train_loss = 4.299\n",
      "Epoch   0 Batch 11961/17275   train_loss = 2.706\n",
      "Epoch   0 Batch 11962/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 11963/17275   train_loss = 3.703\n",
      "Epoch   0 Batch 11964/17275   train_loss = 3.751\n",
      "Epoch   0 Batch 11965/17275   train_loss = 3.727\n",
      "Epoch   0 Batch 11966/17275   train_loss = 6.473\n",
      "Epoch   0 Batch 11967/17275   train_loss = 2.595\n",
      "Epoch   0 Batch 11968/17275   train_loss = 4.327\n",
      "Epoch   0 Batch 11969/17275   train_loss = 2.326\n",
      "Epoch   0 Batch 11970/17275   train_loss = 3.805\n",
      "Epoch   0 Batch 11971/17275   train_loss = 3.446\n",
      "Epoch   0 Batch 11972/17275   train_loss = 2.995\n",
      "Epoch   0 Batch 11973/17275   train_loss = 3.262\n",
      "Epoch   0 Batch 11974/17275   train_loss = 7.061\n",
      "Epoch   0 Batch 11975/17275   train_loss = 3.700\n",
      "Epoch   0 Batch 11976/17275   train_loss = 3.283\n",
      "Epoch   0 Batch 11977/17275   train_loss = 2.378\n",
      "Epoch   0 Batch 11978/17275   train_loss = 7.291\n",
      "Epoch   0 Batch 11979/17275   train_loss = 2.543\n",
      "Epoch   0 Batch 11980/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 11981/17275   train_loss = 2.907\n",
      "Epoch   0 Batch 11982/17275   train_loss = 7.292\n",
      "Epoch   0 Batch 11983/17275   train_loss = 2.145\n",
      "Epoch   0 Batch 11984/17275   train_loss = 2.806\n",
      "Epoch   0 Batch 11985/17275   train_loss = 4.671\n",
      "Epoch   0 Batch 11986/17275   train_loss = 2.497\n",
      "Epoch   0 Batch 11987/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 11988/17275   train_loss = 7.287\n",
      "Epoch   0 Batch 11989/17275   train_loss = 4.873\n",
      "Epoch   0 Batch 11990/17275   train_loss = 2.328\n",
      "Epoch   0 Batch 11991/17275   train_loss = 3.201\n",
      "Epoch   0 Batch 11992/17275   train_loss = 2.544\n",
      "Epoch   0 Batch 11993/17275   train_loss = 3.128\n",
      "Epoch   0 Batch 11994/17275   train_loss = 2.805\n",
      "Epoch   0 Batch 11995/17275   train_loss = 2.347\n",
      "Epoch   0 Batch 11996/17275   train_loss = 2.673\n",
      "Epoch   0 Batch 11997/17275   train_loss = 3.299\n",
      "Epoch   0 Batch 11998/17275   train_loss = 7.005\n",
      "Epoch   0 Batch 11999/17275   train_loss = 2.736\n",
      "Epoch   0 Batch 12000/17275   train_loss = 2.809\n",
      "Epoch   0 Batch 12001/17275   train_loss = 2.157\n",
      "Epoch   0 Batch 12002/17275   train_loss = 5.514\n",
      "Epoch   0 Batch 12003/17275   train_loss = 4.333\n",
      "Epoch   0 Batch 12004/17275   train_loss = 2.114\n",
      "Epoch   0 Batch 12005/17275   train_loss = 2.865\n",
      "Epoch   0 Batch 12006/17275   train_loss = 9.637\n",
      "Epoch   0 Batch 12007/17275   train_loss = 4.062\n",
      "Epoch   0 Batch 12008/17275   train_loss = 2.964\n",
      "Epoch   0 Batch 12009/17275   train_loss = 7.792\n",
      "Epoch   0 Batch 12010/17275   train_loss = 7.632\n",
      "Epoch   0 Batch 12011/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 12012/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 12013/17275   train_loss = 6.399\n",
      "Epoch   0 Batch 12014/17275   train_loss = 2.485\n",
      "Epoch   0 Batch 12015/17275   train_loss = 3.831\n",
      "Epoch   0 Batch 12016/17275   train_loss = 4.306\n",
      "Epoch   0 Batch 12017/17275   train_loss = 2.810\n",
      "Epoch   0 Batch 12018/17275   train_loss = 2.454\n",
      "Epoch   0 Batch 12019/17275   train_loss = 2.348\n",
      "Epoch   0 Batch 12020/17275   train_loss = 3.358\n",
      "Epoch   0 Batch 12021/17275   train_loss = 3.535\n",
      "Epoch   0 Batch 12022/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 12023/17275   train_loss = 2.607\n",
      "Epoch   0 Batch 12024/17275   train_loss = 4.808\n",
      "Epoch   0 Batch 12025/17275   train_loss = 4.498\n",
      "Epoch   0 Batch 12026/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 12027/17275   train_loss = 3.409\n",
      "Epoch   0 Batch 12028/17275   train_loss = 3.992\n",
      "Epoch   0 Batch 12029/17275   train_loss = 6.327\n",
      "Epoch   0 Batch 12030/17275   train_loss = 4.186\n",
      "Epoch   0 Batch 12031/17275   train_loss = 7.058\n",
      "Epoch   0 Batch 12032/17275   train_loss = 2.287\n",
      "Epoch   0 Batch 12033/17275   train_loss = 6.639\n",
      "Epoch   0 Batch 12034/17275   train_loss = 7.062\n",
      "Epoch   0 Batch 12035/17275   train_loss = 4.297\n",
      "Epoch   0 Batch 12036/17275   train_loss = 1.901\n",
      "Epoch   0 Batch 12037/17275   train_loss = 3.733\n",
      "Epoch   0 Batch 12038/17275   train_loss = 2.945\n",
      "Epoch   0 Batch 12039/17275   train_loss = 3.946\n",
      "Epoch   0 Batch 12040/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 12041/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 12042/17275   train_loss = 3.978\n",
      "Epoch   0 Batch 12043/17275   train_loss = 3.492\n",
      "Epoch   0 Batch 12044/17275   train_loss = 3.791\n",
      "Epoch   0 Batch 12045/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 12046/17275   train_loss = 6.879\n",
      "Epoch   0 Batch 12047/17275   train_loss = 1.762\n",
      "Epoch   0 Batch 12048/17275   train_loss = 2.024\n",
      "Epoch   0 Batch 12049/17275   train_loss = 3.210\n",
      "Epoch   0 Batch 12050/17275   train_loss = 2.376\n",
      "Epoch   0 Batch 12051/17275   train_loss = 3.144\n",
      "Epoch   0 Batch 12052/17275   train_loss = 1.664\n",
      "Epoch   0 Batch 12053/17275   train_loss = 5.658\n",
      "Epoch   0 Batch 12054/17275   train_loss = 4.591\n",
      "Epoch   0 Batch 12055/17275   train_loss = 2.564\n",
      "Epoch   0 Batch 12056/17275   train_loss = 2.871\n",
      "Epoch   0 Batch 12057/17275   train_loss = 3.962\n",
      "Epoch   0 Batch 12058/17275   train_loss = 6.957\n",
      "Epoch   0 Batch 12059/17275   train_loss = 3.479\n",
      "Epoch   0 Batch 12060/17275   train_loss = 2.385\n",
      "Epoch   0 Batch 12061/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 12062/17275   train_loss = 4.881\n",
      "Epoch   0 Batch 12063/17275   train_loss = 3.270\n",
      "Epoch   0 Batch 12064/17275   train_loss = 2.831\n",
      "Epoch   0 Batch 12065/17275   train_loss = 3.975\n",
      "Epoch   0 Batch 12066/17275   train_loss = 4.067\n",
      "Epoch   0 Batch 12067/17275   train_loss = 2.921\n",
      "Epoch   0 Batch 12068/17275   train_loss = 6.390\n",
      "Epoch   0 Batch 12069/17275   train_loss = 3.850\n",
      "Epoch   0 Batch 12070/17275   train_loss = 3.533\n",
      "Epoch   0 Batch 12071/17275   train_loss = 3.355\n",
      "Epoch   0 Batch 12072/17275   train_loss = 4.081\n",
      "Epoch   0 Batch 12073/17275   train_loss = 3.013\n",
      "Epoch   0 Batch 12074/17275   train_loss = 3.637\n",
      "Epoch   0 Batch 12075/17275   train_loss = 3.734\n",
      "Epoch   0 Batch 12076/17275   train_loss = 3.271\n",
      "Epoch   0 Batch 12077/17275   train_loss = 5.593\n",
      "Epoch   0 Batch 12078/17275   train_loss = 4.719\n",
      "Epoch   0 Batch 12079/17275   train_loss = 7.169\n",
      "Epoch   0 Batch 12080/17275   train_loss = 2.689\n",
      "Epoch   0 Batch 12081/17275   train_loss = 4.647\n",
      "Epoch   0 Batch 12082/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 12083/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 12084/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 12085/17275   train_loss = 1.910\n",
      "Epoch   0 Batch 12086/17275   train_loss = 2.179\n",
      "Epoch   0 Batch 12087/17275   train_loss = 2.451\n",
      "Epoch   0 Batch 12088/17275   train_loss = 5.216\n",
      "Epoch   0 Batch 12089/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 12090/17275   train_loss = 3.376\n",
      "Epoch   0 Batch 12091/17275   train_loss = 3.199\n",
      "Epoch   0 Batch 12092/17275   train_loss = 2.509\n",
      "Epoch   0 Batch 12093/17275   train_loss = 2.906\n",
      "Epoch   0 Batch 12094/17275   train_loss = 7.799\n",
      "Epoch   0 Batch 12095/17275   train_loss = 6.905\n",
      "Epoch   0 Batch 12096/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 12097/17275   train_loss = 3.177\n",
      "Epoch   0 Batch 12098/17275   train_loss = 4.843\n",
      "Epoch   0 Batch 12099/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 12100/17275   train_loss = 3.627\n",
      "Epoch   0 Batch 12101/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 12102/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 12103/17275   train_loss = 2.394\n",
      "Epoch   0 Batch 12104/17275   train_loss = 10.280\n",
      "Epoch   0 Batch 12105/17275   train_loss = 2.770\n",
      "Epoch   0 Batch 12106/17275   train_loss = 4.364\n",
      "Epoch   0 Batch 12107/17275   train_loss = 3.786\n",
      "Epoch   0 Batch 12108/17275   train_loss = 6.812\n",
      "Epoch   0 Batch 12109/17275   train_loss = 2.576\n",
      "Epoch   0 Batch 12110/17275   train_loss = 3.420\n",
      "Epoch   0 Batch 12111/17275   train_loss = 2.361\n",
      "Epoch   0 Batch 12112/17275   train_loss = 7.581\n",
      "Epoch   0 Batch 12113/17275   train_loss = 3.414\n",
      "Epoch   0 Batch 12114/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 12115/17275   train_loss = 3.859\n",
      "Epoch   0 Batch 12116/17275   train_loss = 2.417\n",
      "Epoch   0 Batch 12117/17275   train_loss = 6.676\n",
      "Epoch   0 Batch 12118/17275   train_loss = 7.338\n",
      "Epoch   0 Batch 12119/17275   train_loss = 6.345\n",
      "Epoch   0 Batch 12120/17275   train_loss = 1.921\n",
      "Epoch   0 Batch 12121/17275   train_loss = 3.198\n",
      "Epoch   0 Batch 12122/17275   train_loss = 2.819\n",
      "Epoch   0 Batch 12123/17275   train_loss = 3.904\n",
      "Epoch   0 Batch 12124/17275   train_loss = 2.201\n",
      "Epoch   0 Batch 12125/17275   train_loss = 4.720\n",
      "Epoch   0 Batch 12126/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 12127/17275   train_loss = 3.476\n",
      "Epoch   0 Batch 12128/17275   train_loss = 3.161\n",
      "Epoch   0 Batch 12129/17275   train_loss = 3.939\n",
      "Epoch   0 Batch 12130/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 12131/17275   train_loss = 2.162\n",
      "Epoch   0 Batch 12132/17275   train_loss = 2.419\n",
      "Epoch   0 Batch 12133/17275   train_loss = 1.981\n",
      "Epoch   0 Batch 12134/17275   train_loss = 3.123\n",
      "Epoch   0 Batch 12135/17275   train_loss = 4.098\n",
      "Epoch   0 Batch 12136/17275   train_loss = 4.340\n",
      "Epoch   0 Batch 12137/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 12138/17275   train_loss = 2.639\n",
      "Epoch   0 Batch 12139/17275   train_loss = 5.260\n",
      "Epoch   0 Batch 12140/17275   train_loss = 4.223\n",
      "Epoch   0 Batch 12141/17275   train_loss = 6.352\n",
      "Epoch   0 Batch 12142/17275   train_loss = 1.901\n",
      "Epoch   0 Batch 12143/17275   train_loss = 6.118\n",
      "Epoch   0 Batch 12144/17275   train_loss = 6.918\n",
      "Epoch   0 Batch 12145/17275   train_loss = 2.728\n",
      "Epoch   0 Batch 12146/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 12147/17275   train_loss = 2.588\n",
      "Epoch   0 Batch 12148/17275   train_loss = 3.155\n",
      "Epoch   0 Batch 12149/17275   train_loss = 3.993\n",
      "Epoch   0 Batch 12150/17275   train_loss = 4.616\n",
      "Epoch   0 Batch 12151/17275   train_loss = 2.978\n",
      "Epoch   0 Batch 12152/17275   train_loss = 4.517\n",
      "Epoch   0 Batch 12153/17275   train_loss = 4.836\n",
      "Epoch   0 Batch 12154/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 12155/17275   train_loss = 6.408\n",
      "Epoch   0 Batch 12156/17275   train_loss = 2.252\n",
      "Epoch   0 Batch 12157/17275   train_loss = 3.096\n",
      "Epoch   0 Batch 12158/17275   train_loss = 6.901\n",
      "Epoch   0 Batch 12159/17275   train_loss = 3.111\n",
      "Epoch   0 Batch 12160/17275   train_loss = 2.596\n",
      "Epoch   0 Batch 12161/17275   train_loss = 3.337\n",
      "Epoch   0 Batch 12162/17275   train_loss = 5.974\n",
      "Epoch   0 Batch 12163/17275   train_loss = 4.880\n",
      "Epoch   0 Batch 12164/17275   train_loss = 3.160\n",
      "Epoch   0 Batch 12165/17275   train_loss = 5.520\n",
      "Epoch   0 Batch 12166/17275   train_loss = 1.958\n",
      "Epoch   0 Batch 12167/17275   train_loss = 3.314\n",
      "Epoch   0 Batch 12168/17275   train_loss = 3.184\n",
      "Epoch   0 Batch 12169/17275   train_loss = 3.375\n",
      "Epoch   0 Batch 12170/17275   train_loss = 2.151\n",
      "Epoch   0 Batch 12171/17275   train_loss = 2.936\n",
      "Epoch   0 Batch 12172/17275   train_loss = 4.086\n",
      "Epoch   0 Batch 12173/17275   train_loss = 3.804\n",
      "Epoch   0 Batch 12174/17275   train_loss = 3.533\n",
      "Epoch   0 Batch 12175/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 12176/17275   train_loss = 2.436\n",
      "Epoch   0 Batch 12177/17275   train_loss = 4.281\n",
      "Epoch   0 Batch 12178/17275   train_loss = 2.849\n",
      "Epoch   0 Batch 12179/17275   train_loss = 3.843\n",
      "Epoch   0 Batch 12180/17275   train_loss = 4.426\n",
      "Epoch   0 Batch 12181/17275   train_loss = 4.883\n",
      "Epoch   0 Batch 12182/17275   train_loss = 3.987\n",
      "Epoch   0 Batch 12183/17275   train_loss = 4.055\n",
      "Epoch   0 Batch 12184/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 12185/17275   train_loss = 2.473\n",
      "Epoch   0 Batch 12186/17275   train_loss = 3.761\n",
      "Epoch   0 Batch 12187/17275   train_loss = 3.798\n",
      "Epoch   0 Batch 12188/17275   train_loss = 6.800\n",
      "Epoch   0 Batch 12189/17275   train_loss = 4.266\n",
      "Epoch   0 Batch 12190/17275   train_loss = 3.800\n",
      "Epoch   0 Batch 12191/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 12192/17275   train_loss = 7.787\n",
      "Epoch   0 Batch 12193/17275   train_loss = 2.523\n",
      "Epoch   0 Batch 12194/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 12195/17275   train_loss = 2.412\n",
      "Epoch   0 Batch 12196/17275   train_loss = 4.888\n",
      "Epoch   0 Batch 12197/17275   train_loss = 3.993\n",
      "Epoch   0 Batch 12198/17275   train_loss = 3.392\n",
      "Epoch   0 Batch 12199/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 12200/17275   train_loss = 2.513\n",
      "Epoch   0 Batch 12201/17275   train_loss = 3.260\n",
      "Epoch   0 Batch 12202/17275   train_loss = 3.688\n",
      "Epoch   0 Batch 12203/17275   train_loss = 2.751\n",
      "Epoch   0 Batch 12204/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 12205/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 12206/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 12207/17275   train_loss = 6.324\n",
      "Epoch   0 Batch 12208/17275   train_loss = 4.714\n",
      "Epoch   0 Batch 12209/17275   train_loss = 6.796\n",
      "Epoch   0 Batch 12210/17275   train_loss = 1.974\n",
      "Epoch   0 Batch 12211/17275   train_loss = 2.627\n",
      "Epoch   0 Batch 12212/17275   train_loss = 4.775\n",
      "Epoch   0 Batch 12213/17275   train_loss = 3.100\n",
      "Epoch   0 Batch 12214/17275   train_loss = 6.274\n",
      "Epoch   0 Batch 12215/17275   train_loss = 1.729\n",
      "Epoch   0 Batch 12216/17275   train_loss = 3.583\n",
      "Epoch   0 Batch 12217/17275   train_loss = 2.930\n",
      "Epoch   0 Batch 12218/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 12219/17275   train_loss = 4.990\n",
      "Epoch   0 Batch 12220/17275   train_loss = 4.996\n",
      "Epoch   0 Batch 12221/17275   train_loss = 2.746\n",
      "Epoch   0 Batch 12222/17275   train_loss = 2.852\n",
      "Epoch   0 Batch 12223/17275   train_loss = 3.913\n",
      "Epoch   0 Batch 12224/17275   train_loss = 3.109\n",
      "Epoch   0 Batch 12225/17275   train_loss = 3.896\n",
      "Epoch   0 Batch 12226/17275   train_loss = 5.658\n",
      "Epoch   0 Batch 12227/17275   train_loss = 1.892\n",
      "Epoch   0 Batch 12228/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 12229/17275   train_loss = 4.411\n",
      "Epoch   0 Batch 12230/17275   train_loss = 6.894\n",
      "Epoch   0 Batch 12231/17275   train_loss = 3.703\n",
      "Epoch   0 Batch 12232/17275   train_loss = 4.624\n",
      "Epoch   0 Batch 12233/17275   train_loss = 6.183\n",
      "Epoch   0 Batch 12234/17275   train_loss = 4.127\n",
      "Epoch   0 Batch 12235/17275   train_loss = 6.318\n",
      "Epoch   0 Batch 12236/17275   train_loss = 3.735\n",
      "Epoch   0 Batch 12237/17275   train_loss = 3.426\n",
      "Epoch   0 Batch 12238/17275   train_loss = 4.428\n",
      "Epoch   0 Batch 12239/17275   train_loss = 6.440\n",
      "Epoch   0 Batch 12240/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 12241/17275   train_loss = 7.686\n",
      "Epoch   0 Batch 12242/17275   train_loss = 4.863\n",
      "Epoch   0 Batch 12243/17275   train_loss = 1.636\n",
      "Epoch   0 Batch 12244/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 12245/17275   train_loss = 3.028\n",
      "Epoch   0 Batch 12246/17275   train_loss = 4.071\n",
      "Epoch   0 Batch 12247/17275   train_loss = 2.920\n",
      "Epoch   0 Batch 12248/17275   train_loss = 3.916\n",
      "Epoch   0 Batch 12249/17275   train_loss = 2.744\n",
      "Epoch   0 Batch 12250/17275   train_loss = 6.599\n",
      "Epoch   0 Batch 12251/17275   train_loss = 2.769\n",
      "Epoch   0 Batch 12252/17275   train_loss = 4.381\n",
      "Epoch   0 Batch 12253/17275   train_loss = 2.723\n",
      "Epoch   0 Batch 12254/17275   train_loss = 4.705\n",
      "Epoch   0 Batch 12255/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 12256/17275   train_loss = 4.264\n",
      "Epoch   0 Batch 12257/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 12258/17275   train_loss = 3.951\n",
      "Epoch   0 Batch 12259/17275   train_loss = 3.388\n",
      "Epoch   0 Batch 12260/17275   train_loss = 6.818\n",
      "Epoch   0 Batch 12261/17275   train_loss = 3.899\n",
      "Epoch   0 Batch 12262/17275   train_loss = 2.404\n",
      "Epoch   0 Batch 12263/17275   train_loss = 6.559\n",
      "Epoch   0 Batch 12264/17275   train_loss = 6.696\n",
      "Epoch   0 Batch 12265/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 12266/17275   train_loss = 4.767\n",
      "Epoch   0 Batch 12267/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 12268/17275   train_loss = 6.651\n",
      "Epoch   0 Batch 12269/17275   train_loss = 2.017\n",
      "Epoch   0 Batch 12270/17275   train_loss = 2.089\n",
      "Epoch   0 Batch 12271/17275   train_loss = 3.980\n",
      "Epoch   0 Batch 12272/17275   train_loss = 7.848\n",
      "Epoch   0 Batch 12273/17275   train_loss = 4.104\n",
      "Epoch   0 Batch 12274/17275   train_loss = 3.890\n",
      "Epoch   0 Batch 12275/17275   train_loss = 2.722\n",
      "Epoch   0 Batch 12276/17275   train_loss = 7.058\n",
      "Epoch   0 Batch 12277/17275   train_loss = 2.061\n",
      "Epoch   0 Batch 12278/17275   train_loss = 3.224\n",
      "Epoch   0 Batch 12279/17275   train_loss = 3.648\n",
      "Epoch   0 Batch 12280/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 12281/17275   train_loss = 6.885\n",
      "Epoch   0 Batch 12282/17275   train_loss = 4.314\n",
      "Epoch   0 Batch 12283/17275   train_loss = 7.095\n",
      "Epoch   0 Batch 12284/17275   train_loss = 3.558\n",
      "Epoch   0 Batch 12285/17275   train_loss = 6.460\n",
      "Epoch   0 Batch 12286/17275   train_loss = 6.458\n",
      "Epoch   0 Batch 12287/17275   train_loss = 5.481\n",
      "Epoch   0 Batch 12288/17275   train_loss = 3.313\n",
      "Epoch   0 Batch 12289/17275   train_loss = 2.920\n",
      "Epoch   0 Batch 12290/17275   train_loss = 2.660\n",
      "Epoch   0 Batch 12291/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 12292/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 12293/17275   train_loss = 3.008\n",
      "Epoch   0 Batch 12294/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 12295/17275   train_loss = 5.122\n",
      "Epoch   0 Batch 12296/17275   train_loss = 1.808\n",
      "Epoch   0 Batch 12297/17275   train_loss = 2.091\n",
      "Epoch   0 Batch 12298/17275   train_loss = 4.762\n",
      "Epoch   0 Batch 12299/17275   train_loss = 2.674\n",
      "Epoch   0 Batch 12300/17275   train_loss = 6.582\n",
      "Epoch   0 Batch 12301/17275   train_loss = 3.755\n",
      "Epoch   0 Batch 12302/17275   train_loss = 2.506\n",
      "Epoch   0 Batch 12303/17275   train_loss = 4.302\n",
      "Epoch   0 Batch 12304/17275   train_loss = 6.673\n",
      "Epoch   0 Batch 12305/17275   train_loss = 7.217\n",
      "Epoch   0 Batch 12306/17275   train_loss = 1.732\n",
      "Epoch   0 Batch 12307/17275   train_loss = 1.962\n",
      "Epoch   0 Batch 12308/17275   train_loss = 3.910\n",
      "Epoch   0 Batch 12309/17275   train_loss = 2.772\n",
      "Epoch   0 Batch 12310/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 12311/17275   train_loss = 2.335\n",
      "Epoch   0 Batch 12312/17275   train_loss = 2.560\n",
      "Epoch   0 Batch 12313/17275   train_loss = 4.361\n",
      "Epoch   0 Batch 12314/17275   train_loss = 6.485\n",
      "Epoch   0 Batch 12315/17275   train_loss = 4.898\n",
      "Epoch   0 Batch 12316/17275   train_loss = 7.599\n",
      "Epoch   0 Batch 12317/17275   train_loss = 6.251\n",
      "Epoch   0 Batch 12318/17275   train_loss = 2.463\n",
      "Epoch   0 Batch 12319/17275   train_loss = 3.310\n",
      "Epoch   0 Batch 12320/17275   train_loss = 3.210\n",
      "Epoch   0 Batch 12321/17275   train_loss = 5.049\n",
      "Epoch   0 Batch 12322/17275   train_loss = 3.974\n",
      "Epoch   0 Batch 12323/17275   train_loss = 3.751\n",
      "Epoch   0 Batch 12324/17275   train_loss = 4.363\n",
      "Epoch   0 Batch 12325/17275   train_loss = 2.941\n",
      "Epoch   0 Batch 12326/17275   train_loss = 2.661\n",
      "Epoch   0 Batch 12327/17275   train_loss = 2.394\n",
      "Epoch   0 Batch 12328/17275   train_loss = 4.668\n",
      "Epoch   0 Batch 12329/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 12330/17275   train_loss = 3.447\n",
      "Epoch   0 Batch 12331/17275   train_loss = 1.926\n",
      "Epoch   0 Batch 12332/17275   train_loss = 3.642\n",
      "Epoch   0 Batch 12333/17275   train_loss = 2.693\n",
      "Epoch   0 Batch 12334/17275   train_loss = 4.394\n",
      "Epoch   0 Batch 12335/17275   train_loss = 4.032\n",
      "Epoch   0 Batch 12336/17275   train_loss = 4.618\n",
      "Epoch   0 Batch 12337/17275   train_loss = 1.908\n",
      "Epoch   0 Batch 12338/17275   train_loss = 2.622\n",
      "Epoch   0 Batch 12339/17275   train_loss = 2.597\n",
      "Epoch   0 Batch 12340/17275   train_loss = 6.720\n",
      "Epoch   0 Batch 12341/17275   train_loss = 1.899\n",
      "Epoch   0 Batch 12342/17275   train_loss = 6.938\n",
      "Epoch   0 Batch 12343/17275   train_loss = 5.587\n",
      "Epoch   0 Batch 12344/17275   train_loss = 3.135\n",
      "Epoch   0 Batch 12345/17275   train_loss = 2.628\n",
      "Epoch   0 Batch 12346/17275   train_loss = 5.134\n",
      "Epoch   0 Batch 12347/17275   train_loss = 3.870\n",
      "Epoch   0 Batch 12348/17275   train_loss = 4.061\n",
      "Epoch   0 Batch 12349/17275   train_loss = 4.121\n",
      "Epoch   0 Batch 12350/17275   train_loss = 7.422\n",
      "Epoch   0 Batch 12351/17275   train_loss = 1.913\n",
      "Epoch   0 Batch 12352/17275   train_loss = 3.140\n",
      "Epoch   0 Batch 12353/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 12354/17275   train_loss = 6.335\n",
      "Epoch   0 Batch 12355/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 12356/17275   train_loss = 3.500\n",
      "Epoch   0 Batch 12357/17275   train_loss = 3.186\n",
      "Epoch   0 Batch 12358/17275   train_loss = 3.616\n",
      "Epoch   0 Batch 12359/17275   train_loss = 4.440\n",
      "Epoch   0 Batch 12360/17275   train_loss = 10.820\n",
      "Epoch   0 Batch 12361/17275   train_loss = 6.340\n",
      "Epoch   0 Batch 12362/17275   train_loss = 2.647\n",
      "Epoch   0 Batch 12363/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 12364/17275   train_loss = 3.756\n",
      "Epoch   0 Batch 12365/17275   train_loss = 10.810\n",
      "Epoch   0 Batch 12366/17275   train_loss = 6.342\n",
      "Epoch   0 Batch 12367/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 12368/17275   train_loss = 4.523\n",
      "Epoch   0 Batch 12369/17275   train_loss = 3.023\n",
      "Epoch   0 Batch 12370/17275   train_loss = 4.487\n",
      "Epoch   0 Batch 12371/17275   train_loss = 7.355\n",
      "Epoch   0 Batch 12372/17275   train_loss = 4.626\n",
      "Epoch   0 Batch 12373/17275   train_loss = 3.011\n",
      "Epoch   0 Batch 12374/17275   train_loss = 6.967\n",
      "Epoch   0 Batch 12375/17275   train_loss = 2.592\n",
      "Epoch   0 Batch 12376/17275   train_loss = 2.848\n",
      "Epoch   0 Batch 12377/17275   train_loss = 4.835\n",
      "Epoch   0 Batch 12378/17275   train_loss = 3.564\n",
      "Epoch   0 Batch 12379/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 12380/17275   train_loss = 3.462\n",
      "Epoch   0 Batch 12381/17275   train_loss = 2.938\n",
      "Epoch   0 Batch 12382/17275   train_loss = 6.680\n",
      "Epoch   0 Batch 12383/17275   train_loss = 5.070\n",
      "Epoch   0 Batch 12384/17275   train_loss = 5.959\n",
      "Epoch   0 Batch 12385/17275   train_loss = 2.957\n",
      "Epoch   0 Batch 12386/17275   train_loss = 2.515\n",
      "Epoch   0 Batch 12387/17275   train_loss = 6.585\n",
      "Epoch   0 Batch 12388/17275   train_loss = 3.243\n",
      "Epoch   0 Batch 12389/17275   train_loss = 3.945\n",
      "Epoch   0 Batch 12390/17275   train_loss = 3.791\n",
      "Epoch   0 Batch 12391/17275   train_loss = 6.601\n",
      "Epoch   0 Batch 12392/17275   train_loss = 6.464\n",
      "Epoch   0 Batch 12393/17275   train_loss = 2.629\n",
      "Epoch   0 Batch 12394/17275   train_loss = 3.008\n",
      "Epoch   0 Batch 12395/17275   train_loss = 2.531\n",
      "Epoch   0 Batch 12396/17275   train_loss = 7.228\n",
      "Epoch   0 Batch 12397/17275   train_loss = 3.413\n",
      "Epoch   0 Batch 12398/17275   train_loss = 3.237\n",
      "Epoch   0 Batch 12399/17275   train_loss = 3.522\n",
      "Epoch   0 Batch 12400/17275   train_loss = 3.002\n",
      "Epoch   0 Batch 12401/17275   train_loss = 2.414\n",
      "Epoch   0 Batch 12402/17275   train_loss = 2.652\n",
      "Epoch   0 Batch 12403/17275   train_loss = 4.192\n",
      "Epoch   0 Batch 12404/17275   train_loss = 6.496\n",
      "Epoch   0 Batch 12405/17275   train_loss = 3.856\n",
      "Epoch   0 Batch 12406/17275   train_loss = 5.047\n",
      "Epoch   0 Batch 12407/17275   train_loss = 7.545\n",
      "Epoch   0 Batch 12408/17275   train_loss = 2.188\n",
      "Epoch   0 Batch 12409/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 12410/17275   train_loss = 2.899\n",
      "Epoch   0 Batch 12411/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 12412/17275   train_loss = 4.172\n",
      "Epoch   0 Batch 12413/17275   train_loss = 2.367\n",
      "Epoch   0 Batch 12414/17275   train_loss = 3.827\n",
      "Epoch   0 Batch 12415/17275   train_loss = 3.588\n",
      "Epoch   0 Batch 12416/17275   train_loss = 2.450\n",
      "Epoch   0 Batch 12417/17275   train_loss = 4.662\n",
      "Epoch   0 Batch 12418/17275   train_loss = 6.370\n",
      "Epoch   0 Batch 12419/17275   train_loss = 5.724\n",
      "Epoch   0 Batch 12420/17275   train_loss = 2.617\n",
      "Epoch   0 Batch 12421/17275   train_loss = 3.975\n",
      "Epoch   0 Batch 12422/17275   train_loss = 3.989\n",
      "Epoch   0 Batch 12423/17275   train_loss = 2.793\n",
      "Epoch   0 Batch 12424/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 12425/17275   train_loss = 4.698\n",
      "Epoch   0 Batch 12426/17275   train_loss = 6.982\n",
      "Epoch   0 Batch 12427/17275   train_loss = 2.539\n",
      "Epoch   0 Batch 12428/17275   train_loss = 3.174\n",
      "Epoch   0 Batch 12429/17275   train_loss = 3.847\n",
      "Epoch   0 Batch 12430/17275   train_loss = 4.577\n",
      "Epoch   0 Batch 12431/17275   train_loss = 3.576\n",
      "Epoch   0 Batch 12432/17275   train_loss = 2.082\n",
      "Epoch   0 Batch 12433/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 12434/17275   train_loss = 3.184\n",
      "Epoch   0 Batch 12435/17275   train_loss = 4.807\n",
      "Epoch   0 Batch 12436/17275   train_loss = 2.055\n",
      "Epoch   0 Batch 12437/17275   train_loss = 3.039\n",
      "Epoch   0 Batch 12438/17275   train_loss = 2.404\n",
      "Epoch   0 Batch 12439/17275   train_loss = 3.559\n",
      "Epoch   0 Batch 12440/17275   train_loss = 2.021\n",
      "Epoch   0 Batch 12441/17275   train_loss = 2.412\n",
      "Epoch   0 Batch 12442/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 12443/17275   train_loss = 3.660\n",
      "Epoch   0 Batch 12444/17275   train_loss = 3.381\n",
      "Epoch   0 Batch 12445/17275   train_loss = 3.251\n",
      "Epoch   0 Batch 12446/17275   train_loss = 2.354\n",
      "Epoch   0 Batch 12447/17275   train_loss = 3.162\n",
      "Epoch   0 Batch 12448/17275   train_loss = 3.782\n",
      "Epoch   0 Batch 12449/17275   train_loss = 4.292\n",
      "Epoch   0 Batch 12450/17275   train_loss = 4.295\n",
      "Epoch   0 Batch 12451/17275   train_loss = 6.443\n",
      "Epoch   0 Batch 12452/17275   train_loss = 1.915\n",
      "Epoch   0 Batch 12453/17275   train_loss = 3.263\n",
      "Epoch   0 Batch 12454/17275   train_loss = 2.649\n",
      "Epoch   0 Batch 12455/17275   train_loss = 7.328\n",
      "Epoch   0 Batch 12456/17275   train_loss = 5.185\n",
      "Epoch   0 Batch 12457/17275   train_loss = 2.404\n",
      "Epoch   0 Batch 12458/17275   train_loss = 8.229\n",
      "Epoch   0 Batch 12459/17275   train_loss = 2.772\n",
      "Epoch   0 Batch 12460/17275   train_loss = 6.973\n",
      "Epoch   0 Batch 12461/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 12462/17275   train_loss = 7.651\n",
      "Epoch   0 Batch 12463/17275   train_loss = 1.867\n",
      "Epoch   0 Batch 12464/17275   train_loss = 4.386\n",
      "Epoch   0 Batch 12465/17275   train_loss = 3.124\n",
      "Epoch   0 Batch 12466/17275   train_loss = 3.151\n",
      "Epoch   0 Batch 12467/17275   train_loss = 3.905\n",
      "Epoch   0 Batch 12468/17275   train_loss = 2.837\n",
      "Epoch   0 Batch 12469/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 12470/17275   train_loss = 4.608\n",
      "Epoch   0 Batch 12471/17275   train_loss = 2.696\n",
      "Epoch   0 Batch 12472/17275   train_loss = 8.480\n",
      "Epoch   0 Batch 12473/17275   train_loss = 3.594\n",
      "Epoch   0 Batch 12474/17275   train_loss = 2.308\n",
      "Epoch   0 Batch 12475/17275   train_loss = 3.530\n",
      "Epoch   0 Batch 12476/17275   train_loss = 3.600\n",
      "Epoch   0 Batch 12477/17275   train_loss = 2.257\n",
      "Epoch   0 Batch 12478/17275   train_loss = 6.859\n",
      "Epoch   0 Batch 12479/17275   train_loss = 2.843\n",
      "Epoch   0 Batch 12480/17275   train_loss = 5.346\n",
      "Epoch   0 Batch 12481/17275   train_loss = 3.793\n",
      "Epoch   0 Batch 12482/17275   train_loss = 1.933\n",
      "Epoch   0 Batch 12483/17275   train_loss = 2.622\n",
      "Epoch   0 Batch 12484/17275   train_loss = 3.314\n",
      "Epoch   0 Batch 12485/17275   train_loss = 6.797\n",
      "Epoch   0 Batch 12486/17275   train_loss = 2.955\n",
      "Epoch   0 Batch 12487/17275   train_loss = 4.010\n",
      "Epoch   0 Batch 12488/17275   train_loss = 2.423\n",
      "Epoch   0 Batch 12489/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 12490/17275   train_loss = 3.543\n",
      "Epoch   0 Batch 12491/17275   train_loss = 3.726\n",
      "Epoch   0 Batch 12492/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 12493/17275   train_loss = 3.933\n",
      "Epoch   0 Batch 12494/17275   train_loss = 3.215\n",
      "Epoch   0 Batch 12495/17275   train_loss = 2.292\n",
      "Epoch   0 Batch 12496/17275   train_loss = 6.698\n",
      "Epoch   0 Batch 12497/17275   train_loss = 3.730\n",
      "Epoch   0 Batch 12498/17275   train_loss = 3.460\n",
      "Epoch   0 Batch 12499/17275   train_loss = 2.973\n",
      "Epoch   0 Batch 12500/17275   train_loss = 3.346\n",
      "Epoch   0 Batch 12501/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 12502/17275   train_loss = 4.768\n",
      "Epoch   0 Batch 12503/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 12504/17275   train_loss = 3.121\n",
      "Epoch   0 Batch 12505/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 12506/17275   train_loss = 3.951\n",
      "Epoch   0 Batch 12507/17275   train_loss = 2.562\n",
      "Epoch   0 Batch 12508/17275   train_loss = 4.605\n",
      "Epoch   0 Batch 12509/17275   train_loss = 3.047\n",
      "Epoch   0 Batch 12510/17275   train_loss = 7.257\n",
      "Epoch   0 Batch 12511/17275   train_loss = 3.008\n",
      "Epoch   0 Batch 12512/17275   train_loss = 2.115\n",
      "Epoch   0 Batch 12513/17275   train_loss = 4.566\n",
      "Epoch   0 Batch 12514/17275   train_loss = 6.747\n",
      "Epoch   0 Batch 12515/17275   train_loss = 3.422\n",
      "Epoch   0 Batch 12516/17275   train_loss = 2.013\n",
      "Epoch   0 Batch 12517/17275   train_loss = 3.332\n",
      "Epoch   0 Batch 12518/17275   train_loss = 3.420\n",
      "Epoch   0 Batch 12519/17275   train_loss = 4.466\n",
      "Epoch   0 Batch 12520/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 12521/17275   train_loss = 3.493\n",
      "Epoch   0 Batch 12522/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 12523/17275   train_loss = 2.377\n",
      "Epoch   0 Batch 12524/17275   train_loss = 2.783\n",
      "Epoch   0 Batch 12525/17275   train_loss = 2.699\n",
      "Epoch   0 Batch 12526/17275   train_loss = 3.453\n",
      "Epoch   0 Batch 12527/17275   train_loss = 5.730\n",
      "Epoch   0 Batch 12528/17275   train_loss = 2.997\n",
      "Epoch   0 Batch 12529/17275   train_loss = 2.763\n",
      "Epoch   0 Batch 12530/17275   train_loss = 2.732\n",
      "Epoch   0 Batch 12531/17275   train_loss = 2.675\n",
      "Epoch   0 Batch 12532/17275   train_loss = 3.019\n",
      "Epoch   0 Batch 12533/17275   train_loss = 5.248\n",
      "Epoch   0 Batch 12534/17275   train_loss = 2.885\n",
      "Epoch   0 Batch 12535/17275   train_loss = 6.949\n",
      "Epoch   0 Batch 12536/17275   train_loss = 2.487\n",
      "Epoch   0 Batch 12537/17275   train_loss = 3.691\n",
      "Epoch   0 Batch 12538/17275   train_loss = 4.880\n",
      "Epoch   0 Batch 12539/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 12540/17275   train_loss = 2.648\n",
      "Epoch   0 Batch 12541/17275   train_loss = 6.749\n",
      "Epoch   0 Batch 12542/17275   train_loss = 3.438\n",
      "Epoch   0 Batch 12543/17275   train_loss = 8.204\n",
      "Epoch   0 Batch 12544/17275   train_loss = 2.986\n",
      "Epoch   0 Batch 12545/17275   train_loss = 5.009\n",
      "Epoch   0 Batch 12546/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 12547/17275   train_loss = 2.920\n",
      "Epoch   0 Batch 12548/17275   train_loss = 3.964\n",
      "Epoch   0 Batch 12549/17275   train_loss = 2.624\n",
      "Epoch   0 Batch 12550/17275   train_loss = 2.975\n",
      "Epoch   0 Batch 12551/17275   train_loss = 3.697\n",
      "Epoch   0 Batch 12552/17275   train_loss = 6.403\n",
      "Epoch   0 Batch 12553/17275   train_loss = 7.014\n",
      "Epoch   0 Batch 12554/17275   train_loss = 2.914\n",
      "Epoch   0 Batch 12555/17275   train_loss = 3.037\n",
      "Epoch   0 Batch 12556/17275   train_loss = 2.853\n",
      "Epoch   0 Batch 12557/17275   train_loss = 4.823\n",
      "Epoch   0 Batch 12558/17275   train_loss = 4.968\n",
      "Epoch   0 Batch 12559/17275   train_loss = 9.901\n",
      "Epoch   0 Batch 12560/17275   train_loss = 8.726\n",
      "Epoch   0 Batch 12561/17275   train_loss = 2.022\n",
      "Epoch   0 Batch 12562/17275   train_loss = 3.171\n",
      "Epoch   0 Batch 12563/17275   train_loss = 3.375\n",
      "Epoch   0 Batch 12564/17275   train_loss = 2.700\n",
      "Epoch   0 Batch 12565/17275   train_loss = 3.400\n",
      "Epoch   0 Batch 12566/17275   train_loss = 3.777\n",
      "Epoch   0 Batch 12567/17275   train_loss = 3.260\n",
      "Epoch   0 Batch 12568/17275   train_loss = 2.841\n",
      "Epoch   0 Batch 12569/17275   train_loss = 8.953\n",
      "Epoch   0 Batch 12570/17275   train_loss = 2.350\n",
      "Epoch   0 Batch 12571/17275   train_loss = 3.230\n",
      "Epoch   0 Batch 12572/17275   train_loss = 2.421\n",
      "Epoch   0 Batch 12573/17275   train_loss = 3.073\n",
      "Epoch   0 Batch 12574/17275   train_loss = 3.352\n",
      "Epoch   0 Batch 12575/17275   train_loss = 3.201\n",
      "Epoch   0 Batch 12576/17275   train_loss = 3.272\n",
      "Epoch   0 Batch 12577/17275   train_loss = 3.095\n",
      "Epoch   0 Batch 12578/17275   train_loss = 5.771\n",
      "Epoch   0 Batch 12579/17275   train_loss = 4.584\n",
      "Epoch   0 Batch 12580/17275   train_loss = 2.525\n",
      "Epoch   0 Batch 12581/17275   train_loss = 2.515\n",
      "Epoch   0 Batch 12582/17275   train_loss = 3.860\n",
      "Epoch   0 Batch 12583/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 12584/17275   train_loss = 1.975\n",
      "Epoch   0 Batch 12585/17275   train_loss = 2.308\n",
      "Epoch   0 Batch 12586/17275   train_loss = 3.204\n",
      "Epoch   0 Batch 12587/17275   train_loss = 3.313\n",
      "Epoch   0 Batch 12588/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 12589/17275   train_loss = 3.995\n",
      "Epoch   0 Batch 12590/17275   train_loss = 4.257\n",
      "Epoch   0 Batch 12591/17275   train_loss = 6.887\n",
      "Epoch   0 Batch 12592/17275   train_loss = 2.822\n",
      "Epoch   0 Batch 12593/17275   train_loss = 5.286\n",
      "Epoch   0 Batch 12594/17275   train_loss = 3.374\n",
      "Epoch   0 Batch 12595/17275   train_loss = 6.387\n",
      "Epoch   0 Batch 12596/17275   train_loss = 2.992\n",
      "Epoch   0 Batch 12597/17275   train_loss = 2.523\n",
      "Epoch   0 Batch 12598/17275   train_loss = 2.976\n",
      "Epoch   0 Batch 12599/17275   train_loss = 2.749\n",
      "Epoch   0 Batch 12600/17275   train_loss = 6.566\n",
      "Epoch   0 Batch 12601/17275   train_loss = 2.044\n",
      "Epoch   0 Batch 12602/17275   train_loss = 4.285\n",
      "Epoch   0 Batch 12603/17275   train_loss = 3.341\n",
      "Epoch   0 Batch 12604/17275   train_loss = 4.366\n",
      "Epoch   0 Batch 12605/17275   train_loss = 2.039\n",
      "Epoch   0 Batch 12606/17275   train_loss = 3.529\n",
      "Epoch   0 Batch 12607/17275   train_loss = 3.856\n",
      "Epoch   0 Batch 12608/17275   train_loss = 4.300\n",
      "Epoch   0 Batch 12609/17275   train_loss = 2.303\n",
      "Epoch   0 Batch 12610/17275   train_loss = 2.505\n",
      "Epoch   0 Batch 12611/17275   train_loss = 2.751\n",
      "Epoch   0 Batch 12612/17275   train_loss = 4.832\n",
      "Epoch   0 Batch 12613/17275   train_loss = 2.963\n",
      "Epoch   0 Batch 12614/17275   train_loss = 2.241\n",
      "Epoch   0 Batch 12615/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 12616/17275   train_loss = 3.922\n",
      "Epoch   0 Batch 12617/17275   train_loss = 4.575\n",
      "Epoch   0 Batch 12618/17275   train_loss = 5.359\n",
      "Epoch   0 Batch 12619/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 12620/17275   train_loss = 5.151\n",
      "Epoch   0 Batch 12621/17275   train_loss = 5.698\n",
      "Epoch   0 Batch 12622/17275   train_loss = 2.680\n",
      "Epoch   0 Batch 12623/17275   train_loss = 6.788\n",
      "Epoch   0 Batch 12624/17275   train_loss = 4.764\n",
      "Epoch   0 Batch 12625/17275   train_loss = 4.350\n",
      "Epoch   0 Batch 12626/17275   train_loss = 1.914\n",
      "Epoch   0 Batch 12627/17275   train_loss = 2.866\n",
      "Epoch   0 Batch 12628/17275   train_loss = 6.944\n",
      "Epoch   0 Batch 12629/17275   train_loss = 2.403\n",
      "Epoch   0 Batch 12630/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 12631/17275   train_loss = 3.097\n",
      "Epoch   0 Batch 12632/17275   train_loss = 3.352\n",
      "Epoch   0 Batch 12633/17275   train_loss = 4.456\n",
      "Epoch   0 Batch 12634/17275   train_loss = 3.353\n",
      "Epoch   0 Batch 12635/17275   train_loss = 7.387\n",
      "Epoch   0 Batch 12636/17275   train_loss = 7.151\n",
      "Epoch   0 Batch 12637/17275   train_loss = 7.676\n",
      "Epoch   0 Batch 12638/17275   train_loss = 3.844\n",
      "Epoch   0 Batch 12639/17275   train_loss = 5.824\n",
      "Epoch   0 Batch 12640/17275   train_loss = 1.906\n",
      "Epoch   0 Batch 12641/17275   train_loss = 3.340\n",
      "Epoch   0 Batch 12642/17275   train_loss = 2.772\n",
      "Epoch   0 Batch 12643/17275   train_loss = 2.486\n",
      "Epoch   0 Batch 12644/17275   train_loss = 3.232\n",
      "Epoch   0 Batch 12645/17275   train_loss = 2.424\n",
      "Epoch   0 Batch 12646/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 12647/17275   train_loss = 3.042\n",
      "Epoch   0 Batch 12648/17275   train_loss = 2.267\n",
      "Epoch   0 Batch 12649/17275   train_loss = 4.359\n",
      "Epoch   0 Batch 12650/17275   train_loss = 6.438\n",
      "Epoch   0 Batch 12651/17275   train_loss = 7.470\n",
      "Epoch   0 Batch 12652/17275   train_loss = 10.904\n",
      "Epoch   0 Batch 12653/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 12654/17275   train_loss = 4.447\n",
      "Epoch   0 Batch 12655/17275   train_loss = 3.659\n",
      "Epoch   0 Batch 12656/17275   train_loss = 5.245\n",
      "Epoch   0 Batch 12657/17275   train_loss = 4.003\n",
      "Epoch   0 Batch 12658/17275   train_loss = 1.844\n",
      "Epoch   0 Batch 12659/17275   train_loss = 4.080\n",
      "Epoch   0 Batch 12660/17275   train_loss = 6.787\n",
      "Epoch   0 Batch 12661/17275   train_loss = 1.971\n",
      "Epoch   0 Batch 12662/17275   train_loss = 3.039\n",
      "Epoch   0 Batch 12663/17275   train_loss = 2.751\n",
      "Epoch   0 Batch 12664/17275   train_loss = 7.775\n",
      "Epoch   0 Batch 12665/17275   train_loss = 6.934\n",
      "Epoch   0 Batch 12666/17275   train_loss = 5.401\n",
      "Epoch   0 Batch 12667/17275   train_loss = 1.947\n",
      "Epoch   0 Batch 12668/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 12669/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 12670/17275   train_loss = 5.853\n",
      "Epoch   0 Batch 12671/17275   train_loss = 8.208\n",
      "Epoch   0 Batch 12672/17275   train_loss = 1.923\n",
      "Epoch   0 Batch 12673/17275   train_loss = 4.813\n",
      "Epoch   0 Batch 12674/17275   train_loss = 7.839\n",
      "Epoch   0 Batch 12675/17275   train_loss = 3.652\n",
      "Epoch   0 Batch 12676/17275   train_loss = 6.437\n",
      "Epoch   0 Batch 12677/17275   train_loss = 6.436\n",
      "Epoch   0 Batch 12678/17275   train_loss = 7.758\n",
      "Epoch   0 Batch 12679/17275   train_loss = 4.288\n",
      "Epoch   0 Batch 12680/17275   train_loss = 3.178\n",
      "Epoch   0 Batch 12681/17275   train_loss = 2.492\n",
      "Epoch   0 Batch 12682/17275   train_loss = 2.914\n",
      "Epoch   0 Batch 12683/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 12684/17275   train_loss = 3.858\n",
      "Epoch   0 Batch 12685/17275   train_loss = 4.407\n",
      "Epoch   0 Batch 12686/17275   train_loss = 2.500\n",
      "Epoch   0 Batch 12687/17275   train_loss = 7.026\n",
      "Epoch   0 Batch 12688/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 12689/17275   train_loss = 7.346\n",
      "Epoch   0 Batch 12690/17275   train_loss = 6.813\n",
      "Epoch   0 Batch 12691/17275   train_loss = 3.903\n",
      "Epoch   0 Batch 12692/17275   train_loss = 6.422\n",
      "Epoch   0 Batch 12693/17275   train_loss = 4.147\n",
      "Epoch   0 Batch 12694/17275   train_loss = 3.765\n",
      "Epoch   0 Batch 12695/17275   train_loss = 6.439\n",
      "Epoch   0 Batch 12696/17275   train_loss = 6.769\n",
      "Epoch   0 Batch 12697/17275   train_loss = 3.343\n",
      "Epoch   0 Batch 12698/17275   train_loss = 10.859\n",
      "Epoch   0 Batch 12699/17275   train_loss = 3.881\n",
      "Epoch   0 Batch 12700/17275   train_loss = 7.041\n",
      "Epoch   0 Batch 12701/17275   train_loss = 6.725\n",
      "Epoch   0 Batch 12702/17275   train_loss = 2.592\n",
      "Epoch   0 Batch 12703/17275   train_loss = 5.580\n",
      "Epoch   0 Batch 12704/17275   train_loss = 4.149\n",
      "Epoch   0 Batch 12705/17275   train_loss = 6.569\n",
      "Epoch   0 Batch 12706/17275   train_loss = 4.098\n",
      "Epoch   0 Batch 12707/17275   train_loss = 2.109\n",
      "Epoch   0 Batch 12708/17275   train_loss = 3.089\n",
      "Epoch   0 Batch 12709/17275   train_loss = 5.708\n",
      "Epoch   0 Batch 12710/17275   train_loss = 3.500\n",
      "Epoch   0 Batch 12711/17275   train_loss = 3.803\n",
      "Epoch   0 Batch 12712/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 12713/17275   train_loss = 6.171\n",
      "Epoch   0 Batch 12714/17275   train_loss = 6.051\n",
      "Epoch   0 Batch 12715/17275   train_loss = 2.334\n",
      "Epoch   0 Batch 12716/17275   train_loss = 6.529\n",
      "Epoch   0 Batch 12717/17275   train_loss = 2.574\n",
      "Epoch   0 Batch 12718/17275   train_loss = 3.906\n",
      "Epoch   0 Batch 12719/17275   train_loss = 6.587\n",
      "Epoch   0 Batch 12720/17275   train_loss = 5.581\n",
      "Epoch   0 Batch 12721/17275   train_loss = 5.437\n",
      "Epoch   0 Batch 12722/17275   train_loss = 6.814\n",
      "Epoch   0 Batch 12723/17275   train_loss = 10.882\n",
      "Epoch   0 Batch 12724/17275   train_loss = 6.522\n",
      "Epoch   0 Batch 12725/17275   train_loss = 5.857\n",
      "Epoch   0 Batch 12726/17275   train_loss = 7.843\n",
      "Epoch   0 Batch 12727/17275   train_loss = 4.751\n",
      "Epoch   0 Batch 12728/17275   train_loss = 7.241\n",
      "Epoch   0 Batch 12729/17275   train_loss = 6.759\n",
      "Epoch   0 Batch 12730/17275   train_loss = 4.454\n",
      "Epoch   0 Batch 12731/17275   train_loss = 6.527\n",
      "Epoch   0 Batch 12732/17275   train_loss = 7.126\n",
      "Epoch   0 Batch 12733/17275   train_loss = 2.217\n",
      "Epoch   0 Batch 12734/17275   train_loss = 3.319\n",
      "Epoch   0 Batch 12735/17275   train_loss = 2.595\n",
      "Epoch   0 Batch 12736/17275   train_loss = 6.686\n",
      "Epoch   0 Batch 12737/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 12738/17275   train_loss = 3.243\n",
      "Epoch   0 Batch 12739/17275   train_loss = 4.136\n",
      "Epoch   0 Batch 12740/17275   train_loss = 4.384\n",
      "Epoch   0 Batch 12741/17275   train_loss = 2.733\n",
      "Epoch   0 Batch 12742/17275   train_loss = 3.424\n",
      "Epoch   0 Batch 12743/17275   train_loss = 3.006\n",
      "Epoch   0 Batch 12744/17275   train_loss = 7.618\n",
      "Epoch   0 Batch 12745/17275   train_loss = 6.804\n",
      "Epoch   0 Batch 12746/17275   train_loss = 2.507\n",
      "Epoch   0 Batch 12747/17275   train_loss = 2.646\n",
      "Epoch   0 Batch 12748/17275   train_loss = 2.059\n",
      "Epoch   0 Batch 12749/17275   train_loss = 2.448\n",
      "Epoch   0 Batch 12750/17275   train_loss = 3.659\n",
      "Epoch   0 Batch 12751/17275   train_loss = 4.266\n",
      "Epoch   0 Batch 12752/17275   train_loss = 6.397\n",
      "Epoch   0 Batch 12753/17275   train_loss = 3.880\n",
      "Epoch   0 Batch 12754/17275   train_loss = 4.425\n",
      "Epoch   0 Batch 12755/17275   train_loss = 7.086\n",
      "Epoch   0 Batch 12756/17275   train_loss = 2.594\n",
      "Epoch   0 Batch 12757/17275   train_loss = 6.961\n",
      "Epoch   0 Batch 12758/17275   train_loss = 6.527\n",
      "Epoch   0 Batch 12759/17275   train_loss = 6.959\n",
      "Epoch   0 Batch 12760/17275   train_loss = 5.078\n",
      "Epoch   0 Batch 12761/17275   train_loss = 4.905\n",
      "Epoch   0 Batch 12762/17275   train_loss = 2.695\n",
      "Epoch   0 Batch 12763/17275   train_loss = 3.694\n",
      "Epoch   0 Batch 12764/17275   train_loss = 2.033\n",
      "Epoch   0 Batch 12765/17275   train_loss = 2.229\n",
      "Epoch   0 Batch 12766/17275   train_loss = 9.089\n",
      "Epoch   0 Batch 12767/17275   train_loss = 3.781\n",
      "Epoch   0 Batch 12768/17275   train_loss = 3.417\n",
      "Epoch   0 Batch 12769/17275   train_loss = 1.855\n",
      "Epoch   0 Batch 12770/17275   train_loss = 2.425\n",
      "Epoch   0 Batch 12771/17275   train_loss = 2.952\n",
      "Epoch   0 Batch 12772/17275   train_loss = 3.051\n",
      "Epoch   0 Batch 12773/17275   train_loss = 4.199\n",
      "Epoch   0 Batch 12774/17275   train_loss = 2.880\n",
      "Epoch   0 Batch 12775/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 12776/17275   train_loss = 5.046\n",
      "Epoch   0 Batch 12777/17275   train_loss = 4.104\n",
      "Epoch   0 Batch 12778/17275   train_loss = 2.494\n",
      "Epoch   0 Batch 12779/17275   train_loss = 2.807\n",
      "Epoch   0 Batch 12780/17275   train_loss = 1.805\n",
      "Epoch   0 Batch 12781/17275   train_loss = 2.713\n",
      "Epoch   0 Batch 12782/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 12783/17275   train_loss = 4.143\n",
      "Epoch   0 Batch 12784/17275   train_loss = 1.754\n",
      "Epoch   0 Batch 12785/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 12786/17275   train_loss = 6.402\n",
      "Epoch   0 Batch 12787/17275   train_loss = 3.771\n",
      "Epoch   0 Batch 12788/17275   train_loss = 4.446\n",
      "Epoch   0 Batch 12789/17275   train_loss = 8.533\n",
      "Epoch   0 Batch 12790/17275   train_loss = 1.829\n",
      "Epoch   0 Batch 12791/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 12792/17275   train_loss = 2.934\n",
      "Epoch   0 Batch 12793/17275   train_loss = 2.923\n",
      "Epoch   0 Batch 12794/17275   train_loss = 2.426\n",
      "Epoch   0 Batch 12795/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 12796/17275   train_loss = 7.188\n",
      "Epoch   0 Batch 12797/17275   train_loss = 3.364\n",
      "Epoch   0 Batch 12798/17275   train_loss = 3.671\n",
      "Epoch   0 Batch 12799/17275   train_loss = 5.042\n",
      "Epoch   0 Batch 12800/17275   train_loss = 3.736\n",
      "Epoch   0 Batch 12801/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 12802/17275   train_loss = 3.377\n",
      "Epoch   0 Batch 12803/17275   train_loss = 3.456\n",
      "Epoch   0 Batch 12804/17275   train_loss = 3.082\n",
      "Epoch   0 Batch 12805/17275   train_loss = 4.410\n",
      "Epoch   0 Batch 12806/17275   train_loss = 6.937\n",
      "Epoch   0 Batch 12807/17275   train_loss = 2.966\n",
      "Epoch   0 Batch 12808/17275   train_loss = 5.018\n",
      "Epoch   0 Batch 12809/17275   train_loss = 4.506\n",
      "Epoch   0 Batch 12810/17275   train_loss = 3.304\n",
      "Epoch   0 Batch 12811/17275   train_loss = 2.243\n",
      "Epoch   0 Batch 12812/17275   train_loss = 3.918\n",
      "Epoch   0 Batch 12813/17275   train_loss = 6.890\n",
      "Epoch   0 Batch 12814/17275   train_loss = 3.429\n",
      "Epoch   0 Batch 12815/17275   train_loss = 7.914\n",
      "Epoch   0 Batch 12816/17275   train_loss = 2.398\n",
      "Epoch   0 Batch 12817/17275   train_loss = 6.906\n",
      "Epoch   0 Batch 12818/17275   train_loss = 4.156\n",
      "Epoch   0 Batch 12819/17275   train_loss = 9.551\n",
      "Epoch   0 Batch 12820/17275   train_loss = 1.896\n",
      "Epoch   0 Batch 12821/17275   train_loss = 3.949\n",
      "Epoch   0 Batch 12822/17275   train_loss = 2.159\n",
      "Epoch   0 Batch 12823/17275   train_loss = 4.026\n",
      "Epoch   0 Batch 12824/17275   train_loss = 2.486\n",
      "Epoch   0 Batch 12825/17275   train_loss = 2.792\n",
      "Epoch   0 Batch 12826/17275   train_loss = 3.002\n",
      "Epoch   0 Batch 12827/17275   train_loss = 7.354\n",
      "Epoch   0 Batch 12828/17275   train_loss = 6.823\n",
      "Epoch   0 Batch 12829/17275   train_loss = 7.258\n",
      "Epoch   0 Batch 12830/17275   train_loss = 2.613\n",
      "Epoch   0 Batch 12831/17275   train_loss = 3.123\n",
      "Epoch   0 Batch 12832/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 12833/17275   train_loss = 6.368\n",
      "Epoch   0 Batch 12834/17275   train_loss = 2.294\n",
      "Epoch   0 Batch 12835/17275   train_loss = 1.938\n",
      "Epoch   0 Batch 12836/17275   train_loss = 5.530\n",
      "Epoch   0 Batch 12837/17275   train_loss = 6.956\n",
      "Epoch   0 Batch 12838/17275   train_loss = 4.737\n",
      "Epoch   0 Batch 12839/17275   train_loss = 2.072\n",
      "Epoch   0 Batch 12840/17275   train_loss = 3.327\n",
      "Epoch   0 Batch 12841/17275   train_loss = 2.177\n",
      "Epoch   0 Batch 12842/17275   train_loss = 4.080\n",
      "Epoch   0 Batch 12843/17275   train_loss = 4.367\n",
      "Epoch   0 Batch 12844/17275   train_loss = 2.932\n",
      "Epoch   0 Batch 12845/17275   train_loss = 5.129\n",
      "Epoch   0 Batch 12846/17275   train_loss = 3.961\n",
      "Epoch   0 Batch 12847/17275   train_loss = 2.229\n",
      "Epoch   0 Batch 12848/17275   train_loss = 3.003\n",
      "Epoch   0 Batch 12849/17275   train_loss = 6.750\n",
      "Epoch   0 Batch 12850/17275   train_loss = 4.004\n",
      "Epoch   0 Batch 12851/17275   train_loss = 1.826\n",
      "Epoch   0 Batch 12852/17275   train_loss = 1.948\n",
      "Epoch   0 Batch 12853/17275   train_loss = 4.469\n",
      "Epoch   0 Batch 12854/17275   train_loss = 4.117\n",
      "Epoch   0 Batch 12855/17275   train_loss = 4.757\n",
      "Epoch   0 Batch 12856/17275   train_loss = 3.619\n",
      "Epoch   0 Batch 12857/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 12858/17275   train_loss = 4.589\n",
      "Epoch   0 Batch 12859/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 12860/17275   train_loss = 10.900\n",
      "Epoch   0 Batch 12861/17275   train_loss = 6.298\n",
      "Epoch   0 Batch 12862/17275   train_loss = 2.919\n",
      "Epoch   0 Batch 12863/17275   train_loss = 4.791\n",
      "Epoch   0 Batch 12864/17275   train_loss = 3.739\n",
      "Epoch   0 Batch 12865/17275   train_loss = 6.293\n",
      "Epoch   0 Batch 12866/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 12867/17275   train_loss = 3.240\n",
      "Epoch   0 Batch 12868/17275   train_loss = 7.641\n",
      "Epoch   0 Batch 12869/17275   train_loss = 2.830\n",
      "Epoch   0 Batch 12870/17275   train_loss = 2.425\n",
      "Epoch   0 Batch 12871/17275   train_loss = 4.950\n",
      "Epoch   0 Batch 12872/17275   train_loss = 3.250\n",
      "Epoch   0 Batch 12873/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 12874/17275   train_loss = 4.090\n",
      "Epoch   0 Batch 12875/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 12876/17275   train_loss = 2.948\n",
      "Epoch   0 Batch 12877/17275   train_loss = 4.152\n",
      "Epoch   0 Batch 12878/17275   train_loss = 7.804\n",
      "Epoch   0 Batch 12879/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 12880/17275   train_loss = 1.815\n",
      "Epoch   0 Batch 12881/17275   train_loss = 3.630\n",
      "Epoch   0 Batch 12882/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 12883/17275   train_loss = 3.564\n",
      "Epoch   0 Batch 12884/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 12885/17275   train_loss = 5.618\n",
      "Epoch   0 Batch 12886/17275   train_loss = 2.680\n",
      "Epoch   0 Batch 12887/17275   train_loss = 3.040\n",
      "Epoch   0 Batch 12888/17275   train_loss = 2.510\n",
      "Epoch   0 Batch 12889/17275   train_loss = 3.530\n",
      "Epoch   0 Batch 12890/17275   train_loss = 2.890\n",
      "Epoch   0 Batch 12891/17275   train_loss = 6.736\n",
      "Epoch   0 Batch 12892/17275   train_loss = 3.616\n",
      "Epoch   0 Batch 12893/17275   train_loss = 5.373\n",
      "Epoch   0 Batch 12894/17275   train_loss = 3.216\n",
      "Epoch   0 Batch 12895/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 12896/17275   train_loss = 3.276\n",
      "Epoch   0 Batch 12897/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 12898/17275   train_loss = 3.709\n",
      "Epoch   0 Batch 12899/17275   train_loss = 3.787\n",
      "Epoch   0 Batch 12900/17275   train_loss = 2.369\n",
      "Epoch   0 Batch 12901/17275   train_loss = 5.690\n",
      "Epoch   0 Batch 12902/17275   train_loss = 2.326\n",
      "Epoch   0 Batch 12903/17275   train_loss = 3.457\n",
      "Epoch   0 Batch 12904/17275   train_loss = 2.846\n",
      "Epoch   0 Batch 12905/17275   train_loss = 3.734\n",
      "Epoch   0 Batch 12906/17275   train_loss = 3.542\n",
      "Epoch   0 Batch 12907/17275   train_loss = 3.272\n",
      "Epoch   0 Batch 12908/17275   train_loss = 2.506\n",
      "Epoch   0 Batch 12909/17275   train_loss = 3.034\n",
      "Epoch   0 Batch 12910/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 12911/17275   train_loss = 2.287\n",
      "Epoch   0 Batch 12912/17275   train_loss = 2.895\n",
      "Epoch   0 Batch 12913/17275   train_loss = 2.595\n",
      "Epoch   0 Batch 12914/17275   train_loss = 2.752\n",
      "Epoch   0 Batch 12915/17275   train_loss = 3.134\n",
      "Epoch   0 Batch 12916/17275   train_loss = 4.789\n",
      "Epoch   0 Batch 12917/17275   train_loss = 3.557\n",
      "Epoch   0 Batch 12918/17275   train_loss = 4.077\n",
      "Epoch   0 Batch 12919/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 12920/17275   train_loss = 4.856\n",
      "Epoch   0 Batch 12921/17275   train_loss = 7.097\n",
      "Epoch   0 Batch 12922/17275   train_loss = 6.477\n",
      "Epoch   0 Batch 12923/17275   train_loss = 2.202\n",
      "Epoch   0 Batch 12924/17275   train_loss = 5.177\n",
      "Epoch   0 Batch 12925/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 12926/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 12927/17275   train_loss = 3.202\n",
      "Epoch   0 Batch 12928/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 12929/17275   train_loss = 4.223\n",
      "Epoch   0 Batch 12930/17275   train_loss = 2.290\n",
      "Epoch   0 Batch 12931/17275   train_loss = 2.929\n",
      "Epoch   0 Batch 12932/17275   train_loss = 2.009\n",
      "Epoch   0 Batch 12933/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 12934/17275   train_loss = 3.709\n",
      "Epoch   0 Batch 12935/17275   train_loss = 4.255\n",
      "Epoch   0 Batch 12936/17275   train_loss = 2.219\n",
      "Epoch   0 Batch 12937/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 12938/17275   train_loss = 1.986\n",
      "Epoch   0 Batch 12939/17275   train_loss = 3.285\n",
      "Epoch   0 Batch 12940/17275   train_loss = 2.931\n",
      "Epoch   0 Batch 12941/17275   train_loss = 7.663\n",
      "Epoch   0 Batch 12942/17275   train_loss = 2.999\n",
      "Epoch   0 Batch 12943/17275   train_loss = 2.295\n",
      "Epoch   0 Batch 12944/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 12945/17275   train_loss = 4.310\n",
      "Epoch   0 Batch 12946/17275   train_loss = 3.209\n",
      "Epoch   0 Batch 12947/17275   train_loss = 2.003\n",
      "Epoch   0 Batch 12948/17275   train_loss = 2.482\n",
      "Epoch   0 Batch 12949/17275   train_loss = 3.312\n",
      "Epoch   0 Batch 12950/17275   train_loss = 4.470\n",
      "Epoch   0 Batch 12951/17275   train_loss = 3.452\n",
      "Epoch   0 Batch 12952/17275   train_loss = 1.966\n",
      "Epoch   0 Batch 12953/17275   train_loss = 2.863\n",
      "Epoch   0 Batch 12954/17275   train_loss = 5.671\n",
      "Epoch   0 Batch 12955/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 12956/17275   train_loss = 2.634\n",
      "Epoch   0 Batch 12957/17275   train_loss = 5.815\n",
      "Epoch   0 Batch 12958/17275   train_loss = 2.389\n",
      "Epoch   0 Batch 12959/17275   train_loss = 5.254\n",
      "Epoch   0 Batch 12960/17275   train_loss = 3.373\n",
      "Epoch   0 Batch 12961/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 12962/17275   train_loss = 3.241\n",
      "Epoch   0 Batch 12963/17275   train_loss = 2.962\n",
      "Epoch   0 Batch 12964/17275   train_loss = 2.195\n",
      "Epoch   0 Batch 12965/17275   train_loss = 4.491\n",
      "Epoch   0 Batch 12966/17275   train_loss = 2.581\n",
      "Epoch   0 Batch 12967/17275   train_loss = 4.809\n",
      "Epoch   0 Batch 12968/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 12969/17275   train_loss = 3.172\n",
      "Epoch   0 Batch 12970/17275   train_loss = 2.719\n",
      "Epoch   0 Batch 12971/17275   train_loss = 3.582\n",
      "Epoch   0 Batch 12972/17275   train_loss = 2.998\n",
      "Epoch   0 Batch 12973/17275   train_loss = 2.803\n",
      "Epoch   0 Batch 12974/17275   train_loss = 1.940\n",
      "Epoch   0 Batch 12975/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 12976/17275   train_loss = 6.808\n",
      "Epoch   0 Batch 12977/17275   train_loss = 7.426\n",
      "Epoch   0 Batch 12978/17275   train_loss = 5.613\n",
      "Epoch   0 Batch 12979/17275   train_loss = 7.474\n",
      "Epoch   0 Batch 12980/17275   train_loss = 4.048\n",
      "Epoch   0 Batch 12981/17275   train_loss = 6.545\n",
      "Epoch   0 Batch 12982/17275   train_loss = 6.086\n",
      "Epoch   0 Batch 12983/17275   train_loss = 6.564\n",
      "Epoch   0 Batch 12984/17275   train_loss = 4.677\n",
      "Epoch   0 Batch 12985/17275   train_loss = 1.958\n",
      "Epoch   0 Batch 12986/17275   train_loss = 2.535\n",
      "Epoch   0 Batch 12987/17275   train_loss = 3.852\n",
      "Epoch   0 Batch 12988/17275   train_loss = 6.537\n",
      "Epoch   0 Batch 12989/17275   train_loss = 2.377\n",
      "Epoch   0 Batch 12990/17275   train_loss = 6.258\n",
      "Epoch   0 Batch 12991/17275   train_loss = 6.361\n",
      "Epoch   0 Batch 12992/17275   train_loss = 6.557\n",
      "Epoch   0 Batch 12993/17275   train_loss = 6.353\n",
      "Epoch   0 Batch 12994/17275   train_loss = 2.750\n",
      "Epoch   0 Batch 12995/17275   train_loss = 6.515\n",
      "Epoch   0 Batch 12996/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 12997/17275   train_loss = 4.054\n",
      "Epoch   0 Batch 12998/17275   train_loss = 7.063\n",
      "Epoch   0 Batch 12999/17275   train_loss = 1.691\n",
      "Epoch   0 Batch 13000/17275   train_loss = 1.884\n",
      "Epoch   0 Batch 13001/17275   train_loss = 5.838\n",
      "Epoch   0 Batch 13002/17275   train_loss = 6.261\n",
      "Epoch   0 Batch 13003/17275   train_loss = 4.085\n",
      "Epoch   0 Batch 13004/17275   train_loss = 6.450\n",
      "Epoch   0 Batch 13005/17275   train_loss = 3.506\n",
      "Epoch   0 Batch 13006/17275   train_loss = 3.659\n",
      "Epoch   0 Batch 13007/17275   train_loss = 4.133\n",
      "Epoch   0 Batch 13008/17275   train_loss = 2.087\n",
      "Epoch   0 Batch 13009/17275   train_loss = 3.822\n",
      "Epoch   0 Batch 13010/17275   train_loss = 4.469\n",
      "Epoch   0 Batch 13011/17275   train_loss = 4.378\n",
      "Epoch   0 Batch 13012/17275   train_loss = 4.246\n",
      "Epoch   0 Batch 13013/17275   train_loss = 2.892\n",
      "Epoch   0 Batch 13014/17275   train_loss = 3.307\n",
      "Epoch   0 Batch 13015/17275   train_loss = 2.716\n",
      "Epoch   0 Batch 13016/17275   train_loss = 2.222\n",
      "Epoch   0 Batch 13017/17275   train_loss = 3.222\n",
      "Epoch   0 Batch 13018/17275   train_loss = 5.421\n",
      "Epoch   0 Batch 13019/17275   train_loss = 3.502\n",
      "Epoch   0 Batch 13020/17275   train_loss = 4.795\n",
      "Epoch   0 Batch 13021/17275   train_loss = 3.149\n",
      "Epoch   0 Batch 13022/17275   train_loss = 10.976\n",
      "Epoch   0 Batch 13023/17275   train_loss = 6.367\n",
      "Epoch   0 Batch 13024/17275   train_loss = 2.300\n",
      "Epoch   0 Batch 13025/17275   train_loss = 3.405\n",
      "Epoch   0 Batch 13026/17275   train_loss = 3.153\n",
      "Epoch   0 Batch 13027/17275   train_loss = 6.457\n",
      "Epoch   0 Batch 13028/17275   train_loss = 4.263\n",
      "Epoch   0 Batch 13029/17275   train_loss = 2.655\n",
      "Epoch   0 Batch 13030/17275   train_loss = 3.033\n",
      "Epoch   0 Batch 13031/17275   train_loss = 6.151\n",
      "Epoch   0 Batch 13032/17275   train_loss = 1.890\n",
      "Epoch   0 Batch 13033/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 13034/17275   train_loss = 1.857\n",
      "Epoch   0 Batch 13035/17275   train_loss = 9.413\n",
      "Epoch   0 Batch 13036/17275   train_loss = 1.788\n",
      "Epoch   0 Batch 13037/17275   train_loss = 1.816\n",
      "Epoch   0 Batch 13038/17275   train_loss = 6.770\n",
      "Epoch   0 Batch 13039/17275   train_loss = 5.094\n",
      "Epoch   0 Batch 13040/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 13041/17275   train_loss = 3.460\n",
      "Epoch   0 Batch 13042/17275   train_loss = 2.833\n",
      "Epoch   0 Batch 13043/17275   train_loss = 2.200\n",
      "Epoch   0 Batch 13044/17275   train_loss = 7.356\n",
      "Epoch   0 Batch 13045/17275   train_loss = 6.790\n",
      "Epoch   0 Batch 13046/17275   train_loss = 5.896\n",
      "Epoch   0 Batch 13047/17275   train_loss = 3.458\n",
      "Epoch   0 Batch 13048/17275   train_loss = 6.764\n",
      "Epoch   0 Batch 13049/17275   train_loss = 1.745\n",
      "Epoch   0 Batch 13050/17275   train_loss = 2.831\n",
      "Epoch   0 Batch 13051/17275   train_loss = 6.886\n",
      "Epoch   0 Batch 13052/17275   train_loss = 2.731\n",
      "Epoch   0 Batch 13053/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 13054/17275   train_loss = 2.876\n",
      "Epoch   0 Batch 13055/17275   train_loss = 2.890\n",
      "Epoch   0 Batch 13056/17275   train_loss = 2.381\n",
      "Epoch   0 Batch 13057/17275   train_loss = 2.517\n",
      "Epoch   0 Batch 13058/17275   train_loss = 4.916\n",
      "Epoch   0 Batch 13059/17275   train_loss = 7.948\n",
      "Epoch   0 Batch 13060/17275   train_loss = 4.161\n",
      "Epoch   0 Batch 13061/17275   train_loss = 2.385\n",
      "Epoch   0 Batch 13062/17275   train_loss = 2.876\n",
      "Epoch   0 Batch 13063/17275   train_loss = 3.085\n",
      "Epoch   0 Batch 13064/17275   train_loss = 6.682\n",
      "Epoch   0 Batch 13065/17275   train_loss = 7.491\n",
      "Epoch   0 Batch 13066/17275   train_loss = 1.868\n",
      "Epoch   0 Batch 13067/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 13068/17275   train_loss = 4.275\n",
      "Epoch   0 Batch 13069/17275   train_loss = 3.884\n",
      "Epoch   0 Batch 13070/17275   train_loss = 6.794\n",
      "Epoch   0 Batch 13071/17275   train_loss = 2.303\n",
      "Epoch   0 Batch 13072/17275   train_loss = 2.618\n",
      "Epoch   0 Batch 13073/17275   train_loss = 7.364\n",
      "Epoch   0 Batch 13074/17275   train_loss = 4.950\n",
      "Epoch   0 Batch 13075/17275   train_loss = 6.800\n",
      "Epoch   0 Batch 13076/17275   train_loss = 3.604\n",
      "Epoch   0 Batch 13077/17275   train_loss = 3.642\n",
      "Epoch   0 Batch 13078/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 13079/17275   train_loss = 2.317\n",
      "Epoch   0 Batch 13080/17275   train_loss = 6.465\n",
      "Epoch   0 Batch 13081/17275   train_loss = 3.019\n",
      "Epoch   0 Batch 13082/17275   train_loss = 2.949\n",
      "Epoch   0 Batch 13083/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 13084/17275   train_loss = 2.799\n",
      "Epoch   0 Batch 13085/17275   train_loss = 2.254\n",
      "Epoch   0 Batch 13086/17275   train_loss = 6.517\n",
      "Epoch   0 Batch 13087/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 13088/17275   train_loss = 2.476\n",
      "Epoch   0 Batch 13089/17275   train_loss = 6.279\n",
      "Epoch   0 Batch 13090/17275   train_loss = 4.081\n",
      "Epoch   0 Batch 13091/17275   train_loss = 6.184\n",
      "Epoch   0 Batch 13092/17275   train_loss = 6.751\n",
      "Epoch   0 Batch 13093/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 13094/17275   train_loss = 3.110\n",
      "Epoch   0 Batch 13095/17275   train_loss = 2.952\n",
      "Epoch   0 Batch 13096/17275   train_loss = 2.205\n",
      "Epoch   0 Batch 13097/17275   train_loss = 4.209\n",
      "Epoch   0 Batch 13098/17275   train_loss = 2.609\n",
      "Epoch   0 Batch 13099/17275   train_loss = 5.291\n",
      "Epoch   0 Batch 13100/17275   train_loss = 4.206\n",
      "Epoch   0 Batch 13101/17275   train_loss = 6.548\n",
      "Epoch   0 Batch 13102/17275   train_loss = 6.478\n",
      "Epoch   0 Batch 13103/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 13104/17275   train_loss = 3.849\n",
      "Epoch   0 Batch 13105/17275   train_loss = 3.935\n",
      "Epoch   0 Batch 13106/17275   train_loss = 2.003\n",
      "Epoch   0 Batch 13107/17275   train_loss = 2.806\n",
      "Epoch   0 Batch 13108/17275   train_loss = 3.473\n",
      "Epoch   0 Batch 13109/17275   train_loss = 4.505\n",
      "Epoch   0 Batch 13110/17275   train_loss = 2.214\n",
      "Epoch   0 Batch 13111/17275   train_loss = 3.656\n",
      "Epoch   0 Batch 13112/17275   train_loss = 2.803\n",
      "Epoch   0 Batch 13113/17275   train_loss = 6.514\n",
      "Epoch   0 Batch 13114/17275   train_loss = 5.006\n",
      "Epoch   0 Batch 13115/17275   train_loss = 4.455\n",
      "Epoch   0 Batch 13116/17275   train_loss = 6.562\n",
      "Epoch   0 Batch 13117/17275   train_loss = 4.456\n",
      "Epoch   0 Batch 13118/17275   train_loss = 4.299\n",
      "Epoch   0 Batch 13119/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 13120/17275   train_loss = 2.809\n",
      "Epoch   0 Batch 13121/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 13122/17275   train_loss = 7.900\n",
      "Epoch   0 Batch 13123/17275   train_loss = 2.416\n",
      "Epoch   0 Batch 13124/17275   train_loss = 2.389\n",
      "Epoch   0 Batch 13125/17275   train_loss = 3.261\n",
      "Epoch   0 Batch 13126/17275   train_loss = 3.624\n",
      "Epoch   0 Batch 13127/17275   train_loss = 4.860\n",
      "Epoch   0 Batch 13128/17275   train_loss = 3.660\n",
      "Epoch   0 Batch 13129/17275   train_loss = 5.748\n",
      "Epoch   0 Batch 13130/17275   train_loss = 5.830\n",
      "Epoch   0 Batch 13131/17275   train_loss = 3.688\n",
      "Epoch   0 Batch 13132/17275   train_loss = 2.345\n",
      "Epoch   0 Batch 13133/17275   train_loss = 4.274\n",
      "Epoch   0 Batch 13134/17275   train_loss = 1.931\n",
      "Epoch   0 Batch 13135/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 13136/17275   train_loss = 5.443\n",
      "Epoch   0 Batch 13137/17275   train_loss = 3.552\n",
      "Epoch   0 Batch 13138/17275   train_loss = 3.177\n",
      "Epoch   0 Batch 13139/17275   train_loss = 7.783\n",
      "Epoch   0 Batch 13140/17275   train_loss = 1.927\n",
      "Epoch   0 Batch 13141/17275   train_loss = 3.766\n",
      "Epoch   0 Batch 13142/17275   train_loss = 2.876\n",
      "Epoch   0 Batch 13143/17275   train_loss = 4.662\n",
      "Epoch   0 Batch 13144/17275   train_loss = 10.939\n",
      "Epoch   0 Batch 13145/17275   train_loss = 7.512\n",
      "Epoch   0 Batch 13146/17275   train_loss = 3.744\n",
      "Epoch   0 Batch 13147/17275   train_loss = 4.287\n",
      "Epoch   0 Batch 13148/17275   train_loss = 1.893\n",
      "Epoch   0 Batch 13149/17275   train_loss = 2.392\n",
      "Epoch   0 Batch 13150/17275   train_loss = 6.099\n",
      "Epoch   0 Batch 13151/17275   train_loss = 6.564\n",
      "Epoch   0 Batch 13152/17275   train_loss = 1.908\n",
      "Epoch   0 Batch 13153/17275   train_loss = 2.913\n",
      "Epoch   0 Batch 13154/17275   train_loss = 7.475\n",
      "Epoch   0 Batch 13155/17275   train_loss = 3.004\n",
      "Epoch   0 Batch 13156/17275   train_loss = 2.995\n",
      "Epoch   0 Batch 13157/17275   train_loss = 6.551\n",
      "Epoch   0 Batch 13158/17275   train_loss = 6.535\n",
      "Epoch   0 Batch 13159/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 13160/17275   train_loss = 3.533\n",
      "Epoch   0 Batch 13161/17275   train_loss = 4.506\n",
      "Epoch   0 Batch 13162/17275   train_loss = 3.542\n",
      "Epoch   0 Batch 13163/17275   train_loss = 7.408\n",
      "Epoch   0 Batch 13164/17275   train_loss = 2.980\n",
      "Epoch   0 Batch 13165/17275   train_loss = 7.872\n",
      "Epoch   0 Batch 13166/17275   train_loss = 1.938\n",
      "Epoch   0 Batch 13167/17275   train_loss = 2.721\n",
      "Epoch   0 Batch 13168/17275   train_loss = 6.873\n",
      "Epoch   0 Batch 13169/17275   train_loss = 3.083\n",
      "Epoch   0 Batch 13170/17275   train_loss = 2.736\n",
      "Epoch   0 Batch 13171/17275   train_loss = 4.684\n",
      "Epoch   0 Batch 13172/17275   train_loss = 7.813\n",
      "Epoch   0 Batch 13173/17275   train_loss = 5.231\n",
      "Epoch   0 Batch 13174/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 13175/17275   train_loss = 2.875\n",
      "Epoch   0 Batch 13176/17275   train_loss = 4.057\n",
      "Epoch   0 Batch 13177/17275   train_loss = 6.789\n",
      "Epoch   0 Batch 13178/17275   train_loss = 8.643\n",
      "Epoch   0 Batch 13179/17275   train_loss = 6.785\n",
      "Epoch   0 Batch 13180/17275   train_loss = 6.968\n",
      "Epoch   0 Batch 13181/17275   train_loss = 10.940\n",
      "Epoch   0 Batch 13182/17275   train_loss = 1.983\n",
      "Epoch   0 Batch 13183/17275   train_loss = 3.059\n",
      "Epoch   0 Batch 13184/17275   train_loss = 2.703\n",
      "Epoch   0 Batch 13185/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 13186/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 13187/17275   train_loss = 4.987\n",
      "Epoch   0 Batch 13188/17275   train_loss = 5.030\n",
      "Epoch   0 Batch 13189/17275   train_loss = 1.983\n",
      "Epoch   0 Batch 13190/17275   train_loss = 6.787\n",
      "Epoch   0 Batch 13191/17275   train_loss = 2.363\n",
      "Epoch   0 Batch 13192/17275   train_loss = 10.931\n",
      "Epoch   0 Batch 13193/17275   train_loss = 1.973\n",
      "Epoch   0 Batch 13194/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 13195/17275   train_loss = 2.552\n",
      "Epoch   0 Batch 13196/17275   train_loss = 3.036\n",
      "Epoch   0 Batch 13197/17275   train_loss = 1.956\n",
      "Epoch   0 Batch 13198/17275   train_loss = 2.546\n",
      "Epoch   0 Batch 13199/17275   train_loss = 6.733\n",
      "Epoch   0 Batch 13200/17275   train_loss = 7.016\n",
      "Epoch   0 Batch 13201/17275   train_loss = 5.567\n",
      "Epoch   0 Batch 13202/17275   train_loss = 6.722\n",
      "Epoch   0 Batch 13203/17275   train_loss = 6.780\n",
      "Epoch   0 Batch 13204/17275   train_loss = 5.350\n",
      "Epoch   0 Batch 13205/17275   train_loss = 6.471\n",
      "Epoch   0 Batch 13206/17275   train_loss = 2.158\n",
      "Epoch   0 Batch 13207/17275   train_loss = 4.975\n",
      "Epoch   0 Batch 13208/17275   train_loss = 3.293\n",
      "Epoch   0 Batch 13209/17275   train_loss = 4.354\n",
      "Epoch   0 Batch 13210/17275   train_loss = 5.127\n",
      "Epoch   0 Batch 13211/17275   train_loss = 1.966\n",
      "Epoch   0 Batch 13212/17275   train_loss = 3.596\n",
      "Epoch   0 Batch 13213/17275   train_loss = 1.933\n",
      "Epoch   0 Batch 13214/17275   train_loss = 1.962\n",
      "Epoch   0 Batch 13215/17275   train_loss = 6.742\n",
      "Epoch   0 Batch 13216/17275   train_loss = 6.949\n",
      "Epoch   0 Batch 13217/17275   train_loss = 3.977\n",
      "Epoch   0 Batch 13218/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 13219/17275   train_loss = 2.438\n",
      "Epoch   0 Batch 13220/17275   train_loss = 3.976\n",
      "Epoch   0 Batch 13221/17275   train_loss = 1.873\n",
      "Epoch   0 Batch 13222/17275   train_loss = 1.989\n",
      "Epoch   0 Batch 13223/17275   train_loss = 3.618\n",
      "Epoch   0 Batch 13224/17275   train_loss = 3.513\n",
      "Epoch   0 Batch 13225/17275   train_loss = 2.094\n",
      "Epoch   0 Batch 13226/17275   train_loss = 4.180\n",
      "Epoch   0 Batch 13227/17275   train_loss = 3.507\n",
      "Epoch   0 Batch 13228/17275   train_loss = 2.018\n",
      "Epoch   0 Batch 13229/17275   train_loss = 3.839\n",
      "Epoch   0 Batch 13230/17275   train_loss = 3.964\n",
      "Epoch   0 Batch 13231/17275   train_loss = 7.559\n",
      "Epoch   0 Batch 13232/17275   train_loss = 5.421\n",
      "Epoch   0 Batch 13233/17275   train_loss = 2.307\n",
      "Epoch   0 Batch 13234/17275   train_loss = 4.548\n",
      "Epoch   0 Batch 13235/17275   train_loss = 4.236\n",
      "Epoch   0 Batch 13236/17275   train_loss = 4.173\n",
      "Epoch   0 Batch 13237/17275   train_loss = 2.559\n",
      "Epoch   0 Batch 13238/17275   train_loss = 1.886\n",
      "Epoch   0 Batch 13239/17275   train_loss = 5.215\n",
      "Epoch   0 Batch 13240/17275   train_loss = 3.318\n",
      "Epoch   0 Batch 13241/17275   train_loss = 1.794\n",
      "Epoch   0 Batch 13242/17275   train_loss = 1.745\n",
      "Epoch   0 Batch 13243/17275   train_loss = 2.844\n",
      "Epoch   0 Batch 13244/17275   train_loss = 3.187\n",
      "Epoch   0 Batch 13245/17275   train_loss = 3.810\n",
      "Epoch   0 Batch 13246/17275   train_loss = 6.839\n",
      "Epoch   0 Batch 13247/17275   train_loss = 2.195\n",
      "Epoch   0 Batch 13248/17275   train_loss = 3.530\n",
      "Epoch   0 Batch 13249/17275   train_loss = 3.319\n",
      "Epoch   0 Batch 13250/17275   train_loss = 4.375\n",
      "Epoch   0 Batch 13251/17275   train_loss = 3.193\n",
      "Epoch   0 Batch 13252/17275   train_loss = 2.589\n",
      "Epoch   0 Batch 13253/17275   train_loss = 4.309\n",
      "Epoch   0 Batch 13254/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 13255/17275   train_loss = 3.319\n",
      "Epoch   0 Batch 13256/17275   train_loss = 3.658\n",
      "Epoch   0 Batch 13257/17275   train_loss = 1.952\n",
      "Epoch   0 Batch 13258/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 13259/17275   train_loss = 3.207\n",
      "Epoch   0 Batch 13260/17275   train_loss = 3.068\n",
      "Epoch   0 Batch 13261/17275   train_loss = 5.302\n",
      "Epoch   0 Batch 13262/17275   train_loss = 3.326\n",
      "Epoch   0 Batch 13263/17275   train_loss = 3.383\n",
      "Epoch   0 Batch 13264/17275   train_loss = 6.447\n",
      "Epoch   0 Batch 13265/17275   train_loss = 3.930\n",
      "Epoch   0 Batch 13266/17275   train_loss = 2.147\n",
      "Epoch   0 Batch 13267/17275   train_loss = 5.316\n",
      "Epoch   0 Batch 13268/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 13269/17275   train_loss = 6.627\n",
      "Epoch   0 Batch 13270/17275   train_loss = 4.509\n",
      "Epoch   0 Batch 13271/17275   train_loss = 4.149\n",
      "Epoch   0 Batch 13272/17275   train_loss = 7.179\n",
      "Epoch   0 Batch 13273/17275   train_loss = 6.354\n",
      "Epoch   0 Batch 13274/17275   train_loss = 3.754\n",
      "Epoch   0 Batch 13275/17275   train_loss = 4.396\n",
      "Epoch   0 Batch 13276/17275   train_loss = 2.227\n",
      "Epoch   0 Batch 13277/17275   train_loss = 2.396\n",
      "Epoch   0 Batch 13278/17275   train_loss = 3.324\n",
      "Epoch   0 Batch 13279/17275   train_loss = 5.748\n",
      "Epoch   0 Batch 13280/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 13281/17275   train_loss = 3.394\n",
      "Epoch   0 Batch 13282/17275   train_loss = 6.515\n",
      "Epoch   0 Batch 13283/17275   train_loss = 3.621\n",
      "Epoch   0 Batch 13284/17275   train_loss = 7.197\n",
      "Epoch   0 Batch 13285/17275   train_loss = 2.887\n",
      "Epoch   0 Batch 13286/17275   train_loss = 2.785\n",
      "Epoch   0 Batch 13287/17275   train_loss = 7.280\n",
      "Epoch   0 Batch 13288/17275   train_loss = 3.942\n",
      "Epoch   0 Batch 13289/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 13290/17275   train_loss = 2.437\n",
      "Epoch   0 Batch 13291/17275   train_loss = 1.895\n",
      "Epoch   0 Batch 13292/17275   train_loss = 6.636\n",
      "Epoch   0 Batch 13293/17275   train_loss = 3.182\n",
      "Epoch   0 Batch 13294/17275   train_loss = 8.616\n",
      "Epoch   0 Batch 13295/17275   train_loss = 4.205\n",
      "Epoch   0 Batch 13296/17275   train_loss = 6.415\n",
      "Epoch   0 Batch 13297/17275   train_loss = 5.397\n",
      "Epoch   0 Batch 13298/17275   train_loss = 5.081\n",
      "Epoch   0 Batch 13299/17275   train_loss = 2.714\n",
      "Epoch   0 Batch 13300/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 13301/17275   train_loss = 6.997\n",
      "Epoch   0 Batch 13302/17275   train_loss = 6.902\n",
      "Epoch   0 Batch 13303/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 13304/17275   train_loss = 3.586\n",
      "Epoch   0 Batch 13305/17275   train_loss = 2.414\n",
      "Epoch   0 Batch 13306/17275   train_loss = 7.093\n",
      "Epoch   0 Batch 13307/17275   train_loss = 2.561\n",
      "Epoch   0 Batch 13308/17275   train_loss = 3.953\n",
      "Epoch   0 Batch 13309/17275   train_loss = 8.074\n",
      "Epoch   0 Batch 13310/17275   train_loss = 2.564\n",
      "Epoch   0 Batch 13311/17275   train_loss = 3.411\n",
      "Epoch   0 Batch 13312/17275   train_loss = 4.262\n",
      "Epoch   0 Batch 13313/17275   train_loss = 8.190\n",
      "Epoch   0 Batch 13314/17275   train_loss = 1.927\n",
      "Epoch   0 Batch 13315/17275   train_loss = 2.685\n",
      "Epoch   0 Batch 13316/17275   train_loss = 7.036\n",
      "Epoch   0 Batch 13317/17275   train_loss = 4.176\n",
      "Epoch   0 Batch 13318/17275   train_loss = 3.668\n",
      "Epoch   0 Batch 13319/17275   train_loss = 3.108\n",
      "Epoch   0 Batch 13320/17275   train_loss = 3.334\n",
      "Epoch   0 Batch 13321/17275   train_loss = 5.042\n",
      "Epoch   0 Batch 13322/17275   train_loss = 1.915\n",
      "Epoch   0 Batch 13323/17275   train_loss = 5.728\n",
      "Epoch   0 Batch 13324/17275   train_loss = 3.304\n",
      "Epoch   0 Batch 13325/17275   train_loss = 2.953\n",
      "Epoch   0 Batch 13326/17275   train_loss = 4.766\n",
      "Epoch   0 Batch 13327/17275   train_loss = 3.698\n",
      "Epoch   0 Batch 13328/17275   train_loss = 10.973\n",
      "Epoch   0 Batch 13329/17275   train_loss = 3.095\n",
      "Epoch   0 Batch 13330/17275   train_loss = 7.611\n",
      "Epoch   0 Batch 13331/17275   train_loss = 6.196\n",
      "Epoch   0 Batch 13332/17275   train_loss = 1.918\n",
      "Epoch   0 Batch 13333/17275   train_loss = 3.154\n",
      "Epoch   0 Batch 13334/17275   train_loss = 2.783\n",
      "Epoch   0 Batch 13335/17275   train_loss = 7.834\n",
      "Epoch   0 Batch 13336/17275   train_loss = 4.473\n",
      "Epoch   0 Batch 13337/17275   train_loss = 6.415\n",
      "Epoch   0 Batch 13338/17275   train_loss = 2.650\n",
      "Epoch   0 Batch 13339/17275   train_loss = 4.468\n",
      "Epoch   0 Batch 13340/17275   train_loss = 2.796\n",
      "Epoch   0 Batch 13341/17275   train_loss = 3.154\n",
      "Epoch   0 Batch 13342/17275   train_loss = 4.181\n",
      "Epoch   0 Batch 13343/17275   train_loss = 4.916\n",
      "Epoch   0 Batch 13344/17275   train_loss = 4.708\n",
      "Epoch   0 Batch 13345/17275   train_loss = 3.838\n",
      "Epoch   0 Batch 13346/17275   train_loss = 2.440\n",
      "Epoch   0 Batch 13347/17275   train_loss = 5.169\n",
      "Epoch   0 Batch 13348/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 13349/17275   train_loss = 4.106\n",
      "Epoch   0 Batch 13350/17275   train_loss = 7.371\n",
      "Epoch   0 Batch 13351/17275   train_loss = 7.135\n",
      "Epoch   0 Batch 13352/17275   train_loss = 3.108\n",
      "Epoch   0 Batch 13353/17275   train_loss = 4.204\n",
      "Epoch   0 Batch 13354/17275   train_loss = 2.418\n",
      "Epoch   0 Batch 13355/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 13356/17275   train_loss = 6.718\n",
      "Epoch   0 Batch 13357/17275   train_loss = 8.102\n",
      "Epoch   0 Batch 13358/17275   train_loss = 2.232\n",
      "Epoch   0 Batch 13359/17275   train_loss = 1.966\n",
      "Epoch   0 Batch 13360/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 13361/17275   train_loss = 4.034\n",
      "Epoch   0 Batch 13362/17275   train_loss = 3.969\n",
      "Epoch   0 Batch 13363/17275   train_loss = 6.452\n",
      "Epoch   0 Batch 13364/17275   train_loss = 4.683\n",
      "Epoch   0 Batch 13365/17275   train_loss = 3.787\n",
      "Epoch   0 Batch 13366/17275   train_loss = 3.388\n",
      "Epoch   0 Batch 13367/17275   train_loss = 3.309\n",
      "Epoch   0 Batch 13368/17275   train_loss = 4.396\n",
      "Epoch   0 Batch 13369/17275   train_loss = 3.785\n",
      "Epoch   0 Batch 13370/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 13371/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 13372/17275   train_loss = 4.588\n",
      "Epoch   0 Batch 13373/17275   train_loss = 1.990\n",
      "Epoch   0 Batch 13374/17275   train_loss = 2.796\n",
      "Epoch   0 Batch 13375/17275   train_loss = 5.674\n",
      "Epoch   0 Batch 13376/17275   train_loss = 4.339\n",
      "Epoch   0 Batch 13377/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 13378/17275   train_loss = 3.475\n",
      "Epoch   0 Batch 13379/17275   train_loss = 5.688\n",
      "Epoch   0 Batch 13380/17275   train_loss = 6.520\n",
      "Epoch   0 Batch 13381/17275   train_loss = 2.517\n",
      "Epoch   0 Batch 13382/17275   train_loss = 4.363\n",
      "Epoch   0 Batch 13383/17275   train_loss = 3.735\n",
      "Epoch   0 Batch 13384/17275   train_loss = 2.403\n",
      "Epoch   0 Batch 13385/17275   train_loss = 4.422\n",
      "Epoch   0 Batch 13386/17275   train_loss = 6.691\n",
      "Epoch   0 Batch 13387/17275   train_loss = 3.186\n",
      "Epoch   0 Batch 13388/17275   train_loss = 4.770\n",
      "Epoch   0 Batch 13389/17275   train_loss = 4.737\n",
      "Epoch   0 Batch 13390/17275   train_loss = 4.305\n",
      "Epoch   0 Batch 13391/17275   train_loss = 7.347\n",
      "Epoch   0 Batch 13392/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 13393/17275   train_loss = 5.031\n",
      "Epoch   0 Batch 13394/17275   train_loss = 7.452\n",
      "Epoch   0 Batch 13395/17275   train_loss = 6.509\n",
      "Epoch   0 Batch 13396/17275   train_loss = 3.421\n",
      "Epoch   0 Batch 13397/17275   train_loss = 3.496\n",
      "Epoch   0 Batch 13398/17275   train_loss = 3.203\n",
      "Epoch   0 Batch 13399/17275   train_loss = 2.226\n",
      "Epoch   0 Batch 13400/17275   train_loss = 4.243\n",
      "Epoch   0 Batch 13401/17275   train_loss = 2.706\n",
      "Epoch   0 Batch 13402/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 13403/17275   train_loss = 3.552\n",
      "Epoch   0 Batch 13404/17275   train_loss = 2.066\n",
      "Epoch   0 Batch 13405/17275   train_loss = 3.803\n",
      "Epoch   0 Batch 13406/17275   train_loss = 3.817\n",
      "Epoch   0 Batch 13407/17275   train_loss = 2.263\n",
      "Epoch   0 Batch 13408/17275   train_loss = 6.631\n",
      "Epoch   0 Batch 13409/17275   train_loss = 4.222\n",
      "Epoch   0 Batch 13410/17275   train_loss = 3.457\n",
      "Epoch   0 Batch 13411/17275   train_loss = 3.482\n",
      "Epoch   0 Batch 13412/17275   train_loss = 2.646\n",
      "Epoch   0 Batch 13413/17275   train_loss = 6.119\n",
      "Epoch   0 Batch 13414/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 13415/17275   train_loss = 6.150\n",
      "Epoch   0 Batch 13416/17275   train_loss = 3.425\n",
      "Epoch   0 Batch 13417/17275   train_loss = 4.311\n",
      "Epoch   0 Batch 13418/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 13419/17275   train_loss = 3.147\n",
      "Epoch   0 Batch 13420/17275   train_loss = 3.944\n",
      "Epoch   0 Batch 13421/17275   train_loss = 6.599\n",
      "Epoch   0 Batch 13422/17275   train_loss = 4.825\n",
      "Epoch   0 Batch 13423/17275   train_loss = 2.556\n",
      "Epoch   0 Batch 13424/17275   train_loss = 6.911\n",
      "Epoch   0 Batch 13425/17275   train_loss = 4.670\n",
      "Epoch   0 Batch 13426/17275   train_loss = 5.367\n",
      "Epoch   0 Batch 13427/17275   train_loss = 4.881\n",
      "Epoch   0 Batch 13428/17275   train_loss = 3.186\n",
      "Epoch   0 Batch 13429/17275   train_loss = 4.796\n",
      "Epoch   0 Batch 13430/17275   train_loss = 3.728\n",
      "Epoch   0 Batch 13431/17275   train_loss = 4.618\n",
      "Epoch   0 Batch 13432/17275   train_loss = 2.180\n",
      "Epoch   0 Batch 13433/17275   train_loss = 3.490\n",
      "Epoch   0 Batch 13434/17275   train_loss = 4.231\n",
      "Epoch   0 Batch 13435/17275   train_loss = 2.100\n",
      "Epoch   0 Batch 13436/17275   train_loss = 3.949\n",
      "Epoch   0 Batch 13437/17275   train_loss = 3.998\n",
      "Epoch   0 Batch 13438/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 13439/17275   train_loss = 4.072\n",
      "Epoch   0 Batch 13440/17275   train_loss = 3.436\n",
      "Epoch   0 Batch 13441/17275   train_loss = 2.075\n",
      "Epoch   0 Batch 13442/17275   train_loss = 2.734\n",
      "Epoch   0 Batch 13443/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 13444/17275   train_loss = 4.293\n",
      "Epoch   0 Batch 13445/17275   train_loss = 3.809\n",
      "Epoch   0 Batch 13446/17275   train_loss = 2.418\n",
      "Epoch   0 Batch 13447/17275   train_loss = 5.354\n",
      "Epoch   0 Batch 13448/17275   train_loss = 4.211\n",
      "Epoch   0 Batch 13449/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 13450/17275   train_loss = 3.431\n",
      "Epoch   0 Batch 13451/17275   train_loss = 2.847\n",
      "Epoch   0 Batch 13452/17275   train_loss = 2.563\n",
      "Epoch   0 Batch 13453/17275   train_loss = 5.714\n",
      "Epoch   0 Batch 13454/17275   train_loss = 1.974\n",
      "Epoch   0 Batch 13455/17275   train_loss = 2.057\n",
      "Epoch   0 Batch 13456/17275   train_loss = 6.970\n",
      "Epoch   0 Batch 13457/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 13458/17275   train_loss = 4.018\n",
      "Epoch   0 Batch 13459/17275   train_loss = 5.453\n",
      "Epoch   0 Batch 13460/17275   train_loss = 7.008\n",
      "Epoch   0 Batch 13461/17275   train_loss = 2.463\n",
      "Epoch   0 Batch 13462/17275   train_loss = 3.119\n",
      "Epoch   0 Batch 13463/17275   train_loss = 3.319\n",
      "Epoch   0 Batch 13464/17275   train_loss = 4.208\n",
      "Epoch   0 Batch 13465/17275   train_loss = 5.812\n",
      "Epoch   0 Batch 13466/17275   train_loss = 7.262\n",
      "Epoch   0 Batch 13467/17275   train_loss = 6.709\n",
      "Epoch   0 Batch 13468/17275   train_loss = 6.447\n",
      "Epoch   0 Batch 13469/17275   train_loss = 5.128\n",
      "Epoch   0 Batch 13470/17275   train_loss = 6.870\n",
      "Epoch   0 Batch 13471/17275   train_loss = 7.207\n",
      "Epoch   0 Batch 13472/17275   train_loss = 4.936\n",
      "Epoch   0 Batch 13473/17275   train_loss = 2.318\n",
      "Epoch   0 Batch 13474/17275   train_loss = 3.446\n",
      "Epoch   0 Batch 13475/17275   train_loss = 2.486\n",
      "Epoch   0 Batch 13476/17275   train_loss = 2.268\n",
      "Epoch   0 Batch 13477/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 13478/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 13479/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 13480/17275   train_loss = 3.484\n",
      "Epoch   0 Batch 13481/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 13482/17275   train_loss = 3.331\n",
      "Epoch   0 Batch 13483/17275   train_loss = 2.234\n",
      "Epoch   0 Batch 13484/17275   train_loss = 3.282\n",
      "Epoch   0 Batch 13485/17275   train_loss = 2.566\n",
      "Epoch   0 Batch 13486/17275   train_loss = 4.898\n",
      "Epoch   0 Batch 13487/17275   train_loss = 3.195\n",
      "Epoch   0 Batch 13488/17275   train_loss = 3.472\n",
      "Epoch   0 Batch 13489/17275   train_loss = 8.514\n",
      "Epoch   0 Batch 13490/17275   train_loss = 7.069\n",
      "Epoch   0 Batch 13491/17275   train_loss = 2.938\n",
      "Epoch   0 Batch 13492/17275   train_loss = 1.961\n",
      "Epoch   0 Batch 13493/17275   train_loss = 4.228\n",
      "Epoch   0 Batch 13494/17275   train_loss = 6.523\n",
      "Epoch   0 Batch 13495/17275   train_loss = 4.569\n",
      "Epoch   0 Batch 13496/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 13497/17275   train_loss = 3.316\n",
      "Epoch   0 Batch 13498/17275   train_loss = 7.140\n",
      "Epoch   0 Batch 13499/17275   train_loss = 1.892\n",
      "Epoch   0 Batch 13500/17275   train_loss = 1.951\n",
      "Epoch   0 Batch 13501/17275   train_loss = 2.664\n",
      "Epoch   0 Batch 13502/17275   train_loss = 3.602\n",
      "Epoch   0 Batch 13503/17275   train_loss = 3.669\n",
      "Epoch   0 Batch 13504/17275   train_loss = 4.558\n",
      "Epoch   0 Batch 13505/17275   train_loss = 3.605\n",
      "Epoch   0 Batch 13506/17275   train_loss = 4.757\n",
      "Epoch   0 Batch 13507/17275   train_loss = 4.997\n",
      "Epoch   0 Batch 13508/17275   train_loss = 7.193\n",
      "Epoch   0 Batch 13509/17275   train_loss = 7.182\n",
      "Epoch   0 Batch 13510/17275   train_loss = 6.737\n",
      "Epoch   0 Batch 13511/17275   train_loss = 2.319\n",
      "Epoch   0 Batch 13512/17275   train_loss = 6.567\n",
      "Epoch   0 Batch 13513/17275   train_loss = 2.979\n",
      "Epoch   0 Batch 13514/17275   train_loss = 5.222\n",
      "Epoch   0 Batch 13515/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 13516/17275   train_loss = 5.173\n",
      "Epoch   0 Batch 13517/17275   train_loss = 4.011\n",
      "Epoch   0 Batch 13518/17275   train_loss = 2.237\n",
      "Epoch   0 Batch 13519/17275   train_loss = 8.108\n",
      "Epoch   0 Batch 13520/17275   train_loss = 2.988\n",
      "Epoch   0 Batch 13521/17275   train_loss = 7.809\n",
      "Epoch   0 Batch 13522/17275   train_loss = 4.293\n",
      "Epoch   0 Batch 13523/17275   train_loss = 1.968\n",
      "Epoch   0 Batch 13524/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 13525/17275   train_loss = 9.266\n",
      "Epoch   0 Batch 13526/17275   train_loss = 2.736\n",
      "Epoch   0 Batch 13527/17275   train_loss = 7.672\n",
      "Epoch   0 Batch 13528/17275   train_loss = 2.958\n",
      "Epoch   0 Batch 13529/17275   train_loss = 4.900\n",
      "Epoch   0 Batch 13530/17275   train_loss = 2.401\n",
      "Epoch   0 Batch 13531/17275   train_loss = 6.698\n",
      "Epoch   0 Batch 13532/17275   train_loss = 3.278\n",
      "Epoch   0 Batch 13533/17275   train_loss = 7.744\n",
      "Epoch   0 Batch 13534/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 13535/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 13536/17275   train_loss = 3.623\n",
      "Epoch   0 Batch 13537/17275   train_loss = 3.583\n",
      "Epoch   0 Batch 13538/17275   train_loss = 7.021\n",
      "Epoch   0 Batch 13539/17275   train_loss = 2.353\n",
      "Epoch   0 Batch 13540/17275   train_loss = 4.599\n",
      "Epoch   0 Batch 13541/17275   train_loss = 2.772\n",
      "Epoch   0 Batch 13542/17275   train_loss = 6.632\n",
      "Epoch   0 Batch 13543/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 13544/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 13545/17275   train_loss = 7.495\n",
      "Epoch   0 Batch 13546/17275   train_loss = 2.026\n",
      "Epoch   0 Batch 13547/17275   train_loss = 6.605\n",
      "Epoch   0 Batch 13548/17275   train_loss = 3.321\n",
      "Epoch   0 Batch 13549/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 13550/17275   train_loss = 6.429\n",
      "Epoch   0 Batch 13551/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 13552/17275   train_loss = 6.000\n",
      "Epoch   0 Batch 13553/17275   train_loss = 3.951\n",
      "Epoch   0 Batch 13554/17275   train_loss = 2.582\n",
      "Epoch   0 Batch 13555/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 13556/17275   train_loss = 4.286\n",
      "Epoch   0 Batch 13557/17275   train_loss = 4.077\n",
      "Epoch   0 Batch 13558/17275   train_loss = 2.514\n",
      "Epoch   0 Batch 13559/17275   train_loss = 3.101\n",
      "Epoch   0 Batch 13560/17275   train_loss = 2.812\n",
      "Epoch   0 Batch 13561/17275   train_loss = 3.562\n",
      "Epoch   0 Batch 13562/17275   train_loss = 5.096\n",
      "Epoch   0 Batch 13563/17275   train_loss = 2.013\n",
      "Epoch   0 Batch 13564/17275   train_loss = 4.628\n",
      "Epoch   0 Batch 13565/17275   train_loss = 4.643\n",
      "Epoch   0 Batch 13566/17275   train_loss = 3.584\n",
      "Epoch   0 Batch 13567/17275   train_loss = 4.605\n",
      "Epoch   0 Batch 13568/17275   train_loss = 4.015\n",
      "Epoch   0 Batch 13569/17275   train_loss = 3.363\n",
      "Epoch   0 Batch 13570/17275   train_loss = 7.566\n",
      "Epoch   0 Batch 13571/17275   train_loss = 1.980\n",
      "Epoch   0 Batch 13572/17275   train_loss = 4.266\n",
      "Epoch   0 Batch 13573/17275   train_loss = 2.872\n",
      "Epoch   0 Batch 13574/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 13575/17275   train_loss = 6.628\n",
      "Epoch   0 Batch 13576/17275   train_loss = 2.755\n",
      "Epoch   0 Batch 13577/17275   train_loss = 3.493\n",
      "Epoch   0 Batch 13578/17275   train_loss = 10.991\n",
      "Epoch   0 Batch 13579/17275   train_loss = 3.873\n",
      "Epoch   0 Batch 13580/17275   train_loss = 1.970\n",
      "Epoch   0 Batch 13581/17275   train_loss = 3.324\n",
      "Epoch   0 Batch 13582/17275   train_loss = 3.499\n",
      "Epoch   0 Batch 13583/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 13584/17275   train_loss = 3.690\n",
      "Epoch   0 Batch 13585/17275   train_loss = 3.518\n",
      "Epoch   0 Batch 13586/17275   train_loss = 10.999\n",
      "Epoch   0 Batch 13587/17275   train_loss = 2.513\n",
      "Epoch   0 Batch 13588/17275   train_loss = 5.091\n",
      "Epoch   0 Batch 13589/17275   train_loss = 3.102\n",
      "Epoch   0 Batch 13590/17275   train_loss = 6.937\n",
      "Epoch   0 Batch 13591/17275   train_loss = 4.141\n",
      "Epoch   0 Batch 13592/17275   train_loss = 6.437\n",
      "Epoch   0 Batch 13593/17275   train_loss = 6.557\n",
      "Epoch   0 Batch 13594/17275   train_loss = 3.402\n",
      "Epoch   0 Batch 13595/17275   train_loss = 4.104\n",
      "Epoch   0 Batch 13596/17275   train_loss = 6.791\n",
      "Epoch   0 Batch 13597/17275   train_loss = 3.902\n",
      "Epoch   0 Batch 13598/17275   train_loss = 7.557\n",
      "Epoch   0 Batch 13599/17275   train_loss = 10.510\n",
      "Epoch   0 Batch 13600/17275   train_loss = 2.005\n",
      "Epoch   0 Batch 13601/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 13602/17275   train_loss = 3.973\n",
      "Epoch   0 Batch 13603/17275   train_loss = 5.714\n",
      "Epoch   0 Batch 13604/17275   train_loss = 1.997\n",
      "Epoch   0 Batch 13605/17275   train_loss = 5.102\n",
      "Epoch   0 Batch 13606/17275   train_loss = 3.560\n",
      "Epoch   0 Batch 13607/17275   train_loss = 4.093\n",
      "Epoch   0 Batch 13608/17275   train_loss = 2.988\n",
      "Epoch   0 Batch 13609/17275   train_loss = 3.422\n",
      "Epoch   0 Batch 13610/17275   train_loss = 2.378\n",
      "Epoch   0 Batch 13611/17275   train_loss = 3.549\n",
      "Epoch   0 Batch 13612/17275   train_loss = 4.414\n",
      "Epoch   0 Batch 13613/17275   train_loss = 4.741\n",
      "Epoch   0 Batch 13614/17275   train_loss = 2.823\n",
      "Epoch   0 Batch 13615/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 13616/17275   train_loss = 3.305\n",
      "Epoch   0 Batch 13617/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 13618/17275   train_loss = 6.534\n",
      "Epoch   0 Batch 13619/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 13620/17275   train_loss = 3.425\n",
      "Epoch   0 Batch 13621/17275   train_loss = 4.767\n",
      "Epoch   0 Batch 13622/17275   train_loss = 3.391\n",
      "Epoch   0 Batch 13623/17275   train_loss = 6.525\n",
      "Epoch   0 Batch 13624/17275   train_loss = 5.489\n",
      "Epoch   0 Batch 13625/17275   train_loss = 6.157\n",
      "Epoch   0 Batch 13626/17275   train_loss = 3.476\n",
      "Epoch   0 Batch 13627/17275   train_loss = 5.724\n",
      "Epoch   0 Batch 13628/17275   train_loss = 4.091\n",
      "Epoch   0 Batch 13629/17275   train_loss = 3.560\n",
      "Epoch   0 Batch 13630/17275   train_loss = 2.203\n",
      "Epoch   0 Batch 13631/17275   train_loss = 6.835\n",
      "Epoch   0 Batch 13632/17275   train_loss = 6.833\n",
      "Epoch   0 Batch 13633/17275   train_loss = 4.023\n",
      "Epoch   0 Batch 13634/17275   train_loss = 2.583\n",
      "Epoch   0 Batch 13635/17275   train_loss = 4.782\n",
      "Epoch   0 Batch 13636/17275   train_loss = 7.126\n",
      "Epoch   0 Batch 13637/17275   train_loss = 5.490\n",
      "Epoch   0 Batch 13638/17275   train_loss = 3.093\n",
      "Epoch   0 Batch 13639/17275   train_loss = 3.370\n",
      "Epoch   0 Batch 13640/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 13641/17275   train_loss = 5.750\n",
      "Epoch   0 Batch 13642/17275   train_loss = 3.217\n",
      "Epoch   0 Batch 13643/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 13644/17275   train_loss = 5.724\n",
      "Epoch   0 Batch 13645/17275   train_loss = 2.411\n",
      "Epoch   0 Batch 13646/17275   train_loss = 5.100\n",
      "Epoch   0 Batch 13647/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 13648/17275   train_loss = 2.876\n",
      "Epoch   0 Batch 13649/17275   train_loss = 6.726\n",
      "Epoch   0 Batch 13650/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 13651/17275   train_loss = 4.543\n",
      "Epoch   0 Batch 13652/17275   train_loss = 4.144\n",
      "Epoch   0 Batch 13653/17275   train_loss = 2.404\n",
      "Epoch   0 Batch 13654/17275   train_loss = 2.904\n",
      "Epoch   0 Batch 13655/17275   train_loss = 2.626\n",
      "Epoch   0 Batch 13656/17275   train_loss = 5.690\n",
      "Epoch   0 Batch 13657/17275   train_loss = 3.206\n",
      "Epoch   0 Batch 13658/17275   train_loss = 4.417\n",
      "Epoch   0 Batch 13659/17275   train_loss = 3.384\n",
      "Epoch   0 Batch 13660/17275   train_loss = 4.700\n",
      "Epoch   0 Batch 13661/17275   train_loss = 3.406\n",
      "Epoch   0 Batch 13662/17275   train_loss = 3.187\n",
      "Epoch   0 Batch 13663/17275   train_loss = 2.709\n",
      "Epoch   0 Batch 13664/17275   train_loss = 3.786\n",
      "Epoch   0 Batch 13665/17275   train_loss = 5.016\n",
      "Epoch   0 Batch 13666/17275   train_loss = 3.164\n",
      "Epoch   0 Batch 13667/17275   train_loss = 3.662\n",
      "Epoch   0 Batch 13668/17275   train_loss = 3.078\n",
      "Epoch   0 Batch 13669/17275   train_loss = 4.798\n",
      "Epoch   0 Batch 13670/17275   train_loss = 3.627\n",
      "Epoch   0 Batch 13671/17275   train_loss = 7.978\n",
      "Epoch   0 Batch 13672/17275   train_loss = 3.408\n",
      "Epoch   0 Batch 13673/17275   train_loss = 3.646\n",
      "Epoch   0 Batch 13674/17275   train_loss = 8.880\n",
      "Epoch   0 Batch 13675/17275   train_loss = 2.011\n",
      "Epoch   0 Batch 13676/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 13677/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 13678/17275   train_loss = 3.153\n",
      "Epoch   0 Batch 13679/17275   train_loss = 3.145\n",
      "Epoch   0 Batch 13680/17275   train_loss = 3.331\n",
      "Epoch   0 Batch 13681/17275   train_loss = 2.555\n",
      "Epoch   0 Batch 13682/17275   train_loss = 3.954\n",
      "Epoch   0 Batch 13683/17275   train_loss = 2.814\n",
      "Epoch   0 Batch 13684/17275   train_loss = 6.742\n",
      "Epoch   0 Batch 13685/17275   train_loss = 3.974\n",
      "Epoch   0 Batch 13686/17275   train_loss = 3.599\n",
      "Epoch   0 Batch 13687/17275   train_loss = 2.501\n",
      "Epoch   0 Batch 13688/17275   train_loss = 3.498\n",
      "Epoch   0 Batch 13689/17275   train_loss = 3.522\n",
      "Epoch   0 Batch 13690/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 13691/17275   train_loss = 3.483\n",
      "Epoch   0 Batch 13692/17275   train_loss = 3.903\n",
      "Epoch   0 Batch 13693/17275   train_loss = 4.835\n",
      "Epoch   0 Batch 13694/17275   train_loss = 2.702\n",
      "Epoch   0 Batch 13695/17275   train_loss = 2.238\n",
      "Epoch   0 Batch 13696/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 13697/17275   train_loss = 3.772\n",
      "Epoch   0 Batch 13698/17275   train_loss = 3.504\n",
      "Epoch   0 Batch 13699/17275   train_loss = 4.377\n",
      "Epoch   0 Batch 13700/17275   train_loss = 3.277\n",
      "Epoch   0 Batch 13701/17275   train_loss = 3.477\n",
      "Epoch   0 Batch 13702/17275   train_loss = 4.478\n",
      "Epoch   0 Batch 13703/17275   train_loss = 8.029\n",
      "Epoch   0 Batch 13704/17275   train_loss = 2.088\n",
      "Epoch   0 Batch 13705/17275   train_loss = 3.080\n",
      "Epoch   0 Batch 13706/17275   train_loss = 7.279\n",
      "Epoch   0 Batch 13707/17275   train_loss = 4.236\n",
      "Epoch   0 Batch 13708/17275   train_loss = 6.979\n",
      "Epoch   0 Batch 13709/17275   train_loss = 6.311\n",
      "Epoch   0 Batch 13710/17275   train_loss = 4.565\n",
      "Epoch   0 Batch 13711/17275   train_loss = 3.176\n",
      "Epoch   0 Batch 13712/17275   train_loss = 8.068\n",
      "Epoch   0 Batch 13713/17275   train_loss = 3.724\n",
      "Epoch   0 Batch 13714/17275   train_loss = 6.999\n",
      "Epoch   0 Batch 13715/17275   train_loss = 7.795\n",
      "Epoch   0 Batch 13716/17275   train_loss = 2.929\n",
      "Epoch   0 Batch 13717/17275   train_loss = 3.918\n",
      "Epoch   0 Batch 13718/17275   train_loss = 3.321\n",
      "Epoch   0 Batch 13719/17275   train_loss = 3.190\n",
      "Epoch   0 Batch 13720/17275   train_loss = 3.598\n",
      "Epoch   0 Batch 13721/17275   train_loss = 7.003\n",
      "Epoch   0 Batch 13722/17275   train_loss = 6.806\n",
      "Epoch   0 Batch 13723/17275   train_loss = 2.281\n",
      "Epoch   0 Batch 13724/17275   train_loss = 3.266\n",
      "Epoch   0 Batch 13725/17275   train_loss = 3.049\n",
      "Epoch   0 Batch 13726/17275   train_loss = 7.862\n",
      "Epoch   0 Batch 13727/17275   train_loss = 7.229\n",
      "Epoch   0 Batch 13728/17275   train_loss = 2.113\n",
      "Epoch   0 Batch 13729/17275   train_loss = 2.065\n",
      "Epoch   0 Batch 13730/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 13731/17275   train_loss = 3.031\n",
      "Epoch   0 Batch 13732/17275   train_loss = 4.317\n",
      "Epoch   0 Batch 13733/17275   train_loss = 4.260\n",
      "Epoch   0 Batch 13734/17275   train_loss = 2.909\n",
      "Epoch   0 Batch 13735/17275   train_loss = 8.076\n",
      "Epoch   0 Batch 13736/17275   train_loss = 7.416\n",
      "Epoch   0 Batch 13737/17275   train_loss = 11.049\n",
      "Epoch   0 Batch 13738/17275   train_loss = 2.008\n",
      "Epoch   0 Batch 13739/17275   train_loss = 3.407\n",
      "Epoch   0 Batch 13740/17275   train_loss = 2.861\n",
      "Epoch   0 Batch 13741/17275   train_loss = 3.669\n",
      "Epoch   0 Batch 13742/17275   train_loss = 5.361\n",
      "Epoch   0 Batch 13743/17275   train_loss = 4.068\n",
      "Epoch   0 Batch 13744/17275   train_loss = 3.297\n",
      "Epoch   0 Batch 13745/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 13746/17275   train_loss = 6.671\n",
      "Epoch   0 Batch 13747/17275   train_loss = 1.973\n",
      "Epoch   0 Batch 13748/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 13749/17275   train_loss = 2.667\n",
      "Epoch   0 Batch 13750/17275   train_loss = 3.894\n",
      "Epoch   0 Batch 13751/17275   train_loss = 7.057\n",
      "Epoch   0 Batch 13752/17275   train_loss = 2.857\n",
      "Epoch   0 Batch 13753/17275   train_loss = 6.947\n",
      "Epoch   0 Batch 13754/17275   train_loss = 3.755\n",
      "Epoch   0 Batch 13755/17275   train_loss = 3.667\n",
      "Epoch   0 Batch 13756/17275   train_loss = 4.250\n",
      "Epoch   0 Batch 13757/17275   train_loss = 3.881\n",
      "Epoch   0 Batch 13758/17275   train_loss = 4.782\n",
      "Epoch   0 Batch 13759/17275   train_loss = 5.232\n",
      "Epoch   0 Batch 13760/17275   train_loss = 4.193\n",
      "Epoch   0 Batch 13761/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 13762/17275   train_loss = 2.671\n",
      "Epoch   0 Batch 13763/17275   train_loss = 6.369\n",
      "Epoch   0 Batch 13764/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 13765/17275   train_loss = 3.267\n",
      "Epoch   0 Batch 13766/17275   train_loss = 2.463\n",
      "Epoch   0 Batch 13767/17275   train_loss = 6.039\n",
      "Epoch   0 Batch 13768/17275   train_loss = 1.962\n",
      "Epoch   0 Batch 13769/17275   train_loss = 2.780\n",
      "Epoch   0 Batch 13770/17275   train_loss = 3.924\n",
      "Epoch   0 Batch 13771/17275   train_loss = 2.703\n",
      "Epoch   0 Batch 13772/17275   train_loss = 2.809\n",
      "Epoch   0 Batch 13773/17275   train_loss = 4.636\n",
      "Epoch   0 Batch 13774/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 13775/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 13776/17275   train_loss = 5.320\n",
      "Epoch   0 Batch 13777/17275   train_loss = 2.431\n",
      "Epoch   0 Batch 13778/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 13779/17275   train_loss = 3.487\n",
      "Epoch   0 Batch 13780/17275   train_loss = 3.848\n",
      "Epoch   0 Batch 13781/17275   train_loss = 2.006\n",
      "Epoch   0 Batch 13782/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 13783/17275   train_loss = 4.024\n",
      "Epoch   0 Batch 13784/17275   train_loss = 4.455\n",
      "Epoch   0 Batch 13785/17275   train_loss = 2.596\n",
      "Epoch   0 Batch 13786/17275   train_loss = 1.993\n",
      "Epoch   0 Batch 13787/17275   train_loss = 3.604\n",
      "Epoch   0 Batch 13788/17275   train_loss = 2.936\n",
      "Epoch   0 Batch 13789/17275   train_loss = 3.816\n",
      "Epoch   0 Batch 13790/17275   train_loss = 1.969\n",
      "Epoch   0 Batch 13791/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 13792/17275   train_loss = 2.778\n",
      "Epoch   0 Batch 13793/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 13794/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 13795/17275   train_loss = 3.653\n",
      "Epoch   0 Batch 13796/17275   train_loss = 1.928\n",
      "Epoch   0 Batch 13797/17275   train_loss = 3.434\n",
      "Epoch   0 Batch 13798/17275   train_loss = 3.196\n",
      "Epoch   0 Batch 13799/17275   train_loss = 2.368\n",
      "Epoch   0 Batch 13800/17275   train_loss = 2.516\n",
      "Epoch   0 Batch 13801/17275   train_loss = 6.919\n",
      "Epoch   0 Batch 13802/17275   train_loss = 3.897\n",
      "Epoch   0 Batch 13803/17275   train_loss = 4.202\n",
      "Epoch   0 Batch 13804/17275   train_loss = 6.653\n",
      "Epoch   0 Batch 13805/17275   train_loss = 3.844\n",
      "Epoch   0 Batch 13806/17275   train_loss = 2.804\n",
      "Epoch   0 Batch 13807/17275   train_loss = 2.069\n",
      "Epoch   0 Batch 13808/17275   train_loss = 3.631\n",
      "Epoch   0 Batch 13809/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 13810/17275   train_loss = 2.876\n",
      "Epoch   0 Batch 13811/17275   train_loss = 6.918\n",
      "Epoch   0 Batch 13812/17275   train_loss = 3.330\n",
      "Epoch   0 Batch 13813/17275   train_loss = 2.507\n",
      "Epoch   0 Batch 13814/17275   train_loss = 3.438\n",
      "Epoch   0 Batch 13815/17275   train_loss = 2.954\n",
      "Epoch   0 Batch 13816/17275   train_loss = 5.343\n",
      "Epoch   0 Batch 13817/17275   train_loss = 4.262\n",
      "Epoch   0 Batch 13818/17275   train_loss = 1.908\n",
      "Epoch   0 Batch 13819/17275   train_loss = 3.243\n",
      "Epoch   0 Batch 13820/17275   train_loss = 3.598\n",
      "Epoch   0 Batch 13821/17275   train_loss = 6.523\n",
      "Epoch   0 Batch 13822/17275   train_loss = 2.694\n",
      "Epoch   0 Batch 13823/17275   train_loss = 2.999\n",
      "Epoch   0 Batch 13824/17275   train_loss = 3.470\n",
      "Epoch   0 Batch 13825/17275   train_loss = 4.477\n",
      "Epoch   0 Batch 13826/17275   train_loss = 1.860\n",
      "Epoch   0 Batch 13827/17275   train_loss = 2.655\n",
      "Epoch   0 Batch 13828/17275   train_loss = 4.730\n",
      "Epoch   0 Batch 13829/17275   train_loss = 3.835\n",
      "Epoch   0 Batch 13830/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 13831/17275   train_loss = 5.267\n",
      "Epoch   0 Batch 13832/17275   train_loss = 5.346\n",
      "Epoch   0 Batch 13833/17275   train_loss = 3.953\n",
      "Epoch   0 Batch 13834/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 13835/17275   train_loss = 3.660\n",
      "Epoch   0 Batch 13836/17275   train_loss = 2.039\n",
      "Epoch   0 Batch 13837/17275   train_loss = 2.732\n",
      "Epoch   0 Batch 13838/17275   train_loss = 7.432\n",
      "Epoch   0 Batch 13839/17275   train_loss = 1.842\n",
      "Epoch   0 Batch 13840/17275   train_loss = 2.745\n",
      "Epoch   0 Batch 13841/17275   train_loss = 9.204\n",
      "Epoch   0 Batch 13842/17275   train_loss = 2.791\n",
      "Epoch   0 Batch 13843/17275   train_loss = 2.423\n",
      "Epoch   0 Batch 13844/17275   train_loss = 5.084\n",
      "Epoch   0 Batch 13845/17275   train_loss = 2.941\n",
      "Epoch   0 Batch 13846/17275   train_loss = 2.001\n",
      "Epoch   0 Batch 13847/17275   train_loss = 3.001\n",
      "Epoch   0 Batch 13848/17275   train_loss = 3.579\n",
      "Epoch   0 Batch 13849/17275   train_loss = 2.274\n",
      "Epoch   0 Batch 13850/17275   train_loss = 1.823\n",
      "Epoch   0 Batch 13851/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 13852/17275   train_loss = 2.631\n",
      "Epoch   0 Batch 13853/17275   train_loss = 7.111\n",
      "Epoch   0 Batch 13854/17275   train_loss = 2.803\n",
      "Epoch   0 Batch 13855/17275   train_loss = 1.837\n",
      "Epoch   0 Batch 13856/17275   train_loss = 2.009\n",
      "Epoch   0 Batch 13857/17275   train_loss = 3.225\n",
      "Epoch   0 Batch 13858/17275   train_loss = 6.676\n",
      "Epoch   0 Batch 13859/17275   train_loss = 7.087\n",
      "Epoch   0 Batch 13860/17275   train_loss = 5.336\n",
      "Epoch   0 Batch 13861/17275   train_loss = 6.982\n",
      "Epoch   0 Batch 13862/17275   train_loss = 1.704\n",
      "Epoch   0 Batch 13863/17275   train_loss = 3.527\n",
      "Epoch   0 Batch 13864/17275   train_loss = 7.561\n",
      "Epoch   0 Batch 13865/17275   train_loss = 3.376\n",
      "Epoch   0 Batch 13866/17275   train_loss = 6.421\n",
      "Epoch   0 Batch 13867/17275   train_loss = 1.972\n",
      "Epoch   0 Batch 13868/17275   train_loss = 5.503\n",
      "Epoch   0 Batch 13869/17275   train_loss = 3.491\n",
      "Epoch   0 Batch 13870/17275   train_loss = 6.693\n",
      "Epoch   0 Batch 13871/17275   train_loss = 3.288\n",
      "Epoch   0 Batch 13872/17275   train_loss = 2.101\n",
      "Epoch   0 Batch 13873/17275   train_loss = 3.954\n",
      "Epoch   0 Batch 13874/17275   train_loss = 3.431\n",
      "Epoch   0 Batch 13875/17275   train_loss = 2.961\n",
      "Epoch   0 Batch 13876/17275   train_loss = 4.019\n",
      "Epoch   0 Batch 13877/17275   train_loss = 3.638\n",
      "Epoch   0 Batch 13878/17275   train_loss = 4.178\n",
      "Epoch   0 Batch 13879/17275   train_loss = 2.698\n",
      "Epoch   0 Batch 13880/17275   train_loss = 4.184\n",
      "Epoch   0 Batch 13881/17275   train_loss = 8.351\n",
      "Epoch   0 Batch 13882/17275   train_loss = 3.343\n",
      "Epoch   0 Batch 13883/17275   train_loss = 2.771\n",
      "Epoch   0 Batch 13884/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 13885/17275   train_loss = 4.436\n",
      "Epoch   0 Batch 13886/17275   train_loss = 3.281\n",
      "Epoch   0 Batch 13887/17275   train_loss = 6.088\n",
      "Epoch   0 Batch 13888/17275   train_loss = 7.180\n",
      "Epoch   0 Batch 13889/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 13890/17275   train_loss = 2.126\n",
      "Epoch   0 Batch 13891/17275   train_loss = 2.713\n",
      "Epoch   0 Batch 13892/17275   train_loss = 3.433\n",
      "Epoch   0 Batch 13893/17275   train_loss = 11.142\n",
      "Epoch   0 Batch 13894/17275   train_loss = 1.900\n",
      "Epoch   0 Batch 13895/17275   train_loss = 2.998\n",
      "Epoch   0 Batch 13896/17275   train_loss = 3.008\n",
      "Epoch   0 Batch 13897/17275   train_loss = 8.516\n",
      "Epoch   0 Batch 13898/17275   train_loss = 3.388\n",
      "Epoch   0 Batch 13899/17275   train_loss = 3.379\n",
      "Epoch   0 Batch 13900/17275   train_loss = 3.751\n",
      "Epoch   0 Batch 13901/17275   train_loss = 5.431\n",
      "Epoch   0 Batch 13902/17275   train_loss = 5.463\n",
      "Epoch   0 Batch 13903/17275   train_loss = 8.118\n",
      "Epoch   0 Batch 13904/17275   train_loss = 6.564\n",
      "Epoch   0 Batch 13905/17275   train_loss = 4.095\n",
      "Epoch   0 Batch 13906/17275   train_loss = 3.241\n",
      "Epoch   0 Batch 13907/17275   train_loss = 5.242\n",
      "Epoch   0 Batch 13908/17275   train_loss = 6.898\n",
      "Epoch   0 Batch 13909/17275   train_loss = 3.407\n",
      "Epoch   0 Batch 13910/17275   train_loss = 8.661\n",
      "Epoch   0 Batch 13911/17275   train_loss = 6.544\n",
      "Epoch   0 Batch 13912/17275   train_loss = 3.057\n",
      "Epoch   0 Batch 13913/17275   train_loss = 3.363\n",
      "Epoch   0 Batch 13914/17275   train_loss = 6.253\n",
      "Epoch   0 Batch 13915/17275   train_loss = 2.986\n",
      "Epoch   0 Batch 13916/17275   train_loss = 3.153\n",
      "Epoch   0 Batch 13917/17275   train_loss = 3.107\n",
      "Epoch   0 Batch 13918/17275   train_loss = 2.573\n",
      "Epoch   0 Batch 13919/17275   train_loss = 2.887\n",
      "Epoch   0 Batch 13920/17275   train_loss = 3.968\n",
      "Epoch   0 Batch 13921/17275   train_loss = 4.396\n",
      "Epoch   0 Batch 13922/17275   train_loss = 2.525\n",
      "Epoch   0 Batch 13923/17275   train_loss = 3.713\n",
      "Epoch   0 Batch 13924/17275   train_loss = 2.977\n",
      "Epoch   0 Batch 13925/17275   train_loss = 2.347\n",
      "Epoch   0 Batch 13926/17275   train_loss = 3.064\n",
      "Epoch   0 Batch 13927/17275   train_loss = 11.099\n",
      "Epoch   0 Batch 13928/17275   train_loss = 4.663\n",
      "Epoch   0 Batch 13929/17275   train_loss = 3.260\n",
      "Epoch   0 Batch 13930/17275   train_loss = 5.613\n",
      "Epoch   0 Batch 13931/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 13932/17275   train_loss = 3.559\n",
      "Epoch   0 Batch 13933/17275   train_loss = 2.721\n",
      "Epoch   0 Batch 13934/17275   train_loss = 2.414\n",
      "Epoch   0 Batch 13935/17275   train_loss = 4.054\n",
      "Epoch   0 Batch 13936/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 13937/17275   train_loss = 3.388\n",
      "Epoch   0 Batch 13938/17275   train_loss = 6.125\n",
      "Epoch   0 Batch 13939/17275   train_loss = 4.094\n",
      "Epoch   0 Batch 13940/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 13941/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 13942/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 13943/17275   train_loss = 1.945\n",
      "Epoch   0 Batch 13944/17275   train_loss = 2.864\n",
      "Epoch   0 Batch 13945/17275   train_loss = 2.580\n",
      "Epoch   0 Batch 13946/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 13947/17275   train_loss = 3.615\n",
      "Epoch   0 Batch 13948/17275   train_loss = 4.830\n",
      "Epoch   0 Batch 13949/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 13950/17275   train_loss = 4.580\n",
      "Epoch   0 Batch 13951/17275   train_loss = 4.068\n",
      "Epoch   0 Batch 13952/17275   train_loss = 6.932\n",
      "Epoch   0 Batch 13953/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 13954/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 13955/17275   train_loss = 4.459\n",
      "Epoch   0 Batch 13956/17275   train_loss = 7.678\n",
      "Epoch   0 Batch 13957/17275   train_loss = 1.819\n",
      "Epoch   0 Batch 13958/17275   train_loss = 1.921\n",
      "Epoch   0 Batch 13959/17275   train_loss = 4.094\n",
      "Epoch   0 Batch 13960/17275   train_loss = 4.333\n",
      "Epoch   0 Batch 13961/17275   train_loss = 2.784\n",
      "Epoch   0 Batch 13962/17275   train_loss = 2.306\n",
      "Epoch   0 Batch 13963/17275   train_loss = 4.139\n",
      "Epoch   0 Batch 13964/17275   train_loss = 7.068\n",
      "Epoch   0 Batch 13965/17275   train_loss = 2.798\n",
      "Epoch   0 Batch 13966/17275   train_loss = 3.396\n",
      "Epoch   0 Batch 13967/17275   train_loss = 4.302\n",
      "Epoch   0 Batch 13968/17275   train_loss = 4.054\n",
      "Epoch   0 Batch 13969/17275   train_loss = 4.644\n",
      "Epoch   0 Batch 13970/17275   train_loss = 4.681\n",
      "Epoch   0 Batch 13971/17275   train_loss = 5.935\n",
      "Epoch   0 Batch 13972/17275   train_loss = 2.202\n",
      "Epoch   0 Batch 13973/17275   train_loss = 6.878\n",
      "Epoch   0 Batch 13974/17275   train_loss = 5.152\n",
      "Epoch   0 Batch 13975/17275   train_loss = 6.843\n",
      "Epoch   0 Batch 13976/17275   train_loss = 3.077\n",
      "Epoch   0 Batch 13977/17275   train_loss = 3.039\n",
      "Epoch   0 Batch 13978/17275   train_loss = 2.672\n",
      "Epoch   0 Batch 13979/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 13980/17275   train_loss = 4.302\n",
      "Epoch   0 Batch 13981/17275   train_loss = 5.428\n",
      "Epoch   0 Batch 13982/17275   train_loss = 5.013\n",
      "Epoch   0 Batch 13983/17275   train_loss = 2.420\n",
      "Epoch   0 Batch 13984/17275   train_loss = 5.865\n",
      "Epoch   0 Batch 13985/17275   train_loss = 5.044\n",
      "Epoch   0 Batch 13986/17275   train_loss = 4.448\n",
      "Epoch   0 Batch 13987/17275   train_loss = 5.603\n",
      "Epoch   0 Batch 13988/17275   train_loss = 3.107\n",
      "Epoch   0 Batch 13989/17275   train_loss = 3.367\n",
      "Epoch   0 Batch 13990/17275   train_loss = 2.391\n",
      "Epoch   0 Batch 13991/17275   train_loss = 7.153\n",
      "Epoch   0 Batch 13992/17275   train_loss = 4.428\n",
      "Epoch   0 Batch 13993/17275   train_loss = 2.493\n",
      "Epoch   0 Batch 13994/17275   train_loss = 7.138\n",
      "Epoch   0 Batch 13995/17275   train_loss = 3.313\n",
      "Epoch   0 Batch 13996/17275   train_loss = 3.556\n",
      "Epoch   0 Batch 13997/17275   train_loss = 2.695\n",
      "Epoch   0 Batch 13998/17275   train_loss = 3.099\n",
      "Epoch   0 Batch 13999/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 14000/17275   train_loss = 3.094\n",
      "Epoch   0 Batch 14001/17275   train_loss = 6.930\n",
      "Epoch   0 Batch 14002/17275   train_loss = 3.450\n",
      "Epoch   0 Batch 14003/17275   train_loss = 7.466\n",
      "Epoch   0 Batch 14004/17275   train_loss = 3.882\n",
      "Epoch   0 Batch 14005/17275   train_loss = 6.749\n",
      "Epoch   0 Batch 14006/17275   train_loss = 4.033\n",
      "Epoch   0 Batch 14007/17275   train_loss = 3.460\n",
      "Epoch   0 Batch 14008/17275   train_loss = 7.255\n",
      "Epoch   0 Batch 14009/17275   train_loss = 3.356\n",
      "Epoch   0 Batch 14010/17275   train_loss = 3.652\n",
      "Epoch   0 Batch 14011/17275   train_loss = 2.571\n",
      "Epoch   0 Batch 14012/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 14013/17275   train_loss = 3.406\n",
      "Epoch   0 Batch 14014/17275   train_loss = 6.186\n",
      "Epoch   0 Batch 14015/17275   train_loss = 4.468\n",
      "Epoch   0 Batch 14016/17275   train_loss = 2.268\n",
      "Epoch   0 Batch 14017/17275   train_loss = 4.671\n",
      "Epoch   0 Batch 14018/17275   train_loss = 4.225\n",
      "Epoch   0 Batch 14019/17275   train_loss = 3.523\n",
      "Epoch   0 Batch 14020/17275   train_loss = 7.356\n",
      "Epoch   0 Batch 14021/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 14022/17275   train_loss = 4.618\n",
      "Epoch   0 Batch 14023/17275   train_loss = 3.041\n",
      "Epoch   0 Batch 14024/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 14025/17275   train_loss = 7.683\n",
      "Epoch   0 Batch 14026/17275   train_loss = 2.138\n",
      "Epoch   0 Batch 14027/17275   train_loss = 3.656\n",
      "Epoch   0 Batch 14028/17275   train_loss = 3.847\n",
      "Epoch   0 Batch 14029/17275   train_loss = 5.418\n",
      "Epoch   0 Batch 14030/17275   train_loss = 6.864\n",
      "Epoch   0 Batch 14031/17275   train_loss = 2.166\n",
      "Epoch   0 Batch 14032/17275   train_loss = 3.171\n",
      "Epoch   0 Batch 14033/17275   train_loss = 4.021\n",
      "Epoch   0 Batch 14034/17275   train_loss = 6.693\n",
      "Epoch   0 Batch 14035/17275   train_loss = 3.988\n",
      "Epoch   0 Batch 14036/17275   train_loss = 2.246\n",
      "Epoch   0 Batch 14037/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 14038/17275   train_loss = 2.026\n",
      "Epoch   0 Batch 14039/17275   train_loss = 4.206\n",
      "Epoch   0 Batch 14040/17275   train_loss = 5.975\n",
      "Epoch   0 Batch 14041/17275   train_loss = 2.569\n",
      "Epoch   0 Batch 14042/17275   train_loss = 3.222\n",
      "Epoch   0 Batch 14043/17275   train_loss = 4.915\n",
      "Epoch   0 Batch 14044/17275   train_loss = 2.624\n",
      "Epoch   0 Batch 14045/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 14046/17275   train_loss = 3.972\n",
      "Epoch   0 Batch 14047/17275   train_loss = 7.207\n",
      "Epoch   0 Batch 14048/17275   train_loss = 4.038\n",
      "Epoch   0 Batch 14049/17275   train_loss = 4.626\n",
      "Epoch   0 Batch 14050/17275   train_loss = 3.617\n",
      "Epoch   0 Batch 14051/17275   train_loss = 6.470\n",
      "Epoch   0 Batch 14052/17275   train_loss = 4.442\n",
      "Epoch   0 Batch 14053/17275   train_loss = 5.866\n",
      "Epoch   0 Batch 14054/17275   train_loss = 8.356\n",
      "Epoch   0 Batch 14055/17275   train_loss = 2.225\n",
      "Epoch   0 Batch 14056/17275   train_loss = 4.208\n",
      "Epoch   0 Batch 14057/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 14058/17275   train_loss = 2.635\n",
      "Epoch   0 Batch 14059/17275   train_loss = 4.138\n",
      "Epoch   0 Batch 14060/17275   train_loss = 3.153\n",
      "Epoch   0 Batch 14061/17275   train_loss = 2.667\n",
      "Epoch   0 Batch 14062/17275   train_loss = 4.093\n",
      "Epoch   0 Batch 14063/17275   train_loss = 7.314\n",
      "Epoch   0 Batch 14064/17275   train_loss = 2.767\n",
      "Epoch   0 Batch 14065/17275   train_loss = 2.233\n",
      "Epoch   0 Batch 14066/17275   train_loss = 2.797\n",
      "Epoch   0 Batch 14067/17275   train_loss = 3.257\n",
      "Epoch   0 Batch 14068/17275   train_loss = 3.635\n",
      "Epoch   0 Batch 14069/17275   train_loss = 5.637\n",
      "Epoch   0 Batch 14070/17275   train_loss = 4.349\n",
      "Epoch   0 Batch 14071/17275   train_loss = 2.896\n",
      "Epoch   0 Batch 14072/17275   train_loss = 2.689\n",
      "Epoch   0 Batch 14073/17275   train_loss = 3.356\n",
      "Epoch   0 Batch 14074/17275   train_loss = 3.251\n",
      "Epoch   0 Batch 14075/17275   train_loss = 2.568\n",
      "Epoch   0 Batch 14076/17275   train_loss = 2.018\n",
      "Epoch   0 Batch 14077/17275   train_loss = 3.834\n",
      "Epoch   0 Batch 14078/17275   train_loss = 6.844\n",
      "Epoch   0 Batch 14079/17275   train_loss = 3.551\n",
      "Epoch   0 Batch 14080/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 14081/17275   train_loss = 2.554\n",
      "Epoch   0 Batch 14082/17275   train_loss = 3.553\n",
      "Epoch   0 Batch 14083/17275   train_loss = 4.250\n",
      "Epoch   0 Batch 14084/17275   train_loss = 4.625\n",
      "Epoch   0 Batch 14085/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 14086/17275   train_loss = 1.787\n",
      "Epoch   0 Batch 14087/17275   train_loss = 2.542\n",
      "Epoch   0 Batch 14088/17275   train_loss = 3.129\n",
      "Epoch   0 Batch 14089/17275   train_loss = 5.337\n",
      "Epoch   0 Batch 14090/17275   train_loss = 7.125\n",
      "Epoch   0 Batch 14091/17275   train_loss = 7.113\n",
      "Epoch   0 Batch 14092/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 14093/17275   train_loss = 11.171\n",
      "Epoch   0 Batch 14094/17275   train_loss = 4.211\n",
      "Epoch   0 Batch 14095/17275   train_loss = 7.175\n",
      "Epoch   0 Batch 14096/17275   train_loss = 4.345\n",
      "Epoch   0 Batch 14097/17275   train_loss = 5.773\n",
      "Epoch   0 Batch 14098/17275   train_loss = 4.441\n",
      "Epoch   0 Batch 14099/17275   train_loss = 2.739\n",
      "Epoch   0 Batch 14100/17275   train_loss = 5.138\n",
      "Epoch   0 Batch 14101/17275   train_loss = 4.039\n",
      "Epoch   0 Batch 14102/17275   train_loss = 4.161\n",
      "Epoch   0 Batch 14103/17275   train_loss = 4.685\n",
      "Epoch   0 Batch 14104/17275   train_loss = 2.351\n",
      "Epoch   0 Batch 14105/17275   train_loss = 3.941\n",
      "Epoch   0 Batch 14106/17275   train_loss = 3.491\n",
      "Epoch   0 Batch 14107/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 14108/17275   train_loss = 3.293\n",
      "Epoch   0 Batch 14109/17275   train_loss = 2.743\n",
      "Epoch   0 Batch 14110/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 14111/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 14112/17275   train_loss = 2.543\n",
      "Epoch   0 Batch 14113/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 14114/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 14115/17275   train_loss = 3.530\n",
      "Epoch   0 Batch 14116/17275   train_loss = 7.640\n",
      "Epoch   0 Batch 14117/17275   train_loss = 2.024\n",
      "Epoch   0 Batch 14118/17275   train_loss = 3.791\n",
      "Epoch   0 Batch 14119/17275   train_loss = 2.537\n",
      "Epoch   0 Batch 14120/17275   train_loss = 4.361\n",
      "Epoch   0 Batch 14121/17275   train_loss = 4.458\n",
      "Epoch   0 Batch 14122/17275   train_loss = 11.129\n",
      "Epoch   0 Batch 14123/17275   train_loss = 2.896\n",
      "Epoch   0 Batch 14124/17275   train_loss = 2.007\n",
      "Epoch   0 Batch 14125/17275   train_loss = 5.126\n",
      "Epoch   0 Batch 14126/17275   train_loss = 3.817\n",
      "Epoch   0 Batch 14127/17275   train_loss = 3.129\n",
      "Epoch   0 Batch 14128/17275   train_loss = 2.280\n",
      "Epoch   0 Batch 14129/17275   train_loss = 2.343\n",
      "Epoch   0 Batch 14130/17275   train_loss = 1.932\n",
      "Epoch   0 Batch 14131/17275   train_loss = 3.539\n",
      "Epoch   0 Batch 14132/17275   train_loss = 5.665\n",
      "Epoch   0 Batch 14133/17275   train_loss = 11.147\n",
      "Epoch   0 Batch 14134/17275   train_loss = 4.583\n",
      "Epoch   0 Batch 14135/17275   train_loss = 4.345\n",
      "Epoch   0 Batch 14136/17275   train_loss = 4.477\n",
      "Epoch   0 Batch 14137/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 14138/17275   train_loss = 4.415\n",
      "Epoch   0 Batch 14139/17275   train_loss = 1.931\n",
      "Epoch   0 Batch 14140/17275   train_loss = 3.433\n",
      "Epoch   0 Batch 14141/17275   train_loss = 2.373\n",
      "Epoch   0 Batch 14142/17275   train_loss = 3.557\n",
      "Epoch   0 Batch 14143/17275   train_loss = 4.210\n",
      "Epoch   0 Batch 14144/17275   train_loss = 3.204\n",
      "Epoch   0 Batch 14145/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 14146/17275   train_loss = 2.349\n",
      "Epoch   0 Batch 14147/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 14148/17275   train_loss = 3.789\n",
      "Epoch   0 Batch 14149/17275   train_loss = 4.250\n",
      "Epoch   0 Batch 14150/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 14151/17275   train_loss = 4.406\n",
      "Epoch   0 Batch 14152/17275   train_loss = 3.286\n",
      "Epoch   0 Batch 14153/17275   train_loss = 2.366\n",
      "Epoch   0 Batch 14154/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 14155/17275   train_loss = 2.742\n",
      "Epoch   0 Batch 14156/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 14157/17275   train_loss = 3.644\n",
      "Epoch   0 Batch 14158/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 14159/17275   train_loss = 4.259\n",
      "Epoch   0 Batch 14160/17275   train_loss = 3.942\n",
      "Epoch   0 Batch 14161/17275   train_loss = 2.214\n",
      "Epoch   0 Batch 14162/17275   train_loss = 2.304\n",
      "Epoch   0 Batch 14163/17275   train_loss = 4.437\n",
      "Epoch   0 Batch 14164/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 14165/17275   train_loss = 3.763\n",
      "Epoch   0 Batch 14166/17275   train_loss = 3.053\n",
      "Epoch   0 Batch 14167/17275   train_loss = 3.842\n",
      "Epoch   0 Batch 14168/17275   train_loss = 3.258\n",
      "Epoch   0 Batch 14169/17275   train_loss = 1.935\n",
      "Epoch   0 Batch 14170/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 14171/17275   train_loss = 4.951\n",
      "Epoch   0 Batch 14172/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 14173/17275   train_loss = 3.616\n",
      "Epoch   0 Batch 14174/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 14175/17275   train_loss = 2.801\n",
      "Epoch   0 Batch 14176/17275   train_loss = 1.959\n",
      "Epoch   0 Batch 14177/17275   train_loss = 3.434\n",
      "Epoch   0 Batch 14178/17275   train_loss = 6.707\n",
      "Epoch   0 Batch 14179/17275   train_loss = 3.849\n",
      "Epoch   0 Batch 14180/17275   train_loss = 3.984\n",
      "Epoch   0 Batch 14181/17275   train_loss = 4.756\n",
      "Epoch   0 Batch 14182/17275   train_loss = 2.382\n",
      "Epoch   0 Batch 14183/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 14184/17275   train_loss = 3.166\n",
      "Epoch   0 Batch 14185/17275   train_loss = 3.912\n",
      "Epoch   0 Batch 14186/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 14187/17275   train_loss = 2.694\n",
      "Epoch   0 Batch 14188/17275   train_loss = 3.510\n",
      "Epoch   0 Batch 14189/17275   train_loss = 2.645\n",
      "Epoch   0 Batch 14190/17275   train_loss = 6.725\n",
      "Epoch   0 Batch 14191/17275   train_loss = 3.052\n",
      "Epoch   0 Batch 14192/17275   train_loss = 5.050\n",
      "Epoch   0 Batch 14193/17275   train_loss = 4.870\n",
      "Epoch   0 Batch 14194/17275   train_loss = 5.421\n",
      "Epoch   0 Batch 14195/17275   train_loss = 2.240\n",
      "Epoch   0 Batch 14196/17275   train_loss = 2.976\n",
      "Epoch   0 Batch 14197/17275   train_loss = 2.915\n",
      "Epoch   0 Batch 14198/17275   train_loss = 3.155\n",
      "Epoch   0 Batch 14199/17275   train_loss = 4.066\n",
      "Epoch   0 Batch 14200/17275   train_loss = 3.713\n",
      "Epoch   0 Batch 14201/17275   train_loss = 3.274\n",
      "Epoch   0 Batch 14202/17275   train_loss = 2.274\n",
      "Epoch   0 Batch 14203/17275   train_loss = 2.583\n",
      "Epoch   0 Batch 14204/17275   train_loss = 5.380\n",
      "Epoch   0 Batch 14205/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 14206/17275   train_loss = 4.280\n",
      "Epoch   0 Batch 14207/17275   train_loss = 3.348\n",
      "Epoch   0 Batch 14208/17275   train_loss = 5.375\n",
      "Epoch   0 Batch 14209/17275   train_loss = 2.897\n",
      "Epoch   0 Batch 14210/17275   train_loss = 2.538\n",
      "Epoch   0 Batch 14211/17275   train_loss = 2.913\n",
      "Epoch   0 Batch 14212/17275   train_loss = 2.557\n",
      "Epoch   0 Batch 14213/17275   train_loss = 3.257\n",
      "Epoch   0 Batch 14214/17275   train_loss = 3.690\n",
      "Epoch   0 Batch 14215/17275   train_loss = 2.983\n",
      "Epoch   0 Batch 14216/17275   train_loss = 2.683\n",
      "Epoch   0 Batch 14217/17275   train_loss = 4.389\n",
      "Epoch   0 Batch 14218/17275   train_loss = 2.430\n",
      "Epoch   0 Batch 14219/17275   train_loss = 2.417\n",
      "Epoch   0 Batch 14220/17275   train_loss = 2.784\n",
      "Epoch   0 Batch 14221/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 14222/17275   train_loss = 3.252\n",
      "Epoch   0 Batch 14223/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 14224/17275   train_loss = 2.199\n",
      "Epoch   0 Batch 14225/17275   train_loss = 3.248\n",
      "Epoch   0 Batch 14226/17275   train_loss = 6.852\n",
      "Epoch   0 Batch 14227/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 14228/17275   train_loss = 2.464\n",
      "Epoch   0 Batch 14229/17275   train_loss = 6.049\n",
      "Epoch   0 Batch 14230/17275   train_loss = 6.789\n",
      "Epoch   0 Batch 14231/17275   train_loss = 3.776\n",
      "Epoch   0 Batch 14232/17275   train_loss = 8.945\n",
      "Epoch   0 Batch 14233/17275   train_loss = 5.046\n",
      "Epoch   0 Batch 14234/17275   train_loss = 3.175\n",
      "Epoch   0 Batch 14235/17275   train_loss = 4.654\n",
      "Epoch   0 Batch 14236/17275   train_loss = 2.908\n",
      "Epoch   0 Batch 14237/17275   train_loss = 5.412\n",
      "Epoch   0 Batch 14238/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 14239/17275   train_loss = 3.889\n",
      "Epoch   0 Batch 14240/17275   train_loss = 2.783\n",
      "Epoch   0 Batch 14241/17275   train_loss = 2.495\n",
      "Epoch   0 Batch 14242/17275   train_loss = 4.270\n",
      "Epoch   0 Batch 14243/17275   train_loss = 2.789\n",
      "Epoch   0 Batch 14244/17275   train_loss = 5.448\n",
      "Epoch   0 Batch 14245/17275   train_loss = 2.293\n",
      "Epoch   0 Batch 14246/17275   train_loss = 3.765\n",
      "Epoch   0 Batch 14247/17275   train_loss = 2.463\n",
      "Epoch   0 Batch 14248/17275   train_loss = 4.093\n",
      "Epoch   0 Batch 14249/17275   train_loss = 3.854\n",
      "Epoch   0 Batch 14250/17275   train_loss = 2.867\n",
      "Epoch   0 Batch 14251/17275   train_loss = 7.780\n",
      "Epoch   0 Batch 14252/17275   train_loss = 2.043\n",
      "Epoch   0 Batch 14253/17275   train_loss = 6.844\n",
      "Epoch   0 Batch 14254/17275   train_loss = 2.312\n",
      "Epoch   0 Batch 14255/17275   train_loss = 2.983\n",
      "Epoch   0 Batch 14256/17275   train_loss = 3.827\n",
      "Epoch   0 Batch 14257/17275   train_loss = 6.865\n",
      "Epoch   0 Batch 14258/17275   train_loss = 2.216\n",
      "Epoch   0 Batch 14259/17275   train_loss = 3.572\n",
      "Epoch   0 Batch 14260/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 14261/17275   train_loss = 4.382\n",
      "Epoch   0 Batch 14262/17275   train_loss = 2.233\n",
      "Epoch   0 Batch 14263/17275   train_loss = 2.299\n",
      "Epoch   0 Batch 14264/17275   train_loss = 5.106\n",
      "Epoch   0 Batch 14265/17275   train_loss = 6.233\n",
      "Epoch   0 Batch 14266/17275   train_loss = 1.966\n",
      "Epoch   0 Batch 14267/17275   train_loss = 6.699\n",
      "Epoch   0 Batch 14268/17275   train_loss = 2.177\n",
      "Epoch   0 Batch 14269/17275   train_loss = 4.063\n",
      "Epoch   0 Batch 14270/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 14271/17275   train_loss = 3.276\n",
      "Epoch   0 Batch 14272/17275   train_loss = 7.020\n",
      "Epoch   0 Batch 14273/17275   train_loss = 3.938\n",
      "Epoch   0 Batch 14274/17275   train_loss = 6.656\n",
      "Epoch   0 Batch 14275/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 14276/17275   train_loss = 4.121\n",
      "Epoch   0 Batch 14277/17275   train_loss = 6.635\n",
      "Epoch   0 Batch 14278/17275   train_loss = 1.934\n",
      "Epoch   0 Batch 14279/17275   train_loss = 3.601\n",
      "Epoch   0 Batch 14280/17275   train_loss = 6.854\n",
      "Epoch   0 Batch 14281/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 14282/17275   train_loss = 2.306\n",
      "Epoch   0 Batch 14283/17275   train_loss = 3.893\n",
      "Epoch   0 Batch 14284/17275   train_loss = 3.880\n",
      "Epoch   0 Batch 14285/17275   train_loss = 5.795\n",
      "Epoch   0 Batch 14286/17275   train_loss = 2.470\n",
      "Epoch   0 Batch 14287/17275   train_loss = 3.285\n",
      "Epoch   0 Batch 14288/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 14289/17275   train_loss = 2.768\n",
      "Epoch   0 Batch 14290/17275   train_loss = 4.660\n",
      "Epoch   0 Batch 14291/17275   train_loss = 4.567\n",
      "Epoch   0 Batch 14292/17275   train_loss = 7.879\n",
      "Epoch   0 Batch 14293/17275   train_loss = 5.892\n",
      "Epoch   0 Batch 14294/17275   train_loss = 2.053\n",
      "Epoch   0 Batch 14295/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 14296/17275   train_loss = 3.680\n",
      "Epoch   0 Batch 14297/17275   train_loss = 1.925\n",
      "Epoch   0 Batch 14298/17275   train_loss = 2.714\n",
      "Epoch   0 Batch 14299/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 14300/17275   train_loss = 6.780\n",
      "Epoch   0 Batch 14301/17275   train_loss = 5.365\n",
      "Epoch   0 Batch 14302/17275   train_loss = 4.325\n",
      "Epoch   0 Batch 14303/17275   train_loss = 4.678\n",
      "Epoch   0 Batch 14304/17275   train_loss = 6.574\n",
      "Epoch   0 Batch 14305/17275   train_loss = 2.962\n",
      "Epoch   0 Batch 14306/17275   train_loss = 3.199\n",
      "Epoch   0 Batch 14307/17275   train_loss = 5.124\n",
      "Epoch   0 Batch 14308/17275   train_loss = 2.195\n",
      "Epoch   0 Batch 14309/17275   train_loss = 2.926\n",
      "Epoch   0 Batch 14310/17275   train_loss = 3.748\n",
      "Epoch   0 Batch 14311/17275   train_loss = 2.441\n",
      "Epoch   0 Batch 14312/17275   train_loss = 2.608\n",
      "Epoch   0 Batch 14313/17275   train_loss = 2.742\n",
      "Epoch   0 Batch 14314/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 14315/17275   train_loss = 2.081\n",
      "Epoch   0 Batch 14316/17275   train_loss = 7.087\n",
      "Epoch   0 Batch 14317/17275   train_loss = 6.579\n",
      "Epoch   0 Batch 14318/17275   train_loss = 2.530\n",
      "Epoch   0 Batch 14319/17275   train_loss = 3.862\n",
      "Epoch   0 Batch 14320/17275   train_loss = 4.300\n",
      "Epoch   0 Batch 14321/17275   train_loss = 2.726\n",
      "Epoch   0 Batch 14322/17275   train_loss = 2.718\n",
      "Epoch   0 Batch 14323/17275   train_loss = 3.595\n",
      "Epoch   0 Batch 14324/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 14325/17275   train_loss = 3.856\n",
      "Epoch   0 Batch 14326/17275   train_loss = 3.666\n",
      "Epoch   0 Batch 14327/17275   train_loss = 2.150\n",
      "Epoch   0 Batch 14328/17275   train_loss = 5.747\n",
      "Epoch   0 Batch 14329/17275   train_loss = 6.828\n",
      "Epoch   0 Batch 14330/17275   train_loss = 2.081\n",
      "Epoch   0 Batch 14331/17275   train_loss = 4.652\n",
      "Epoch   0 Batch 14332/17275   train_loss = 2.935\n",
      "Epoch   0 Batch 14333/17275   train_loss = 6.910\n",
      "Epoch   0 Batch 14334/17275   train_loss = 4.690\n",
      "Epoch   0 Batch 14335/17275   train_loss = 2.214\n",
      "Epoch   0 Batch 14336/17275   train_loss = 3.867\n",
      "Epoch   0 Batch 14337/17275   train_loss = 3.233\n",
      "Epoch   0 Batch 14338/17275   train_loss = 2.545\n",
      "Epoch   0 Batch 14339/17275   train_loss = 8.600\n",
      "Epoch   0 Batch 14340/17275   train_loss = 2.525\n",
      "Epoch   0 Batch 14341/17275   train_loss = 8.447\n",
      "Epoch   0 Batch 14342/17275   train_loss = 2.880\n",
      "Epoch   0 Batch 14343/17275   train_loss = 3.718\n",
      "Epoch   0 Batch 14344/17275   train_loss = 3.477\n",
      "Epoch   0 Batch 14345/17275   train_loss = 3.548\n",
      "Epoch   0 Batch 14346/17275   train_loss = 3.393\n",
      "Epoch   0 Batch 14347/17275   train_loss = 5.101\n",
      "Epoch   0 Batch 14348/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 14349/17275   train_loss = 4.231\n",
      "Epoch   0 Batch 14350/17275   train_loss = 2.206\n",
      "Epoch   0 Batch 14351/17275   train_loss = 3.203\n",
      "Epoch   0 Batch 14352/17275   train_loss = 6.121\n",
      "Epoch   0 Batch 14353/17275   train_loss = 2.910\n",
      "Epoch   0 Batch 14354/17275   train_loss = 7.505\n",
      "Epoch   0 Batch 14355/17275   train_loss = 5.123\n",
      "Epoch   0 Batch 14356/17275   train_loss = 2.499\n",
      "Epoch   0 Batch 14357/17275   train_loss = 7.695\n",
      "Epoch   0 Batch 14358/17275   train_loss = 7.243\n",
      "Epoch   0 Batch 14359/17275   train_loss = 2.117\n",
      "Epoch   0 Batch 14360/17275   train_loss = 2.936\n",
      "Epoch   0 Batch 14361/17275   train_loss = 3.319\n",
      "Epoch   0 Batch 14362/17275   train_loss = 4.542\n",
      "Epoch   0 Batch 14363/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 14364/17275   train_loss = 2.117\n",
      "Epoch   0 Batch 14365/17275   train_loss = 3.061\n",
      "Epoch   0 Batch 14366/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 14367/17275   train_loss = 3.513\n",
      "Epoch   0 Batch 14368/17275   train_loss = 2.940\n",
      "Epoch   0 Batch 14369/17275   train_loss = 4.505\n",
      "Epoch   0 Batch 14370/17275   train_loss = 4.793\n",
      "Epoch   0 Batch 14371/17275   train_loss = 4.348\n",
      "Epoch   0 Batch 14372/17275   train_loss = 4.485\n",
      "Epoch   0 Batch 14373/17275   train_loss = 3.830\n",
      "Epoch   0 Batch 14374/17275   train_loss = 11.226\n",
      "Epoch   0 Batch 14375/17275   train_loss = 2.118\n",
      "Epoch   0 Batch 14376/17275   train_loss = 6.721\n",
      "Epoch   0 Batch 14377/17275   train_loss = 7.713\n",
      "Epoch   0 Batch 14378/17275   train_loss = 2.469\n",
      "Epoch   0 Batch 14379/17275   train_loss = 7.576\n",
      "Epoch   0 Batch 14380/17275   train_loss = 6.663\n",
      "Epoch   0 Batch 14381/17275   train_loss = 2.276\n",
      "Epoch   0 Batch 14382/17275   train_loss = 3.927\n",
      "Epoch   0 Batch 14383/17275   train_loss = 6.259\n",
      "Epoch   0 Batch 14384/17275   train_loss = 6.181\n",
      "Epoch   0 Batch 14385/17275   train_loss = 2.905\n",
      "Epoch   0 Batch 14386/17275   train_loss = 2.872\n",
      "Epoch   0 Batch 14387/17275   train_loss = 3.236\n",
      "Epoch   0 Batch 14388/17275   train_loss = 3.584\n",
      "Epoch   0 Batch 14389/17275   train_loss = 4.554\n",
      "Epoch   0 Batch 14390/17275   train_loss = 7.542\n",
      "Epoch   0 Batch 14391/17275   train_loss = 1.987\n",
      "Epoch   0 Batch 14392/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 14393/17275   train_loss = 2.304\n",
      "Epoch   0 Batch 14394/17275   train_loss = 3.133\n",
      "Epoch   0 Batch 14395/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 14396/17275   train_loss = 5.111\n",
      "Epoch   0 Batch 14397/17275   train_loss = 1.943\n",
      "Epoch   0 Batch 14398/17275   train_loss = 4.606\n",
      "Epoch   0 Batch 14399/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 14400/17275   train_loss = 3.816\n",
      "Epoch   0 Batch 14401/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 14402/17275   train_loss = 6.340\n",
      "Epoch   0 Batch 14403/17275   train_loss = 3.907\n",
      "Epoch   0 Batch 14404/17275   train_loss = 2.917\n",
      "Epoch   0 Batch 14405/17275   train_loss = 2.386\n",
      "Epoch   0 Batch 14406/17275   train_loss = 3.414\n",
      "Epoch   0 Batch 14407/17275   train_loss = 5.887\n",
      "Epoch   0 Batch 14408/17275   train_loss = 4.062\n",
      "Epoch   0 Batch 14409/17275   train_loss = 11.212\n",
      "Epoch   0 Batch 14410/17275   train_loss = 1.925\n",
      "Epoch   0 Batch 14411/17275   train_loss = 3.606\n",
      "Epoch   0 Batch 14412/17275   train_loss = 4.082\n",
      "Epoch   0 Batch 14413/17275   train_loss = 4.723\n",
      "Epoch   0 Batch 14414/17275   train_loss = 4.754\n",
      "Epoch   0 Batch 14415/17275   train_loss = 8.743\n",
      "Epoch   0 Batch 14416/17275   train_loss = 1.925\n",
      "Epoch   0 Batch 14417/17275   train_loss = 4.762\n",
      "Epoch   0 Batch 14418/17275   train_loss = 1.915\n",
      "Epoch   0 Batch 14419/17275   train_loss = 3.234\n",
      "Epoch   0 Batch 14420/17275   train_loss = 2.944\n",
      "Epoch   0 Batch 14421/17275   train_loss = 3.850\n",
      "Epoch   0 Batch 14422/17275   train_loss = 2.457\n",
      "Epoch   0 Batch 14423/17275   train_loss = 1.886\n",
      "Epoch   0 Batch 14424/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 14425/17275   train_loss = 3.216\n",
      "Epoch   0 Batch 14426/17275   train_loss = 2.933\n",
      "Epoch   0 Batch 14427/17275   train_loss = 3.200\n",
      "Epoch   0 Batch 14428/17275   train_loss = 3.813\n",
      "Epoch   0 Batch 14429/17275   train_loss = 4.169\n",
      "Epoch   0 Batch 14430/17275   train_loss = 2.884\n",
      "Epoch   0 Batch 14431/17275   train_loss = 6.738\n",
      "Epoch   0 Batch 14432/17275   train_loss = 4.624\n",
      "Epoch   0 Batch 14433/17275   train_loss = 2.656\n",
      "Epoch   0 Batch 14434/17275   train_loss = 3.190\n",
      "Epoch   0 Batch 14435/17275   train_loss = 3.493\n",
      "Epoch   0 Batch 14436/17275   train_loss = 7.354\n",
      "Epoch   0 Batch 14437/17275   train_loss = 3.813\n",
      "Epoch   0 Batch 14438/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 14439/17275   train_loss = 4.125\n",
      "Epoch   0 Batch 14440/17275   train_loss = 4.305\n",
      "Epoch   0 Batch 14441/17275   train_loss = 4.254\n",
      "Epoch   0 Batch 14442/17275   train_loss = 8.846\n",
      "Epoch   0 Batch 14443/17275   train_loss = 5.447\n",
      "Epoch   0 Batch 14444/17275   train_loss = 3.395\n",
      "Epoch   0 Batch 14445/17275   train_loss = 1.954\n",
      "Epoch   0 Batch 14446/17275   train_loss = 2.753\n",
      "Epoch   0 Batch 14447/17275   train_loss = 9.104\n",
      "Epoch   0 Batch 14448/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 14449/17275   train_loss = 3.322\n",
      "Epoch   0 Batch 14450/17275   train_loss = 4.158\n",
      "Epoch   0 Batch 14451/17275   train_loss = 7.043\n",
      "Epoch   0 Batch 14452/17275   train_loss = 2.866\n",
      "Epoch   0 Batch 14453/17275   train_loss = 3.465\n",
      "Epoch   0 Batch 14454/17275   train_loss = 2.240\n",
      "Epoch   0 Batch 14455/17275   train_loss = 8.322\n",
      "Epoch   0 Batch 14456/17275   train_loss = 7.672\n",
      "Epoch   0 Batch 14457/17275   train_loss = 2.942\n",
      "Epoch   0 Batch 14458/17275   train_loss = 6.588\n",
      "Epoch   0 Batch 14459/17275   train_loss = 2.293\n",
      "Epoch   0 Batch 14460/17275   train_loss = 6.985\n",
      "Epoch   0 Batch 14461/17275   train_loss = 3.084\n",
      "Epoch   0 Batch 14462/17275   train_loss = 2.945\n",
      "Epoch   0 Batch 14463/17275   train_loss = 3.049\n",
      "Epoch   0 Batch 14464/17275   train_loss = 1.976\n",
      "Epoch   0 Batch 14465/17275   train_loss = 2.322\n",
      "Epoch   0 Batch 14466/17275   train_loss = 4.357\n",
      "Epoch   0 Batch 14467/17275   train_loss = 3.135\n",
      "Epoch   0 Batch 14468/17275   train_loss = 4.415\n",
      "Epoch   0 Batch 14469/17275   train_loss = 3.907\n",
      "Epoch   0 Batch 14470/17275   train_loss = 6.542\n",
      "Epoch   0 Batch 14471/17275   train_loss = 6.649\n",
      "Epoch   0 Batch 14472/17275   train_loss = 5.023\n",
      "Epoch   0 Batch 14473/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 14474/17275   train_loss = 3.301\n",
      "Epoch   0 Batch 14475/17275   train_loss = 2.630\n",
      "Epoch   0 Batch 14476/17275   train_loss = 3.527\n",
      "Epoch   0 Batch 14477/17275   train_loss = 3.730\n",
      "Epoch   0 Batch 14478/17275   train_loss = 7.413\n",
      "Epoch   0 Batch 14479/17275   train_loss = 7.147\n",
      "Epoch   0 Batch 14480/17275   train_loss = 4.374\n",
      "Epoch   0 Batch 14481/17275   train_loss = 5.637\n",
      "Epoch   0 Batch 14482/17275   train_loss = 7.284\n",
      "Epoch   0 Batch 14483/17275   train_loss = 4.218\n",
      "Epoch   0 Batch 14484/17275   train_loss = 4.304\n",
      "Epoch   0 Batch 14485/17275   train_loss = 6.223\n",
      "Epoch   0 Batch 14486/17275   train_loss = 7.442\n",
      "Epoch   0 Batch 14487/17275   train_loss = 1.929\n",
      "Epoch   0 Batch 14488/17275   train_loss = 11.056\n",
      "Epoch   0 Batch 14489/17275   train_loss = 7.052\n",
      "Epoch   0 Batch 14490/17275   train_loss = 2.632\n",
      "Epoch   0 Batch 14491/17275   train_loss = 3.144\n",
      "Epoch   0 Batch 14492/17275   train_loss = 6.300\n",
      "Epoch   0 Batch 14493/17275   train_loss = 8.021\n",
      "Epoch   0 Batch 14494/17275   train_loss = 3.933\n",
      "Epoch   0 Batch 14495/17275   train_loss = 1.934\n",
      "Epoch   0 Batch 14496/17275   train_loss = 7.427\n",
      "Epoch   0 Batch 14497/17275   train_loss = 3.254\n",
      "Epoch   0 Batch 14498/17275   train_loss = 2.978\n",
      "Epoch   0 Batch 14499/17275   train_loss = 3.000\n",
      "Epoch   0 Batch 14500/17275   train_loss = 4.860\n",
      "Epoch   0 Batch 14501/17275   train_loss = 7.112\n",
      "Epoch   0 Batch 14502/17275   train_loss = 4.180\n",
      "Epoch   0 Batch 14503/17275   train_loss = 5.286\n",
      "Epoch   0 Batch 14504/17275   train_loss = 3.606\n",
      "Epoch   0 Batch 14505/17275   train_loss = 6.620\n",
      "Epoch   0 Batch 14506/17275   train_loss = 6.213\n",
      "Epoch   0 Batch 14507/17275   train_loss = 2.395\n",
      "Epoch   0 Batch 14508/17275   train_loss = 2.598\n",
      "Epoch   0 Batch 14509/17275   train_loss = 5.600\n",
      "Epoch   0 Batch 14510/17275   train_loss = 3.277\n",
      "Epoch   0 Batch 14511/17275   train_loss = 8.184\n",
      "Epoch   0 Batch 14512/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 14513/17275   train_loss = 4.360\n",
      "Epoch   0 Batch 14514/17275   train_loss = 7.906\n",
      "Epoch   0 Batch 14515/17275   train_loss = 6.559\n",
      "Epoch   0 Batch 14516/17275   train_loss = 2.776\n",
      "Epoch   0 Batch 14517/17275   train_loss = 5.968\n",
      "Epoch   0 Batch 14518/17275   train_loss = 2.026\n",
      "Epoch   0 Batch 14519/17275   train_loss = 3.221\n",
      "Epoch   0 Batch 14520/17275   train_loss = 2.903\n",
      "Epoch   0 Batch 14521/17275   train_loss = 3.470\n",
      "Epoch   0 Batch 14522/17275   train_loss = 3.437\n",
      "Epoch   0 Batch 14523/17275   train_loss = 2.320\n",
      "Epoch   0 Batch 14524/17275   train_loss = 4.654\n",
      "Epoch   0 Batch 14525/17275   train_loss = 3.742\n",
      "Epoch   0 Batch 14526/17275   train_loss = 2.377\n",
      "Epoch   0 Batch 14527/17275   train_loss = 2.504\n",
      "Epoch   0 Batch 14528/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 14529/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 14530/17275   train_loss = 2.093\n",
      "Epoch   0 Batch 14531/17275   train_loss = 2.365\n",
      "Epoch   0 Batch 14532/17275   train_loss = 7.462\n",
      "Epoch   0 Batch 14533/17275   train_loss = 2.492\n",
      "Epoch   0 Batch 14534/17275   train_loss = 3.721\n",
      "Epoch   0 Batch 14535/17275   train_loss = 3.458\n",
      "Epoch   0 Batch 14536/17275   train_loss = 2.679\n",
      "Epoch   0 Batch 14537/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 14538/17275   train_loss = 2.840\n",
      "Epoch   0 Batch 14539/17275   train_loss = 3.932\n",
      "Epoch   0 Batch 14540/17275   train_loss = 4.220\n",
      "Epoch   0 Batch 14541/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 14542/17275   train_loss = 4.225\n",
      "Epoch   0 Batch 14543/17275   train_loss = 7.116\n",
      "Epoch   0 Batch 14544/17275   train_loss = 7.307\n",
      "Epoch   0 Batch 14545/17275   train_loss = 7.419\n",
      "Epoch   0 Batch 14546/17275   train_loss = 1.993\n",
      "Epoch   0 Batch 14547/17275   train_loss = 6.935\n",
      "Epoch   0 Batch 14548/17275   train_loss = 4.008\n",
      "Epoch   0 Batch 14549/17275   train_loss = 2.633\n",
      "Epoch   0 Batch 14550/17275   train_loss = 3.236\n",
      "Epoch   0 Batch 14551/17275   train_loss = 3.687\n",
      "Epoch   0 Batch 14552/17275   train_loss = 5.085\n",
      "Epoch   0 Batch 14553/17275   train_loss = 2.251\n",
      "Epoch   0 Batch 14554/17275   train_loss = 3.018\n",
      "Epoch   0 Batch 14555/17275   train_loss = 3.510\n",
      "Epoch   0 Batch 14556/17275   train_loss = 7.511\n",
      "Epoch   0 Batch 14557/17275   train_loss = 2.028\n",
      "Epoch   0 Batch 14558/17275   train_loss = 2.528\n",
      "Epoch   0 Batch 14559/17275   train_loss = 3.761\n",
      "Epoch   0 Batch 14560/17275   train_loss = 2.992\n",
      "Epoch   0 Batch 14561/17275   train_loss = 3.633\n",
      "Epoch   0 Batch 14562/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 14563/17275   train_loss = 4.173\n",
      "Epoch   0 Batch 14564/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 14565/17275   train_loss = 4.556\n",
      "Epoch   0 Batch 14566/17275   train_loss = 3.265\n",
      "Epoch   0 Batch 14567/17275   train_loss = 4.178\n",
      "Epoch   0 Batch 14568/17275   train_loss = 7.384\n",
      "Epoch   0 Batch 14569/17275   train_loss = 4.815\n",
      "Epoch   0 Batch 14570/17275   train_loss = 3.300\n",
      "Epoch   0 Batch 14571/17275   train_loss = 2.788\n",
      "Epoch   0 Batch 14572/17275   train_loss = 6.570\n",
      "Epoch   0 Batch 14573/17275   train_loss = 3.561\n",
      "Epoch   0 Batch 14574/17275   train_loss = 5.122\n",
      "Epoch   0 Batch 14575/17275   train_loss = 3.262\n",
      "Epoch   0 Batch 14576/17275   train_loss = 2.788\n",
      "Epoch   0 Batch 14577/17275   train_loss = 4.411\n",
      "Epoch   0 Batch 14578/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 14579/17275   train_loss = 6.917\n",
      "Epoch   0 Batch 14580/17275   train_loss = 3.383\n",
      "Epoch   0 Batch 14581/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 14582/17275   train_loss = 3.119\n",
      "Epoch   0 Batch 14583/17275   train_loss = 5.171\n",
      "Epoch   0 Batch 14584/17275   train_loss = 3.971\n",
      "Epoch   0 Batch 14585/17275   train_loss = 3.642\n",
      "Epoch   0 Batch 14586/17275   train_loss = 6.640\n",
      "Epoch   0 Batch 14587/17275   train_loss = 2.672\n",
      "Epoch   0 Batch 14588/17275   train_loss = 3.318\n",
      "Epoch   0 Batch 14589/17275   train_loss = 4.396\n",
      "Epoch   0 Batch 14590/17275   train_loss = 2.518\n",
      "Epoch   0 Batch 14591/17275   train_loss = 3.582\n",
      "Epoch   0 Batch 14592/17275   train_loss = 6.600\n",
      "Epoch   0 Batch 14593/17275   train_loss = 3.676\n",
      "Epoch   0 Batch 14594/17275   train_loss = 3.210\n",
      "Epoch   0 Batch 14595/17275   train_loss = 2.061\n",
      "Epoch   0 Batch 14596/17275   train_loss = 2.761\n",
      "Epoch   0 Batch 14597/17275   train_loss = 8.218\n",
      "Epoch   0 Batch 14598/17275   train_loss = 4.838\n",
      "Epoch   0 Batch 14599/17275   train_loss = 2.766\n",
      "Epoch   0 Batch 14600/17275   train_loss = 3.075\n",
      "Epoch   0 Batch 14601/17275   train_loss = 4.927\n",
      "Epoch   0 Batch 14602/17275   train_loss = 11.228\n",
      "Epoch   0 Batch 14603/17275   train_loss = 11.228\n",
      "Epoch   0 Batch 14604/17275   train_loss = 2.011\n",
      "Epoch   0 Batch 14605/17275   train_loss = 6.850\n",
      "Epoch   0 Batch 14606/17275   train_loss = 3.934\n",
      "Epoch   0 Batch 14607/17275   train_loss = 2.802\n",
      "Epoch   0 Batch 14608/17275   train_loss = 4.131\n",
      "Epoch   0 Batch 14609/17275   train_loss = 3.689\n",
      "Epoch   0 Batch 14610/17275   train_loss = 4.259\n",
      "Epoch   0 Batch 14611/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 14612/17275   train_loss = 4.490\n",
      "Epoch   0 Batch 14613/17275   train_loss = 6.926\n",
      "Epoch   0 Batch 14614/17275   train_loss = 2.397\n",
      "Epoch   0 Batch 14615/17275   train_loss = 4.171\n",
      "Epoch   0 Batch 14616/17275   train_loss = 6.689\n",
      "Epoch   0 Batch 14617/17275   train_loss = 2.091\n",
      "Epoch   0 Batch 14618/17275   train_loss = 8.724\n",
      "Epoch   0 Batch 14619/17275   train_loss = 4.203\n",
      "Epoch   0 Batch 14620/17275   train_loss = 3.054\n",
      "Epoch   0 Batch 14621/17275   train_loss = 6.785\n",
      "Epoch   0 Batch 14622/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 14623/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 14624/17275   train_loss = 2.620\n",
      "Epoch   0 Batch 14625/17275   train_loss = 5.218\n",
      "Epoch   0 Batch 14626/17275   train_loss = 3.891\n",
      "Epoch   0 Batch 14627/17275   train_loss = 2.855\n",
      "Epoch   0 Batch 14628/17275   train_loss = 4.540\n",
      "Epoch   0 Batch 14629/17275   train_loss = 7.508\n",
      "Epoch   0 Batch 14630/17275   train_loss = 1.993\n",
      "Epoch   0 Batch 14631/17275   train_loss = 2.479\n",
      "Epoch   0 Batch 14632/17275   train_loss = 6.725\n",
      "Epoch   0 Batch 14633/17275   train_loss = 3.710\n",
      "Epoch   0 Batch 14634/17275   train_loss = 3.567\n",
      "Epoch   0 Batch 14635/17275   train_loss = 4.876\n",
      "Epoch   0 Batch 14636/17275   train_loss = 7.391\n",
      "Epoch   0 Batch 14637/17275   train_loss = 7.114\n",
      "Epoch   0 Batch 14638/17275   train_loss = 4.034\n",
      "Epoch   0 Batch 14639/17275   train_loss = 2.001\n",
      "Epoch   0 Batch 14640/17275   train_loss = 7.355\n",
      "Epoch   0 Batch 14641/17275   train_loss = 1.995\n",
      "Epoch   0 Batch 14642/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 14643/17275   train_loss = 6.504\n",
      "Epoch   0 Batch 14644/17275   train_loss = 1.776\n",
      "Epoch   0 Batch 14645/17275   train_loss = 7.397\n",
      "Epoch   0 Batch 14646/17275   train_loss = 4.114\n",
      "Epoch   0 Batch 14647/17275   train_loss = 5.398\n",
      "Epoch   0 Batch 14648/17275   train_loss = 6.908\n",
      "Epoch   0 Batch 14649/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 14650/17275   train_loss = 1.901\n",
      "Epoch   0 Batch 14651/17275   train_loss = 2.120\n",
      "Epoch   0 Batch 14652/17275   train_loss = 3.431\n",
      "Epoch   0 Batch 14653/17275   train_loss = 2.606\n",
      "Epoch   0 Batch 14654/17275   train_loss = 3.457\n",
      "Epoch   0 Batch 14655/17275   train_loss = 8.969\n",
      "Epoch   0 Batch 14656/17275   train_loss = 3.715\n",
      "Epoch   0 Batch 14657/17275   train_loss = 7.554\n",
      "Epoch   0 Batch 14658/17275   train_loss = 4.000\n",
      "Epoch   0 Batch 14659/17275   train_loss = 3.351\n",
      "Epoch   0 Batch 14660/17275   train_loss = 6.460\n",
      "Epoch   0 Batch 14661/17275   train_loss = 2.760\n",
      "Epoch   0 Batch 14662/17275   train_loss = 3.765\n",
      "Epoch   0 Batch 14663/17275   train_loss = 6.816\n",
      "Epoch   0 Batch 14664/17275   train_loss = 2.666\n",
      "Epoch   0 Batch 14665/17275   train_loss = 2.861\n",
      "Epoch   0 Batch 14666/17275   train_loss = 3.166\n",
      "Epoch   0 Batch 14667/17275   train_loss = 2.754\n",
      "Epoch   0 Batch 14668/17275   train_loss = 2.603\n",
      "Epoch   0 Batch 14669/17275   train_loss = 3.778\n",
      "Epoch   0 Batch 14670/17275   train_loss = 2.194\n",
      "Epoch   0 Batch 14671/17275   train_loss = 9.114\n",
      "Epoch   0 Batch 14672/17275   train_loss = 3.610\n",
      "Epoch   0 Batch 14673/17275   train_loss = 1.818\n",
      "Epoch   0 Batch 14674/17275   train_loss = 4.624\n",
      "Epoch   0 Batch 14675/17275   train_loss = 2.820\n",
      "Epoch   0 Batch 14676/17275   train_loss = 3.105\n",
      "Epoch   0 Batch 14677/17275   train_loss = 5.022\n",
      "Epoch   0 Batch 14678/17275   train_loss = 7.549\n",
      "Epoch   0 Batch 14679/17275   train_loss = 2.938\n",
      "Epoch   0 Batch 14680/17275   train_loss = 4.527\n",
      "Epoch   0 Batch 14681/17275   train_loss = 3.707\n",
      "Epoch   0 Batch 14682/17275   train_loss = 3.752\n",
      "Epoch   0 Batch 14683/17275   train_loss = 4.369\n",
      "Epoch   0 Batch 14684/17275   train_loss = 3.785\n",
      "Epoch   0 Batch 14685/17275   train_loss = 11.232\n",
      "Epoch   0 Batch 14686/17275   train_loss = 6.799\n",
      "Epoch   0 Batch 14687/17275   train_loss = 1.773\n",
      "Epoch   0 Batch 14688/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 14689/17275   train_loss = 3.797\n",
      "Epoch   0 Batch 14690/17275   train_loss = 6.762\n",
      "Epoch   0 Batch 14691/17275   train_loss = 2.995\n",
      "Epoch   0 Batch 14692/17275   train_loss = 6.433\n",
      "Epoch   0 Batch 14693/17275   train_loss = 2.790\n",
      "Epoch   0 Batch 14694/17275   train_loss = 4.003\n",
      "Epoch   0 Batch 14695/17275   train_loss = 6.456\n",
      "Epoch   0 Batch 14696/17275   train_loss = 2.400\n",
      "Epoch   0 Batch 14697/17275   train_loss = 3.291\n",
      "Epoch   0 Batch 14698/17275   train_loss = 3.569\n",
      "Epoch   0 Batch 14699/17275   train_loss = 3.408\n",
      "Epoch   0 Batch 14700/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 14701/17275   train_loss = 4.400\n",
      "Epoch   0 Batch 14702/17275   train_loss = 1.893\n",
      "Epoch   0 Batch 14703/17275   train_loss = 2.868\n",
      "Epoch   0 Batch 14704/17275   train_loss = 7.472\n",
      "Epoch   0 Batch 14705/17275   train_loss = 5.748\n",
      "Epoch   0 Batch 14706/17275   train_loss = 1.899\n",
      "Epoch   0 Batch 14707/17275   train_loss = 3.950\n",
      "Epoch   0 Batch 14708/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 14709/17275   train_loss = 3.947\n",
      "Epoch   0 Batch 14710/17275   train_loss = 4.167\n",
      "Epoch   0 Batch 14711/17275   train_loss = 4.942\n",
      "Epoch   0 Batch 14712/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 14713/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 14714/17275   train_loss = 4.968\n",
      "Epoch   0 Batch 14715/17275   train_loss = 3.099\n",
      "Epoch   0 Batch 14716/17275   train_loss = 2.247\n",
      "Epoch   0 Batch 14717/17275   train_loss = 3.748\n",
      "Epoch   0 Batch 14718/17275   train_loss = 4.283\n",
      "Epoch   0 Batch 14719/17275   train_loss = 3.815\n",
      "Epoch   0 Batch 14720/17275   train_loss = 11.230\n",
      "Epoch   0 Batch 14721/17275   train_loss = 7.275\n",
      "Epoch   0 Batch 14722/17275   train_loss = 4.793\n",
      "Epoch   0 Batch 14723/17275   train_loss = 2.663\n",
      "Epoch   0 Batch 14724/17275   train_loss = 2.859\n",
      "Epoch   0 Batch 14725/17275   train_loss = 5.270\n",
      "Epoch   0 Batch 14726/17275   train_loss = 3.739\n",
      "Epoch   0 Batch 14727/17275   train_loss = 4.345\n",
      "Epoch   0 Batch 14728/17275   train_loss = 5.629\n",
      "Epoch   0 Batch 14729/17275   train_loss = 2.987\n",
      "Epoch   0 Batch 14730/17275   train_loss = 3.771\n",
      "Epoch   0 Batch 14731/17275   train_loss = 2.080\n",
      "Epoch   0 Batch 14732/17275   train_loss = 4.194\n",
      "Epoch   0 Batch 14733/17275   train_loss = 2.955\n",
      "Epoch   0 Batch 14734/17275   train_loss = 7.823\n",
      "Epoch   0 Batch 14735/17275   train_loss = 5.375\n",
      "Epoch   0 Batch 14736/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 14737/17275   train_loss = 3.678\n",
      "Epoch   0 Batch 14738/17275   train_loss = 4.376\n",
      "Epoch   0 Batch 14739/17275   train_loss = 2.625\n",
      "Epoch   0 Batch 14740/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 14741/17275   train_loss = 2.954\n",
      "Epoch   0 Batch 14742/17275   train_loss = 4.718\n",
      "Epoch   0 Batch 14743/17275   train_loss = 2.432\n",
      "Epoch   0 Batch 14744/17275   train_loss = 7.687\n",
      "Epoch   0 Batch 14745/17275   train_loss = 5.585\n",
      "Epoch   0 Batch 14746/17275   train_loss = 5.307\n",
      "Epoch   0 Batch 14747/17275   train_loss = 6.676\n",
      "Epoch   0 Batch 14748/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 14749/17275   train_loss = 4.839\n",
      "Epoch   0 Batch 14750/17275   train_loss = 4.467\n",
      "Epoch   0 Batch 14751/17275   train_loss = 3.527\n",
      "Epoch   0 Batch 14752/17275   train_loss = 6.915\n",
      "Epoch   0 Batch 14753/17275   train_loss = 4.383\n",
      "Epoch   0 Batch 14754/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 14755/17275   train_loss = 6.907\n",
      "Epoch   0 Batch 14756/17275   train_loss = 3.218\n",
      "Epoch   0 Batch 14757/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 14758/17275   train_loss = 2.387\n",
      "Epoch   0 Batch 14759/17275   train_loss = 2.996\n",
      "Epoch   0 Batch 14760/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 14761/17275   train_loss = 3.490\n",
      "Epoch   0 Batch 14762/17275   train_loss = 3.205\n",
      "Epoch   0 Batch 14763/17275   train_loss = 3.230\n",
      "Epoch   0 Batch 14764/17275   train_loss = 7.095\n",
      "Epoch   0 Batch 14765/17275   train_loss = 4.533\n",
      "Epoch   0 Batch 14766/17275   train_loss = 2.881\n",
      "Epoch   0 Batch 14767/17275   train_loss = 3.577\n",
      "Epoch   0 Batch 14768/17275   train_loss = 3.408\n",
      "Epoch   0 Batch 14769/17275   train_loss = 5.192\n",
      "Epoch   0 Batch 14770/17275   train_loss = 3.303\n",
      "Epoch   0 Batch 14771/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 14772/17275   train_loss = 4.581\n",
      "Epoch   0 Batch 14773/17275   train_loss = 11.208\n",
      "Epoch   0 Batch 14774/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 14775/17275   train_loss = 2.005\n",
      "Epoch   0 Batch 14776/17275   train_loss = 3.588\n",
      "Epoch   0 Batch 14777/17275   train_loss = 6.674\n",
      "Epoch   0 Batch 14778/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 14779/17275   train_loss = 6.666\n",
      "Epoch   0 Batch 14780/17275   train_loss = 7.862\n",
      "Epoch   0 Batch 14781/17275   train_loss = 9.121\n",
      "Epoch   0 Batch 14782/17275   train_loss = 2.652\n",
      "Epoch   0 Batch 14783/17275   train_loss = 4.366\n",
      "Epoch   0 Batch 14784/17275   train_loss = 7.168\n",
      "Epoch   0 Batch 14785/17275   train_loss = 7.214\n",
      "Epoch   0 Batch 14786/17275   train_loss = 2.552\n",
      "Epoch   0 Batch 14787/17275   train_loss = 4.041\n",
      "Epoch   0 Batch 14788/17275   train_loss = 6.753\n",
      "Epoch   0 Batch 14789/17275   train_loss = 11.227\n",
      "Epoch   0 Batch 14790/17275   train_loss = 7.134\n",
      "Epoch   0 Batch 14791/17275   train_loss = 2.579\n",
      "Epoch   0 Batch 14792/17275   train_loss = 3.806\n",
      "Epoch   0 Batch 14793/17275   train_loss = 3.285\n",
      "Epoch   0 Batch 14794/17275   train_loss = 3.190\n",
      "Epoch   0 Batch 14795/17275   train_loss = 3.579\n",
      "Epoch   0 Batch 14796/17275   train_loss = 4.089\n",
      "Epoch   0 Batch 14797/17275   train_loss = 3.622\n",
      "Epoch   0 Batch 14798/17275   train_loss = 3.712\n",
      "Epoch   0 Batch 14799/17275   train_loss = 2.073\n",
      "Epoch   0 Batch 14800/17275   train_loss = 2.426\n",
      "Epoch   0 Batch 14801/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 14802/17275   train_loss = 2.612\n",
      "Epoch   0 Batch 14803/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 14804/17275   train_loss = 3.673\n",
      "Epoch   0 Batch 14805/17275   train_loss = 3.409\n",
      "Epoch   0 Batch 14806/17275   train_loss = 4.856\n",
      "Epoch   0 Batch 14807/17275   train_loss = 3.880\n",
      "Epoch   0 Batch 14808/17275   train_loss = 4.396\n",
      "Epoch   0 Batch 14809/17275   train_loss = 3.330\n",
      "Epoch   0 Batch 14810/17275   train_loss = 2.511\n",
      "Epoch   0 Batch 14811/17275   train_loss = 7.525\n",
      "Epoch   0 Batch 14812/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 14813/17275   train_loss = 5.407\n",
      "Epoch   0 Batch 14814/17275   train_loss = 3.910\n",
      "Epoch   0 Batch 14815/17275   train_loss = 5.084\n",
      "Epoch   0 Batch 14816/17275   train_loss = 6.538\n",
      "Epoch   0 Batch 14817/17275   train_loss = 3.504\n",
      "Epoch   0 Batch 14818/17275   train_loss = 3.763\n",
      "Epoch   0 Batch 14819/17275   train_loss = 2.481\n",
      "Epoch   0 Batch 14820/17275   train_loss = 4.650\n",
      "Epoch   0 Batch 14821/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 14822/17275   train_loss = 3.373\n",
      "Epoch   0 Batch 14823/17275   train_loss = 8.881\n",
      "Epoch   0 Batch 14824/17275   train_loss = 3.910\n",
      "Epoch   0 Batch 14825/17275   train_loss = 2.028\n",
      "Epoch   0 Batch 14826/17275   train_loss = 4.161\n",
      "Epoch   0 Batch 14827/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 14828/17275   train_loss = 2.641\n",
      "Epoch   0 Batch 14829/17275   train_loss = 4.409\n",
      "Epoch   0 Batch 14830/17275   train_loss = 3.225\n",
      "Epoch   0 Batch 14831/17275   train_loss = 4.139\n",
      "Epoch   0 Batch 14832/17275   train_loss = 2.728\n",
      "Epoch   0 Batch 14833/17275   train_loss = 2.645\n",
      "Epoch   0 Batch 14834/17275   train_loss = 3.661\n",
      "Epoch   0 Batch 14835/17275   train_loss = 4.032\n",
      "Epoch   0 Batch 14836/17275   train_loss = 3.124\n",
      "Epoch   0 Batch 14837/17275   train_loss = 4.635\n",
      "Epoch   0 Batch 14838/17275   train_loss = 4.287\n",
      "Epoch   0 Batch 14839/17275   train_loss = 1.960\n",
      "Epoch   0 Batch 14840/17275   train_loss = 2.925\n",
      "Epoch   0 Batch 14841/17275   train_loss = 4.991\n",
      "Epoch   0 Batch 14842/17275   train_loss = 4.356\n",
      "Epoch   0 Batch 14843/17275   train_loss = 3.975\n",
      "Epoch   0 Batch 14844/17275   train_loss = 3.325\n",
      "Epoch   0 Batch 14845/17275   train_loss = 4.270\n",
      "Epoch   0 Batch 14846/17275   train_loss = 4.118\n",
      "Epoch   0 Batch 14847/17275   train_loss = 3.810\n",
      "Epoch   0 Batch 14848/17275   train_loss = 3.389\n",
      "Epoch   0 Batch 14849/17275   train_loss = 4.006\n",
      "Epoch   0 Batch 14850/17275   train_loss = 4.160\n",
      "Epoch   0 Batch 14851/17275   train_loss = 3.826\n",
      "Epoch   0 Batch 14852/17275   train_loss = 1.967\n",
      "Epoch   0 Batch 14853/17275   train_loss = 3.667\n",
      "Epoch   0 Batch 14854/17275   train_loss = 3.426\n",
      "Epoch   0 Batch 14855/17275   train_loss = 4.772\n",
      "Epoch   0 Batch 14856/17275   train_loss = 1.970\n",
      "Epoch   0 Batch 14857/17275   train_loss = 4.507\n",
      "Epoch   0 Batch 14858/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 14859/17275   train_loss = 3.359\n",
      "Epoch   0 Batch 14860/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 14861/17275   train_loss = 7.431\n",
      "Epoch   0 Batch 14862/17275   train_loss = 7.655\n",
      "Epoch   0 Batch 14863/17275   train_loss = 3.340\n",
      "Epoch   0 Batch 14864/17275   train_loss = 2.435\n",
      "Epoch   0 Batch 14865/17275   train_loss = 3.633\n",
      "Epoch   0 Batch 14866/17275   train_loss = 2.810\n",
      "Epoch   0 Batch 14867/17275   train_loss = 4.323\n",
      "Epoch   0 Batch 14868/17275   train_loss = 7.170\n",
      "Epoch   0 Batch 14869/17275   train_loss = 3.736\n",
      "Epoch   0 Batch 14870/17275   train_loss = 3.640\n",
      "Epoch   0 Batch 14871/17275   train_loss = 2.222\n",
      "Epoch   0 Batch 14872/17275   train_loss = 3.234\n",
      "Epoch   0 Batch 14873/17275   train_loss = 2.922\n",
      "Epoch   0 Batch 14874/17275   train_loss = 2.499\n",
      "Epoch   0 Batch 14875/17275   train_loss = 4.497\n",
      "Epoch   0 Batch 14876/17275   train_loss = 2.064\n",
      "Epoch   0 Batch 14877/17275   train_loss = 2.765\n",
      "Epoch   0 Batch 14878/17275   train_loss = 3.569\n",
      "Epoch   0 Batch 14879/17275   train_loss = 4.849\n",
      "Epoch   0 Batch 14880/17275   train_loss = 3.756\n",
      "Epoch   0 Batch 14881/17275   train_loss = 6.819\n",
      "Epoch   0 Batch 14882/17275   train_loss = 4.184\n",
      "Epoch   0 Batch 14883/17275   train_loss = 5.736\n",
      "Epoch   0 Batch 14884/17275   train_loss = 3.870\n",
      "Epoch   0 Batch 14885/17275   train_loss = 3.967\n",
      "Epoch   0 Batch 14886/17275   train_loss = 3.159\n",
      "Epoch   0 Batch 14887/17275   train_loss = 6.684\n",
      "Epoch   0 Batch 14888/17275   train_loss = 3.264\n",
      "Epoch   0 Batch 14889/17275   train_loss = 8.101\n",
      "Epoch   0 Batch 14890/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 14891/17275   train_loss = 6.751\n",
      "Epoch   0 Batch 14892/17275   train_loss = 6.794\n",
      "Epoch   0 Batch 14893/17275   train_loss = 4.212\n",
      "Epoch   0 Batch 14894/17275   train_loss = 3.315\n",
      "Epoch   0 Batch 14895/17275   train_loss = 7.633\n",
      "Epoch   0 Batch 14896/17275   train_loss = 7.862\n",
      "Epoch   0 Batch 14897/17275   train_loss = 7.968\n",
      "Epoch   0 Batch 14898/17275   train_loss = 3.231\n",
      "Epoch   0 Batch 14899/17275   train_loss = 6.700\n",
      "Epoch   0 Batch 14900/17275   train_loss = 2.717\n",
      "Epoch   0 Batch 14901/17275   train_loss = 2.733\n",
      "Epoch   0 Batch 14902/17275   train_loss = 3.560\n",
      "Epoch   0 Batch 14903/17275   train_loss = 3.350\n",
      "Epoch   0 Batch 14904/17275   train_loss = 3.469\n",
      "Epoch   0 Batch 14905/17275   train_loss = 2.182\n",
      "Epoch   0 Batch 14906/17275   train_loss = 6.494\n",
      "Epoch   0 Batch 14907/17275   train_loss = 5.156\n",
      "Epoch   0 Batch 14908/17275   train_loss = 3.467\n",
      "Epoch   0 Batch 14909/17275   train_loss = 5.457\n",
      "Epoch   0 Batch 14910/17275   train_loss = 3.012\n",
      "Epoch   0 Batch 14911/17275   train_loss = 3.365\n",
      "Epoch   0 Batch 14912/17275   train_loss = 5.231\n",
      "Epoch   0 Batch 14913/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 14914/17275   train_loss = 3.792\n",
      "Epoch   0 Batch 14915/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 14916/17275   train_loss = 4.273\n",
      "Epoch   0 Batch 14917/17275   train_loss = 6.718\n",
      "Epoch   0 Batch 14918/17275   train_loss = 2.103\n",
      "Epoch   0 Batch 14919/17275   train_loss = 2.061\n",
      "Epoch   0 Batch 14920/17275   train_loss = 2.897\n",
      "Epoch   0 Batch 14921/17275   train_loss = 7.117\n",
      "Epoch   0 Batch 14922/17275   train_loss = 7.482\n",
      "Epoch   0 Batch 14923/17275   train_loss = 3.440\n",
      "Epoch   0 Batch 14924/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 14925/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 14926/17275   train_loss = 3.697\n",
      "Epoch   0 Batch 14927/17275   train_loss = 8.206\n",
      "Epoch   0 Batch 14928/17275   train_loss = 3.452\n",
      "Epoch   0 Batch 14929/17275   train_loss = 2.263\n",
      "Epoch   0 Batch 14930/17275   train_loss = 2.756\n",
      "Epoch   0 Batch 14931/17275   train_loss = 5.073\n",
      "Epoch   0 Batch 14932/17275   train_loss = 4.469\n",
      "Epoch   0 Batch 14933/17275   train_loss = 3.142\n",
      "Epoch   0 Batch 14934/17275   train_loss = 7.326\n",
      "Epoch   0 Batch 14935/17275   train_loss = 1.943\n",
      "Epoch   0 Batch 14936/17275   train_loss = 2.548\n",
      "Epoch   0 Batch 14937/17275   train_loss = 4.802\n",
      "Epoch   0 Batch 14938/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 14939/17275   train_loss = 2.915\n",
      "Epoch   0 Batch 14940/17275   train_loss = 7.634\n",
      "Epoch   0 Batch 14941/17275   train_loss = 3.086\n",
      "Epoch   0 Batch 14942/17275   train_loss = 8.073\n",
      "Epoch   0 Batch 14943/17275   train_loss = 1.900\n",
      "Epoch   0 Batch 14944/17275   train_loss = 3.357\n",
      "Epoch   0 Batch 14945/17275   train_loss = 2.427\n",
      "Epoch   0 Batch 14946/17275   train_loss = 6.193\n",
      "Epoch   0 Batch 14947/17275   train_loss = 2.935\n",
      "Epoch   0 Batch 14948/17275   train_loss = 4.593\n",
      "Epoch   0 Batch 14949/17275   train_loss = 3.267\n",
      "Epoch   0 Batch 14950/17275   train_loss = 3.978\n",
      "Epoch   0 Batch 14951/17275   train_loss = 2.886\n",
      "Epoch   0 Batch 14952/17275   train_loss = 1.883\n",
      "Epoch   0 Batch 14953/17275   train_loss = 6.573\n",
      "Epoch   0 Batch 14954/17275   train_loss = 3.002\n",
      "Epoch   0 Batch 14955/17275   train_loss = 7.609\n",
      "Epoch   0 Batch 14956/17275   train_loss = 6.550\n",
      "Epoch   0 Batch 14957/17275   train_loss = 7.104\n",
      "Epoch   0 Batch 14958/17275   train_loss = 4.253\n",
      "Epoch   0 Batch 14959/17275   train_loss = 2.722\n",
      "Epoch   0 Batch 14960/17275   train_loss = 4.591\n",
      "Epoch   0 Batch 14961/17275   train_loss = 5.334\n",
      "Epoch   0 Batch 14962/17275   train_loss = 6.516\n",
      "Epoch   0 Batch 14963/17275   train_loss = 4.552\n",
      "Epoch   0 Batch 14964/17275   train_loss = 3.360\n",
      "Epoch   0 Batch 14965/17275   train_loss = 4.427\n",
      "Epoch   0 Batch 14966/17275   train_loss = 1.720\n",
      "Epoch   0 Batch 14967/17275   train_loss = 1.911\n",
      "Epoch   0 Batch 14968/17275   train_loss = 3.387\n",
      "Epoch   0 Batch 14969/17275   train_loss = 3.569\n",
      "Epoch   0 Batch 14970/17275   train_loss = 7.625\n",
      "Epoch   0 Batch 14971/17275   train_loss = 5.206\n",
      "Epoch   0 Batch 14972/17275   train_loss = 7.028\n",
      "Epoch   0 Batch 14973/17275   train_loss = 1.877\n",
      "Epoch   0 Batch 14974/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 14975/17275   train_loss = 4.154\n",
      "Epoch   0 Batch 14976/17275   train_loss = 3.097\n",
      "Epoch   0 Batch 14977/17275   train_loss = 3.404\n",
      "Epoch   0 Batch 14978/17275   train_loss = 4.371\n",
      "Epoch   0 Batch 14979/17275   train_loss = 3.629\n",
      "Epoch   0 Batch 14980/17275   train_loss = 4.925\n",
      "Epoch   0 Batch 14981/17275   train_loss = 3.900\n",
      "Epoch   0 Batch 14982/17275   train_loss = 3.934\n",
      "Epoch   0 Batch 14983/17275   train_loss = 3.843\n",
      "Epoch   0 Batch 14984/17275   train_loss = 5.250\n",
      "Epoch   0 Batch 14985/17275   train_loss = 7.454\n",
      "Epoch   0 Batch 14986/17275   train_loss = 3.773\n",
      "Epoch   0 Batch 14987/17275   train_loss = 2.580\n",
      "Epoch   0 Batch 14988/17275   train_loss = 4.455\n",
      "Epoch   0 Batch 14989/17275   train_loss = 5.001\n",
      "Epoch   0 Batch 14990/17275   train_loss = 1.966\n",
      "Epoch   0 Batch 14991/17275   train_loss = 3.217\n",
      "Epoch   0 Batch 14992/17275   train_loss = 3.274\n",
      "Epoch   0 Batch 14993/17275   train_loss = 2.650\n",
      "Epoch   0 Batch 14994/17275   train_loss = 2.823\n",
      "Epoch   0 Batch 14995/17275   train_loss = 3.710\n",
      "Epoch   0 Batch 14996/17275   train_loss = 7.415\n",
      "Epoch   0 Batch 14997/17275   train_loss = 3.572\n",
      "Epoch   0 Batch 14998/17275   train_loss = 4.209\n",
      "Epoch   0 Batch 14999/17275   train_loss = 3.307\n",
      "Epoch   0 Batch 15000/17275   train_loss = 2.923\n",
      "Epoch   0 Batch 15001/17275   train_loss = 7.186\n",
      "Epoch   0 Batch 15002/17275   train_loss = 3.955\n",
      "Epoch   0 Batch 15003/17275   train_loss = 3.284\n",
      "Epoch   0 Batch 15004/17275   train_loss = 1.971\n",
      "Epoch   0 Batch 15005/17275   train_loss = 3.165\n",
      "Epoch   0 Batch 15006/17275   train_loss = 3.871\n",
      "Epoch   0 Batch 15007/17275   train_loss = 3.777\n",
      "Epoch   0 Batch 15008/17275   train_loss = 3.093\n",
      "Epoch   0 Batch 15009/17275   train_loss = 3.511\n",
      "Epoch   0 Batch 15010/17275   train_loss = 3.640\n",
      "Epoch   0 Batch 15011/17275   train_loss = 4.259\n",
      "Epoch   0 Batch 15012/17275   train_loss = 5.474\n",
      "Epoch   0 Batch 15013/17275   train_loss = 1.977\n",
      "Epoch   0 Batch 15014/17275   train_loss = 2.697\n",
      "Epoch   0 Batch 15015/17275   train_loss = 3.881\n",
      "Epoch   0 Batch 15016/17275   train_loss = 4.112\n",
      "Epoch   0 Batch 15017/17275   train_loss = 4.071\n",
      "Epoch   0 Batch 15018/17275   train_loss = 2.280\n",
      "Epoch   0 Batch 15019/17275   train_loss = 3.677\n",
      "Epoch   0 Batch 15020/17275   train_loss = 3.065\n",
      "Epoch   0 Batch 15021/17275   train_loss = 7.569\n",
      "Epoch   0 Batch 15022/17275   train_loss = 2.250\n",
      "Epoch   0 Batch 15023/17275   train_loss = 5.067\n",
      "Epoch   0 Batch 15024/17275   train_loss = 4.703\n",
      "Epoch   0 Batch 15025/17275   train_loss = 8.571\n",
      "Epoch   0 Batch 15026/17275   train_loss = 2.787\n",
      "Epoch   0 Batch 15027/17275   train_loss = 2.566\n",
      "Epoch   0 Batch 15028/17275   train_loss = 3.139\n",
      "Epoch   0 Batch 15029/17275   train_loss = 4.062\n",
      "Epoch   0 Batch 15030/17275   train_loss = 4.417\n",
      "Epoch   0 Batch 15031/17275   train_loss = 3.998\n",
      "Epoch   0 Batch 15032/17275   train_loss = 4.973\n",
      "Epoch   0 Batch 15033/17275   train_loss = 3.011\n",
      "Epoch   0 Batch 15034/17275   train_loss = 5.263\n",
      "Epoch   0 Batch 15035/17275   train_loss = 3.095\n",
      "Epoch   0 Batch 15036/17275   train_loss = 2.926\n",
      "Epoch   0 Batch 15037/17275   train_loss = 2.496\n",
      "Epoch   0 Batch 15038/17275   train_loss = 3.045\n",
      "Epoch   0 Batch 15039/17275   train_loss = 3.182\n",
      "Epoch   0 Batch 15040/17275   train_loss = 3.002\n",
      "Epoch   0 Batch 15041/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 15042/17275   train_loss = 1.986\n",
      "Epoch   0 Batch 15043/17275   train_loss = 2.827\n",
      "Epoch   0 Batch 15044/17275   train_loss = 3.729\n",
      "Epoch   0 Batch 15045/17275   train_loss = 3.740\n",
      "Epoch   0 Batch 15046/17275   train_loss = 2.370\n",
      "Epoch   0 Batch 15047/17275   train_loss = 5.120\n",
      "Epoch   0 Batch 15048/17275   train_loss = 4.609\n",
      "Epoch   0 Batch 15049/17275   train_loss = 3.744\n",
      "Epoch   0 Batch 15050/17275   train_loss = 3.384\n",
      "Epoch   0 Batch 15051/17275   train_loss = 3.012\n",
      "Epoch   0 Batch 15052/17275   train_loss = 4.788\n",
      "Epoch   0 Batch 15053/17275   train_loss = 5.303\n",
      "Epoch   0 Batch 15054/17275   train_loss = 2.498\n",
      "Epoch   0 Batch 15055/17275   train_loss = 3.708\n",
      "Epoch   0 Batch 15056/17275   train_loss = 4.080\n",
      "Epoch   0 Batch 15057/17275   train_loss = 2.560\n",
      "Epoch   0 Batch 15058/17275   train_loss = 3.957\n",
      "Epoch   0 Batch 15059/17275   train_loss = 2.877\n",
      "Epoch   0 Batch 15060/17275   train_loss = 3.889\n",
      "Epoch   0 Batch 15061/17275   train_loss = 2.305\n",
      "Epoch   0 Batch 15062/17275   train_loss = 4.088\n",
      "Epoch   0 Batch 15063/17275   train_loss = 6.651\n",
      "Epoch   0 Batch 15064/17275   train_loss = 4.504\n",
      "Epoch   0 Batch 15065/17275   train_loss = 6.166\n",
      "Epoch   0 Batch 15066/17275   train_loss = 2.044\n",
      "Epoch   0 Batch 15067/17275   train_loss = 7.283\n",
      "Epoch   0 Batch 15068/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 15069/17275   train_loss = 3.882\n",
      "Epoch   0 Batch 15070/17275   train_loss = 3.653\n",
      "Epoch   0 Batch 15071/17275   train_loss = 2.056\n",
      "Epoch   0 Batch 15072/17275   train_loss = 6.664\n",
      "Epoch   0 Batch 15073/17275   train_loss = 4.794\n",
      "Epoch   0 Batch 15074/17275   train_loss = 3.823\n",
      "Epoch   0 Batch 15075/17275   train_loss = 2.954\n",
      "Epoch   0 Batch 15076/17275   train_loss = 6.640\n",
      "Epoch   0 Batch 15077/17275   train_loss = 3.946\n",
      "Epoch   0 Batch 15078/17275   train_loss = 4.357\n",
      "Epoch   0 Batch 15079/17275   train_loss = 4.547\n",
      "Epoch   0 Batch 15080/17275   train_loss = 9.981\n",
      "Epoch   0 Batch 15081/17275   train_loss = 2.716\n",
      "Epoch   0 Batch 15082/17275   train_loss = 5.265\n",
      "Epoch   0 Batch 15083/17275   train_loss = 7.650\n",
      "Epoch   0 Batch 15084/17275   train_loss = 1.927\n",
      "Epoch   0 Batch 15085/17275   train_loss = 2.548\n",
      "Epoch   0 Batch 15086/17275   train_loss = 6.079\n",
      "Epoch   0 Batch 15087/17275   train_loss = 3.111\n",
      "Epoch   0 Batch 15088/17275   train_loss = 3.777\n",
      "Epoch   0 Batch 15089/17275   train_loss = 3.675\n",
      "Epoch   0 Batch 15090/17275   train_loss = 4.476\n",
      "Epoch   0 Batch 15091/17275   train_loss = 4.006\n",
      "Epoch   0 Batch 15092/17275   train_loss = 4.144\n",
      "Epoch   0 Batch 15093/17275   train_loss = 3.942\n",
      "Epoch   0 Batch 15094/17275   train_loss = 1.953\n",
      "Epoch   0 Batch 15095/17275   train_loss = 2.214\n",
      "Epoch   0 Batch 15096/17275   train_loss = 11.296\n",
      "Epoch   0 Batch 15097/17275   train_loss = 1.906\n",
      "Epoch   0 Batch 15098/17275   train_loss = 2.715\n",
      "Epoch   0 Batch 15099/17275   train_loss = 8.294\n",
      "Epoch   0 Batch 15100/17275   train_loss = 6.845\n",
      "Epoch   0 Batch 15101/17275   train_loss = 6.705\n",
      "Epoch   0 Batch 15102/17275   train_loss = 6.597\n",
      "Epoch   0 Batch 15103/17275   train_loss = 1.786\n",
      "Epoch   0 Batch 15104/17275   train_loss = 1.852\n",
      "Epoch   0 Batch 15105/17275   train_loss = 3.424\n",
      "Epoch   0 Batch 15106/17275   train_loss = 3.012\n",
      "Epoch   0 Batch 15107/17275   train_loss = 5.902\n",
      "Epoch   0 Batch 15108/17275   train_loss = 7.471\n",
      "Epoch   0 Batch 15109/17275   train_loss = 7.052\n",
      "Epoch   0 Batch 15110/17275   train_loss = 4.339\n",
      "Epoch   0 Batch 15111/17275   train_loss = 3.436\n",
      "Epoch   0 Batch 15112/17275   train_loss = 8.439\n",
      "Epoch   0 Batch 15113/17275   train_loss = 5.815\n",
      "Epoch   0 Batch 15114/17275   train_loss = 1.826\n",
      "Epoch   0 Batch 15115/17275   train_loss = 7.377\n",
      "Epoch   0 Batch 15116/17275   train_loss = 4.705\n",
      "Epoch   0 Batch 15117/17275   train_loss = 4.016\n",
      "Epoch   0 Batch 15118/17275   train_loss = 4.947\n",
      "Epoch   0 Batch 15119/17275   train_loss = 6.500\n",
      "Epoch   0 Batch 15120/17275   train_loss = 2.428\n",
      "Epoch   0 Batch 15121/17275   train_loss = 3.271\n",
      "Epoch   0 Batch 15122/17275   train_loss = 4.196\n",
      "Epoch   0 Batch 15123/17275   train_loss = 3.620\n",
      "Epoch   0 Batch 15124/17275   train_loss = 2.450\n",
      "Epoch   0 Batch 15125/17275   train_loss = 4.298\n",
      "Epoch   0 Batch 15126/17275   train_loss = 5.354\n",
      "Epoch   0 Batch 15127/17275   train_loss = 4.709\n",
      "Epoch   0 Batch 15128/17275   train_loss = 4.162\n",
      "Epoch   0 Batch 15129/17275   train_loss = 7.210\n",
      "Epoch   0 Batch 15130/17275   train_loss = 5.287\n",
      "Epoch   0 Batch 15131/17275   train_loss = 2.560\n",
      "Epoch   0 Batch 15132/17275   train_loss = 3.236\n",
      "Epoch   0 Batch 15133/17275   train_loss = 4.121\n",
      "Epoch   0 Batch 15134/17275   train_loss = 3.177\n",
      "Epoch   0 Batch 15135/17275   train_loss = 6.895\n",
      "Epoch   0 Batch 15136/17275   train_loss = 5.468\n",
      "Epoch   0 Batch 15137/17275   train_loss = 2.513\n",
      "Epoch   0 Batch 15138/17275   train_loss = 5.886\n",
      "Epoch   0 Batch 15139/17275   train_loss = 4.166\n",
      "Epoch   0 Batch 15140/17275   train_loss = 3.498\n",
      "Epoch   0 Batch 15141/17275   train_loss = 3.992\n",
      "Epoch   0 Batch 15142/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 15143/17275   train_loss = 4.406\n",
      "Epoch   0 Batch 15144/17275   train_loss = 7.200\n",
      "Epoch   0 Batch 15145/17275   train_loss = 6.686\n",
      "Epoch   0 Batch 15146/17275   train_loss = 2.465\n",
      "Epoch   0 Batch 15147/17275   train_loss = 4.018\n",
      "Epoch   0 Batch 15148/17275   train_loss = 3.242\n",
      "Epoch   0 Batch 15149/17275   train_loss = 7.530\n",
      "Epoch   0 Batch 15150/17275   train_loss = 3.630\n",
      "Epoch   0 Batch 15151/17275   train_loss = 4.361\n",
      "Epoch   0 Batch 15152/17275   train_loss = 3.361\n",
      "Epoch   0 Batch 15153/17275   train_loss = 7.147\n",
      "Epoch   0 Batch 15154/17275   train_loss = 6.720\n",
      "Epoch   0 Batch 15155/17275   train_loss = 1.989\n",
      "Epoch   0 Batch 15156/17275   train_loss = 2.405\n",
      "Epoch   0 Batch 15157/17275   train_loss = 4.236\n",
      "Epoch   0 Batch 15158/17275   train_loss = 5.030\n",
      "Epoch   0 Batch 15159/17275   train_loss = 8.335\n",
      "Epoch   0 Batch 15160/17275   train_loss = 4.500\n",
      "Epoch   0 Batch 15161/17275   train_loss = 5.537\n",
      "Epoch   0 Batch 15162/17275   train_loss = 7.133\n",
      "Epoch   0 Batch 15163/17275   train_loss = 2.030\n",
      "Epoch   0 Batch 15164/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 15165/17275   train_loss = 6.973\n",
      "Epoch   0 Batch 15166/17275   train_loss = 3.046\n",
      "Epoch   0 Batch 15167/17275   train_loss = 4.762\n",
      "Epoch   0 Batch 15168/17275   train_loss = 8.001\n",
      "Epoch   0 Batch 15169/17275   train_loss = 3.618\n",
      "Epoch   0 Batch 15170/17275   train_loss = 2.903\n",
      "Epoch   0 Batch 15171/17275   train_loss = 3.897\n",
      "Epoch   0 Batch 15172/17275   train_loss = 4.633\n",
      "Epoch   0 Batch 15173/17275   train_loss = 3.898\n",
      "Epoch   0 Batch 15174/17275   train_loss = 7.649\n",
      "Epoch   0 Batch 15175/17275   train_loss = 2.022\n",
      "Epoch   0 Batch 15176/17275   train_loss = 3.168\n",
      "Epoch   0 Batch 15177/17275   train_loss = 5.094\n",
      "Epoch   0 Batch 15178/17275   train_loss = 4.966\n",
      "Epoch   0 Batch 15179/17275   train_loss = 2.836\n",
      "Epoch   0 Batch 15180/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 15181/17275   train_loss = 3.850\n",
      "Epoch   0 Batch 15182/17275   train_loss = 7.483\n",
      "Epoch   0 Batch 15183/17275   train_loss = 2.001\n",
      "Epoch   0 Batch 15184/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 15185/17275   train_loss = 2.754\n",
      "Epoch   0 Batch 15186/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 15187/17275   train_loss = 2.855\n",
      "Epoch   0 Batch 15188/17275   train_loss = 5.261\n",
      "Epoch   0 Batch 15189/17275   train_loss = 2.590\n",
      "Epoch   0 Batch 15190/17275   train_loss = 3.880\n",
      "Epoch   0 Batch 15191/17275   train_loss = 7.698\n",
      "Epoch   0 Batch 15192/17275   train_loss = 3.062\n",
      "Epoch   0 Batch 15193/17275   train_loss = 2.282\n",
      "Epoch   0 Batch 15194/17275   train_loss = 3.228\n",
      "Epoch   0 Batch 15195/17275   train_loss = 7.184\n",
      "Epoch   0 Batch 15196/17275   train_loss = 2.869\n",
      "Epoch   0 Batch 15197/17275   train_loss = 3.450\n",
      "Epoch   0 Batch 15198/17275   train_loss = 2.944\n",
      "Epoch   0 Batch 15199/17275   train_loss = 3.545\n",
      "Epoch   0 Batch 15200/17275   train_loss = 5.328\n",
      "Epoch   0 Batch 15201/17275   train_loss = 4.667\n",
      "Epoch   0 Batch 15202/17275   train_loss = 1.936\n",
      "Epoch   0 Batch 15203/17275   train_loss = 3.455\n",
      "Epoch   0 Batch 15204/17275   train_loss = 4.462\n",
      "Epoch   0 Batch 15205/17275   train_loss = 3.053\n",
      "Epoch   0 Batch 15206/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 15207/17275   train_loss = 4.201\n",
      "Epoch   0 Batch 15208/17275   train_loss = 3.999\n",
      "Epoch   0 Batch 15209/17275   train_loss = 7.206\n",
      "Epoch   0 Batch 15210/17275   train_loss = 3.120\n",
      "Epoch   0 Batch 15211/17275   train_loss = 2.403\n",
      "Epoch   0 Batch 15212/17275   train_loss = 5.241\n",
      "Epoch   0 Batch 15213/17275   train_loss = 5.061\n",
      "Epoch   0 Batch 15214/17275   train_loss = 5.248\n",
      "Epoch   0 Batch 15215/17275   train_loss = 3.838\n",
      "Epoch   0 Batch 15216/17275   train_loss = 2.986\n",
      "Epoch   0 Batch 15217/17275   train_loss = 2.082\n",
      "Epoch   0 Batch 15218/17275   train_loss = 2.719\n",
      "Epoch   0 Batch 15219/17275   train_loss = 2.508\n",
      "Epoch   0 Batch 15220/17275   train_loss = 3.470\n",
      "Epoch   0 Batch 15221/17275   train_loss = 6.034\n",
      "Epoch   0 Batch 15222/17275   train_loss = 3.607\n",
      "Epoch   0 Batch 15223/17275   train_loss = 11.299\n",
      "Epoch   0 Batch 15224/17275   train_loss = 1.976\n",
      "Epoch   0 Batch 15225/17275   train_loss = 3.501\n",
      "Epoch   0 Batch 15226/17275   train_loss = 2.593\n",
      "Epoch   0 Batch 15227/17275   train_loss = 4.671\n",
      "Epoch   0 Batch 15228/17275   train_loss = 7.374\n",
      "Epoch   0 Batch 15229/17275   train_loss = 3.797\n",
      "Epoch   0 Batch 15230/17275   train_loss = 2.681\n",
      "Epoch   0 Batch 15231/17275   train_loss = 4.218\n",
      "Epoch   0 Batch 15232/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 15233/17275   train_loss = 6.627\n",
      "Epoch   0 Batch 15234/17275   train_loss = 2.707\n",
      "Epoch   0 Batch 15235/17275   train_loss = 2.751\n",
      "Epoch   0 Batch 15236/17275   train_loss = 4.032\n",
      "Epoch   0 Batch 15237/17275   train_loss = 4.610\n",
      "Epoch   0 Batch 15238/17275   train_loss = 4.052\n",
      "Epoch   0 Batch 15239/17275   train_loss = 4.147\n",
      "Epoch   0 Batch 15240/17275   train_loss = 6.618\n",
      "Epoch   0 Batch 15241/17275   train_loss = 3.525\n",
      "Epoch   0 Batch 15242/17275   train_loss = 4.954\n",
      "Epoch   0 Batch 15243/17275   train_loss = 4.133\n",
      "Epoch   0 Batch 15244/17275   train_loss = 2.284\n",
      "Epoch   0 Batch 15245/17275   train_loss = 4.237\n",
      "Epoch   0 Batch 15246/17275   train_loss = 2.794\n",
      "Epoch   0 Batch 15247/17275   train_loss = 4.864\n",
      "Epoch   0 Batch 15248/17275   train_loss = 8.543\n",
      "Epoch   0 Batch 15249/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 15250/17275   train_loss = 3.801\n",
      "Epoch   0 Batch 15251/17275   train_loss = 7.502\n",
      "Epoch   0 Batch 15252/17275   train_loss = 1.961\n",
      "Epoch   0 Batch 15253/17275   train_loss = 2.081\n",
      "Epoch   0 Batch 15254/17275   train_loss = 2.348\n",
      "Epoch   0 Batch 15255/17275   train_loss = 1.817\n",
      "Epoch   0 Batch 15256/17275   train_loss = 4.523\n",
      "Epoch   0 Batch 15257/17275   train_loss = 2.970\n",
      "Epoch   0 Batch 15258/17275   train_loss = 3.842\n",
      "Epoch   0 Batch 15259/17275   train_loss = 4.388\n",
      "Epoch   0 Batch 15260/17275   train_loss = 3.676\n",
      "Epoch   0 Batch 15261/17275   train_loss = 4.177\n",
      "Epoch   0 Batch 15262/17275   train_loss = 3.926\n",
      "Epoch   0 Batch 15263/17275   train_loss = 3.178\n",
      "Epoch   0 Batch 15264/17275   train_loss = 4.518\n",
      "Epoch   0 Batch 15265/17275   train_loss = 6.762\n",
      "Epoch   0 Batch 15266/17275   train_loss = 7.122\n",
      "Epoch   0 Batch 15267/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 15268/17275   train_loss = 2.258\n",
      "Epoch   0 Batch 15269/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 15270/17275   train_loss = 4.426\n",
      "Epoch   0 Batch 15271/17275   train_loss = 7.722\n",
      "Epoch   0 Batch 15272/17275   train_loss = 7.395\n",
      "Epoch   0 Batch 15273/17275   train_loss = 4.062\n",
      "Epoch   0 Batch 15274/17275   train_loss = 3.945\n",
      "Epoch   0 Batch 15275/17275   train_loss = 3.415\n",
      "Epoch   0 Batch 15276/17275   train_loss = 2.711\n",
      "Epoch   0 Batch 15277/17275   train_loss = 2.388\n",
      "Epoch   0 Batch 15278/17275   train_loss = 3.853\n",
      "Epoch   0 Batch 15279/17275   train_loss = 4.155\n",
      "Epoch   0 Batch 15280/17275   train_loss = 3.537\n",
      "Epoch   0 Batch 15281/17275   train_loss = 2.586\n",
      "Epoch   0 Batch 15282/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 15283/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 15284/17275   train_loss = 3.713\n",
      "Epoch   0 Batch 15285/17275   train_loss = 3.759\n",
      "Epoch   0 Batch 15286/17275   train_loss = 3.246\n",
      "Epoch   0 Batch 15287/17275   train_loss = 2.496\n",
      "Epoch   0 Batch 15288/17275   train_loss = 3.132\n",
      "Epoch   0 Batch 15289/17275   train_loss = 3.516\n",
      "Epoch   0 Batch 15290/17275   train_loss = 3.738\n",
      "Epoch   0 Batch 15291/17275   train_loss = 3.244\n",
      "Epoch   0 Batch 15292/17275   train_loss = 3.794\n",
      "Epoch   0 Batch 15293/17275   train_loss = 4.147\n",
      "Epoch   0 Batch 15294/17275   train_loss = 3.449\n",
      "Epoch   0 Batch 15295/17275   train_loss = 2.311\n",
      "Epoch   0 Batch 15296/17275   train_loss = 2.198\n",
      "Epoch   0 Batch 15297/17275   train_loss = 2.543\n",
      "Epoch   0 Batch 15298/17275   train_loss = 7.085\n",
      "Epoch   0 Batch 15299/17275   train_loss = 3.449\n",
      "Epoch   0 Batch 15300/17275   train_loss = 6.921\n",
      "Epoch   0 Batch 15301/17275   train_loss = 2.815\n",
      "Epoch   0 Batch 15302/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 15303/17275   train_loss = 2.078\n",
      "Epoch   0 Batch 15304/17275   train_loss = 2.405\n",
      "Epoch   0 Batch 15305/17275   train_loss = 3.896\n",
      "Epoch   0 Batch 15306/17275   train_loss = 7.020\n",
      "Epoch   0 Batch 15307/17275   train_loss = 5.206\n",
      "Epoch   0 Batch 15308/17275   train_loss = 2.731\n",
      "Epoch   0 Batch 15309/17275   train_loss = 11.337\n",
      "Epoch   0 Batch 15310/17275   train_loss = 2.416\n",
      "Epoch   0 Batch 15311/17275   train_loss = 6.157\n",
      "Epoch   0 Batch 15312/17275   train_loss = 7.310\n",
      "Epoch   0 Batch 15313/17275   train_loss = 6.724\n",
      "Epoch   0 Batch 15314/17275   train_loss = 2.101\n",
      "Epoch   0 Batch 15315/17275   train_loss = 1.971\n",
      "Epoch   0 Batch 15316/17275   train_loss = 8.001\n",
      "Epoch   0 Batch 15317/17275   train_loss = 3.002\n",
      "Epoch   0 Batch 15318/17275   train_loss = 7.644\n",
      "Epoch   0 Batch 15319/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 15320/17275   train_loss = 3.159\n",
      "Epoch   0 Batch 15321/17275   train_loss = 4.834\n",
      "Epoch   0 Batch 15322/17275   train_loss = 4.220\n",
      "Epoch   0 Batch 15323/17275   train_loss = 2.652\n",
      "Epoch   0 Batch 15324/17275   train_loss = 3.905\n",
      "Epoch   0 Batch 15325/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 15326/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 15327/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 15328/17275   train_loss = 3.977\n",
      "Epoch   0 Batch 15329/17275   train_loss = 2.376\n",
      "Epoch   0 Batch 15330/17275   train_loss = 4.030\n",
      "Epoch   0 Batch 15331/17275   train_loss = 4.967\n",
      "Epoch   0 Batch 15332/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 15333/17275   train_loss = 6.607\n",
      "Epoch   0 Batch 15334/17275   train_loss = 2.344\n",
      "Epoch   0 Batch 15335/17275   train_loss = 4.266\n",
      "Epoch   0 Batch 15336/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 15337/17275   train_loss = 2.830\n",
      "Epoch   0 Batch 15338/17275   train_loss = 3.127\n",
      "Epoch   0 Batch 15339/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 15340/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 15341/17275   train_loss = 3.241\n",
      "Epoch   0 Batch 15342/17275   train_loss = 3.459\n",
      "Epoch   0 Batch 15343/17275   train_loss = 2.256\n",
      "Epoch   0 Batch 15344/17275   train_loss = 2.863\n",
      "Epoch   0 Batch 15345/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 15346/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 15347/17275   train_loss = 8.676\n",
      "Epoch   0 Batch 15348/17275   train_loss = 7.563\n",
      "Epoch   0 Batch 15349/17275   train_loss = 7.461\n",
      "Epoch   0 Batch 15350/17275   train_loss = 7.352\n",
      "Epoch   0 Batch 15351/17275   train_loss = 2.777\n",
      "Epoch   0 Batch 15352/17275   train_loss = 4.540\n",
      "Epoch   0 Batch 15353/17275   train_loss = 4.342\n",
      "Epoch   0 Batch 15354/17275   train_loss = 3.875\n",
      "Epoch   0 Batch 15355/17275   train_loss = 2.551\n",
      "Epoch   0 Batch 15356/17275   train_loss = 4.856\n",
      "Epoch   0 Batch 15357/17275   train_loss = 3.475\n",
      "Epoch   0 Batch 15358/17275   train_loss = 3.193\n",
      "Epoch   0 Batch 15359/17275   train_loss = 3.871\n",
      "Epoch   0 Batch 15360/17275   train_loss = 4.419\n",
      "Epoch   0 Batch 15361/17275   train_loss = 3.501\n",
      "Epoch   0 Batch 15362/17275   train_loss = 6.690\n",
      "Epoch   0 Batch 15363/17275   train_loss = 2.346\n",
      "Epoch   0 Batch 15364/17275   train_loss = 6.984\n",
      "Epoch   0 Batch 15365/17275   train_loss = 3.300\n",
      "Epoch   0 Batch 15366/17275   train_loss = 2.214\n",
      "Epoch   0 Batch 15367/17275   train_loss = 7.322\n",
      "Epoch   0 Batch 15368/17275   train_loss = 1.995\n",
      "Epoch   0 Batch 15369/17275   train_loss = 2.705\n",
      "Epoch   0 Batch 15370/17275   train_loss = 4.129\n",
      "Epoch   0 Batch 15371/17275   train_loss = 3.252\n",
      "Epoch   0 Batch 15372/17275   train_loss = 3.459\n",
      "Epoch   0 Batch 15373/17275   train_loss = 3.625\n",
      "Epoch   0 Batch 15374/17275   train_loss = 2.881\n",
      "Epoch   0 Batch 15375/17275   train_loss = 2.907\n",
      "Epoch   0 Batch 15376/17275   train_loss = 3.104\n",
      "Epoch   0 Batch 15377/17275   train_loss = 4.692\n",
      "Epoch   0 Batch 15378/17275   train_loss = 5.534\n",
      "Epoch   0 Batch 15379/17275   train_loss = 2.518\n",
      "Epoch   0 Batch 15380/17275   train_loss = 3.018\n",
      "Epoch   0 Batch 15381/17275   train_loss = 2.260\n",
      "Epoch   0 Batch 15382/17275   train_loss = 2.591\n",
      "Epoch   0 Batch 15383/17275   train_loss = 4.558\n",
      "Epoch   0 Batch 15384/17275   train_loss = 3.289\n",
      "Epoch   0 Batch 15385/17275   train_loss = 4.008\n",
      "Epoch   0 Batch 15386/17275   train_loss = 6.912\n",
      "Epoch   0 Batch 15387/17275   train_loss = 1.989\n",
      "Epoch   0 Batch 15388/17275   train_loss = 3.438\n",
      "Epoch   0 Batch 15389/17275   train_loss = 3.409\n",
      "Epoch   0 Batch 15390/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 15391/17275   train_loss = 3.494\n",
      "Epoch   0 Batch 15392/17275   train_loss = 3.508\n",
      "Epoch   0 Batch 15393/17275   train_loss = 8.140\n",
      "Epoch   0 Batch 15394/17275   train_loss = 2.358\n",
      "Epoch   0 Batch 15395/17275   train_loss = 3.691\n",
      "Epoch   0 Batch 15396/17275   train_loss = 1.943\n",
      "Epoch   0 Batch 15397/17275   train_loss = 3.144\n",
      "Epoch   0 Batch 15398/17275   train_loss = 7.127\n",
      "Epoch   0 Batch 15399/17275   train_loss = 2.295\n",
      "Epoch   0 Batch 15400/17275   train_loss = 2.821\n",
      "Epoch   0 Batch 15401/17275   train_loss = 6.631\n",
      "Epoch   0 Batch 15402/17275   train_loss = 3.472\n",
      "Epoch   0 Batch 15403/17275   train_loss = 11.076\n",
      "Epoch   0 Batch 15404/17275   train_loss = 1.890\n",
      "Epoch   0 Batch 15405/17275   train_loss = 1.909\n",
      "Epoch   0 Batch 15406/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 15407/17275   train_loss = 3.699\n",
      "Epoch   0 Batch 15408/17275   train_loss = 7.363\n",
      "Epoch   0 Batch 15409/17275   train_loss = 6.949\n",
      "Epoch   0 Batch 15410/17275   train_loss = 3.656\n",
      "Epoch   0 Batch 15411/17275   train_loss = 4.733\n",
      "Epoch   0 Batch 15412/17275   train_loss = 4.106\n",
      "Epoch   0 Batch 15413/17275   train_loss = 4.580\n",
      "Epoch   0 Batch 15414/17275   train_loss = 11.414\n",
      "Epoch   0 Batch 15415/17275   train_loss = 1.821\n",
      "Epoch   0 Batch 15416/17275   train_loss = 3.720\n",
      "Epoch   0 Batch 15417/17275   train_loss = 2.879\n",
      "Epoch   0 Batch 15418/17275   train_loss = 3.779\n",
      "Epoch   0 Batch 15419/17275   train_loss = 11.400\n",
      "Epoch   0 Batch 15420/17275   train_loss = 9.119\n",
      "Epoch   0 Batch 15421/17275   train_loss = 6.941\n",
      "Epoch   0 Batch 15422/17275   train_loss = 2.211\n",
      "Epoch   0 Batch 15423/17275   train_loss = 3.127\n",
      "Epoch   0 Batch 15424/17275   train_loss = 4.590\n",
      "Epoch   0 Batch 15425/17275   train_loss = 3.855\n",
      "Epoch   0 Batch 15426/17275   train_loss = 4.106\n",
      "Epoch   0 Batch 15427/17275   train_loss = 1.863\n",
      "Epoch   0 Batch 15428/17275   train_loss = 3.668\n",
      "Epoch   0 Batch 15429/17275   train_loss = 2.280\n",
      "Epoch   0 Batch 15430/17275   train_loss = 5.881\n",
      "Epoch   0 Batch 15431/17275   train_loss = 4.191\n",
      "Epoch   0 Batch 15432/17275   train_loss = 4.024\n",
      "Epoch   0 Batch 15433/17275   train_loss = 9.541\n",
      "Epoch   0 Batch 15434/17275   train_loss = 3.380\n",
      "Epoch   0 Batch 15435/17275   train_loss = 11.365\n",
      "Epoch   0 Batch 15436/17275   train_loss = 1.918\n",
      "Epoch   0 Batch 15437/17275   train_loss = 3.191\n",
      "Epoch   0 Batch 15438/17275   train_loss = 10.927\n",
      "Epoch   0 Batch 15439/17275   train_loss = 2.148\n",
      "Epoch   0 Batch 15440/17275   train_loss = 2.920\n",
      "Epoch   0 Batch 15441/17275   train_loss = 2.480\n",
      "Epoch   0 Batch 15442/17275   train_loss = 11.351\n",
      "Epoch   0 Batch 15443/17275   train_loss = 3.143\n",
      "Epoch   0 Batch 15444/17275   train_loss = 4.791\n",
      "Epoch   0 Batch 15445/17275   train_loss = 5.001\n",
      "Epoch   0 Batch 15446/17275   train_loss = 7.680\n",
      "Epoch   0 Batch 15447/17275   train_loss = 4.142\n",
      "Epoch   0 Batch 15448/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 15449/17275   train_loss = 3.254\n",
      "Epoch   0 Batch 15450/17275   train_loss = 2.973\n",
      "Epoch   0 Batch 15451/17275   train_loss = 4.102\n",
      "Epoch   0 Batch 15452/17275   train_loss = 4.414\n",
      "Epoch   0 Batch 15453/17275   train_loss = 2.547\n",
      "Epoch   0 Batch 15454/17275   train_loss = 2.449\n",
      "Epoch   0 Batch 15455/17275   train_loss = 3.630\n",
      "Epoch   0 Batch 15456/17275   train_loss = 4.168\n",
      "Epoch   0 Batch 15457/17275   train_loss = 7.153\n",
      "Epoch   0 Batch 15458/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 15459/17275   train_loss = 3.157\n",
      "Epoch   0 Batch 15460/17275   train_loss = 11.346\n",
      "Epoch   0 Batch 15461/17275   train_loss = 3.228\n",
      "Epoch   0 Batch 15462/17275   train_loss = 2.015\n",
      "Epoch   0 Batch 15463/17275   train_loss = 2.679\n",
      "Epoch   0 Batch 15464/17275   train_loss = 3.446\n",
      "Epoch   0 Batch 15465/17275   train_loss = 5.115\n",
      "Epoch   0 Batch 15466/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 15467/17275   train_loss = 2.820\n",
      "Epoch   0 Batch 15468/17275   train_loss = 2.464\n",
      "Epoch   0 Batch 15469/17275   train_loss = 2.262\n",
      "Epoch   0 Batch 15470/17275   train_loss = 3.609\n",
      "Epoch   0 Batch 15471/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 15472/17275   train_loss = 4.123\n",
      "Epoch   0 Batch 15473/17275   train_loss = 9.131\n",
      "Epoch   0 Batch 15474/17275   train_loss = 3.070\n",
      "Epoch   0 Batch 15475/17275   train_loss = 3.711\n",
      "Epoch   0 Batch 15476/17275   train_loss = 8.200\n",
      "Epoch   0 Batch 15477/17275   train_loss = 2.357\n",
      "Epoch   0 Batch 15478/17275   train_loss = 7.169\n",
      "Epoch   0 Batch 15479/17275   train_loss = 6.626\n",
      "Epoch   0 Batch 15480/17275   train_loss = 3.108\n",
      "Epoch   0 Batch 15481/17275   train_loss = 5.125\n",
      "Epoch   0 Batch 15482/17275   train_loss = 6.957\n",
      "Epoch   0 Batch 15483/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 15484/17275   train_loss = 3.355\n",
      "Epoch   0 Batch 15485/17275   train_loss = 7.533\n",
      "Epoch   0 Batch 15486/17275   train_loss = 3.014\n",
      "Epoch   0 Batch 15487/17275   train_loss = 9.305\n",
      "Epoch   0 Batch 15488/17275   train_loss = 4.102\n",
      "Epoch   0 Batch 15489/17275   train_loss = 6.832\n",
      "Epoch   0 Batch 15490/17275   train_loss = 3.705\n",
      "Epoch   0 Batch 15491/17275   train_loss = 7.352\n",
      "Epoch   0 Batch 15492/17275   train_loss = 2.418\n",
      "Epoch   0 Batch 15493/17275   train_loss = 3.313\n",
      "Epoch   0 Batch 15494/17275   train_loss = 3.984\n",
      "Epoch   0 Batch 15495/17275   train_loss = 7.355\n",
      "Epoch   0 Batch 15496/17275   train_loss = 2.047\n",
      "Epoch   0 Batch 15497/17275   train_loss = 4.130\n",
      "Epoch   0 Batch 15498/17275   train_loss = 4.586\n",
      "Epoch   0 Batch 15499/17275   train_loss = 3.442\n",
      "Epoch   0 Batch 15500/17275   train_loss = 2.542\n",
      "Epoch   0 Batch 15501/17275   train_loss = 7.129\n",
      "Epoch   0 Batch 15502/17275   train_loss = 4.148\n",
      "Epoch   0 Batch 15503/17275   train_loss = 3.287\n",
      "Epoch   0 Batch 15504/17275   train_loss = 11.333\n",
      "Epoch   0 Batch 15505/17275   train_loss = 2.409\n",
      "Epoch   0 Batch 15506/17275   train_loss = 2.997\n",
      "Epoch   0 Batch 15507/17275   train_loss = 4.440\n",
      "Epoch   0 Batch 15508/17275   train_loss = 3.039\n",
      "Epoch   0 Batch 15509/17275   train_loss = 5.252\n",
      "Epoch   0 Batch 15510/17275   train_loss = 6.698\n",
      "Epoch   0 Batch 15511/17275   train_loss = 2.308\n",
      "Epoch   0 Batch 15512/17275   train_loss = 3.122\n",
      "Epoch   0 Batch 15513/17275   train_loss = 3.515\n",
      "Epoch   0 Batch 15514/17275   train_loss = 3.902\n",
      "Epoch   0 Batch 15515/17275   train_loss = 2.883\n",
      "Epoch   0 Batch 15516/17275   train_loss = 7.062\n",
      "Epoch   0 Batch 15517/17275   train_loss = 2.330\n",
      "Epoch   0 Batch 15518/17275   train_loss = 3.095\n",
      "Epoch   0 Batch 15519/17275   train_loss = 4.701\n",
      "Epoch   0 Batch 15520/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 15521/17275   train_loss = 7.568\n",
      "Epoch   0 Batch 15522/17275   train_loss = 7.356\n",
      "Epoch   0 Batch 15523/17275   train_loss = 3.292\n",
      "Epoch   0 Batch 15524/17275   train_loss = 5.138\n",
      "Epoch   0 Batch 15525/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 15526/17275   train_loss = 4.848\n",
      "Epoch   0 Batch 15527/17275   train_loss = 6.402\n",
      "Epoch   0 Batch 15528/17275   train_loss = 2.098\n",
      "Epoch   0 Batch 15529/17275   train_loss = 3.472\n",
      "Epoch   0 Batch 15530/17275   train_loss = 3.836\n",
      "Epoch   0 Batch 15531/17275   train_loss = 3.268\n",
      "Epoch   0 Batch 15532/17275   train_loss = 4.100\n",
      "Epoch   0 Batch 15533/17275   train_loss = 4.236\n",
      "Epoch   0 Batch 15534/17275   train_loss = 6.504\n",
      "Epoch   0 Batch 15535/17275   train_loss = 3.911\n",
      "Epoch   0 Batch 15536/17275   train_loss = 5.839\n",
      "Epoch   0 Batch 15537/17275   train_loss = 2.908\n",
      "Epoch   0 Batch 15538/17275   train_loss = 3.317\n",
      "Epoch   0 Batch 15539/17275   train_loss = 6.511\n",
      "Epoch   0 Batch 15540/17275   train_loss = 3.129\n",
      "Epoch   0 Batch 15541/17275   train_loss = 2.302\n",
      "Epoch   0 Batch 15542/17275   train_loss = 5.199\n",
      "Epoch   0 Batch 15543/17275   train_loss = 3.662\n",
      "Epoch   0 Batch 15544/17275   train_loss = 4.931\n",
      "Epoch   0 Batch 15545/17275   train_loss = 3.255\n",
      "Epoch   0 Batch 15546/17275   train_loss = 5.850\n",
      "Epoch   0 Batch 15547/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 15548/17275   train_loss = 5.660\n",
      "Epoch   0 Batch 15549/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 15550/17275   train_loss = 2.138\n",
      "Epoch   0 Batch 15551/17275   train_loss = 3.685\n",
      "Epoch   0 Batch 15552/17275   train_loss = 3.079\n",
      "Epoch   0 Batch 15553/17275   train_loss = 3.087\n",
      "Epoch   0 Batch 15554/17275   train_loss = 2.969\n",
      "Epoch   0 Batch 15555/17275   train_loss = 2.621\n",
      "Epoch   0 Batch 15556/17275   train_loss = 4.968\n",
      "Epoch   0 Batch 15557/17275   train_loss = 3.141\n",
      "Epoch   0 Batch 15558/17275   train_loss = 3.028\n",
      "Epoch   0 Batch 15559/17275   train_loss = 3.060\n",
      "Epoch   0 Batch 15560/17275   train_loss = 2.571\n",
      "Epoch   0 Batch 15561/17275   train_loss = 6.349\n",
      "Epoch   0 Batch 15562/17275   train_loss = 3.115\n",
      "Epoch   0 Batch 15563/17275   train_loss = 3.007\n",
      "Epoch   0 Batch 15564/17275   train_loss = 2.361\n",
      "Epoch   0 Batch 15565/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 15566/17275   train_loss = 3.296\n",
      "Epoch   0 Batch 15567/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 15568/17275   train_loss = 3.888\n",
      "Epoch   0 Batch 15569/17275   train_loss = 7.643\n",
      "Epoch   0 Batch 15570/17275   train_loss = 4.115\n",
      "Epoch   0 Batch 15571/17275   train_loss = 4.252\n",
      "Epoch   0 Batch 15572/17275   train_loss = 2.589\n",
      "Epoch   0 Batch 15573/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 15574/17275   train_loss = 3.296\n",
      "Epoch   0 Batch 15575/17275   train_loss = 7.541\n",
      "Epoch   0 Batch 15576/17275   train_loss = 4.745\n",
      "Epoch   0 Batch 15577/17275   train_loss = 5.293\n",
      "Epoch   0 Batch 15578/17275   train_loss = 1.986\n",
      "Epoch   0 Batch 15579/17275   train_loss = 4.022\n",
      "Epoch   0 Batch 15580/17275   train_loss = 7.597\n",
      "Epoch   0 Batch 15581/17275   train_loss = 1.971\n",
      "Epoch   0 Batch 15582/17275   train_loss = 2.418\n",
      "Epoch   0 Batch 15583/17275   train_loss = 9.141\n",
      "Epoch   0 Batch 15584/17275   train_loss = 7.983\n",
      "Epoch   0 Batch 15585/17275   train_loss = 6.823\n",
      "Epoch   0 Batch 15586/17275   train_loss = 2.335\n",
      "Epoch   0 Batch 15587/17275   train_loss = 4.348\n",
      "Epoch   0 Batch 15588/17275   train_loss = 6.028\n",
      "Epoch   0 Batch 15589/17275   train_loss = 2.721\n",
      "Epoch   0 Batch 15590/17275   train_loss = 2.374\n",
      "Epoch   0 Batch 15591/17275   train_loss = 3.815\n",
      "Epoch   0 Batch 15592/17275   train_loss = 3.499\n",
      "Epoch   0 Batch 15593/17275   train_loss = 4.878\n",
      "Epoch   0 Batch 15594/17275   train_loss = 3.317\n",
      "Epoch   0 Batch 15595/17275   train_loss = 4.233\n",
      "Epoch   0 Batch 15596/17275   train_loss = 3.335\n",
      "Epoch   0 Batch 15597/17275   train_loss = 5.909\n",
      "Epoch   0 Batch 15598/17275   train_loss = 2.070\n",
      "Epoch   0 Batch 15599/17275   train_loss = 2.275\n",
      "Epoch   0 Batch 15600/17275   train_loss = 4.667\n",
      "Epoch   0 Batch 15601/17275   train_loss = 7.656\n",
      "Epoch   0 Batch 15602/17275   train_loss = 4.592\n",
      "Epoch   0 Batch 15603/17275   train_loss = 7.353\n",
      "Epoch   0 Batch 15604/17275   train_loss = 6.602\n",
      "Epoch   0 Batch 15605/17275   train_loss = 3.387\n",
      "Epoch   0 Batch 15606/17275   train_loss = 4.472\n",
      "Epoch   0 Batch 15607/17275   train_loss = 2.531\n",
      "Epoch   0 Batch 15608/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 15609/17275   train_loss = 3.419\n",
      "Epoch   0 Batch 15610/17275   train_loss = 3.871\n",
      "Epoch   0 Batch 15611/17275   train_loss = 4.670\n",
      "Epoch   0 Batch 15612/17275   train_loss = 2.461\n",
      "Epoch   0 Batch 15613/17275   train_loss = 3.098\n",
      "Epoch   0 Batch 15614/17275   train_loss = 4.308\n",
      "Epoch   0 Batch 15615/17275   train_loss = 2.395\n",
      "Epoch   0 Batch 15616/17275   train_loss = 3.699\n",
      "Epoch   0 Batch 15617/17275   train_loss = 2.332\n",
      "Epoch   0 Batch 15618/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 15619/17275   train_loss = 4.176\n",
      "Epoch   0 Batch 15620/17275   train_loss = 2.033\n",
      "Epoch   0 Batch 15621/17275   train_loss = 4.617\n",
      "Epoch   0 Batch 15622/17275   train_loss = 3.714\n",
      "Epoch   0 Batch 15623/17275   train_loss = 4.143\n",
      "Epoch   0 Batch 15624/17275   train_loss = 3.639\n",
      "Epoch   0 Batch 15625/17275   train_loss = 7.499\n",
      "Epoch   0 Batch 15626/17275   train_loss = 2.334\n",
      "Epoch   0 Batch 15627/17275   train_loss = 6.959\n",
      "Epoch   0 Batch 15628/17275   train_loss = 3.641\n",
      "Epoch   0 Batch 15629/17275   train_loss = 3.672\n",
      "Epoch   0 Batch 15630/17275   train_loss = 3.125\n",
      "Epoch   0 Batch 15631/17275   train_loss = 6.996\n",
      "Epoch   0 Batch 15632/17275   train_loss = 1.960\n",
      "Epoch   0 Batch 15633/17275   train_loss = 3.893\n",
      "Epoch   0 Batch 15634/17275   train_loss = 4.349\n",
      "Epoch   0 Batch 15635/17275   train_loss = 4.376\n",
      "Epoch   0 Batch 15636/17275   train_loss = 4.139\n",
      "Epoch   0 Batch 15637/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 15638/17275   train_loss = 3.686\n",
      "Epoch   0 Batch 15639/17275   train_loss = 3.860\n",
      "Epoch   0 Batch 15640/17275   train_loss = 1.972\n",
      "Epoch   0 Batch 15641/17275   train_loss = 3.146\n",
      "Epoch   0 Batch 15642/17275   train_loss = 3.495\n",
      "Epoch   0 Batch 15643/17275   train_loss = 2.762\n",
      "Epoch   0 Batch 15644/17275   train_loss = 3.824\n",
      "Epoch   0 Batch 15645/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 15646/17275   train_loss = 2.921\n",
      "Epoch   0 Batch 15647/17275   train_loss = 1.854\n",
      "Epoch   0 Batch 15648/17275   train_loss = 2.245\n",
      "Epoch   0 Batch 15649/17275   train_loss = 3.436\n",
      "Epoch   0 Batch 15650/17275   train_loss = 3.027\n",
      "Epoch   0 Batch 15651/17275   train_loss = 1.953\n",
      "Epoch   0 Batch 15652/17275   train_loss = 4.569\n",
      "Epoch   0 Batch 15653/17275   train_loss = 7.315\n",
      "Epoch   0 Batch 15654/17275   train_loss = 3.505\n",
      "Epoch   0 Batch 15655/17275   train_loss = 3.931\n",
      "Epoch   0 Batch 15656/17275   train_loss = 6.592\n",
      "Epoch   0 Batch 15657/17275   train_loss = 3.133\n",
      "Epoch   0 Batch 15658/17275   train_loss = 5.700\n",
      "Epoch   0 Batch 15659/17275   train_loss = 6.596\n",
      "Epoch   0 Batch 15660/17275   train_loss = 2.362\n",
      "Epoch   0 Batch 15661/17275   train_loss = 4.042\n",
      "Epoch   0 Batch 15662/17275   train_loss = 5.744\n",
      "Epoch   0 Batch 15663/17275   train_loss = 4.146\n",
      "Epoch   0 Batch 15664/17275   train_loss = 4.269\n",
      "Epoch   0 Batch 15665/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 15666/17275   train_loss = 5.069\n",
      "Epoch   0 Batch 15667/17275   train_loss = 1.763\n",
      "Epoch   0 Batch 15668/17275   train_loss = 8.157\n",
      "Epoch   0 Batch 15669/17275   train_loss = 3.752\n",
      "Epoch   0 Batch 15670/17275   train_loss = 6.589\n",
      "Epoch   0 Batch 15671/17275   train_loss = 6.357\n",
      "Epoch   0 Batch 15672/17275   train_loss = 7.547\n",
      "Epoch   0 Batch 15673/17275   train_loss = 2.832\n",
      "Epoch   0 Batch 15674/17275   train_loss = 4.428\n",
      "Epoch   0 Batch 15675/17275   train_loss = 6.713\n",
      "Epoch   0 Batch 15676/17275   train_loss = 2.911\n",
      "Epoch   0 Batch 15677/17275   train_loss = 6.433\n",
      "Epoch   0 Batch 15678/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 15679/17275   train_loss = 7.115\n",
      "Epoch   0 Batch 15680/17275   train_loss = 1.772\n",
      "Epoch   0 Batch 15681/17275   train_loss = 6.098\n",
      "Epoch   0 Batch 15682/17275   train_loss = 5.141\n",
      "Epoch   0 Batch 15683/17275   train_loss = 5.392\n",
      "Epoch   0 Batch 15684/17275   train_loss = 7.776\n",
      "Epoch   0 Batch 15685/17275   train_loss = 6.621\n",
      "Epoch   0 Batch 15686/17275   train_loss = 5.223\n",
      "Epoch   0 Batch 15687/17275   train_loss = 2.951\n",
      "Epoch   0 Batch 15688/17275   train_loss = 5.743\n",
      "Epoch   0 Batch 15689/17275   train_loss = 7.611\n",
      "Epoch   0 Batch 15690/17275   train_loss = 6.624\n",
      "Epoch   0 Batch 15691/17275   train_loss = 3.167\n",
      "Epoch   0 Batch 15692/17275   train_loss = 2.967\n",
      "Epoch   0 Batch 15693/17275   train_loss = 8.801\n",
      "Epoch   0 Batch 15694/17275   train_loss = 7.223\n",
      "Epoch   0 Batch 15695/17275   train_loss = 6.993\n",
      "Epoch   0 Batch 15696/17275   train_loss = 2.957\n",
      "Epoch   0 Batch 15697/17275   train_loss = 6.134\n",
      "Epoch   0 Batch 15698/17275   train_loss = 6.871\n",
      "Epoch   0 Batch 15699/17275   train_loss = 5.014\n",
      "Epoch   0 Batch 15700/17275   train_loss = 7.799\n",
      "Epoch   0 Batch 15701/17275   train_loss = 7.980\n",
      "Epoch   0 Batch 15702/17275   train_loss = 4.379\n",
      "Epoch   0 Batch 15703/17275   train_loss = 3.578\n",
      "Epoch   0 Batch 15704/17275   train_loss = 3.891\n",
      "Epoch   0 Batch 15705/17275   train_loss = 1.960\n",
      "Epoch   0 Batch 15706/17275   train_loss = 1.934\n",
      "Epoch   0 Batch 15707/17275   train_loss = 5.684\n",
      "Epoch   0 Batch 15708/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 15709/17275   train_loss = 7.104\n",
      "Epoch   0 Batch 15710/17275   train_loss = 7.470\n",
      "Epoch   0 Batch 15711/17275   train_loss = 6.620\n",
      "Epoch   0 Batch 15712/17275   train_loss = 1.878\n",
      "Epoch   0 Batch 15713/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 15714/17275   train_loss = 4.181\n",
      "Epoch   0 Batch 15715/17275   train_loss = 4.683\n",
      "Epoch   0 Batch 15716/17275   train_loss = 3.218\n",
      "Epoch   0 Batch 15717/17275   train_loss = 2.490\n",
      "Epoch   0 Batch 15718/17275   train_loss = 3.811\n",
      "Epoch   0 Batch 15719/17275   train_loss = 4.626\n",
      "Epoch   0 Batch 15720/17275   train_loss = 3.323\n",
      "Epoch   0 Batch 15721/17275   train_loss = 4.204\n",
      "Epoch   0 Batch 15722/17275   train_loss = 3.262\n",
      "Epoch   0 Batch 15723/17275   train_loss = 4.602\n",
      "Epoch   0 Batch 15724/17275   train_loss = 3.807\n",
      "Epoch   0 Batch 15725/17275   train_loss = 3.351\n",
      "Epoch   0 Batch 15726/17275   train_loss = 4.840\n",
      "Epoch   0 Batch 15727/17275   train_loss = 1.856\n",
      "Epoch   0 Batch 15728/17275   train_loss = 3.507\n",
      "Epoch   0 Batch 15729/17275   train_loss = 4.681\n",
      "Epoch   0 Batch 15730/17275   train_loss = 5.152\n",
      "Epoch   0 Batch 15731/17275   train_loss = 3.109\n",
      "Epoch   0 Batch 15732/17275   train_loss = 2.934\n",
      "Epoch   0 Batch 15733/17275   train_loss = 6.041\n",
      "Epoch   0 Batch 15734/17275   train_loss = 7.974\n",
      "Epoch   0 Batch 15735/17275   train_loss = 4.466\n",
      "Epoch   0 Batch 15736/17275   train_loss = 1.868\n",
      "Epoch   0 Batch 15737/17275   train_loss = 3.416\n",
      "Epoch   0 Batch 15738/17275   train_loss = 2.938\n",
      "Epoch   0 Batch 15739/17275   train_loss = 3.084\n",
      "Epoch   0 Batch 15740/17275   train_loss = 11.346\n",
      "Epoch   0 Batch 15741/17275   train_loss = 2.159\n",
      "Epoch   0 Batch 15742/17275   train_loss = 3.734\n",
      "Epoch   0 Batch 15743/17275   train_loss = 3.336\n",
      "Epoch   0 Batch 15744/17275   train_loss = 4.379\n",
      "Epoch   0 Batch 15745/17275   train_loss = 2.319\n",
      "Epoch   0 Batch 15746/17275   train_loss = 6.671\n",
      "Epoch   0 Batch 15747/17275   train_loss = 4.260\n",
      "Epoch   0 Batch 15748/17275   train_loss = 3.137\n",
      "Epoch   0 Batch 15749/17275   train_loss = 7.680\n",
      "Epoch   0 Batch 15750/17275   train_loss = 7.122\n",
      "Epoch   0 Batch 15751/17275   train_loss = 3.111\n",
      "Epoch   0 Batch 15752/17275   train_loss = 4.296\n",
      "Epoch   0 Batch 15753/17275   train_loss = 2.758\n",
      "Epoch   0 Batch 15754/17275   train_loss = 1.847\n",
      "Epoch   0 Batch 15755/17275   train_loss = 3.794\n",
      "Epoch   0 Batch 15756/17275   train_loss = 3.549\n",
      "Epoch   0 Batch 15757/17275   train_loss = 4.231\n",
      "Epoch   0 Batch 15758/17275   train_loss = 3.823\n",
      "Epoch   0 Batch 15759/17275   train_loss = 2.863\n",
      "Epoch   0 Batch 15760/17275   train_loss = 3.962\n",
      "Epoch   0 Batch 15761/17275   train_loss = 3.796\n",
      "Epoch   0 Batch 15762/17275   train_loss = 3.852\n",
      "Epoch   0 Batch 15763/17275   train_loss = 2.476\n",
      "Epoch   0 Batch 15764/17275   train_loss = 3.679\n",
      "Epoch   0 Batch 15765/17275   train_loss = 3.037\n",
      "Epoch   0 Batch 15766/17275   train_loss = 3.625\n",
      "Epoch   0 Batch 15767/17275   train_loss = 7.413\n",
      "Epoch   0 Batch 15768/17275   train_loss = 3.905\n",
      "Epoch   0 Batch 15769/17275   train_loss = 2.627\n",
      "Epoch   0 Batch 15770/17275   train_loss = 5.320\n",
      "Epoch   0 Batch 15771/17275   train_loss = 4.153\n",
      "Epoch   0 Batch 15772/17275   train_loss = 3.604\n",
      "Epoch   0 Batch 15773/17275   train_loss = 5.159\n",
      "Epoch   0 Batch 15774/17275   train_loss = 11.350\n",
      "Epoch   0 Batch 15775/17275   train_loss = 1.998\n",
      "Epoch   0 Batch 15776/17275   train_loss = 2.141\n",
      "Epoch   0 Batch 15777/17275   train_loss = 7.009\n",
      "Epoch   0 Batch 15778/17275   train_loss = 6.066\n",
      "Epoch   0 Batch 15779/17275   train_loss = 7.569\n",
      "Epoch   0 Batch 15780/17275   train_loss = 3.341\n",
      "Epoch   0 Batch 15781/17275   train_loss = 4.751\n",
      "Epoch   0 Batch 15782/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 15783/17275   train_loss = 7.581\n",
      "Epoch   0 Batch 15784/17275   train_loss = 1.953\n",
      "Epoch   0 Batch 15785/17275   train_loss = 3.620\n",
      "Epoch   0 Batch 15786/17275   train_loss = 3.071\n",
      "Epoch   0 Batch 15787/17275   train_loss = 2.903\n",
      "Epoch   0 Batch 15788/17275   train_loss = 4.301\n",
      "Epoch   0 Batch 15789/17275   train_loss = 2.564\n",
      "Epoch   0 Batch 15790/17275   train_loss = 2.975\n",
      "Epoch   0 Batch 15791/17275   train_loss = 6.772\n",
      "Epoch   0 Batch 15792/17275   train_loss = 7.044\n",
      "Epoch   0 Batch 15793/17275   train_loss = 3.849\n",
      "Epoch   0 Batch 15794/17275   train_loss = 3.219\n",
      "Epoch   0 Batch 15795/17275   train_loss = 5.029\n",
      "Epoch   0 Batch 15796/17275   train_loss = 5.214\n",
      "Epoch   0 Batch 15797/17275   train_loss = 1.943\n",
      "Epoch   0 Batch 15798/17275   train_loss = 3.532\n",
      "Epoch   0 Batch 15799/17275   train_loss = 3.864\n",
      "Epoch   0 Batch 15800/17275   train_loss = 2.830\n",
      "Epoch   0 Batch 15801/17275   train_loss = 4.809\n",
      "Epoch   0 Batch 15802/17275   train_loss = 2.317\n",
      "Epoch   0 Batch 15803/17275   train_loss = 4.845\n",
      "Epoch   0 Batch 15804/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 15805/17275   train_loss = 3.502\n",
      "Epoch   0 Batch 15806/17275   train_loss = 4.685\n",
      "Epoch   0 Batch 15807/17275   train_loss = 3.400\n",
      "Epoch   0 Batch 15808/17275   train_loss = 1.945\n",
      "Epoch   0 Batch 15809/17275   train_loss = 2.532\n",
      "Epoch   0 Batch 15810/17275   train_loss = 4.425\n",
      "Epoch   0 Batch 15811/17275   train_loss = 3.213\n",
      "Epoch   0 Batch 15812/17275   train_loss = 3.049\n",
      "Epoch   0 Batch 15813/17275   train_loss = 4.265\n",
      "Epoch   0 Batch 15814/17275   train_loss = 4.133\n",
      "Epoch   0 Batch 15815/17275   train_loss = 2.833\n",
      "Epoch   0 Batch 15816/17275   train_loss = 4.692\n",
      "Epoch   0 Batch 15817/17275   train_loss = 5.780\n",
      "Epoch   0 Batch 15818/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 15819/17275   train_loss = 8.048\n",
      "Epoch   0 Batch 15820/17275   train_loss = 5.478\n",
      "Epoch   0 Batch 15821/17275   train_loss = 3.160\n",
      "Epoch   0 Batch 15822/17275   train_loss = 2.961\n",
      "Epoch   0 Batch 15823/17275   train_loss = 2.589\n",
      "Epoch   0 Batch 15824/17275   train_loss = 2.655\n",
      "Epoch   0 Batch 15825/17275   train_loss = 3.725\n",
      "Epoch   0 Batch 15826/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 15827/17275   train_loss = 4.080\n",
      "Epoch   0 Batch 15828/17275   train_loss = 3.545\n",
      "Epoch   0 Batch 15829/17275   train_loss = 5.563\n",
      "Epoch   0 Batch 15830/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 15831/17275   train_loss = 4.734\n",
      "Epoch   0 Batch 15832/17275   train_loss = 6.646\n",
      "Epoch   0 Batch 15833/17275   train_loss = 2.325\n",
      "Epoch   0 Batch 15834/17275   train_loss = 3.290\n",
      "Epoch   0 Batch 15835/17275   train_loss = 2.647\n",
      "Epoch   0 Batch 15836/17275   train_loss = 4.003\n",
      "Epoch   0 Batch 15837/17275   train_loss = 5.398\n",
      "Epoch   0 Batch 15838/17275   train_loss = 4.218\n",
      "Epoch   0 Batch 15839/17275   train_loss = 3.699\n",
      "Epoch   0 Batch 15840/17275   train_loss = 4.722\n",
      "Epoch   0 Batch 15841/17275   train_loss = 2.051\n",
      "Epoch   0 Batch 15842/17275   train_loss = 3.831\n",
      "Epoch   0 Batch 15843/17275   train_loss = 2.533\n",
      "Epoch   0 Batch 15844/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 15845/17275   train_loss = 2.713\n",
      "Epoch   0 Batch 15846/17275   train_loss = 4.059\n",
      "Epoch   0 Batch 15847/17275   train_loss = 3.954\n",
      "Epoch   0 Batch 15848/17275   train_loss = 3.555\n",
      "Epoch   0 Batch 15849/17275   train_loss = 3.874\n",
      "Epoch   0 Batch 15850/17275   train_loss = 5.425\n",
      "Epoch   0 Batch 15851/17275   train_loss = 3.939\n",
      "Epoch   0 Batch 15852/17275   train_loss = 3.639\n",
      "Epoch   0 Batch 15853/17275   train_loss = 2.434\n",
      "Epoch   0 Batch 15854/17275   train_loss = 5.208\n",
      "Epoch   0 Batch 15855/17275   train_loss = 2.622\n",
      "Epoch   0 Batch 15856/17275   train_loss = 2.324\n",
      "Epoch   0 Batch 15857/17275   train_loss = 3.307\n",
      "Epoch   0 Batch 15858/17275   train_loss = 4.237\n",
      "Epoch   0 Batch 15859/17275   train_loss = 3.724\n",
      "Epoch   0 Batch 15860/17275   train_loss = 1.924\n",
      "Epoch   0 Batch 15861/17275   train_loss = 7.053\n",
      "Epoch   0 Batch 15862/17275   train_loss = 1.903\n",
      "Epoch   0 Batch 15863/17275   train_loss = 5.302\n",
      "Epoch   0 Batch 15864/17275   train_loss = 3.124\n",
      "Epoch   0 Batch 15865/17275   train_loss = 5.171\n",
      "Epoch   0 Batch 15866/17275   train_loss = 3.890\n",
      "Epoch   0 Batch 15867/17275   train_loss = 4.816\n",
      "Epoch   0 Batch 15868/17275   train_loss = 3.173\n",
      "Epoch   0 Batch 15869/17275   train_loss = 7.182\n",
      "Epoch   0 Batch 15870/17275   train_loss = 6.604\n",
      "Epoch   0 Batch 15871/17275   train_loss = 2.816\n",
      "Epoch   0 Batch 15872/17275   train_loss = 4.265\n",
      "Epoch   0 Batch 15873/17275   train_loss = 5.575\n",
      "Epoch   0 Batch 15874/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 15875/17275   train_loss = 4.172\n",
      "Epoch   0 Batch 15876/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 15877/17275   train_loss = 2.485\n",
      "Epoch   0 Batch 15878/17275   train_loss = 3.598\n",
      "Epoch   0 Batch 15879/17275   train_loss = 3.784\n",
      "Epoch   0 Batch 15880/17275   train_loss = 2.703\n",
      "Epoch   0 Batch 15881/17275   train_loss = 3.288\n",
      "Epoch   0 Batch 15882/17275   train_loss = 4.253\n",
      "Epoch   0 Batch 15883/17275   train_loss = 3.249\n",
      "Epoch   0 Batch 15884/17275   train_loss = 3.364\n",
      "Epoch   0 Batch 15885/17275   train_loss = 3.424\n",
      "Epoch   0 Batch 15886/17275   train_loss = 2.229\n",
      "Epoch   0 Batch 15887/17275   train_loss = 3.654\n",
      "Epoch   0 Batch 15888/17275   train_loss = 3.354\n",
      "Epoch   0 Batch 15889/17275   train_loss = 2.712\n",
      "Epoch   0 Batch 15890/17275   train_loss = 3.981\n",
      "Epoch   0 Batch 15891/17275   train_loss = 4.599\n",
      "Epoch   0 Batch 15892/17275   train_loss = 3.650\n",
      "Epoch   0 Batch 15893/17275   train_loss = 3.222\n",
      "Epoch   0 Batch 15894/17275   train_loss = 7.256\n",
      "Epoch   0 Batch 15895/17275   train_loss = 6.689\n",
      "Epoch   0 Batch 15896/17275   train_loss = 2.273\n",
      "Epoch   0 Batch 15897/17275   train_loss = 3.225\n",
      "Epoch   0 Batch 15898/17275   train_loss = 2.558\n",
      "Epoch   0 Batch 15899/17275   train_loss = 1.988\n",
      "Epoch   0 Batch 15900/17275   train_loss = 2.247\n",
      "Epoch   0 Batch 15901/17275   train_loss = 2.551\n",
      "Epoch   0 Batch 15902/17275   train_loss = 3.132\n",
      "Epoch   0 Batch 15903/17275   train_loss = 2.866\n",
      "Epoch   0 Batch 15904/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 15905/17275   train_loss = 4.603\n",
      "Epoch   0 Batch 15906/17275   train_loss = 1.932\n",
      "Epoch   0 Batch 15907/17275   train_loss = 3.185\n",
      "Epoch   0 Batch 15908/17275   train_loss = 1.912\n",
      "Epoch   0 Batch 15909/17275   train_loss = 2.648\n",
      "Epoch   0 Batch 15910/17275   train_loss = 3.417\n",
      "Epoch   0 Batch 15911/17275   train_loss = 7.106\n",
      "Epoch   0 Batch 15912/17275   train_loss = 3.338\n",
      "Epoch   0 Batch 15913/17275   train_loss = 3.328\n",
      "Epoch   0 Batch 15914/17275   train_loss = 3.985\n",
      "Epoch   0 Batch 15915/17275   train_loss = 7.055\n",
      "Epoch   0 Batch 15916/17275   train_loss = 3.580\n",
      "Epoch   0 Batch 15917/17275   train_loss = 6.793\n",
      "Epoch   0 Batch 15918/17275   train_loss = 3.056\n",
      "Epoch   0 Batch 15919/17275   train_loss = 3.430\n",
      "Epoch   0 Batch 15920/17275   train_loss = 4.134\n",
      "Epoch   0 Batch 15921/17275   train_loss = 7.064\n",
      "Epoch   0 Batch 15922/17275   train_loss = 2.356\n",
      "Epoch   0 Batch 15923/17275   train_loss = 3.693\n",
      "Epoch   0 Batch 15924/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 15925/17275   train_loss = 4.632\n",
      "Epoch   0 Batch 15926/17275   train_loss = 4.737\n",
      "Epoch   0 Batch 15927/17275   train_loss = 4.137\n",
      "Epoch   0 Batch 15928/17275   train_loss = 3.800\n",
      "Epoch   0 Batch 15929/17275   train_loss = 2.336\n",
      "Epoch   0 Batch 15930/17275   train_loss = 2.405\n",
      "Epoch   0 Batch 15931/17275   train_loss = 3.199\n",
      "Epoch   0 Batch 15932/17275   train_loss = 3.350\n",
      "Epoch   0 Batch 15933/17275   train_loss = 11.442\n",
      "Epoch   0 Batch 15934/17275   train_loss = 2.497\n",
      "Epoch   0 Batch 15935/17275   train_loss = 2.502\n",
      "Epoch   0 Batch 15936/17275   train_loss = 6.999\n",
      "Epoch   0 Batch 15937/17275   train_loss = 2.683\n",
      "Epoch   0 Batch 15938/17275   train_loss = 4.329\n",
      "Epoch   0 Batch 15939/17275   train_loss = 3.727\n",
      "Epoch   0 Batch 15940/17275   train_loss = 2.326\n",
      "Epoch   0 Batch 15941/17275   train_loss = 2.977\n",
      "Epoch   0 Batch 15942/17275   train_loss = 1.994\n",
      "Epoch   0 Batch 15943/17275   train_loss = 2.791\n",
      "Epoch   0 Batch 15944/17275   train_loss = 2.927\n",
      "Epoch   0 Batch 15945/17275   train_loss = 4.056\n",
      "Epoch   0 Batch 15946/17275   train_loss = 1.988\n",
      "Epoch   0 Batch 15947/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 15948/17275   train_loss = 3.782\n",
      "Epoch   0 Batch 15949/17275   train_loss = 3.975\n",
      "Epoch   0 Batch 15950/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 15951/17275   train_loss = 1.952\n",
      "Epoch   0 Batch 15952/17275   train_loss = 3.204\n",
      "Epoch   0 Batch 15953/17275   train_loss = 3.241\n",
      "Epoch   0 Batch 15954/17275   train_loss = 2.638\n",
      "Epoch   0 Batch 15955/17275   train_loss = 3.481\n",
      "Epoch   0 Batch 15956/17275   train_loss = 6.706\n",
      "Epoch   0 Batch 15957/17275   train_loss = 1.908\n",
      "Epoch   0 Batch 15958/17275   train_loss = 2.648\n",
      "Epoch   0 Batch 15959/17275   train_loss = 4.380\n",
      "Epoch   0 Batch 15960/17275   train_loss = 1.862\n",
      "Epoch   0 Batch 15961/17275   train_loss = 1.870\n",
      "Epoch   0 Batch 15962/17275   train_loss = 3.157\n",
      "Epoch   0 Batch 15963/17275   train_loss = 3.004\n",
      "Epoch   0 Batch 15964/17275   train_loss = 4.181\n",
      "Epoch   0 Batch 15965/17275   train_loss = 3.943\n",
      "Epoch   0 Batch 15966/17275   train_loss = 4.604\n",
      "Epoch   0 Batch 15967/17275   train_loss = 2.834\n",
      "Epoch   0 Batch 15968/17275   train_loss = 7.073\n",
      "Epoch   0 Batch 15969/17275   train_loss = 2.747\n",
      "Epoch   0 Batch 15970/17275   train_loss = 1.797\n",
      "Epoch   0 Batch 15971/17275   train_loss = 3.252\n",
      "Epoch   0 Batch 15972/17275   train_loss = 5.480\n",
      "Epoch   0 Batch 15973/17275   train_loss = 2.490\n",
      "Epoch   0 Batch 15974/17275   train_loss = 2.592\n",
      "Epoch   0 Batch 15975/17275   train_loss = 7.138\n",
      "Epoch   0 Batch 15976/17275   train_loss = 2.581\n",
      "Epoch   0 Batch 15977/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 15978/17275   train_loss = 4.475\n",
      "Epoch   0 Batch 15979/17275   train_loss = 2.342\n",
      "Epoch   0 Batch 15980/17275   train_loss = 2.882\n",
      "Epoch   0 Batch 15981/17275   train_loss = 4.573\n",
      "Epoch   0 Batch 15982/17275   train_loss = 6.774\n",
      "Epoch   0 Batch 15983/17275   train_loss = 2.236\n",
      "Epoch   0 Batch 15984/17275   train_loss = 8.370\n",
      "Epoch   0 Batch 15985/17275   train_loss = 2.274\n",
      "Epoch   0 Batch 15986/17275   train_loss = 2.750\n",
      "Epoch   0 Batch 15987/17275   train_loss = 3.427\n",
      "Epoch   0 Batch 15988/17275   train_loss = 6.302\n",
      "Epoch   0 Batch 15989/17275   train_loss = 6.725\n",
      "Epoch   0 Batch 15990/17275   train_loss = 3.577\n",
      "Epoch   0 Batch 15991/17275   train_loss = 2.030\n",
      "Epoch   0 Batch 15992/17275   train_loss = 4.970\n",
      "Epoch   0 Batch 15993/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 15994/17275   train_loss = 3.764\n",
      "Epoch   0 Batch 15995/17275   train_loss = 3.683\n",
      "Epoch   0 Batch 15996/17275   train_loss = 4.501\n",
      "Epoch   0 Batch 15997/17275   train_loss = 3.038\n",
      "Epoch   0 Batch 15998/17275   train_loss = 6.107\n",
      "Epoch   0 Batch 15999/17275   train_loss = 2.169\n",
      "Epoch   0 Batch 16000/17275   train_loss = 11.512\n",
      "Epoch   0 Batch 16001/17275   train_loss = 3.368\n",
      "Epoch   0 Batch 16002/17275   train_loss = 2.306\n",
      "Epoch   0 Batch 16003/17275   train_loss = 6.912\n",
      "Epoch   0 Batch 16004/17275   train_loss = 2.713\n",
      "Epoch   0 Batch 16005/17275   train_loss = 3.067\n",
      "Epoch   0 Batch 16006/17275   train_loss = 2.901\n",
      "Epoch   0 Batch 16007/17275   train_loss = 6.732\n",
      "Epoch   0 Batch 16008/17275   train_loss = 4.146\n",
      "Epoch   0 Batch 16009/17275   train_loss = 3.587\n",
      "Epoch   0 Batch 16010/17275   train_loss = 2.270\n",
      "Epoch   0 Batch 16011/17275   train_loss = 3.617\n",
      "Epoch   0 Batch 16012/17275   train_loss = 3.808\n",
      "Epoch   0 Batch 16013/17275   train_loss = 1.931\n",
      "Epoch   0 Batch 16014/17275   train_loss = 2.058\n",
      "Epoch   0 Batch 16015/17275   train_loss = 3.514\n",
      "Epoch   0 Batch 16016/17275   train_loss = 4.228\n",
      "Epoch   0 Batch 16017/17275   train_loss = 4.820\n",
      "Epoch   0 Batch 16018/17275   train_loss = 11.516\n",
      "Epoch   0 Batch 16019/17275   train_loss = 2.410\n",
      "Epoch   0 Batch 16020/17275   train_loss = 3.566\n",
      "Epoch   0 Batch 16021/17275   train_loss = 4.429\n",
      "Epoch   0 Batch 16022/17275   train_loss = 2.860\n",
      "Epoch   0 Batch 16023/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 16024/17275   train_loss = 2.415\n",
      "Epoch   0 Batch 16025/17275   train_loss = 2.717\n",
      "Epoch   0 Batch 16026/17275   train_loss = 3.681\n",
      "Epoch   0 Batch 16027/17275   train_loss = 7.214\n",
      "Epoch   0 Batch 16028/17275   train_loss = 4.168\n",
      "Epoch   0 Batch 16029/17275   train_loss = 4.964\n",
      "Epoch   0 Batch 16030/17275   train_loss = 5.684\n",
      "Epoch   0 Batch 16031/17275   train_loss = 2.975\n",
      "Epoch   0 Batch 16032/17275   train_loss = 2.796\n",
      "Epoch   0 Batch 16033/17275   train_loss = 4.039\n",
      "Epoch   0 Batch 16034/17275   train_loss = 7.347\n",
      "Epoch   0 Batch 16035/17275   train_loss = 4.099\n",
      "Epoch   0 Batch 16036/17275   train_loss = 5.277\n",
      "Epoch   0 Batch 16037/17275   train_loss = 2.752\n",
      "Epoch   0 Batch 16038/17275   train_loss = 4.478\n",
      "Epoch   0 Batch 16039/17275   train_loss = 3.374\n",
      "Epoch   0 Batch 16040/17275   train_loss = 3.308\n",
      "Epoch   0 Batch 16041/17275   train_loss = 6.303\n",
      "Epoch   0 Batch 16042/17275   train_loss = 1.905\n",
      "Epoch   0 Batch 16043/17275   train_loss = 3.994\n",
      "Epoch   0 Batch 16044/17275   train_loss = 3.514\n",
      "Epoch   0 Batch 16045/17275   train_loss = 3.410\n",
      "Epoch   0 Batch 16046/17275   train_loss = 2.389\n",
      "Epoch   0 Batch 16047/17275   train_loss = 4.317\n",
      "Epoch   0 Batch 16048/17275   train_loss = 6.102\n",
      "Epoch   0 Batch 16049/17275   train_loss = 2.290\n",
      "Epoch   0 Batch 16050/17275   train_loss = 3.092\n",
      "Epoch   0 Batch 16051/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 16052/17275   train_loss = 5.154\n",
      "Epoch   0 Batch 16053/17275   train_loss = 5.203\n",
      "Epoch   0 Batch 16054/17275   train_loss = 4.151\n",
      "Epoch   0 Batch 16055/17275   train_loss = 3.042\n",
      "Epoch   0 Batch 16056/17275   train_loss = 6.673\n",
      "Epoch   0 Batch 16057/17275   train_loss = 1.955\n",
      "Epoch   0 Batch 16058/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 16059/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 16060/17275   train_loss = 7.960\n",
      "Epoch   0 Batch 16061/17275   train_loss = 3.637\n",
      "Epoch   0 Batch 16062/17275   train_loss = 5.098\n",
      "Epoch   0 Batch 16063/17275   train_loss = 4.504\n",
      "Epoch   0 Batch 16064/17275   train_loss = 3.533\n",
      "Epoch   0 Batch 16065/17275   train_loss = 4.692\n",
      "Epoch   0 Batch 16066/17275   train_loss = 5.048\n",
      "Epoch   0 Batch 16067/17275   train_loss = 3.901\n",
      "Epoch   0 Batch 16068/17275   train_loss = 2.737\n",
      "Epoch   0 Batch 16069/17275   train_loss = 2.229\n",
      "Epoch   0 Batch 16070/17275   train_loss = 4.191\n",
      "Epoch   0 Batch 16071/17275   train_loss = 3.296\n",
      "Epoch   0 Batch 16072/17275   train_loss = 2.398\n",
      "Epoch   0 Batch 16073/17275   train_loss = 4.832\n",
      "Epoch   0 Batch 16074/17275   train_loss = 6.624\n",
      "Epoch   0 Batch 16075/17275   train_loss = 3.570\n",
      "Epoch   0 Batch 16076/17275   train_loss = 8.560\n",
      "Epoch   0 Batch 16077/17275   train_loss = 2.726\n",
      "Epoch   0 Batch 16078/17275   train_loss = 3.479\n",
      "Epoch   0 Batch 16079/17275   train_loss = 4.244\n",
      "Epoch   0 Batch 16080/17275   train_loss = 3.345\n",
      "Epoch   0 Batch 16081/17275   train_loss = 3.238\n",
      "Epoch   0 Batch 16082/17275   train_loss = 3.620\n",
      "Epoch   0 Batch 16083/17275   train_loss = 1.730\n",
      "Epoch   0 Batch 16084/17275   train_loss = 2.448\n",
      "Epoch   0 Batch 16085/17275   train_loss = 7.149\n",
      "Epoch   0 Batch 16086/17275   train_loss = 3.619\n",
      "Epoch   0 Batch 16087/17275   train_loss = 4.233\n",
      "Epoch   0 Batch 16088/17275   train_loss = 2.922\n",
      "Epoch   0 Batch 16089/17275   train_loss = 3.864\n",
      "Epoch   0 Batch 16090/17275   train_loss = 3.066\n",
      "Epoch   0 Batch 16091/17275   train_loss = 3.266\n",
      "Epoch   0 Batch 16092/17275   train_loss = 3.324\n",
      "Epoch   0 Batch 16093/17275   train_loss = 4.225\n",
      "Epoch   0 Batch 16094/17275   train_loss = 4.266\n",
      "Epoch   0 Batch 16095/17275   train_loss = 4.086\n",
      "Epoch   0 Batch 16096/17275   train_loss = 3.737\n",
      "Epoch   0 Batch 16097/17275   train_loss = 3.208\n",
      "Epoch   0 Batch 16098/17275   train_loss = 3.434\n",
      "Epoch   0 Batch 16099/17275   train_loss = 4.432\n",
      "Epoch   0 Batch 16100/17275   train_loss = 3.375\n",
      "Epoch   0 Batch 16101/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 16102/17275   train_loss = 6.634\n",
      "Epoch   0 Batch 16103/17275   train_loss = 3.439\n",
      "Epoch   0 Batch 16104/17275   train_loss = 3.642\n",
      "Epoch   0 Batch 16105/17275   train_loss = 2.629\n",
      "Epoch   0 Batch 16106/17275   train_loss = 4.318\n",
      "Epoch   0 Batch 16107/17275   train_loss = 3.543\n",
      "Epoch   0 Batch 16108/17275   train_loss = 8.272\n",
      "Epoch   0 Batch 16109/17275   train_loss = 4.276\n",
      "Epoch   0 Batch 16110/17275   train_loss = 3.282\n",
      "Epoch   0 Batch 16111/17275   train_loss = 3.833\n",
      "Epoch   0 Batch 16112/17275   train_loss = 3.828\n",
      "Epoch   0 Batch 16113/17275   train_loss = 4.103\n",
      "Epoch   0 Batch 16114/17275   train_loss = 2.034\n",
      "Epoch   0 Batch 16115/17275   train_loss = 3.369\n",
      "Epoch   0 Batch 16116/17275   train_loss = 2.845\n",
      "Epoch   0 Batch 16117/17275   train_loss = 6.959\n",
      "Epoch   0 Batch 16118/17275   train_loss = 2.999\n",
      "Epoch   0 Batch 16119/17275   train_loss = 3.227\n",
      "Epoch   0 Batch 16120/17275   train_loss = 4.605\n",
      "Epoch   0 Batch 16121/17275   train_loss = 6.728\n",
      "Epoch   0 Batch 16122/17275   train_loss = 2.767\n",
      "Epoch   0 Batch 16123/17275   train_loss = 3.780\n",
      "Epoch   0 Batch 16124/17275   train_loss = 4.246\n",
      "Epoch   0 Batch 16125/17275   train_loss = 4.250\n",
      "Epoch   0 Batch 16126/17275   train_loss = 4.448\n",
      "Epoch   0 Batch 16127/17275   train_loss = 2.094\n",
      "Epoch   0 Batch 16128/17275   train_loss = 6.771\n",
      "Epoch   0 Batch 16129/17275   train_loss = 3.689\n",
      "Epoch   0 Batch 16130/17275   train_loss = 2.817\n",
      "Epoch   0 Batch 16131/17275   train_loss = 4.639\n",
      "Epoch   0 Batch 16132/17275   train_loss = 5.094\n",
      "Epoch   0 Batch 16133/17275   train_loss = 3.427\n",
      "Epoch   0 Batch 16134/17275   train_loss = 7.126\n",
      "Epoch   0 Batch 16135/17275   train_loss = 6.621\n",
      "Epoch   0 Batch 16136/17275   train_loss = 3.275\n",
      "Epoch   0 Batch 16137/17275   train_loss = 6.708\n",
      "Epoch   0 Batch 16138/17275   train_loss = 2.572\n",
      "Epoch   0 Batch 16139/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 16140/17275   train_loss = 7.511\n",
      "Epoch   0 Batch 16141/17275   train_loss = 2.066\n",
      "Epoch   0 Batch 16142/17275   train_loss = 3.238\n",
      "Epoch   0 Batch 16143/17275   train_loss = 3.081\n",
      "Epoch   0 Batch 16144/17275   train_loss = 4.522\n",
      "Epoch   0 Batch 16145/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 16146/17275   train_loss = 2.036\n",
      "Epoch   0 Batch 16147/17275   train_loss = 2.130\n",
      "Epoch   0 Batch 16148/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 16149/17275   train_loss = 4.807\n",
      "Epoch   0 Batch 16150/17275   train_loss = 3.162\n",
      "Epoch   0 Batch 16151/17275   train_loss = 3.099\n",
      "Epoch   0 Batch 16152/17275   train_loss = 4.430\n",
      "Epoch   0 Batch 16153/17275   train_loss = 4.390\n",
      "Epoch   0 Batch 16154/17275   train_loss = 5.199\n",
      "Epoch   0 Batch 16155/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 16156/17275   train_loss = 3.022\n",
      "Epoch   0 Batch 16157/17275   train_loss = 2.271\n",
      "Epoch   0 Batch 16158/17275   train_loss = 5.704\n",
      "Epoch   0 Batch 16159/17275   train_loss = 4.295\n",
      "Epoch   0 Batch 16160/17275   train_loss = 6.907\n",
      "Epoch   0 Batch 16161/17275   train_loss = 3.539\n",
      "Epoch   0 Batch 16162/17275   train_loss = 2.735\n",
      "Epoch   0 Batch 16163/17275   train_loss = 4.028\n",
      "Epoch   0 Batch 16164/17275   train_loss = 3.638\n",
      "Epoch   0 Batch 16165/17275   train_loss = 5.538\n",
      "Epoch   0 Batch 16166/17275   train_loss = 3.253\n",
      "Epoch   0 Batch 16167/17275   train_loss = 5.753\n",
      "Epoch   0 Batch 16168/17275   train_loss = 7.778\n",
      "Epoch   0 Batch 16169/17275   train_loss = 4.892\n",
      "Epoch   0 Batch 16170/17275   train_loss = 6.769\n",
      "Epoch   0 Batch 16171/17275   train_loss = 2.323\n",
      "Epoch   0 Batch 16172/17275   train_loss = 2.990\n",
      "Epoch   0 Batch 16173/17275   train_loss = 4.690\n",
      "Epoch   0 Batch 16174/17275   train_loss = 4.199\n",
      "Epoch   0 Batch 16175/17275   train_loss = 3.377\n",
      "Epoch   0 Batch 16176/17275   train_loss = 4.179\n",
      "Epoch   0 Batch 16177/17275   train_loss = 3.585\n",
      "Epoch   0 Batch 16178/17275   train_loss = 3.964\n",
      "Epoch   0 Batch 16179/17275   train_loss = 4.703\n",
      "Epoch   0 Batch 16180/17275   train_loss = 3.302\n",
      "Epoch   0 Batch 16181/17275   train_loss = 6.708\n",
      "Epoch   0 Batch 16182/17275   train_loss = 2.851\n",
      "Epoch   0 Batch 16183/17275   train_loss = 3.514\n",
      "Epoch   0 Batch 16184/17275   train_loss = 5.635\n",
      "Epoch   0 Batch 16185/17275   train_loss = 8.191\n",
      "Epoch   0 Batch 16186/17275   train_loss = 8.573\n",
      "Epoch   0 Batch 16187/17275   train_loss = 3.514\n",
      "Epoch   0 Batch 16188/17275   train_loss = 6.783\n",
      "Epoch   0 Batch 16189/17275   train_loss = 3.279\n",
      "Epoch   0 Batch 16190/17275   train_loss = 10.095\n",
      "Epoch   0 Batch 16191/17275   train_loss = 2.013\n",
      "Epoch   0 Batch 16192/17275   train_loss = 2.004\n",
      "Epoch   0 Batch 16193/17275   train_loss = 4.048\n",
      "Epoch   0 Batch 16194/17275   train_loss = 2.675\n",
      "Epoch   0 Batch 16195/17275   train_loss = 3.517\n",
      "Epoch   0 Batch 16196/17275   train_loss = 5.725\n",
      "Epoch   0 Batch 16197/17275   train_loss = 1.974\n",
      "Epoch   0 Batch 16198/17275   train_loss = 2.953\n",
      "Epoch   0 Batch 16199/17275   train_loss = 2.894\n",
      "Epoch   0 Batch 16200/17275   train_loss = 4.448\n",
      "Epoch   0 Batch 16201/17275   train_loss = 8.104\n",
      "Epoch   0 Batch 16202/17275   train_loss = 5.077\n",
      "Epoch   0 Batch 16203/17275   train_loss = 4.162\n",
      "Epoch   0 Batch 16204/17275   train_loss = 4.341\n",
      "Epoch   0 Batch 16205/17275   train_loss = 3.662\n",
      "Epoch   0 Batch 16206/17275   train_loss = 6.800\n",
      "Epoch   0 Batch 16207/17275   train_loss = 1.958\n",
      "Epoch   0 Batch 16208/17275   train_loss = 3.098\n",
      "Epoch   0 Batch 16209/17275   train_loss = 2.653\n",
      "Epoch   0 Batch 16210/17275   train_loss = 7.882\n",
      "Epoch   0 Batch 16211/17275   train_loss = 4.289\n",
      "Epoch   0 Batch 16212/17275   train_loss = 3.265\n",
      "Epoch   0 Batch 16213/17275   train_loss = 4.122\n",
      "Epoch   0 Batch 16214/17275   train_loss = 4.126\n",
      "Epoch   0 Batch 16215/17275   train_loss = 1.972\n",
      "Epoch   0 Batch 16216/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 16217/17275   train_loss = 3.071\n",
      "Epoch   0 Batch 16218/17275   train_loss = 6.730\n",
      "Epoch   0 Batch 16219/17275   train_loss = 3.088\n",
      "Epoch   0 Batch 16220/17275   train_loss = 4.171\n",
      "Epoch   0 Batch 16221/17275   train_loss = 3.192\n",
      "Epoch   0 Batch 16222/17275   train_loss = 4.208\n",
      "Epoch   0 Batch 16223/17275   train_loss = 3.862\n",
      "Epoch   0 Batch 16224/17275   train_loss = 4.167\n",
      "Epoch   0 Batch 16225/17275   train_loss = 2.020\n",
      "Epoch   0 Batch 16226/17275   train_loss = 3.090\n",
      "Epoch   0 Batch 16227/17275   train_loss = 7.347\n",
      "Epoch   0 Batch 16228/17275   train_loss = 6.759\n",
      "Epoch   0 Batch 16229/17275   train_loss = 3.750\n",
      "Epoch   0 Batch 16230/17275   train_loss = 5.115\n",
      "Epoch   0 Batch 16231/17275   train_loss = 2.885\n",
      "Epoch   0 Batch 16232/17275   train_loss = 5.748\n",
      "Epoch   0 Batch 16233/17275   train_loss = 8.159\n",
      "Epoch   0 Batch 16234/17275   train_loss = 5.423\n",
      "Epoch   0 Batch 16235/17275   train_loss = 3.853\n",
      "Epoch   0 Batch 16236/17275   train_loss = 2.979\n",
      "Epoch   0 Batch 16237/17275   train_loss = 3.731\n",
      "Epoch   0 Batch 16238/17275   train_loss = 7.270\n",
      "Epoch   0 Batch 16239/17275   train_loss = 2.074\n",
      "Epoch   0 Batch 16240/17275   train_loss = 3.465\n",
      "Epoch   0 Batch 16241/17275   train_loss = 4.516\n",
      "Epoch   0 Batch 16242/17275   train_loss = 4.164\n",
      "Epoch   0 Batch 16243/17275   train_loss = 11.448\n",
      "Epoch   0 Batch 16244/17275   train_loss = 3.110\n",
      "Epoch   0 Batch 16245/17275   train_loss = 4.150\n",
      "Epoch   0 Batch 16246/17275   train_loss = 3.543\n",
      "Epoch   0 Batch 16247/17275   train_loss = 2.942\n",
      "Epoch   0 Batch 16248/17275   train_loss = 5.288\n",
      "Epoch   0 Batch 16249/17275   train_loss = 6.746\n",
      "Epoch   0 Batch 16250/17275   train_loss = 2.501\n",
      "Epoch   0 Batch 16251/17275   train_loss = 2.749\n",
      "Epoch   0 Batch 16252/17275   train_loss = 2.005\n",
      "Epoch   0 Batch 16253/17275   train_loss = 7.500\n",
      "Epoch   0 Batch 16254/17275   train_loss = 3.326\n",
      "Epoch   0 Batch 16255/17275   train_loss = 4.290\n",
      "Epoch   0 Batch 16256/17275   train_loss = 4.274\n",
      "Epoch   0 Batch 16257/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 16258/17275   train_loss = 3.163\n",
      "Epoch   0 Batch 16259/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 16260/17275   train_loss = 3.612\n",
      "Epoch   0 Batch 16261/17275   train_loss = 2.541\n",
      "Epoch   0 Batch 16262/17275   train_loss = 3.343\n",
      "Epoch   0 Batch 16263/17275   train_loss = 3.506\n",
      "Epoch   0 Batch 16264/17275   train_loss = 3.571\n",
      "Epoch   0 Batch 16265/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 16266/17275   train_loss = 2.777\n",
      "Epoch   0 Batch 16267/17275   train_loss = 4.470\n",
      "Epoch   0 Batch 16268/17275   train_loss = 4.223\n",
      "Epoch   0 Batch 16269/17275   train_loss = 4.849\n",
      "Epoch   0 Batch 16270/17275   train_loss = 7.122\n",
      "Epoch   0 Batch 16271/17275   train_loss = 2.044\n",
      "Epoch   0 Batch 16272/17275   train_loss = 3.004\n",
      "Epoch   0 Batch 16273/17275   train_loss = 4.223\n",
      "Epoch   0 Batch 16274/17275   train_loss = 2.881\n",
      "Epoch   0 Batch 16275/17275   train_loss = 3.458\n",
      "Epoch   0 Batch 16276/17275   train_loss = 2.202\n",
      "Epoch   0 Batch 16277/17275   train_loss = 3.005\n",
      "Epoch   0 Batch 16278/17275   train_loss = 3.564\n",
      "Epoch   0 Batch 16279/17275   train_loss = 5.511\n",
      "Epoch   0 Batch 16280/17275   train_loss = 7.383\n",
      "Epoch   0 Batch 16281/17275   train_loss = 6.937\n",
      "Epoch   0 Batch 16282/17275   train_loss = 5.199\n",
      "Epoch   0 Batch 16283/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 16284/17275   train_loss = 4.631\n",
      "Epoch   0 Batch 16285/17275   train_loss = 4.801\n",
      "Epoch   0 Batch 16286/17275   train_loss = 3.751\n",
      "Epoch   0 Batch 16287/17275   train_loss = 1.956\n",
      "Epoch   0 Batch 16288/17275   train_loss = 2.962\n",
      "Epoch   0 Batch 16289/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 16290/17275   train_loss = 7.479\n",
      "Epoch   0 Batch 16291/17275   train_loss = 3.021\n",
      "Epoch   0 Batch 16292/17275   train_loss = 3.770\n",
      "Epoch   0 Batch 16293/17275   train_loss = 2.413\n",
      "Epoch   0 Batch 16294/17275   train_loss = 7.620\n",
      "Epoch   0 Batch 16295/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 16296/17275   train_loss = 7.231\n",
      "Epoch   0 Batch 16297/17275   train_loss = 4.449\n",
      "Epoch   0 Batch 16298/17275   train_loss = 6.711\n",
      "Epoch   0 Batch 16299/17275   train_loss = 2.664\n",
      "Epoch   0 Batch 16300/17275   train_loss = 7.312\n",
      "Epoch   0 Batch 16301/17275   train_loss = 3.100\n",
      "Epoch   0 Batch 16302/17275   train_loss = 4.678\n",
      "Epoch   0 Batch 16303/17275   train_loss = 3.460\n",
      "Epoch   0 Batch 16304/17275   train_loss = 4.104\n",
      "Epoch   0 Batch 16305/17275   train_loss = 2.384\n",
      "Epoch   0 Batch 16306/17275   train_loss = 3.180\n",
      "Epoch   0 Batch 16307/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 16308/17275   train_loss = 3.041\n",
      "Epoch   0 Batch 16309/17275   train_loss = 2.483\n",
      "Epoch   0 Batch 16310/17275   train_loss = 7.737\n",
      "Epoch   0 Batch 16311/17275   train_loss = 2.663\n",
      "Epoch   0 Batch 16312/17275   train_loss = 3.723\n",
      "Epoch   0 Batch 16313/17275   train_loss = 7.272\n",
      "Epoch   0 Batch 16314/17275   train_loss = 3.001\n",
      "Epoch   0 Batch 16315/17275   train_loss = 7.086\n",
      "Epoch   0 Batch 16316/17275   train_loss = 11.470\n",
      "Epoch   0 Batch 16317/17275   train_loss = 2.034\n",
      "Epoch   0 Batch 16318/17275   train_loss = 2.007\n",
      "Epoch   0 Batch 16319/17275   train_loss = 2.837\n",
      "Epoch   0 Batch 16320/17275   train_loss = 7.242\n",
      "Epoch   0 Batch 16321/17275   train_loss = 6.973\n",
      "Epoch   0 Batch 16322/17275   train_loss = 2.414\n",
      "Epoch   0 Batch 16323/17275   train_loss = 4.569\n",
      "Epoch   0 Batch 16324/17275   train_loss = 4.226\n",
      "Epoch   0 Batch 16325/17275   train_loss = 3.085\n",
      "Epoch   0 Batch 16326/17275   train_loss = 7.179\n",
      "Epoch   0 Batch 16327/17275   train_loss = 7.433\n",
      "Epoch   0 Batch 16328/17275   train_loss = 5.820\n",
      "Epoch   0 Batch 16329/17275   train_loss = 2.336\n",
      "Epoch   0 Batch 16330/17275   train_loss = 3.195\n",
      "Epoch   0 Batch 16331/17275   train_loss = 9.201\n",
      "Epoch   0 Batch 16332/17275   train_loss = 2.702\n",
      "Epoch   0 Batch 16333/17275   train_loss = 4.517\n",
      "Epoch   0 Batch 16334/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 16335/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 16336/17275   train_loss = 3.369\n",
      "Epoch   0 Batch 16337/17275   train_loss = 3.153\n",
      "Epoch   0 Batch 16338/17275   train_loss = 3.655\n",
      "Epoch   0 Batch 16339/17275   train_loss = 3.604\n",
      "Epoch   0 Batch 16340/17275   train_loss = 7.355\n",
      "Epoch   0 Batch 16341/17275   train_loss = 2.704\n",
      "Epoch   0 Batch 16342/17275   train_loss = 3.942\n",
      "Epoch   0 Batch 16343/17275   train_loss = 4.530\n",
      "Epoch   0 Batch 16344/17275   train_loss = 3.257\n",
      "Epoch   0 Batch 16345/17275   train_loss = 3.350\n",
      "Epoch   0 Batch 16346/17275   train_loss = 3.283\n",
      "Epoch   0 Batch 16347/17275   train_loss = 4.352\n",
      "Epoch   0 Batch 16348/17275   train_loss = 2.044\n",
      "Epoch   0 Batch 16349/17275   train_loss = 3.320\n",
      "Epoch   0 Batch 16350/17275   train_loss = 7.677\n",
      "Epoch   0 Batch 16351/17275   train_loss = 4.227\n",
      "Epoch   0 Batch 16352/17275   train_loss = 7.000\n",
      "Epoch   0 Batch 16353/17275   train_loss = 2.422\n",
      "Epoch   0 Batch 16354/17275   train_loss = 2.862\n",
      "Epoch   0 Batch 16355/17275   train_loss = 3.738\n",
      "Epoch   0 Batch 16356/17275   train_loss = 2.613\n",
      "Epoch   0 Batch 16357/17275   train_loss = 8.947\n",
      "Epoch   0 Batch 16358/17275   train_loss = 4.441\n",
      "Epoch   0 Batch 16359/17275   train_loss = 3.553\n",
      "Epoch   0 Batch 16360/17275   train_loss = 6.737\n",
      "Epoch   0 Batch 16361/17275   train_loss = 4.390\n",
      "Epoch   0 Batch 16362/17275   train_loss = 5.549\n",
      "Epoch   0 Batch 16363/17275   train_loss = 11.484\n",
      "Epoch   0 Batch 16364/17275   train_loss = 3.924\n",
      "Epoch   0 Batch 16365/17275   train_loss = 11.334\n",
      "Epoch   0 Batch 16366/17275   train_loss = 2.076\n",
      "Epoch   0 Batch 16367/17275   train_loss = 1.932\n",
      "Epoch   0 Batch 16368/17275   train_loss = 2.589\n",
      "Epoch   0 Batch 16369/17275   train_loss = 5.329\n",
      "Epoch   0 Batch 16370/17275   train_loss = 3.930\n",
      "Epoch   0 Batch 16371/17275   train_loss = 4.091\n",
      "Epoch   0 Batch 16372/17275   train_loss = 3.591\n",
      "Epoch   0 Batch 16373/17275   train_loss = 3.901\n",
      "Epoch   0 Batch 16374/17275   train_loss = 2.676\n",
      "Epoch   0 Batch 16375/17275   train_loss = 3.960\n",
      "Epoch   0 Batch 16376/17275   train_loss = 6.643\n",
      "Epoch   0 Batch 16377/17275   train_loss = 3.952\n",
      "Epoch   0 Batch 16378/17275   train_loss = 3.169\n",
      "Epoch   0 Batch 16379/17275   train_loss = 2.371\n",
      "Epoch   0 Batch 16380/17275   train_loss = 7.205\n",
      "Epoch   0 Batch 16381/17275   train_loss = 6.794\n",
      "Epoch   0 Batch 16382/17275   train_loss = 2.273\n",
      "Epoch   0 Batch 16383/17275   train_loss = 3.793\n",
      "Epoch   0 Batch 16384/17275   train_loss = 4.110\n",
      "Epoch   0 Batch 16385/17275   train_loss = 3.883\n",
      "Epoch   0 Batch 16386/17275   train_loss = 3.795\n",
      "Epoch   0 Batch 16387/17275   train_loss = 3.285\n",
      "Epoch   0 Batch 16388/17275   train_loss = 2.266\n",
      "Epoch   0 Batch 16389/17275   train_loss = 7.094\n",
      "Epoch   0 Batch 16390/17275   train_loss = 3.323\n",
      "Epoch   0 Batch 16391/17275   train_loss = 3.664\n",
      "Epoch   0 Batch 16392/17275   train_loss = 8.027\n",
      "Epoch   0 Batch 16393/17275   train_loss = 3.773\n",
      "Epoch   0 Batch 16394/17275   train_loss = 4.157\n",
      "Epoch   0 Batch 16395/17275   train_loss = 4.980\n",
      "Epoch   0 Batch 16396/17275   train_loss = 2.643\n",
      "Epoch   0 Batch 16397/17275   train_loss = 2.248\n",
      "Epoch   0 Batch 16398/17275   train_loss = 3.090\n",
      "Epoch   0 Batch 16399/17275   train_loss = 3.202\n",
      "Epoch   0 Batch 16400/17275   train_loss = 6.352\n",
      "Epoch   0 Batch 16401/17275   train_loss = 7.332\n",
      "Epoch   0 Batch 16402/17275   train_loss = 3.247\n",
      "Epoch   0 Batch 16403/17275   train_loss = 3.091\n",
      "Epoch   0 Batch 16404/17275   train_loss = 4.543\n",
      "Epoch   0 Batch 16405/17275   train_loss = 7.606\n",
      "Epoch   0 Batch 16406/17275   train_loss = 2.170\n",
      "Epoch   0 Batch 16407/17275   train_loss = 7.057\n",
      "Epoch   0 Batch 16408/17275   train_loss = 2.932\n",
      "Epoch   0 Batch 16409/17275   train_loss = 2.989\n",
      "Epoch   0 Batch 16410/17275   train_loss = 2.779\n",
      "Epoch   0 Batch 16411/17275   train_loss = 2.408\n",
      "Epoch   0 Batch 16412/17275   train_loss = 3.012\n",
      "Epoch   0 Batch 16413/17275   train_loss = 4.730\n",
      "Epoch   0 Batch 16414/17275   train_loss = 11.478\n",
      "Epoch   0 Batch 16415/17275   train_loss = 3.170\n",
      "Epoch   0 Batch 16416/17275   train_loss = 3.272\n",
      "Epoch   0 Batch 16417/17275   train_loss = 2.297\n",
      "Epoch   0 Batch 16418/17275   train_loss = 3.983\n",
      "Epoch   0 Batch 16419/17275   train_loss = 2.954\n",
      "Epoch   0 Batch 16420/17275   train_loss = 4.596\n",
      "Epoch   0 Batch 16421/17275   train_loss = 4.289\n",
      "Epoch   0 Batch 16422/17275   train_loss = 8.277\n",
      "Epoch   0 Batch 16423/17275   train_loss = 2.497\n",
      "Epoch   0 Batch 16424/17275   train_loss = 3.931\n",
      "Epoch   0 Batch 16425/17275   train_loss = 2.321\n",
      "Epoch   0 Batch 16426/17275   train_loss = 3.269\n",
      "Epoch   0 Batch 16427/17275   train_loss = 3.577\n",
      "Epoch   0 Batch 16428/17275   train_loss = 5.687\n",
      "Epoch   0 Batch 16429/17275   train_loss = 3.693\n",
      "Epoch   0 Batch 16430/17275   train_loss = 4.065\n",
      "Epoch   0 Batch 16431/17275   train_loss = 7.874\n",
      "Epoch   0 Batch 16432/17275   train_loss = 2.094\n",
      "Epoch   0 Batch 16433/17275   train_loss = 2.016\n",
      "Epoch   0 Batch 16434/17275   train_loss = 3.653\n",
      "Epoch   0 Batch 16435/17275   train_loss = 4.555\n",
      "Epoch   0 Batch 16436/17275   train_loss = 6.890\n",
      "Epoch   0 Batch 16437/17275   train_loss = 4.555\n",
      "Epoch   0 Batch 16438/17275   train_loss = 2.620\n",
      "Epoch   0 Batch 16439/17275   train_loss = 3.898\n",
      "Epoch   0 Batch 16440/17275   train_loss = 3.690\n",
      "Epoch   0 Batch 16441/17275   train_loss = 3.008\n",
      "Epoch   0 Batch 16442/17275   train_loss = 5.011\n",
      "Epoch   0 Batch 16443/17275   train_loss = 4.668\n",
      "Epoch   0 Batch 16444/17275   train_loss = 2.383\n",
      "Epoch   0 Batch 16445/17275   train_loss = 3.914\n",
      "Epoch   0 Batch 16446/17275   train_loss = 6.769\n",
      "Epoch   0 Batch 16447/17275   train_loss = 2.185\n",
      "Epoch   0 Batch 16448/17275   train_loss = 7.127\n",
      "Epoch   0 Batch 16449/17275   train_loss = 4.020\n",
      "Epoch   0 Batch 16450/17275   train_loss = 7.531\n",
      "Epoch   0 Batch 16451/17275   train_loss = 6.469\n",
      "Epoch   0 Batch 16452/17275   train_loss = 4.212\n",
      "Epoch   0 Batch 16453/17275   train_loss = 3.866\n",
      "Epoch   0 Batch 16454/17275   train_loss = 7.424\n",
      "Epoch   0 Batch 16455/17275   train_loss = 7.052\n",
      "Epoch   0 Batch 16456/17275   train_loss = 2.945\n",
      "Epoch   0 Batch 16457/17275   train_loss = 3.230\n",
      "Epoch   0 Batch 16458/17275   train_loss = 3.953\n",
      "Epoch   0 Batch 16459/17275   train_loss = 2.855\n",
      "Epoch   0 Batch 16460/17275   train_loss = 2.157\n",
      "Epoch   0 Batch 16461/17275   train_loss = 3.100\n",
      "Epoch   0 Batch 16462/17275   train_loss = 3.868\n",
      "Epoch   0 Batch 16463/17275   train_loss = 2.958\n",
      "Epoch   0 Batch 16464/17275   train_loss = 2.331\n",
      "Epoch   0 Batch 16465/17275   train_loss = 3.170\n",
      "Epoch   0 Batch 16466/17275   train_loss = 4.407\n",
      "Epoch   0 Batch 16467/17275   train_loss = 3.025\n",
      "Epoch   0 Batch 16468/17275   train_loss = 5.624\n",
      "Epoch   0 Batch 16469/17275   train_loss = 4.796\n",
      "Epoch   0 Batch 16470/17275   train_loss = 3.065\n",
      "Epoch   0 Batch 16471/17275   train_loss = 2.791\n",
      "Epoch   0 Batch 16472/17275   train_loss = 2.839\n",
      "Epoch   0 Batch 16473/17275   train_loss = 3.397\n",
      "Epoch   0 Batch 16474/17275   train_loss = 3.401\n",
      "Epoch   0 Batch 16475/17275   train_loss = 4.865\n",
      "Epoch   0 Batch 16476/17275   train_loss = 2.705\n",
      "Epoch   0 Batch 16477/17275   train_loss = 7.422\n",
      "Epoch   0 Batch 16478/17275   train_loss = 6.709\n",
      "Epoch   0 Batch 16479/17275   train_loss = 2.418\n",
      "Epoch   0 Batch 16480/17275   train_loss = 2.939\n",
      "Epoch   0 Batch 16481/17275   train_loss = 7.946\n",
      "Epoch   0 Batch 16482/17275   train_loss = 6.711\n",
      "Epoch   0 Batch 16483/17275   train_loss = 4.421\n",
      "Epoch   0 Batch 16484/17275   train_loss = 4.308\n",
      "Epoch   0 Batch 16485/17275   train_loss = 8.092\n",
      "Epoch   0 Batch 16486/17275   train_loss = 2.831\n",
      "Epoch   0 Batch 16487/17275   train_loss = 4.407\n",
      "Epoch   0 Batch 16488/17275   train_loss = 6.218\n",
      "Epoch   0 Batch 16489/17275   train_loss = 7.873\n",
      "Epoch   0 Batch 16490/17275   train_loss = 3.477\n",
      "Epoch   0 Batch 16491/17275   train_loss = 1.964\n",
      "Epoch   0 Batch 16492/17275   train_loss = 7.113\n",
      "Epoch   0 Batch 16493/17275   train_loss = 7.634\n",
      "Epoch   0 Batch 16494/17275   train_loss = 2.257\n",
      "Epoch   0 Batch 16495/17275   train_loss = 7.126\n",
      "Epoch   0 Batch 16496/17275   train_loss = 2.496\n",
      "Epoch   0 Batch 16497/17275   train_loss = 3.860\n",
      "Epoch   0 Batch 16498/17275   train_loss = 6.958\n",
      "Epoch   0 Batch 16499/17275   train_loss = 2.218\n",
      "Epoch   0 Batch 16500/17275   train_loss = 2.012\n",
      "Epoch   0 Batch 16501/17275   train_loss = 8.581\n",
      "Epoch   0 Batch 16502/17275   train_loss = 3.460\n",
      "Epoch   0 Batch 16503/17275   train_loss = 3.230\n",
      "Epoch   0 Batch 16504/17275   train_loss = 2.510\n",
      "Epoch   0 Batch 16505/17275   train_loss = 5.567\n",
      "Epoch   0 Batch 16506/17275   train_loss = 7.375\n",
      "Epoch   0 Batch 16507/17275   train_loss = 3.454\n",
      "Epoch   0 Batch 16508/17275   train_loss = 6.273\n",
      "Epoch   0 Batch 16509/17275   train_loss = 4.234\n",
      "Epoch   0 Batch 16510/17275   train_loss = 7.612\n",
      "Epoch   0 Batch 16511/17275   train_loss = 3.755\n",
      "Epoch   0 Batch 16512/17275   train_loss = 6.909\n",
      "Epoch   0 Batch 16513/17275   train_loss = 1.851\n",
      "Epoch   0 Batch 16514/17275   train_loss = 2.748\n",
      "Epoch   0 Batch 16515/17275   train_loss = 4.727\n",
      "Epoch   0 Batch 16516/17275   train_loss = 5.371\n",
      "Epoch   0 Batch 16517/17275   train_loss = 6.337\n",
      "Epoch   0 Batch 16518/17275   train_loss = 1.864\n",
      "Epoch   0 Batch 16519/17275   train_loss = 2.409\n",
      "Epoch   0 Batch 16520/17275   train_loss = 7.194\n",
      "Epoch   0 Batch 16521/17275   train_loss = 1.816\n",
      "Epoch   0 Batch 16522/17275   train_loss = 3.110\n",
      "Epoch   0 Batch 16523/17275   train_loss = 3.877\n",
      "Epoch   0 Batch 16524/17275   train_loss = 4.633\n",
      "Epoch   0 Batch 16525/17275   train_loss = 3.239\n",
      "Epoch   0 Batch 16526/17275   train_loss = 2.779\n",
      "Epoch   0 Batch 16527/17275   train_loss = 1.786\n",
      "Epoch   0 Batch 16528/17275   train_loss = 2.780\n",
      "Epoch   0 Batch 16529/17275   train_loss = 4.498\n",
      "Epoch   0 Batch 16530/17275   train_loss = 4.023\n",
      "Epoch   0 Batch 16531/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 16532/17275   train_loss = 3.146\n",
      "Epoch   0 Batch 16533/17275   train_loss = 4.062\n",
      "Epoch   0 Batch 16534/17275   train_loss = 4.335\n",
      "Epoch   0 Batch 16535/17275   train_loss = 4.920\n",
      "Epoch   0 Batch 16536/17275   train_loss = 3.016\n",
      "Epoch   0 Batch 16537/17275   train_loss = 3.177\n",
      "Epoch   0 Batch 16538/17275   train_loss = 2.468\n",
      "Epoch   0 Batch 16539/17275   train_loss = 3.908\n",
      "Epoch   0 Batch 16540/17275   train_loss = 6.240\n",
      "Epoch   0 Batch 16541/17275   train_loss = 2.469\n",
      "Epoch   0 Batch 16542/17275   train_loss = 8.535\n",
      "Epoch   0 Batch 16543/17275   train_loss = 3.360\n",
      "Epoch   0 Batch 16544/17275   train_loss = 8.220\n",
      "Epoch   0 Batch 16545/17275   train_loss = 4.420\n",
      "Epoch   0 Batch 16546/17275   train_loss = 6.947\n",
      "Epoch   0 Batch 16547/17275   train_loss = 3.428\n",
      "Epoch   0 Batch 16548/17275   train_loss = 2.200\n",
      "Epoch   0 Batch 16549/17275   train_loss = 7.138\n",
      "Epoch   0 Batch 16550/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 16551/17275   train_loss = 4.704\n",
      "Epoch   0 Batch 16552/17275   train_loss = 7.177\n",
      "Epoch   0 Batch 16553/17275   train_loss = 5.002\n",
      "Epoch   0 Batch 16554/17275   train_loss = 2.183\n",
      "Epoch   0 Batch 16555/17275   train_loss = 4.284\n",
      "Epoch   0 Batch 16556/17275   train_loss = 7.360\n",
      "Epoch   0 Batch 16557/17275   train_loss = 3.590\n",
      "Epoch   0 Batch 16558/17275   train_loss = 3.774\n",
      "Epoch   0 Batch 16559/17275   train_loss = 2.131\n",
      "Epoch   0 Batch 16560/17275   train_loss = 3.203\n",
      "Epoch   0 Batch 16561/17275   train_loss = 8.498\n",
      "Epoch   0 Batch 16562/17275   train_loss = 4.762\n",
      "Epoch   0 Batch 16563/17275   train_loss = 4.161\n",
      "Epoch   0 Batch 16564/17275   train_loss = 1.999\n",
      "Epoch   0 Batch 16565/17275   train_loss = 2.346\n",
      "Epoch   0 Batch 16566/17275   train_loss = 8.283\n",
      "Epoch   0 Batch 16567/17275   train_loss = 5.224\n",
      "Epoch   0 Batch 16568/17275   train_loss = 3.288\n",
      "Epoch   0 Batch 16569/17275   train_loss = 4.805\n",
      "Epoch   0 Batch 16570/17275   train_loss = 4.175\n",
      "Epoch   0 Batch 16571/17275   train_loss = 3.614\n",
      "Epoch   0 Batch 16572/17275   train_loss = 6.221\n",
      "Epoch   0 Batch 16573/17275   train_loss = 3.488\n",
      "Epoch   0 Batch 16574/17275   train_loss = 3.515\n",
      "Epoch   0 Batch 16575/17275   train_loss = 2.846\n",
      "Epoch   0 Batch 16576/17275   train_loss = 5.044\n",
      "Epoch   0 Batch 16577/17275   train_loss = 4.848\n",
      "Epoch   0 Batch 16578/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 16579/17275   train_loss = 11.470\n",
      "Epoch   0 Batch 16580/17275   train_loss = 2.062\n",
      "Epoch   0 Batch 16581/17275   train_loss = 7.309\n",
      "Epoch   0 Batch 16582/17275   train_loss = 3.924\n",
      "Epoch   0 Batch 16583/17275   train_loss = 4.944\n",
      "Epoch   0 Batch 16584/17275   train_loss = 7.847\n",
      "Epoch   0 Batch 16585/17275   train_loss = 2.100\n",
      "Epoch   0 Batch 16586/17275   train_loss = 2.062\n",
      "Epoch   0 Batch 16587/17275   train_loss = 6.610\n",
      "Epoch   0 Batch 16588/17275   train_loss = 3.490\n",
      "Epoch   0 Batch 16589/17275   train_loss = 2.012\n",
      "Epoch   0 Batch 16590/17275   train_loss = 3.220\n",
      "Epoch   0 Batch 16591/17275   train_loss = 3.841\n",
      "Epoch   0 Batch 16592/17275   train_loss = 9.742\n",
      "Epoch   0 Batch 16593/17275   train_loss = 3.461\n",
      "Epoch   0 Batch 16594/17275   train_loss = 8.358\n",
      "Epoch   0 Batch 16595/17275   train_loss = 1.942\n",
      "Epoch   0 Batch 16596/17275   train_loss = 6.454\n",
      "Epoch   0 Batch 16597/17275   train_loss = 3.291\n",
      "Epoch   0 Batch 16598/17275   train_loss = 4.209\n",
      "Epoch   0 Batch 16599/17275   train_loss = 5.759\n",
      "Epoch   0 Batch 16600/17275   train_loss = 5.619\n",
      "Epoch   0 Batch 16601/17275   train_loss = 3.009\n",
      "Epoch   0 Batch 16602/17275   train_loss = 3.371\n",
      "Epoch   0 Batch 16603/17275   train_loss = 3.731\n",
      "Epoch   0 Batch 16604/17275   train_loss = 6.095\n",
      "Epoch   0 Batch 16605/17275   train_loss = 2.192\n",
      "Epoch   0 Batch 16606/17275   train_loss = 5.222\n",
      "Epoch   0 Batch 16607/17275   train_loss = 3.727\n",
      "Epoch   0 Batch 16608/17275   train_loss = 6.351\n",
      "Epoch   0 Batch 16609/17275   train_loss = 5.091\n",
      "Epoch   0 Batch 16610/17275   train_loss = 3.873\n",
      "Epoch   0 Batch 16611/17275   train_loss = 2.917\n",
      "Epoch   0 Batch 16612/17275   train_loss = 3.325\n",
      "Epoch   0 Batch 16613/17275   train_loss = 3.668\n",
      "Epoch   0 Batch 16614/17275   train_loss = 3.768\n",
      "Epoch   0 Batch 16615/17275   train_loss = 3.909\n",
      "Epoch   0 Batch 16616/17275   train_loss = 3.390\n",
      "Epoch   0 Batch 16617/17275   train_loss = 2.906\n",
      "Epoch   0 Batch 16618/17275   train_loss = 4.683\n",
      "Epoch   0 Batch 16619/17275   train_loss = 4.516\n",
      "Epoch   0 Batch 16620/17275   train_loss = 3.990\n",
      "Epoch   0 Batch 16621/17275   train_loss = 3.257\n",
      "Epoch   0 Batch 16622/17275   train_loss = 4.056\n",
      "Epoch   0 Batch 16623/17275   train_loss = 3.024\n",
      "Epoch   0 Batch 16624/17275   train_loss = 2.937\n",
      "Epoch   0 Batch 16625/17275   train_loss = 8.978\n",
      "Epoch   0 Batch 16626/17275   train_loss = 4.767\n",
      "Epoch   0 Batch 16627/17275   train_loss = 3.959\n",
      "Epoch   0 Batch 16628/17275   train_loss = 4.750\n",
      "Epoch   0 Batch 16629/17275   train_loss = 4.278\n",
      "Epoch   0 Batch 16630/17275   train_loss = 3.906\n",
      "Epoch   0 Batch 16631/17275   train_loss = 2.424\n",
      "Epoch   0 Batch 16632/17275   train_loss = 3.055\n",
      "Epoch   0 Batch 16633/17275   train_loss = 3.991\n",
      "Epoch   0 Batch 16634/17275   train_loss = 6.655\n",
      "Epoch   0 Batch 16635/17275   train_loss = 1.850\n",
      "Epoch   0 Batch 16636/17275   train_loss = 2.454\n",
      "Epoch   0 Batch 16637/17275   train_loss = 7.003\n",
      "Epoch   0 Batch 16638/17275   train_loss = 3.170\n",
      "Epoch   0 Batch 16639/17275   train_loss = 1.903\n",
      "Epoch   0 Batch 16640/17275   train_loss = 2.800\n",
      "Epoch   0 Batch 16641/17275   train_loss = 3.547\n",
      "Epoch   0 Batch 16642/17275   train_loss = 6.621\n",
      "Epoch   0 Batch 16643/17275   train_loss = 1.748\n",
      "Epoch   0 Batch 16644/17275   train_loss = 2.398\n",
      "Epoch   0 Batch 16645/17275   train_loss = 6.455\n",
      "Epoch   0 Batch 16646/17275   train_loss = 2.938\n",
      "Epoch   0 Batch 16647/17275   train_loss = 1.813\n",
      "Epoch   0 Batch 16648/17275   train_loss = 2.496\n",
      "Epoch   0 Batch 16649/17275   train_loss = 3.028\n",
      "Epoch   0 Batch 16650/17275   train_loss = 6.575\n",
      "Epoch   0 Batch 16651/17275   train_loss = 1.611\n",
      "Epoch   0 Batch 16652/17275   train_loss = 2.337\n",
      "Epoch   0 Batch 16653/17275   train_loss = 5.906\n",
      "Epoch   0 Batch 16654/17275   train_loss = 3.473\n",
      "Epoch   0 Batch 16655/17275   train_loss = 1.741\n",
      "Epoch   0 Batch 16656/17275   train_loss = 4.557\n",
      "Epoch   0 Batch 16657/17275   train_loss = 3.878\n",
      "Epoch   0 Batch 16658/17275   train_loss = 4.072\n",
      "Epoch   0 Batch 16659/17275   train_loss = 2.276\n",
      "Epoch   0 Batch 16660/17275   train_loss = 4.220\n",
      "Epoch   0 Batch 16661/17275   train_loss = 3.085\n",
      "Epoch   0 Batch 16662/17275   train_loss = 1.545\n",
      "Epoch   0 Batch 16663/17275   train_loss = 2.750\n",
      "Epoch   0 Batch 16664/17275   train_loss = 4.604\n",
      "Epoch   0 Batch 16665/17275   train_loss = 3.772\n",
      "Epoch   0 Batch 16666/17275   train_loss = 2.361\n",
      "Epoch   0 Batch 16667/17275   train_loss = 3.155\n",
      "Epoch   0 Batch 16668/17275   train_loss = 3.223\n",
      "Epoch   0 Batch 16669/17275   train_loss = 3.709\n",
      "Epoch   0 Batch 16670/17275   train_loss = 7.645\n",
      "Epoch   0 Batch 16671/17275   train_loss = 7.587\n",
      "Epoch   0 Batch 16672/17275   train_loss = 4.231\n",
      "Epoch   0 Batch 16673/17275   train_loss = 2.265\n",
      "Epoch   0 Batch 16674/17275   train_loss = 3.208\n",
      "Epoch   0 Batch 16675/17275   train_loss = 2.873\n",
      "Epoch   0 Batch 16676/17275   train_loss = 7.842\n",
      "Epoch   0 Batch 16677/17275   train_loss = 7.479\n",
      "Epoch   0 Batch 16678/17275   train_loss = 7.617\n",
      "Epoch   0 Batch 16679/17275   train_loss = 2.264\n",
      "Epoch   0 Batch 16680/17275   train_loss = 5.535\n",
      "Epoch   0 Batch 16681/17275   train_loss = 3.330\n",
      "Epoch   0 Batch 16682/17275   train_loss = 1.791\n",
      "Epoch   0 Batch 16683/17275   train_loss = 3.550\n",
      "Epoch   0 Batch 16684/17275   train_loss = 2.125\n",
      "Epoch   0 Batch 16685/17275   train_loss = 2.232\n",
      "Epoch   0 Batch 16686/17275   train_loss = 5.561\n",
      "Epoch   0 Batch 16687/17275   train_loss = 3.379\n",
      "Epoch   0 Batch 16688/17275   train_loss = 3.526\n",
      "Epoch   0 Batch 16689/17275   train_loss = 4.633\n",
      "Epoch   0 Batch 16690/17275   train_loss = 3.460\n",
      "Epoch   0 Batch 16691/17275   train_loss = 2.389\n",
      "Epoch   0 Batch 16692/17275   train_loss = 3.889\n",
      "Epoch   0 Batch 16693/17275   train_loss = 3.905\n",
      "Epoch   0 Batch 16694/17275   train_loss = 3.031\n",
      "Epoch   0 Batch 16695/17275   train_loss = 2.152\n",
      "Epoch   0 Batch 16696/17275   train_loss = 4.207\n",
      "Epoch   0 Batch 16697/17275   train_loss = 3.256\n",
      "Epoch   0 Batch 16698/17275   train_loss = 3.394\n",
      "Epoch   0 Batch 16699/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 16700/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 16701/17275   train_loss = 7.491\n",
      "Epoch   0 Batch 16702/17275   train_loss = 6.743\n",
      "Epoch   0 Batch 16703/17275   train_loss = 2.115\n",
      "Epoch   0 Batch 16704/17275   train_loss = 2.929\n",
      "Epoch   0 Batch 16705/17275   train_loss = 3.997\n",
      "Epoch   0 Batch 16706/17275   train_loss = 3.943\n",
      "Epoch   0 Batch 16707/17275   train_loss = 2.564\n",
      "Epoch   0 Batch 16708/17275   train_loss = 3.327\n",
      "Epoch   0 Batch 16709/17275   train_loss = 3.613\n",
      "Epoch   0 Batch 16710/17275   train_loss = 3.394\n",
      "Epoch   0 Batch 16711/17275   train_loss = 2.943\n",
      "Epoch   0 Batch 16712/17275   train_loss = 2.225\n",
      "Epoch   0 Batch 16713/17275   train_loss = 6.680\n",
      "Epoch   0 Batch 16714/17275   train_loss = 7.275\n",
      "Epoch   0 Batch 16715/17275   train_loss = 2.781\n",
      "Epoch   0 Batch 16716/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 16717/17275   train_loss = 3.942\n",
      "Epoch   0 Batch 16718/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 16719/17275   train_loss = 3.490\n",
      "Epoch   0 Batch 16720/17275   train_loss = 2.262\n",
      "Epoch   0 Batch 16721/17275   train_loss = 3.148\n",
      "Epoch   0 Batch 16722/17275   train_loss = 3.534\n",
      "Epoch   0 Batch 16723/17275   train_loss = 2.371\n",
      "Epoch   0 Batch 16724/17275   train_loss = 4.933\n",
      "Epoch   0 Batch 16725/17275   train_loss = 2.835\n",
      "Epoch   0 Batch 16726/17275   train_loss = 4.149\n",
      "Epoch   0 Batch 16727/17275   train_loss = 4.660\n",
      "Epoch   0 Batch 16728/17275   train_loss = 3.096\n",
      "Epoch   0 Batch 16729/17275   train_loss = 5.142\n",
      "Epoch   0 Batch 16730/17275   train_loss = 5.279\n",
      "Epoch   0 Batch 16731/17275   train_loss = 2.044\n",
      "Epoch   0 Batch 16732/17275   train_loss = 3.116\n",
      "Epoch   0 Batch 16733/17275   train_loss = 3.549\n",
      "Epoch   0 Batch 16734/17275   train_loss = 5.669\n",
      "Epoch   0 Batch 16735/17275   train_loss = 4.596\n",
      "Epoch   0 Batch 16736/17275   train_loss = 4.108\n",
      "Epoch   0 Batch 16737/17275   train_loss = 7.243\n",
      "Epoch   0 Batch 16738/17275   train_loss = 4.130\n",
      "Epoch   0 Batch 16739/17275   train_loss = 3.283\n",
      "Epoch   0 Batch 16740/17275   train_loss = 2.329\n",
      "Epoch   0 Batch 16741/17275   train_loss = 3.706\n",
      "Epoch   0 Batch 16742/17275   train_loss = 4.562\n",
      "Epoch   0 Batch 16743/17275   train_loss = 2.719\n",
      "Epoch   0 Batch 16744/17275   train_loss = 2.267\n",
      "Epoch   0 Batch 16745/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 16746/17275   train_loss = 4.146\n",
      "Epoch   0 Batch 16747/17275   train_loss = 5.102\n",
      "Epoch   0 Batch 16748/17275   train_loss = 4.846\n",
      "Epoch   0 Batch 16749/17275   train_loss = 8.060\n",
      "Epoch   0 Batch 16750/17275   train_loss = 2.277\n",
      "Epoch   0 Batch 16751/17275   train_loss = 2.214\n",
      "Epoch   0 Batch 16752/17275   train_loss = 2.974\n",
      "Epoch   0 Batch 16753/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 16754/17275   train_loss = 2.374\n",
      "Epoch   0 Batch 16755/17275   train_loss = 3.196\n",
      "Epoch   0 Batch 16756/17275   train_loss = 3.670\n",
      "Epoch   0 Batch 16757/17275   train_loss = 4.255\n",
      "Epoch   0 Batch 16758/17275   train_loss = 3.512\n",
      "Epoch   0 Batch 16759/17275   train_loss = 5.941\n",
      "Epoch   0 Batch 16760/17275   train_loss = 3.463\n",
      "Epoch   0 Batch 16761/17275   train_loss = 3.886\n",
      "Epoch   0 Batch 16762/17275   train_loss = 2.772\n",
      "Epoch   0 Batch 16763/17275   train_loss = 4.528\n",
      "Epoch   0 Batch 16764/17275   train_loss = 4.221\n",
      "Epoch   0 Batch 16765/17275   train_loss = 4.737\n",
      "Epoch   0 Batch 16766/17275   train_loss = 4.216\n",
      "Epoch   0 Batch 16767/17275   train_loss = 3.978\n",
      "Epoch   0 Batch 16768/17275   train_loss = 2.799\n",
      "Epoch   0 Batch 16769/17275   train_loss = 4.443\n",
      "Epoch   0 Batch 16770/17275   train_loss = 6.801\n",
      "Epoch   0 Batch 16771/17275   train_loss = 3.214\n",
      "Epoch   0 Batch 16772/17275   train_loss = 1.884\n",
      "Epoch   0 Batch 16773/17275   train_loss = 2.878\n",
      "Epoch   0 Batch 16774/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 16775/17275   train_loss = 2.632\n",
      "Epoch   0 Batch 16776/17275   train_loss = 2.390\n",
      "Epoch   0 Batch 16777/17275   train_loss = 4.273\n",
      "Epoch   0 Batch 16778/17275   train_loss = 4.456\n",
      "Epoch   0 Batch 16779/17275   train_loss = 8.051\n",
      "Epoch   0 Batch 16780/17275   train_loss = 3.109\n",
      "Epoch   0 Batch 16781/17275   train_loss = 2.211\n",
      "Epoch   0 Batch 16782/17275   train_loss = 3.059\n",
      "Epoch   0 Batch 16783/17275   train_loss = 7.312\n",
      "Epoch   0 Batch 16784/17275   train_loss = 7.313\n",
      "Epoch   0 Batch 16785/17275   train_loss = 2.844\n",
      "Epoch   0 Batch 16786/17275   train_loss = 2.806\n",
      "Epoch   0 Batch 16787/17275   train_loss = 3.408\n",
      "Epoch   0 Batch 16788/17275   train_loss = 3.955\n",
      "Epoch   0 Batch 16789/17275   train_loss = 3.667\n",
      "Epoch   0 Batch 16790/17275   train_loss = 4.170\n",
      "Epoch   0 Batch 16791/17275   train_loss = 4.689\n",
      "Epoch   0 Batch 16792/17275   train_loss = 4.146\n",
      "Epoch   0 Batch 16793/17275   train_loss = 4.054\n",
      "Epoch   0 Batch 16794/17275   train_loss = 4.487\n",
      "Epoch   0 Batch 16795/17275   train_loss = 3.580\n",
      "Epoch   0 Batch 16796/17275   train_loss = 7.544\n",
      "Epoch   0 Batch 16797/17275   train_loss = 2.640\n",
      "Epoch   0 Batch 16798/17275   train_loss = 9.667\n",
      "Epoch   0 Batch 16799/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 16800/17275   train_loss = 4.037\n",
      "Epoch   0 Batch 16801/17275   train_loss = 11.514\n",
      "Epoch   0 Batch 16802/17275   train_loss = 7.330\n",
      "Epoch   0 Batch 16803/17275   train_loss = 3.638\n",
      "Epoch   0 Batch 16804/17275   train_loss = 2.726\n",
      "Epoch   0 Batch 16805/17275   train_loss = 3.790\n",
      "Epoch   0 Batch 16806/17275   train_loss = 8.225\n",
      "Epoch   0 Batch 16807/17275   train_loss = 7.324\n",
      "Epoch   0 Batch 16808/17275   train_loss = 7.935\n",
      "Epoch   0 Batch 16809/17275   train_loss = 3.232\n",
      "Epoch   0 Batch 16810/17275   train_loss = 2.727\n",
      "Epoch   0 Batch 16811/17275   train_loss = 4.140\n",
      "Epoch   0 Batch 16812/17275   train_loss = 7.103\n",
      "Epoch   0 Batch 16813/17275   train_loss = 7.222\n",
      "Epoch   0 Batch 16814/17275   train_loss = 2.474\n",
      "Epoch   0 Batch 16815/17275   train_loss = 2.988\n",
      "Epoch   0 Batch 16816/17275   train_loss = 3.795\n",
      "Epoch   0 Batch 16817/17275   train_loss = 6.817\n",
      "Epoch   0 Batch 16818/17275   train_loss = 6.815\n",
      "Epoch   0 Batch 16819/17275   train_loss = 6.805\n",
      "Epoch   0 Batch 16820/17275   train_loss = 4.249\n",
      "Epoch   0 Batch 16821/17275   train_loss = 5.190\n",
      "Epoch   0 Batch 16822/17275   train_loss = 2.166\n",
      "Epoch   0 Batch 16823/17275   train_loss = 2.082\n",
      "Epoch   0 Batch 16824/17275   train_loss = 6.509\n",
      "Epoch   0 Batch 16825/17275   train_loss = 2.224\n",
      "Epoch   0 Batch 16826/17275   train_loss = 3.664\n",
      "Epoch   0 Batch 16827/17275   train_loss = 8.722\n",
      "Epoch   0 Batch 16828/17275   train_loss = 4.121\n",
      "Epoch   0 Batch 16829/17275   train_loss = 7.652\n",
      "Epoch   0 Batch 16830/17275   train_loss = 6.788\n",
      "Epoch   0 Batch 16831/17275   train_loss = 2.873\n",
      "Epoch   0 Batch 16832/17275   train_loss = 3.121\n",
      "Epoch   0 Batch 16833/17275   train_loss = 4.188\n",
      "Epoch   0 Batch 16834/17275   train_loss = 7.435\n",
      "Epoch   0 Batch 16835/17275   train_loss = 3.346\n",
      "Epoch   0 Batch 16836/17275   train_loss = 5.579\n",
      "Epoch   0 Batch 16837/17275   train_loss = 2.446\n",
      "Epoch   0 Batch 16838/17275   train_loss = 7.836\n",
      "Epoch   0 Batch 16839/17275   train_loss = 1.999\n",
      "Epoch   0 Batch 16840/17275   train_loss = 3.361\n",
      "Epoch   0 Batch 16841/17275   train_loss = 3.520\n",
      "Epoch   0 Batch 16842/17275   train_loss = 3.430\n",
      "Epoch   0 Batch 16843/17275   train_loss = 3.200\n",
      "Epoch   0 Batch 16844/17275   train_loss = 3.312\n",
      "Epoch   0 Batch 16845/17275   train_loss = 3.575\n",
      "Epoch   0 Batch 16846/17275   train_loss = 3.339\n",
      "Epoch   0 Batch 16847/17275   train_loss = 3.073\n",
      "Epoch   0 Batch 16848/17275   train_loss = 3.892\n",
      "Epoch   0 Batch 16849/17275   train_loss = 4.130\n",
      "Epoch   0 Batch 16850/17275   train_loss = 2.709\n",
      "Epoch   0 Batch 16851/17275   train_loss = 3.741\n",
      "Epoch   0 Batch 16852/17275   train_loss = 4.390\n",
      "Epoch   0 Batch 16853/17275   train_loss = 6.743\n",
      "Epoch   0 Batch 16854/17275   train_loss = 5.065\n",
      "Epoch   0 Batch 16855/17275   train_loss = 4.564\n",
      "Epoch   0 Batch 16856/17275   train_loss = 2.826\n",
      "Epoch   0 Batch 16857/17275   train_loss = 3.235\n",
      "Epoch   0 Batch 16858/17275   train_loss = 2.709\n",
      "Epoch   0 Batch 16859/17275   train_loss = 3.922\n",
      "Epoch   0 Batch 16860/17275   train_loss = 3.074\n",
      "Epoch   0 Batch 16861/17275   train_loss = 7.217\n",
      "Epoch   0 Batch 16862/17275   train_loss = 2.690\n",
      "Epoch   0 Batch 16863/17275   train_loss = 2.432\n",
      "Epoch   0 Batch 16864/17275   train_loss = 7.046\n",
      "Epoch   0 Batch 16865/17275   train_loss = 4.017\n",
      "Epoch   0 Batch 16866/17275   train_loss = 3.962\n",
      "Epoch   0 Batch 16867/17275   train_loss = 3.330\n",
      "Epoch   0 Batch 16868/17275   train_loss = 2.083\n",
      "Epoch   0 Batch 16869/17275   train_loss = 2.648\n",
      "Epoch   0 Batch 16870/17275   train_loss = 3.956\n",
      "Epoch   0 Batch 16871/17275   train_loss = 6.132\n",
      "Epoch   0 Batch 16872/17275   train_loss = 11.515\n",
      "Epoch   0 Batch 16873/17275   train_loss = 7.146\n",
      "Epoch   0 Batch 16874/17275   train_loss = 1.955\n",
      "Epoch   0 Batch 16875/17275   train_loss = 3.580\n",
      "Epoch   0 Batch 16876/17275   train_loss = 5.571\n",
      "Epoch   0 Batch 16877/17275   train_loss = 2.396\n",
      "Epoch   0 Batch 16878/17275   train_loss = 4.935\n",
      "Epoch   0 Batch 16879/17275   train_loss = 2.479\n",
      "Epoch   0 Batch 16880/17275   train_loss = 3.671\n",
      "Epoch   0 Batch 16881/17275   train_loss = 5.671\n",
      "Epoch   0 Batch 16882/17275   train_loss = 6.742\n",
      "Epoch   0 Batch 16883/17275   train_loss = 4.591\n",
      "Epoch   0 Batch 16884/17275   train_loss = 3.710\n",
      "Epoch   0 Batch 16885/17275   train_loss = 3.184\n",
      "Epoch   0 Batch 16886/17275   train_loss = 6.738\n",
      "Epoch   0 Batch 16887/17275   train_loss = 2.361\n",
      "Epoch   0 Batch 16888/17275   train_loss = 2.935\n",
      "Epoch   0 Batch 16889/17275   train_loss = 5.223\n",
      "Epoch   0 Batch 16890/17275   train_loss = 2.521\n",
      "Epoch   0 Batch 16891/17275   train_loss = 11.523\n",
      "Epoch   0 Batch 16892/17275   train_loss = 3.197\n",
      "Epoch   0 Batch 16893/17275   train_loss = 3.673\n",
      "Epoch   0 Batch 16894/17275   train_loss = 2.268\n",
      "Epoch   0 Batch 16895/17275   train_loss = 2.706\n",
      "Epoch   0 Batch 16896/17275   train_loss = 2.671\n",
      "Epoch   0 Batch 16897/17275   train_loss = 3.833\n",
      "Epoch   0 Batch 16898/17275   train_loss = 2.788\n",
      "Epoch   0 Batch 16899/17275   train_loss = 4.507\n",
      "Epoch   0 Batch 16900/17275   train_loss = 3.822\n",
      "Epoch   0 Batch 16901/17275   train_loss = 2.891\n",
      "Epoch   0 Batch 16902/17275   train_loss = 4.371\n",
      "Epoch   0 Batch 16903/17275   train_loss = 3.758\n",
      "Epoch   0 Batch 16904/17275   train_loss = 3.296\n",
      "Epoch   0 Batch 16905/17275   train_loss = 3.805\n",
      "Epoch   0 Batch 16906/17275   train_loss = 1.920\n",
      "Epoch   0 Batch 16907/17275   train_loss = 1.978\n",
      "Epoch   0 Batch 16908/17275   train_loss = 2.659\n",
      "Epoch   0 Batch 16909/17275   train_loss = 3.984\n",
      "Epoch   0 Batch 16910/17275   train_loss = 4.113\n",
      "Epoch   0 Batch 16911/17275   train_loss = 1.837\n",
      "Epoch   0 Batch 16912/17275   train_loss = 4.347\n",
      "Epoch   0 Batch 16913/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 16914/17275   train_loss = 3.857\n",
      "Epoch   0 Batch 16915/17275   train_loss = 3.473\n",
      "Epoch   0 Batch 16916/17275   train_loss = 2.143\n",
      "Epoch   0 Batch 16917/17275   train_loss = 6.640\n",
      "Epoch   0 Batch 16918/17275   train_loss = 4.797\n",
      "Epoch   0 Batch 16919/17275   train_loss = 3.909\n",
      "Epoch   0 Batch 16920/17275   train_loss = 10.098\n",
      "Epoch   0 Batch 16921/17275   train_loss = 2.486\n",
      "Epoch   0 Batch 16922/17275   train_loss = 2.829\n",
      "Epoch   0 Batch 16923/17275   train_loss = 3.616\n",
      "Epoch   0 Batch 16924/17275   train_loss = 2.192\n",
      "Epoch   0 Batch 16925/17275   train_loss = 7.688\n",
      "Epoch   0 Batch 16926/17275   train_loss = 3.786\n",
      "Epoch   0 Batch 16927/17275   train_loss = 3.714\n",
      "Epoch   0 Batch 16928/17275   train_loss = 3.671\n",
      "Epoch   0 Batch 16929/17275   train_loss = 2.824\n",
      "Epoch   0 Batch 16930/17275   train_loss = 3.321\n",
      "Epoch   0 Batch 16931/17275   train_loss = 3.540\n",
      "Epoch   0 Batch 16932/17275   train_loss = 2.654\n",
      "Epoch   0 Batch 16933/17275   train_loss = 3.946\n",
      "Epoch   0 Batch 16934/17275   train_loss = 2.332\n",
      "Epoch   0 Batch 16935/17275   train_loss = 3.263\n",
      "Epoch   0 Batch 16936/17275   train_loss = 2.303\n",
      "Epoch   0 Batch 16937/17275   train_loss = 4.801\n",
      "Epoch   0 Batch 16938/17275   train_loss = 2.956\n",
      "Epoch   0 Batch 16939/17275   train_loss = 3.239\n",
      "Epoch   0 Batch 16940/17275   train_loss = 3.742\n",
      "Epoch   0 Batch 16941/17275   train_loss = 5.143\n",
      "Epoch   0 Batch 16942/17275   train_loss = 7.509\n",
      "Epoch   0 Batch 16943/17275   train_loss = 4.609\n",
      "Epoch   0 Batch 16944/17275   train_loss = 7.445\n",
      "Epoch   0 Batch 16945/17275   train_loss = 6.838\n",
      "Epoch   0 Batch 16946/17275   train_loss = 2.745\n",
      "Epoch   0 Batch 16947/17275   train_loss = 2.249\n",
      "Epoch   0 Batch 16948/17275   train_loss = 3.298\n",
      "Epoch   0 Batch 16949/17275   train_loss = 2.831\n",
      "Epoch   0 Batch 16950/17275   train_loss = 6.699\n",
      "Epoch   0 Batch 16951/17275   train_loss = 4.258\n",
      "Epoch   0 Batch 16952/17275   train_loss = 3.856\n",
      "Epoch   0 Batch 16953/17275   train_loss = 6.701\n",
      "Epoch   0 Batch 16954/17275   train_loss = 2.315\n",
      "Epoch   0 Batch 16955/17275   train_loss = 2.487\n",
      "Epoch   0 Batch 16956/17275   train_loss = 3.922\n",
      "Epoch   0 Batch 16957/17275   train_loss = 2.810\n",
      "Epoch   0 Batch 16958/17275   train_loss = 4.081\n",
      "Epoch   0 Batch 16959/17275   train_loss = 3.492\n",
      "Epoch   0 Batch 16960/17275   train_loss = 2.517\n",
      "Epoch   0 Batch 16961/17275   train_loss = 4.520\n",
      "Epoch   0 Batch 16962/17275   train_loss = 3.248\n",
      "Epoch   0 Batch 16963/17275   train_loss = 6.679\n",
      "Epoch   0 Batch 16964/17275   train_loss = 2.305\n",
      "Epoch   0 Batch 16965/17275   train_loss = 3.078\n",
      "Epoch   0 Batch 16966/17275   train_loss = 3.536\n",
      "Epoch   0 Batch 16967/17275   train_loss = 3.555\n",
      "Epoch   0 Batch 16968/17275   train_loss = 5.081\n",
      "Epoch   0 Batch 16969/17275   train_loss = 2.440\n",
      "Epoch   0 Batch 16970/17275   train_loss = 4.025\n",
      "Epoch   0 Batch 16971/17275   train_loss = 3.391\n",
      "Epoch   0 Batch 16972/17275   train_loss = 2.893\n",
      "Epoch   0 Batch 16973/17275   train_loss = 3.733\n",
      "Epoch   0 Batch 16974/17275   train_loss = 3.591\n",
      "Epoch   0 Batch 16975/17275   train_loss = 3.584\n",
      "Epoch   0 Batch 16976/17275   train_loss = 7.993\n",
      "Epoch   0 Batch 16977/17275   train_loss = 5.684\n",
      "Epoch   0 Batch 16978/17275   train_loss = 4.970\n",
      "Epoch   0 Batch 16979/17275   train_loss = 3.226\n",
      "Epoch   0 Batch 16980/17275   train_loss = 3.158\n",
      "Epoch   0 Batch 16981/17275   train_loss = 5.481\n",
      "Epoch   0 Batch 16982/17275   train_loss = 7.250\n",
      "Epoch   0 Batch 16983/17275   train_loss = 1.983\n",
      "Epoch   0 Batch 16984/17275   train_loss = 3.353\n",
      "Epoch   0 Batch 16985/17275   train_loss = 4.211\n",
      "Epoch   0 Batch 16986/17275   train_loss = 3.524\n",
      "Epoch   0 Batch 16987/17275   train_loss = 4.153\n",
      "Epoch   0 Batch 16988/17275   train_loss = 2.651\n",
      "Epoch   0 Batch 16989/17275   train_loss = 3.736\n",
      "Epoch   0 Batch 16990/17275   train_loss = 3.818\n",
      "Epoch   0 Batch 16991/17275   train_loss = 4.904\n",
      "Epoch   0 Batch 16992/17275   train_loss = 5.336\n",
      "Epoch   0 Batch 16993/17275   train_loss = 11.542\n",
      "Epoch   0 Batch 16994/17275   train_loss = 2.312\n",
      "Epoch   0 Batch 16995/17275   train_loss = 7.350\n",
      "Epoch   0 Batch 16996/17275   train_loss = 6.984\n",
      "Epoch   0 Batch 16997/17275   train_loss = 6.710\n",
      "Epoch   0 Batch 16998/17275   train_loss = 2.327\n",
      "Epoch   0 Batch 16999/17275   train_loss = 4.095\n",
      "Epoch   0 Batch 17000/17275   train_loss = 3.356\n",
      "Epoch   0 Batch 17001/17275   train_loss = 3.479\n",
      "Epoch   0 Batch 17002/17275   train_loss = 6.753\n",
      "Epoch   0 Batch 17003/17275   train_loss = 6.768\n",
      "Epoch   0 Batch 17004/17275   train_loss = 4.735\n",
      "Epoch   0 Batch 17005/17275   train_loss = 2.946\n",
      "Epoch   0 Batch 17006/17275   train_loss = 6.729\n",
      "Epoch   0 Batch 17007/17275   train_loss = 3.913\n",
      "Epoch   0 Batch 17008/17275   train_loss = 3.814\n",
      "Epoch   0 Batch 17009/17275   train_loss = 5.047\n",
      "Epoch   0 Batch 17010/17275   train_loss = 2.934\n",
      "Epoch   0 Batch 17011/17275   train_loss = 2.516\n",
      "Epoch   0 Batch 17012/17275   train_loss = 4.183\n",
      "Epoch   0 Batch 17013/17275   train_loss = 6.355\n",
      "Epoch   0 Batch 17014/17275   train_loss = 2.515\n",
      "Epoch   0 Batch 17015/17275   train_loss = 5.723\n",
      "Epoch   0 Batch 17016/17275   train_loss = 2.347\n",
      "Epoch   0 Batch 17017/17275   train_loss = 3.657\n",
      "Epoch   0 Batch 17018/17275   train_loss = 3.207\n",
      "Epoch   0 Batch 17019/17275   train_loss = 7.226\n",
      "Epoch   0 Batch 17020/17275   train_loss = 2.112\n",
      "Epoch   0 Batch 17021/17275   train_loss = 3.573\n",
      "Epoch   0 Batch 17022/17275   train_loss = 3.072\n",
      "Epoch   0 Batch 17023/17275   train_loss = 2.965\n",
      "Epoch   0 Batch 17024/17275   train_loss = 4.816\n",
      "Epoch   0 Batch 17025/17275   train_loss = 6.996\n",
      "Epoch   0 Batch 17026/17275   train_loss = 3.073\n",
      "Epoch   0 Batch 17027/17275   train_loss = 3.161\n",
      "Epoch   0 Batch 17028/17275   train_loss = 2.927\n",
      "Epoch   0 Batch 17029/17275   train_loss = 3.168\n",
      "Epoch   0 Batch 17030/17275   train_loss = 2.981\n",
      "Epoch   0 Batch 17031/17275   train_loss = 2.593\n",
      "Epoch   0 Batch 17032/17275   train_loss = 3.649\n",
      "Epoch   0 Batch 17033/17275   train_loss = 2.399\n",
      "Epoch   0 Batch 17034/17275   train_loss = 5.475\n",
      "Epoch   0 Batch 17035/17275   train_loss = 3.006\n",
      "Epoch   0 Batch 17036/17275   train_loss = 9.598\n",
      "Epoch   0 Batch 17037/17275   train_loss = 11.554\n",
      "Epoch   0 Batch 17038/17275   train_loss = 11.554\n",
      "Epoch   0 Batch 17039/17275   train_loss = 8.408\n",
      "Epoch   0 Batch 17040/17275   train_loss = 3.682\n",
      "Epoch   0 Batch 17041/17275   train_loss = 3.626\n",
      "Epoch   0 Batch 17042/17275   train_loss = 7.860\n",
      "Epoch   0 Batch 17043/17275   train_loss = 4.312\n",
      "Epoch   0 Batch 17044/17275   train_loss = 2.534\n",
      "Epoch   0 Batch 17045/17275   train_loss = 3.554\n",
      "Epoch   0 Batch 17046/17275   train_loss = 3.740\n",
      "Epoch   0 Batch 17047/17275   train_loss = 5.113\n",
      "Epoch   0 Batch 17048/17275   train_loss = 3.831\n",
      "Epoch   0 Batch 17049/17275   train_loss = 2.193\n",
      "Epoch   0 Batch 17050/17275   train_loss = 2.505\n",
      "Epoch   0 Batch 17051/17275   train_loss = 6.508\n",
      "Epoch   0 Batch 17052/17275   train_loss = 2.740\n",
      "Epoch   0 Batch 17053/17275   train_loss = 8.853\n",
      "Epoch   0 Batch 17054/17275   train_loss = 2.993\n",
      "Epoch   0 Batch 17055/17275   train_loss = 4.107\n",
      "Epoch   0 Batch 17056/17275   train_loss = 3.245\n",
      "Epoch   0 Batch 17057/17275   train_loss = 4.369\n",
      "Epoch   0 Batch 17058/17275   train_loss = 1.968\n",
      "Epoch   0 Batch 17059/17275   train_loss = 4.487\n",
      "Epoch   0 Batch 17060/17275   train_loss = 4.556\n",
      "Epoch   0 Batch 17061/17275   train_loss = 7.860\n",
      "Epoch   0 Batch 17062/17275   train_loss = 6.892\n",
      "Epoch   0 Batch 17063/17275   train_loss = 4.790\n",
      "Epoch   0 Batch 17064/17275   train_loss = 6.827\n",
      "Epoch   0 Batch 17065/17275   train_loss = 3.103\n",
      "Epoch   0 Batch 17066/17275   train_loss = 7.244\n",
      "Epoch   0 Batch 17067/17275   train_loss = 7.001\n",
      "Epoch   0 Batch 17068/17275   train_loss = 7.301\n",
      "Epoch   0 Batch 17069/17275   train_loss = 3.667\n",
      "Epoch   0 Batch 17070/17275   train_loss = 7.842\n",
      "Epoch   0 Batch 17071/17275   train_loss = 4.708\n",
      "Epoch   0 Batch 17072/17275   train_loss = 4.703\n",
      "Epoch   0 Batch 17073/17275   train_loss = 1.985\n",
      "Epoch   0 Batch 17074/17275   train_loss = 2.850\n",
      "Epoch   0 Batch 17075/17275   train_loss = 3.760\n",
      "Epoch   0 Batch 17076/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 17077/17275   train_loss = 8.048\n",
      "Epoch   0 Batch 17078/17275   train_loss = 3.464\n",
      "Epoch   0 Batch 17079/17275   train_loss = 4.237\n",
      "Epoch   0 Batch 17080/17275   train_loss = 5.826\n",
      "Epoch   0 Batch 17081/17275   train_loss = 3.334\n",
      "Epoch   0 Batch 17082/17275   train_loss = 2.335\n",
      "Epoch   0 Batch 17083/17275   train_loss = 7.091\n",
      "Epoch   0 Batch 17084/17275   train_loss = 3.689\n",
      "Epoch   0 Batch 17085/17275   train_loss = 7.774\n",
      "Epoch   0 Batch 17086/17275   train_loss = 3.450\n",
      "Epoch   0 Batch 17087/17275   train_loss = 7.018\n",
      "Epoch   0 Batch 17088/17275   train_loss = 2.270\n",
      "Epoch   0 Batch 17089/17275   train_loss = 3.313\n",
      "Epoch   0 Batch 17090/17275   train_loss = 4.577\n",
      "Epoch   0 Batch 17091/17275   train_loss = 3.795\n",
      "Epoch   0 Batch 17092/17275   train_loss = 2.204\n",
      "Epoch   0 Batch 17093/17275   train_loss = 3.934\n",
      "Epoch   0 Batch 17094/17275   train_loss = 4.534\n",
      "Epoch   0 Batch 17095/17275   train_loss = 7.256\n",
      "Epoch   0 Batch 17096/17275   train_loss = 3.208\n",
      "Epoch   0 Batch 17097/17275   train_loss = 4.172\n",
      "Epoch   0 Batch 17098/17275   train_loss = 4.490\n",
      "Epoch   0 Batch 17099/17275   train_loss = 4.081\n",
      "Epoch   0 Batch 17100/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 17101/17275   train_loss = 4.537\n",
      "Epoch   0 Batch 17102/17275   train_loss = 4.356\n",
      "Epoch   0 Batch 17103/17275   train_loss = 2.129\n",
      "Epoch   0 Batch 17104/17275   train_loss = 3.453\n",
      "Epoch   0 Batch 17105/17275   train_loss = 4.213\n",
      "Epoch   0 Batch 17106/17275   train_loss = 6.857\n",
      "Epoch   0 Batch 17107/17275   train_loss = 2.774\n",
      "Epoch   0 Batch 17108/17275   train_loss = 3.758\n",
      "Epoch   0 Batch 17109/17275   train_loss = 4.397\n",
      "Epoch   0 Batch 17110/17275   train_loss = 3.221\n",
      "Epoch   0 Batch 17111/17275   train_loss = 2.092\n",
      "Epoch   0 Batch 17112/17275   train_loss = 2.524\n",
      "Epoch   0 Batch 17113/17275   train_loss = 6.222\n",
      "Epoch   0 Batch 17114/17275   train_loss = 3.223\n",
      "Epoch   0 Batch 17115/17275   train_loss = 3.239\n",
      "Epoch   0 Batch 17116/17275   train_loss = 2.116\n",
      "Epoch   0 Batch 17117/17275   train_loss = 4.902\n",
      "Epoch   0 Batch 17118/17275   train_loss = 7.106\n",
      "Epoch   0 Batch 17119/17275   train_loss = 2.039\n",
      "Epoch   0 Batch 17120/17275   train_loss = 3.863\n",
      "Epoch   0 Batch 17121/17275   train_loss = 3.433\n",
      "Epoch   0 Batch 17122/17275   train_loss = 4.506\n",
      "Epoch   0 Batch 17123/17275   train_loss = 2.869\n",
      "Epoch   0 Batch 17124/17275   train_loss = 3.403\n",
      "Epoch   0 Batch 17125/17275   train_loss = 5.599\n",
      "Epoch   0 Batch 17126/17275   train_loss = 4.321\n",
      "Epoch   0 Batch 17127/17275   train_loss = 3.486\n",
      "Epoch   0 Batch 17128/17275   train_loss = 6.760\n",
      "Epoch   0 Batch 17129/17275   train_loss = 3.726\n",
      "Epoch   0 Batch 17130/17275   train_loss = 4.745\n",
      "Epoch   0 Batch 17131/17275   train_loss = 7.129\n",
      "Epoch   0 Batch 17132/17275   train_loss = 7.115\n",
      "Epoch   0 Batch 17133/17275   train_loss = 7.087\n",
      "Epoch   0 Batch 17134/17275   train_loss = 1.829\n",
      "Epoch   0 Batch 17135/17275   train_loss = 1.909\n",
      "Epoch   0 Batch 17136/17275   train_loss = 2.682\n",
      "Epoch   0 Batch 17137/17275   train_loss = 4.172\n",
      "Epoch   0 Batch 17138/17275   train_loss = 3.804\n",
      "Epoch   0 Batch 17139/17275   train_loss = 2.944\n",
      "Epoch   0 Batch 17140/17275   train_loss = 2.016\n",
      "Epoch   0 Batch 17141/17275   train_loss = 2.119\n",
      "Epoch   0 Batch 17142/17275   train_loss = 3.914\n",
      "Epoch   0 Batch 17143/17275   train_loss = 3.093\n",
      "Epoch   0 Batch 17144/17275   train_loss = 4.165\n",
      "Epoch   0 Batch 17145/17275   train_loss = 3.885\n",
      "Epoch   0 Batch 17146/17275   train_loss = 3.977\n",
      "Epoch   0 Batch 17147/17275   train_loss = 3.692\n",
      "Epoch   0 Batch 17148/17275   train_loss = 8.005\n",
      "Epoch   0 Batch 17149/17275   train_loss = 3.260\n",
      "Epoch   0 Batch 17150/17275   train_loss = 3.882\n",
      "Epoch   0 Batch 17151/17275   train_loss = 6.714\n",
      "Epoch   0 Batch 17152/17275   train_loss = 7.299\n",
      "Epoch   0 Batch 17153/17275   train_loss = 2.047\n",
      "Epoch   0 Batch 17154/17275   train_loss = 7.487\n",
      "Epoch   0 Batch 17155/17275   train_loss = 7.166\n",
      "Epoch   0 Batch 17156/17275   train_loss = 2.593\n",
      "Epoch   0 Batch 17157/17275   train_loss = 3.622\n",
      "Epoch   0 Batch 17158/17275   train_loss = 6.270\n",
      "Epoch   0 Batch 17159/17275   train_loss = 7.213\n",
      "Epoch   0 Batch 17160/17275   train_loss = 6.662\n",
      "Epoch   0 Batch 17161/17275   train_loss = 2.006\n",
      "Epoch   0 Batch 17162/17275   train_loss = 4.158\n",
      "Epoch   0 Batch 17163/17275   train_loss = 3.384\n",
      "Epoch   0 Batch 17164/17275   train_loss = 2.563\n",
      "Epoch   0 Batch 17165/17275   train_loss = 1.777\n",
      "Epoch   0 Batch 17166/17275   train_loss = 2.503\n",
      "Epoch   0 Batch 17167/17275   train_loss = 4.523\n",
      "Epoch   0 Batch 17168/17275   train_loss = 3.086\n",
      "Epoch   0 Batch 17169/17275   train_loss = 3.161\n",
      "Epoch   0 Batch 17170/17275   train_loss = 4.845\n",
      "Epoch   0 Batch 17171/17275   train_loss = 3.853\n",
      "Epoch   0 Batch 17172/17275   train_loss = 1.724\n",
      "Epoch   0 Batch 17173/17275   train_loss = 8.152\n",
      "Epoch   0 Batch 17174/17275   train_loss = 7.270\n",
      "Epoch   0 Batch 17175/17275   train_loss = 3.863\n",
      "Epoch   0 Batch 17176/17275   train_loss = 3.849\n",
      "Epoch   0 Batch 17177/17275   train_loss = 3.885\n",
      "Epoch   0 Batch 17178/17275   train_loss = 4.057\n",
      "Epoch   0 Batch 17179/17275   train_loss = 3.702\n",
      "Epoch   0 Batch 17180/17275   train_loss = 2.700\n",
      "Epoch   0 Batch 17181/17275   train_loss = 7.087\n",
      "Epoch   0 Batch 17182/17275   train_loss = 2.531\n",
      "Epoch   0 Batch 17183/17275   train_loss = 7.741\n",
      "Epoch   0 Batch 17184/17275   train_loss = 3.743\n",
      "Epoch   0 Batch 17185/17275   train_loss = 8.197\n",
      "Epoch   0 Batch 17186/17275   train_loss = 2.338\n",
      "Epoch   0 Batch 17187/17275   train_loss = 6.414\n",
      "Epoch   0 Batch 17188/17275   train_loss = 4.337\n",
      "Epoch   0 Batch 17189/17275   train_loss = 5.351\n",
      "Epoch   0 Batch 17190/17275   train_loss = 2.412\n",
      "Epoch   0 Batch 17191/17275   train_loss = 4.884\n",
      "Epoch   0 Batch 17192/17275   train_loss = 2.488\n",
      "Epoch   0 Batch 17193/17275   train_loss = 3.334\n",
      "Epoch   0 Batch 17194/17275   train_loss = 11.541\n",
      "Epoch   0 Batch 17195/17275   train_loss = 3.609\n",
      "Epoch   0 Batch 17196/17275   train_loss = 4.129\n",
      "Epoch   0 Batch 17197/17275   train_loss = 6.778\n",
      "Epoch   0 Batch 17198/17275   train_loss = 2.599\n",
      "Epoch   0 Batch 17199/17275   train_loss = 3.766\n",
      "Epoch   0 Batch 17200/17275   train_loss = 3.117\n",
      "Epoch   0 Batch 17201/17275   train_loss = 4.545\n",
      "Epoch   0 Batch 17202/17275   train_loss = 6.339\n",
      "Epoch   0 Batch 17203/17275   train_loss = 4.326\n",
      "Epoch   0 Batch 17204/17275   train_loss = 4.423\n",
      "Epoch   0 Batch 17205/17275   train_loss = 3.290\n",
      "Epoch   0 Batch 17206/17275   train_loss = 2.332\n",
      "Epoch   0 Batch 17207/17275   train_loss = 6.894\n",
      "Epoch   0 Batch 17208/17275   train_loss = 3.888\n",
      "Epoch   0 Batch 17209/17275   train_loss = 3.553\n",
      "Epoch   0 Batch 17210/17275   train_loss = 3.087\n",
      "Epoch   0 Batch 17211/17275   train_loss = 3.847\n",
      "Epoch   0 Batch 17212/17275   train_loss = 2.982\n",
      "Epoch   0 Batch 17213/17275   train_loss = 4.773\n",
      "Epoch   0 Batch 17214/17275   train_loss = 4.879\n",
      "Epoch   0 Batch 17215/17275   train_loss = 4.122\n",
      "Epoch   0 Batch 17216/17275   train_loss = 4.670\n",
      "Epoch   0 Batch 17217/17275   train_loss = 4.028\n",
      "Epoch   0 Batch 17218/17275   train_loss = 5.100\n",
      "Epoch   0 Batch 17219/17275   train_loss = 5.226\n",
      "Epoch   0 Batch 17220/17275   train_loss = 3.891\n",
      "Epoch   0 Batch 17221/17275   train_loss = 4.954\n",
      "Epoch   0 Batch 17222/17275   train_loss = 2.012\n",
      "Epoch   0 Batch 17223/17275   train_loss = 2.124\n",
      "Epoch   0 Batch 17224/17275   train_loss = 4.461\n",
      "Epoch   0 Batch 17225/17275   train_loss = 3.399\n",
      "Epoch   0 Batch 17226/17275   train_loss = 7.902\n",
      "Epoch   0 Batch 17227/17275   train_loss = 2.056\n",
      "Epoch   0 Batch 17228/17275   train_loss = 2.189\n",
      "Epoch   0 Batch 17229/17275   train_loss = 3.204\n",
      "Epoch   0 Batch 17230/17275   train_loss = 4.176\n",
      "Epoch   0 Batch 17231/17275   train_loss = 3.386\n",
      "Epoch   0 Batch 17232/17275   train_loss = 5.483\n",
      "Epoch   0 Batch 17233/17275   train_loss = 3.503\n",
      "Epoch   0 Batch 17234/17275   train_loss = 4.471\n",
      "Epoch   0 Batch 17235/17275   train_loss = 5.116\n",
      "Epoch   0 Batch 17236/17275   train_loss = 2.541\n",
      "Epoch   0 Batch 17237/17275   train_loss = 2.676\n",
      "Epoch   0 Batch 17238/17275   train_loss = 4.625\n",
      "Epoch   0 Batch 17239/17275   train_loss = 4.928\n",
      "Epoch   0 Batch 17240/17275   train_loss = 2.471\n",
      "Epoch   0 Batch 17241/17275   train_loss = 2.648\n",
      "Epoch   0 Batch 17242/17275   train_loss = 6.899\n",
      "Epoch   0 Batch 17243/17275   train_loss = 3.783\n",
      "Epoch   0 Batch 17244/17275   train_loss = 3.368\n",
      "Epoch   0 Batch 17245/17275   train_loss = 4.673\n",
      "Epoch   0 Batch 17246/17275   train_loss = 7.387\n",
      "Epoch   0 Batch 17247/17275   train_loss = 1.982\n",
      "Epoch   0 Batch 17248/17275   train_loss = 8.179\n",
      "Epoch   0 Batch 17249/17275   train_loss = 5.433\n",
      "Epoch   0 Batch 17250/17275   train_loss = 7.537\n",
      "Epoch   0 Batch 17251/17275   train_loss = 6.221\n",
      "Epoch   0 Batch 17252/17275   train_loss = 3.718\n",
      "Epoch   0 Batch 17253/17275   train_loss = 4.472\n",
      "Epoch   0 Batch 17254/17275   train_loss = 3.758\n",
      "Epoch   0 Batch 17255/17275   train_loss = 2.388\n",
      "Epoch   0 Batch 17256/17275   train_loss = 4.401\n",
      "Epoch   0 Batch 17257/17275   train_loss = 2.720\n",
      "Epoch   0 Batch 17258/17275   train_loss = 5.335\n",
      "Epoch   0 Batch 17259/17275   train_loss = 3.108\n",
      "Epoch   0 Batch 17260/17275   train_loss = 4.628\n",
      "Epoch   0 Batch 17261/17275   train_loss = 3.173\n",
      "Epoch   0 Batch 17262/17275   train_loss = 2.068\n",
      "Epoch   0 Batch 17263/17275   train_loss = 6.783\n",
      "Epoch   0 Batch 17264/17275   train_loss = 2.001\n",
      "Epoch   0 Batch 17265/17275   train_loss = 2.708\n",
      "Epoch   0 Batch 17266/17275   train_loss = 3.151\n",
      "Epoch   0 Batch 17267/17275   train_loss = 3.438\n",
      "Epoch   0 Batch 17268/17275   train_loss = 3.431\n",
      "Epoch   0 Batch 17269/17275   train_loss = 6.135\n",
      "Epoch   0 Batch 17270/17275   train_loss = 4.988\n",
      "Epoch   0 Batch 17271/17275   train_loss = 1.946\n",
      "Epoch   0 Batch 17272/17275   train_loss = 3.318\n",
      "Epoch   0 Batch 17273/17275   train_loss = 5.009\n",
      "Epoch   0 Batch 17274/17275   train_loss = 0.694\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Parameters\n",
    "Save `seq_length` and `save_dir` for generating a new TV script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Generate Functions\n",
    "### Get Tensors\n",
    "Get tensors from `loaded_graph` using the function [`get_tensor_by_name()`](https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name).  Get the tensors using the following names:\n",
    "- \"input:0\"\n",
    "- \"initial_state:0\"\n",
    "- \"final_state:0\"\n",
    "- \"probs:0\"\n",
    "\n",
    "Return the tensors in the following tuple `(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \"\"\"\n",
    "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
    "    :param loaded_graph: TensorFlow graph loaded from file\n",
    "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function    \n",
    "    inputs = loaded_graph.get_tensor_by_name(\"input:0\")\n",
    "    int_state = loaded_graph.get_tensor_by_name(\"initial_state:0\")\n",
    "    fin_state = loaded_graph.get_tensor_by_name(\"final_state:0\")\n",
    "    prob = loaded_graph.get_tensor_by_name(\"probs:0\")\n",
    "\n",
    "    return inputs, int_state, fin_state, prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_tensors(get_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Choose Word\n",
    "Implement the `pick_word()` function to select the next word using `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word in the generated text\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    max_index = np.argmax(probabilities, axis=0)\n",
    "    return int_to_vocab[max_index]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_pick_word(pick_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate TV Script\n",
    "This will generate the TV script for you.  Set `gen_length` to the length of TV script you want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen_length = 200\n",
    "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
    "prime_word = 'moe_szyslak'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word + ':']\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The TV Script is Nonsensical\n",
    "It's ok if the TV script doesn't make any sense.  We trained on less than a megabyte of text.  In order to get good results, you'll have to use a smaller vocabulary or get more data.  Luckly there's more data!  As we mentioned in the begging of this project, this is a subset of [another dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data).  We didn't have you train on all the data, because that would take too long.  However, you are free to train your neural network on all the data.  After you complete the project, of course.\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
